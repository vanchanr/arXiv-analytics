[
  {
    "title": "The Ethics of Hacking: Should It Be Taught?",
    "authors": [
      "Nicole Radziwill",
      "Jessica Romano",
      "Diane Shorter",
      "Morgan Benton"
    ],
    "abstract": "Poor software quality can adversely affect application security by increasing the potential for a malicious breach of a system. Because computer security and cybersecurity are becoming such relevant topics for practicing software engineers, the need for educational opportunities in this area is steadily increasing. Universities and colleges have recognized this, and have started to offer programs in cybersecurity. At face value, these new programs may not appear controversial, but developing their curriculum requires answering a complex ethical question: Should programs teach hacking to their students? Even though there are different types of hackers, media reports of cybersecurity incidents tend to reserve the \"hacker\" label for cyber criminals, which overlooks the value in hacking (and, by extension, teaching students to hack). This article examines the full spectrum of hacking behavior, as well as arguments for and against including hacking in education programs, and recommends that hacking skills be considered an essential component of an education and practice in software quality assurance.",
    "lastUpdated": "2015-12-09T00:58:10Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1512.02707v1"
  },
  {
    "title": "The Agent Web Model -- Modelling web hacking for reinforcement learning",
    "authors": [
      "Laszlo Erdodi",
      "Fabio Massimo Zennaro"
    ],
    "abstract": "Website hacking is a frequent attack type used by malicious actors to obtain confidential information, modify the integrity of web pages or make websites unavailable. The tools used by attackers are becoming more and more automated and sophisticated, and malicious machine learning agents seems to be the next development in this line. In order to provide ethical hackers with similar tools, and to understand the impact and the limitations of artificial agents, we present in this paper a model that formalizes web hacking tasks for reinforcement learning agents. Our model, named Agent Web Model, considers web hacking as a capture-the-flag style challenge, and it defines reinforcement learning problems at seven different levels of abstraction. We discuss the complexity of these problems in terms of actions and states an agent has to deal with, and we show that such a model allows to represent most of the relevant web vulnerabilities. Aware that the driver of advances in reinforcement learning is the availability of standardized challenges, we provide an implementation for the first three abstraction layers, in the hope that the community would consider these challenges in order to develop intelligent web hacking agents.",
    "lastUpdated": "2020-09-23T17:35:34Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/2009.11274v1"
  },
  {
    "title": "Ethical Hacking for IoT Security: A First Look into Bug Bounty Programs and Responsible Disclosure",
    "authors": [
      "Aaron Yi Ding",
      "Gianluca Limon De Jesus",
      "Marijn Janssen"
    ],
    "abstract": "The security of the Internet of Things (IoT) has attracted much attention due to the growing number of IoT-oriented security incidents. IoT hardware and software security vulnerabilities are exploited affecting many companies and persons. Since the causes of vulnerabilities go beyond pure technical measures, there is a pressing demand nowadays to demystify IoT \"security complex\" and develop practical guidelines for both companies, consumers, and regulators. In this paper, we present an initial study targeting an unexplored sphere in IoT by illuminating the potential of crowdsource ethical hacking approaches for enhancing IoT vulnerability management. We focus on Bug Bounty Programs (BBP) and Responsible Disclosure (RD), which stimulate hackers to report vulnerability in exchange for monetary rewards. We carried out a qualitative investigation supported by literature survey and expert interviews to explore how BBP and RD can facilitate the practice of identifying, classifying, prioritizing, remediating, and mitigating IoT vulnerabilities in an effective and cost-efficient manner. Besides deriving tangible guidelines for IoT stakeholders, our study also sheds light on a systematic integration path to combine BBP and RD with existing security practices (e.g., penetration test) to further boost overall IoT security.",
    "lastUpdated": "2019-09-24T20:48:10Z",
    "categories": [
      "cs.CR",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1909.11166v1"
  },
  {
    "title": "Safe Artificial General Intelligence via Distributed Ledger Technology",
    "authors": [
      "Kristen W. Carlson"
    ],
    "abstract": "Background. Expert observers and artificial intelligence (AI) progression metrics indicate AI will exceed human intelligence within a few decades. Whether general AI that exceeds human capabilities (AGI) will be the single greatest boon in history or a disaster is unknown. No proofs exist that AGI will benefit humans or that AGI will not harm or eliminate humans. Objective. I propose a set of logically distinct conceptual components that are necessary and sufficient to 1) ensure that most known AGI scenarios will not harm humanity and 2) robustly align AGI values and goals with human values. Methods. By systematically addressing each pathway category to malevolent AI we can induce the methods/axioms required to redress the category. Results and Discussion. Distributed ledger technology (DLT, blockchain) is integral to this proposal, e.g. to reduce the probability of hacking, provide an audit trail to detect and correct errors or identify components causing vulnerability or failure and replace them or shut them down remotely and/or automatically, and to separate and balance key AGI components via decentralized apps (dApps). Smart contracts based on DLT are necessary to address evolution of AI that will be too fast for human monitoring and intervention. The proposed axioms. 1) Access to technology by market license. 2) Transparent ethics embodied in DLT. 3) Morality encrypted via DLT. 4) Behavior control structure with values (ethics) at roots. 5) Individual bar-code identification of all critical components. 6) Configuration Item (from business continuity/disaster recovery planning). 7) Identity verification secured via DLT. 8) Smart automated contracts based on DLT. 9) Decentralized applications - AI software code modules encrypted via DLT. 10) Audit trail of component usage stored via DLT. 11) Social ostracism (denial of societal resources) augmented by DLT petitions.",
    "lastUpdated": "2019-03-02T14:27:57Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1902.03689v2"
  },
  {
    "title": "Extrinsically adaptable systems",
    "authors": [
      "Raphael 'kena' Poss"
    ],
    "abstract": "Are there qualitative and quantitative traits of system design that contribute to the ability of people to further innovate? We propose that extrinsic adaptability, the ability given to secondary parties to change a system to match new requirements not envisioned by the primary provider, is such a trait. \"Extrinsic adaptation\" encompasses the popular concepts of \"workaround\", \"fast prototype extension\" or \"hack\", and extrinsic adaptability is thus a measure of how friendly a system is to tinkering by curious minds. In this report, we give \"hackability\" or \"hacker-friendliness\" scientific credentials by formulating and studying a generalization of the concept. During this exercise, we find that system changes by secondary parties fall on a subjective gradient of acceptability, with extrinsic adaptations on one side which confidently preserve existing system features, and invasive modifications on the other side which are perceived to be disruptive to existing system features. Where a change is positioned on this gradient is dependent on how an external observer perceives component boundaries within the changed system. We also find that the existence of objective cost functions can alleviate but not fully eliminate this subjectiveness. The study also enables us to formulate an ethical imperative for system designers to promote extrinsic adaptability.",
    "lastUpdated": "2013-06-23T17:51:42Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1306.5445v1"
  },
  {
    "title": "W3-Scrape - A Windows based Reconnaissance Tool for Web Application Fingerprinting",
    "authors": [
      "Karthik R",
      "Raghavendra Karthik",
      "Pramod S",
      "Sowmya Kamath"
    ],
    "abstract": "Web Application finger printing is a quintessential part of the Information Gathering phase of (ethical) hacking. It allows narrowing down the specifics instead of looking for all clues. Also an application that has been correctly recognized can help in quickly analyzing known weaknesses and then moving ahead with remaining aspects. This step is also essential to allow a pen tester to customize its payload or exploitation techniques based on the identification so to increase the chances of successful intrusion. This paper presents a new tool \"W3-Scrape\" for the relatively nascent field of Web Application finger printing that helps automate web application fingerprinting when performed in the current scenarios.",
    "lastUpdated": "2013-06-24T18:14:03Z",
    "categories": [
      "cs.CR",
      "D.4.6; E.3"
    ],
    "url": "http://arxiv.org/abs/1306.6839v1"
  },
  {
    "title": "Dual Layer Textual Message Cryptosystem with Randomized Sequence of Symmetric Key",
    "authors": [
      "Chandranath Adak"
    ],
    "abstract": "This paper introduces a new concept of textual message encryption and decryption through a pool of randomized symmetric key and the dual layer cryptosystem with the concept of visual cryptography and steganography. A textual message is converted into two image slides, and the images are encrypted through two different randomized sequences of symmetric key. The decryption is done in the reverse way. The encrypted images are decrypted by those two symmetric keys. The decrypted image slides are merged together and converted into textual message. Here the image sharing is done through the concept of visual cryptography and the textual message to image conversion is done through the concept of steganography.",
    "lastUpdated": "2013-12-19T07:18:18Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1312.5424v1"
  },
  {
    "title": "Making ethical decisions for the immersive web",
    "authors": [
      "Diane Hosfelt"
    ],
    "abstract": "Mixed reality (MR) ethics occupies a space that intersects with web ethics, emerging tech ethics, healthcare ethics and product ethics (among others). This paper focuses on how we can build an immersive web that encourages ethical development and usage. The technology is beyond emerging (footnote: generally, the ethics of emerging technologies are focused on ethical assessments of research and innovation), but not quite entrenched. We're still in a position to intervene in the development process, instead of attempting to retrofit ethical decisions into an established design. While we have a wider range of data to analyze than most emerging technologies, we're still in a much more speculative state than entrenched technologies. This space is a challenge and an opportunity.",
    "lastUpdated": "2019-05-14T14:57:20Z",
    "categories": [
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/1905.06995v1"
  },
  {
    "title": "Hacking with God: a Common Programming Language of Robopsychology and Robophilosophy",
    "authors": [
      "Norbert Bátfai"
    ],
    "abstract": "This note is a sketch of how the concept of robopsychology and robophilosophy could be reinterpreted and repositioned in the spirit of the original vocation of psychology and philosophy. The notion of the robopsychology as a fictional science and a fictional occupation was introduced by Asimov in the middle of the last century. The robophilosophy, on the other hand, is only a few years old today. But at this moment, none of these new emerging disciplines focus on the fundamental and overall issues of the development of artificial general intelligence. Instead, they focus only on issues that, although are extremely important, play a complementary role, such as moral or ethical ones, rather than the big questions of life. We try to outline a conception in which the robophilosophy and robopsychology will be able to play a similar leading rule in the progress of artificial intelligence than the philosophy and psychology have done in the progress of human intelligence. To facilitate this, we outline the idea of a visual artificial language and interactive theorem prover-based computer application called Prime Convo Assistant. The question to be decided in the future is whether we can develop such an application. And if so, can we build a computer game on it, or even an esport game? It may be an interesting question in order for this game will be able to transform human thinking on the widest possible social scale and will be able to develop a standard mathematical logic-based communication channel between human and machine intelligence.",
    "lastUpdated": "2020-09-16T11:59:12Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "I.2.0"
    ],
    "url": "http://arxiv.org/abs/2009.09068v1"
  },
  {
    "title": "Analyzing Hack Subnetworks in the Bitcoin Transaction Graph",
    "authors": [
      "Daniel Goldsmith",
      "Kim Grauer",
      "Yonah Shmalo"
    ],
    "abstract": "Hacks are one of the most damaging types of cryptocurrency related crime, accounting for billions of dollars in stolen funds since 2009. Professional investigators at Chainalysis have traced these stolen funds from the initial breach on an exchange to off-ramps, i.e. services where criminals are able to convert the stolen funds into fiat or other cryptocurrencies. We analyzed six hack subnetworks of bitcoin transactions known to belong to two prominent hacking groups. We analyze each hack according to eight network features, both static and temporal, and successfully classify each hack to its respective hacking group through our newly proposed method. We find that the static features, such as node balance, in degree, and out degree are not as useful in classifying the hacks into hacking groups as temporal features related to how quickly the criminals cash out. We validate our operating hypothesis that the key distinction between the two hacking groups is the acceleration with which the funds exit through terminal nodes in the subnetworks.",
    "lastUpdated": "2019-10-29T17:22:23Z",
    "categories": [
      "physics.soc-ph",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1910.13415v1"
  },
  {
    "title": "Stoic Ethics for Artificial Agents",
    "authors": [
      "Gabriel Murray"
    ],
    "abstract": "We present a position paper advocating the notion that Stoic philosophy and ethics can inform the development of ethical A.I. systems. This is in sharp contrast to most work on building ethical A.I., which has focused on Utilitarian or Deontological ethical theories. We relate ethical A.I. to several core Stoic notions, including the dichotomy of control, the four cardinal virtues, the ideal Sage, Stoic practices, and Stoic perspectives on emotion or affect. More generally, we put forward an ethical view of A.I. that focuses more on internal states of the artificial agent rather than on external actions of the agent. We provide examples relating to near-term A.I. systems as well as hypothetical superintelligent agents.",
    "lastUpdated": "2017-03-28T23:59:25Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1701.02388v2"
  },
  {
    "title": "Using experimental game theory to transit human values to ethical AI",
    "authors": [
      "Yijia Wang",
      "Yan Wan",
      "Zhijian Wang"
    ],
    "abstract": "Knowing the reflection of game theory and ethics, we develop a mathematical representation to bridge the gap between the concepts in moral philosophy (e.g., Kantian and Utilitarian) and AI ethics industry technology standard (e.g., IEEE P7000 standard series for Ethical AI). As an application, we demonstrate how human value can be obtained from the experimental game theory (e.g., trust game experiment) so as to build an ethical AI. Moreover, an approach to test the ethics (rightness or wrongness) of a given AI algorithm by using an iterated Prisoner's Dilemma Game experiment is discussed as an example. Compared with existing mathematical frameworks and testing method on AI ethics technology, the advantages of the proposed approach are analyzed.",
    "lastUpdated": "2017-11-16T03:30:29Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1711.05905v1"
  },
  {
    "title": "The Dark Side of Ethical Robots",
    "authors": [
      "Dieter Vanderelst",
      "Alan Winfield"
    ],
    "abstract": "Concerns over the risks associated with advances in Artificial Intelligence have prompted calls for greater efforts toward robust and beneficial AI, including machine ethics. Recently, roboticists have responded by initiating the development of so-called ethical robots. These robots would, ideally, evaluate the consequences of their actions and morally justify their choices. This emerging field promises to develop extensively over the next years. However, in this paper, we point out an inherent limitation of the emerging field of ethical robots. We show that building ethical robots also necessarily facilitates the construction of unethical robots. In three experiments, we show that it is remarkably easy to modify an ethical robot so that it behaves competitively, or even aggressively. The reason for this is that the specific AI, required to make an ethical robot, can always be exploited to make unethical robots. Hence, the development of ethical robots will not guarantee the responsible deployment of AI. While advocating for ethical robots, we conclude that preventing the misuse of robots is beyond the scope of engineering, and requires instead governance frameworks underpinned by legislation. Without this, the development of ethical robots will serve to increase the risks of robotic malpractice instead of diminishing it.",
    "lastUpdated": "2016-06-08T14:47:35Z",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1606.02583v1"
  },
  {
    "title": "Thinging Ethics for Software Engineers",
    "authors": [
      "Sabah Al-Fedaghi"
    ],
    "abstract": "Ethical systems are usually described as principles for distinguishing right from wrong and forming beliefs about proper conduct. Ethical topics are complex, with excessively verbose accounts of mental models and intensely ingrained philosophical assumptions. From practical experience, in teaching ethics for software engineering students, an explanation of ethics alone often cannot provide insights of behavior and thought for students. Additionally, it seems that there has been no exploration into the development of a conceptual presentation of ethics that appeals to computer engineers. This is particularly clear in the area of software engineering, which focuses on software and associated tools such as algorithms, diagramming, documentation, modeling and design as applied to various types of data and conceptual artifacts. It seems that software engineers look at ethical materials as a collection of ideas and notions that lack systemization and uniformity. Accordingly, this paper explores a thinging schematization for ethical theories that can serve a role similar to that of modeling languages (e.g., UML). In this approach, thinging means actualization (existence, presence, being) of things and mechanisms that define a boundary around some region of ethically related reality, separating it from everything else. The resultant diagrammatic representation then developed to model the process of making ethical decisions in that region.",
    "lastUpdated": "2018-09-25T18:57:45Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1810.02685v1"
  },
  {
    "title": "Case Study: Deontological Ethics in NLP",
    "authors": [
      "Shrimai Prabhumoye",
      "Brendon Boldt",
      "Ruslan Salakhutdinov",
      "Alan W Black"
    ],
    "abstract": "Recent work in natural language processing (NLP) has focused on ethical challenges such as understanding and mitigating bias in data and algorithms; identifying objectionable content like hate speech, stereotypes and offensive language; and building frameworks for better system design and data handling practices. However, there has been little discussion about the ethical foundations that underlie these efforts. In this work, we study one ethical theory, namely deontological ethics, from the perspective of NLP. In particular, we focus on the generalization principle and the respect for autonomy through informed consent. We provide four case studies to demonstrate how these principles can be used with NLP systems. We also recommend directions to avoid the ethical issues in these systems.",
    "lastUpdated": "2020-10-09T16:04:51Z",
    "categories": [
      "cs.CL"
    ],
    "url": "http://arxiv.org/abs/2010.04658v1"
  },
  {
    "title": "Ethics in the digital era",
    "authors": [
      "David Pastor-Escuredo"
    ],
    "abstract": "Ethics is an ancient matter for human kind, from the origin of civilizations ethics have been related with the most relevant human concerns and determined cultures. Ethics was initially related to religion, politics and philosophy to then be fragmented into specific communities of practice. The undergoing digital revolution enabled by Artificial Intelligence and Data are bringing ethical wicked problems in the social application of these technologies. However, a broader perspective is also necessary. We now face global and highly dynamics challenges that affect groups and individuals, specially those that are most vulnerable. Individual-oriented ethics are no longer sufficient, the new ethic has to consider the several scales in which the current complex society is organized and the interconnections between different systems. Ethics should also give a response to the systemic changes in behavior produced by external factors and threats. Furthermore, AI and digital technologies are global and make us more connected and smart but also more homogeneous, predictable and ultimately controllable. Ethic must take a stand to preserve and keep promoting individuals rights and uniqueness and cultural heterogeneity. Digital technologies have to the foundation for new models of society and help ensure ethical individual and collective values. For these reasons science has to be at the core of the new ethic as it helps understand the complex world. Finally, AI has advanced through the ambition to humanize matter, so we should expect ethics to give a response to the future status of machines and their interactions with humans.",
    "lastUpdated": "2020-05-11T03:27:08Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2003.06530v3"
  },
  {
    "title": "An Ecosystem Approach to Ethical AI and Data Use: Experimental Reflections",
    "authors": [
      "Mark Findlay",
      "Josephine Seah"
    ],
    "abstract": "While we have witnessed a rapid growth of ethics documents meant to guide AI development, the promotion of AI ethics has nonetheless proceeded with little input from AI practitioners themselves. Given the proliferation of AI for Social Good initiatives, this is an emerging gap that needs to be addressed in order to develop more meaningful ethical approaches to AI use and development. This paper offers a methodology, a shared fairness approach, aimed at identifying the needs of AI practitioners when it comes to confronting and resolving ethical challenges and to find a third space where their operational language can be married with that of the more abstract principles that presently remain at the periphery of their work experiences. We offer a grassroots approach to operational ethics based on dialog and mutualised responsibility. This methodology is centred around conversations intended to elicit practitioners perceived ethical attribution and distribution over key value laden operational decisions, to identify when these decisions arise and what ethical challenges they confront, and to engage in a language of ethics and responsibility which enables practitioners to internalise ethical responsibility. The methodology bridges responsibility imbalances that rest in structural decision making power and elite technical knowledge, by commencing with personal, facilitated conversations, returning the ethical discourse to those meant to give it meaning at the sharp end of the ecosystem. Our primary contribution is to add to the recent literature seeking to bring AI practitioners' experiences to the fore by offering a methodology for understanding how ethics manifests as a relational and interdependent sociotechnical practice in their work.",
    "lastUpdated": "2020-12-27T07:41:26Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2101.02008v1"
  },
  {
    "title": "Landscape of Machine Implemented Ethics",
    "authors": [
      "Vivek Nallur"
    ],
    "abstract": "This paper surveys the state-of-the-art in machine ethics, that is, considerations of how to implement ethical behaviour in robots, unmanned autonomous vehicles, or software systems. The emphasis is on covering the breadth of ethical theories being considered by implementors, as well as the implementation techniques being used. There is no consensus on which ethical theory is best suited for any particular domain, nor is there any agreement on which technique is best placed to implement a particular theory. Another unresolved problem in these implementations of ethical theories is how to objectively validate the implementations. The paper discusses the dilemmas being used as validating 'whetstones' and whether any alternative validation mechanism exists. Finally, it speculates that an intermediate step of creating domain-specific ethics might be a possible stepping stone towards creating machines that exhibit ethical behaviour.",
    "lastUpdated": "2020-09-01T10:34:59Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2009.00335v1"
  },
  {
    "title": "The Moral-IT Deck: A Tool for Ethics by Design",
    "authors": [
      "Lachlan Urquhart",
      "Peter Craigon"
    ],
    "abstract": "This paper presents the design process and empirical evaluation of a new tool for enabling ethics by design: The Moral-IT Cards. Better tools are needed to support the role of technologists in addressing ethical issues during system design. These physical cards support reflection by technologists on normative aspects of technology development, specifically on emerging risks, appropriate safeguards and challenges of implementing these in the system. We discuss how the cards were developed and tested within 5 workshops with 20 participants from both research and commercial settings. We consider the role of technologists in ethics from different EU/UK policymaking initiatives and disciplinary perspectives (i.e. Science and Technology Studies (STS), IT Law, Human Computer Interaction (HCI), Computer/Engineering Ethics). We then examine existing ethics by design tools, and other cards based tools before arguing why cards can be a useful medium for addressing complex ethical issues. We present the development process for the Moral-IT cards, document key features of our card design, background on the content, the impact assessment board process for using them and how this was formulated. We discuss our study design and methodology before examining key findings which are clustered around three overarching themes. These are: the value of our cards as a tool, their impact on the technology design process and how they structure ethical reflection practices. We conclude with key lessons and concepts such as how they level the playing field for debate; enable ethical clustering, sorting and comparison; provide appropriate anchors for discussion and highlighted the intertwined nature of ethics.",
    "lastUpdated": "2020-07-15T07:26:45Z",
    "categories": [
      "cs.CY",
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/2007.07514v1"
  },
  {
    "title": "Gatekeeping Algorithms with Human Ethical Bias: The ethics of algorithms in archives, libraries and society",
    "authors": [
      "Martijn van Otterlo"
    ],
    "abstract": "In the age of algorithms, I focus on the question of how to ensure algorithms that will take over many of our familiar archival and library tasks, will behave according to human ethical norms that have evolved over many years. I start by characterizing physical archives in the context of related institutions such as libraries and museums. In this setting I analyze how ethical principles, in particular about access to information, have been formalized and communicated in the form of ethical codes, or: codes of conducts. After that I describe two main developments: digitalization, in which physical aspects of the world are turned into digital data, and algorithmization, in which intelligent computer programs turn this data into predictions and decisions. Both affect interactions that were once physical but now digital. In this new setting I survey and analyze the ethical aspects of algorithms and how they shape a vision on the future of archivists and librarians, in the form of algorithmic documentalists, or: codementalists. Finally I outline a general research strategy, called IntERMEeDIUM, to obtain algorithms that obey are human ethical values encoded in code of ethics.",
    "lastUpdated": "2018-01-05T10:58:13Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1801.01705v1"
  },
  {
    "title": "Embedded EthiCS: Integrating Ethics Broadly Across Computer Science Education",
    "authors": [
      "Barbara J. Grosz",
      "David Gray Grant",
      "Kate Vredenburgh",
      "Jeff Behrends",
      "Lily Hu",
      "Alison Simmons",
      "Jim Waldo"
    ],
    "abstract": "Computing technologies have become pervasive in daily life, sometimes bringing unintended but harmful consequences. For students to learn to think not only about what technology they could create, but also about what technology they should create, computer science curricula must expand to include ethical reasoning about the societal value and impact of these technologies. This paper presents Embedded EthiCS, a novel approach to integrating ethics into computer science education that incorporates ethical reasoning throughout courses in the standard computer science curriculum. It thus changes existing courses rather than requiring wholly new courses. The paper describes a pilot Embedded EthiCS program that embeds philosophers teaching ethical reasoning directly into computer science courses. It discusses lessons learned and challenges to implementing such a program across different types of academic institutions.",
    "lastUpdated": "2018-08-16T21:45:54Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1808.05686v1"
  },
  {
    "title": "Building Ethics into Artificial Intelligence",
    "authors": [
      "Han Yu",
      "Zhiqi Shen",
      "Chunyan Miao",
      "Cyril Leung",
      "Victor R. Lesser",
      "Qiang Yang"
    ],
    "abstract": "As artificial intelligence (AI) systems become increasingly ubiquitous, the topic of AI governance for ethical decision-making by AI has captured public imagination. Within the AI research community, this topic remains less familiar to many researchers. In this paper, we complement existing surveys, which largely focused on the psychological, social and legal discussions of the topic, with an analysis of recent advances in technical solutions for AI governance. By reviewing publications in leading AI conferences including AAAI, AAMAS, ECAI and IJCAI, we propose a taxonomy which divides the field into four areas: 1) exploring ethical dilemmas; 2) individual ethical decision frameworks; 3) collective ethical decision frameworks; and 4) ethics in human-AI interactions. We highlight the intuitions and key techniques used in each approach, and discuss promising future research directions towards successful integration of ethical AI systems into human societies.",
    "lastUpdated": "2018-12-07T09:18:01Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1812.02953v1"
  },
  {
    "title": "Toward the Engineering of Virtuous Machines",
    "authors": [
      "Naveen Sundar Govindarajulu",
      "Selmer Bringsjord",
      "Rikhiya Ghosh"
    ],
    "abstract": "While various traditions under the 'virtue ethics' umbrella have been studied extensively and advocated by ethicists, it has not been clear that there exists a version of virtue ethics rigorous enough to be a target for machine ethics (which we take to include the engineering of an ethical sensibility in a machine or robot itself, not only the study of ethics in the humans who might create artificial agents). We begin to address this by presenting an embryonic formalization of a key part of any virtue-ethics theory: namely, the learning of virtue by a focus on exemplars of moral virtue. Our work is based in part on a computational formal logic previously used to formally model other ethical theories and principles therein, and to implement these models in artificial agents.",
    "lastUpdated": "2018-12-30T05:37:19Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1812.03868v2"
  },
  {
    "title": "Principles alone cannot guarantee ethical AI",
    "authors": [
      "Brent Mittelstadt"
    ],
    "abstract": "AI Ethics is now a global topic of discussion in academic and policy circles. At least 84 public-private initiatives have produced statements describing high-level principles, values, and other tenets to guide the ethical development, deployment, and governance of AI. According to recent meta-analyses, AI Ethics has seemingly converged on a set of principles that closely resemble the four classic principles of medical ethics. Despite the initial credibility granted to a principled approach to AI Ethics by the connection to principles in medical ethics, there are reasons to be concerned about its future impact on AI development and governance. Significant differences exist between medicine and AI development that suggest a principled approach in the latter may not enjoy success comparable to the former. Compared to medicine, AI development lacks (1) common aims and fiduciary duties, (2) professional history and norms, (3) proven methods to translate principles into practice, and (4) robust legal and professional accountability mechanisms. These differences suggest we should not yet celebrate consensus around high-level principles that hide deep political and normative disagreement.",
    "lastUpdated": "2020-02-18T19:58:35Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1906.06668v2"
  },
  {
    "title": "Knowledge-Base Practicality for Cybersecurity Research Ethics Evaluation",
    "authors": [
      "Robert B. Ramirez",
      "Tomohiko Yano",
      "Masaki Shimaoka",
      "Kenichi Magata"
    ],
    "abstract": "Research ethics in Information and Communications Technology has seen a resurgence in popularity in recent years. Although a number of general ethics standards have been issued, cyber security specifically has yet to see one. Furthermore, such standards are often abstract, lacking in guidance on specific practices. In this paper we compare peer-reviewed ethical analyses of condemned research papers to analyses derived from a knowledge base (KB) of concrete cyber security research ethics best practices. The KB we employ was compiled in prior work from a large random survey of research papers. We demonstrate preliminary evidence that such a KB can be used to yield comparable or more extensive ethical analyses of published cyber security research than expert application of standards like the Menlo Report. We extend the ethical analyses of the reviewed manuscripts, and calculate measures of the efficiency with which the expert versus KB methods yield ethical insights.",
    "lastUpdated": "2020-11-05T04:59:41Z",
    "categories": [
      "cs.CR",
      "68M25",
      "K.7.4"
    ],
    "url": "http://arxiv.org/abs/2011.02661v1"
  },
  {
    "title": "A Low-Cost Ethics Shaping Approach for Designing Reinforcement Learning Agents",
    "authors": [
      "Yueh-Hua Wu",
      "Shou-De Lin"
    ],
    "abstract": "This paper proposes a low-cost, easily realizable strategy to equip a reinforcement learning (RL) agent the capability of behaving ethically. Our model allows the designers of RL agents to solely focus on the task to achieve, without having to worry about the implementation of multiple trivial ethical patterns to follow. Based on the assumption that the majority of human behavior, regardless which goals they are achieving, is ethical, our design integrates human policy with the RL policy to achieve the target objective with less chance of violating the ethical code that human beings normally obey.",
    "lastUpdated": "2018-09-10T04:59:19Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1712.04172v2"
  },
  {
    "title": "One Formalization of Virtue Ethics via Learning",
    "authors": [
      "Naveen Sundar Govindarajulu",
      "Selmer Bringjsord",
      "Rikhiya Ghosh"
    ],
    "abstract": "Given that there exist many different formal and precise treatments of deontologi- cal and consequentialist ethics, we turn to virtue ethics and consider what could be a formalization of virtue ethics that makes it amenable to automation. We present an embroyonic formalization in a cognitive calculus (which subsumes a quantified first-order logic) that has been previously used to model robust ethical principles, in both the deontological and consequentialist traditions.",
    "lastUpdated": "2018-05-20T17:03:47Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1805.07797v1"
  },
  {
    "title": "Truly Autonomous Machines Are Ethical",
    "authors": [
      "John Hooker"
    ],
    "abstract": "While many see the prospect of autonomous machines as threatening, autonomy may be exactly what we want in a superintelligent machine. There is a sense of autonomy, deeply rooted in the ethical literature, in which an autonomous machine is necessarily an ethical one. Development of the theory underlying this idea not only reveals the advantages of autonomy, but it sheds light on a number of issues in the ethics of artificial intelligence. It helps us to understand what sort of obligations we owe to machines, and what obligations they owe to us. It clears up the issue of assigning responsibility to machines or their creators. More generally, a concept of autonomy that is adequate to both human and artificial intelligence can lead to a more adequate ethical theory for both.",
    "lastUpdated": "2018-12-05T20:47:11Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1812.02217v1"
  },
  {
    "title": "Implementations in Machine Ethics: A Survey",
    "authors": [
      "Suzanne Tolmeijer",
      "Markus Kneer",
      "Cristina Sarasua",
      "Markus Christen",
      "Abraham Bernstein"
    ],
    "abstract": "Increasingly complex and autonomous systems require machine ethics to maximize the benefits and minimize the risks to society arising from the new technology. It is challenging to decide which type of ethical theory to employ and how to implement it effectively. This survey provides a threefold contribution. Firstly, it introduces a taxonomy to analyze the field of machine ethics from an ethical, implementational, and technical perspective. Secondly, an exhaustive selection and description of relevant works is presented. Thirdly, applying the new taxonomy to the selected works, dominant research patterns and lessons for the field are identified, and future directions for research are suggested.",
    "lastUpdated": "2020-01-21T14:32:23Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2001.07573v1"
  },
  {
    "title": "Ideal theory in AI ethics",
    "authors": [
      "Daniel Estrada"
    ],
    "abstract": "This paper addresses the ways AI ethics research operates on an ideology of ideal theory, in the sense discussed by Mills (2005) and recently applied to AI ethics by Fazelpour \\& Lipton (2020). I address the structural and methodological conditions that attract AI ethics researchers to ideal theorizing, and the consequences this approach has for the quality and future of our research community. Finally, I discuss the possibilities for a nonideal future in AI ethics.",
    "lastUpdated": "2020-12-04T04:36:05Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2011.02279v2"
  },
  {
    "title": "Ethical Interviews in Software Engineering",
    "authors": [
      "Per Erik Strandberg"
    ],
    "abstract": "Background: Despite a long history, numerous laws and regulations, ethics remains an unnatural topic for many software engineering researchers. Poor research ethics may lead to mistrust of research results, lost funding and retraction of publications. A core principle for research ethics is confidentiality, and anonymization is a standard approach to guarantee it. Many guidelines for qualitative software engineering research, and for qualitative research in general, exist, but these do not penetrate how and why to anonymize interview data. Aims: In this paper we aim to identify ethical guidelines for software engineering interview studies involving industrial practitioners. Method: By learning from previous experiences and listening to the authority of existing guidelines in the more mature field of medicine as well as in software engineering, a comprehensive set of checklists for interview studies was distilled. Results: The elements of an interview study were identified and ethical considerations and recommendations for each step were produced, in particular with respect to anonymization. Important ethical principles are: consent, beneficence, confidentiality, scientific value, researcher skill, justice, respect for law, and ethical reviews. Conclusions: The most important contribution of this study is the set of checklists for ethical interview studies. Future work is needed to refine these guidelines with respect to legal aspects and ethical boards.",
    "lastUpdated": "2019-06-19T09:32:36Z",
    "categories": [
      "cs.SE",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1906.07993v1"
  },
  {
    "title": "Towards and Ethical Framework in the Complex Digital Era",
    "authors": [
      "David Pastor-Escuredo",
      "Ricardo Vinuesa"
    ],
    "abstract": "Since modernity, ethic has been progressively fragmented into specific communities of practice. The digital revolution enabled by AI and Data is bringing ethical wicked problems in the crossroads of technology and behavior. However, the need of a comprehensive and constructive ethical framework is emerging as digital platforms connect us globally. The unequal structure of the global system makes that dynamic changes and systemic problems impact more on those that are most vulnerable. Ethical frameworks based only on the individual-level are not longer sufficient. A new ethical vision must comprise the understanding of the scales and complex interconnections of social systems. Many of these systems are internally fragile and very sensitive to external factors and threats, which turns into unethical situations that require systemic solutions. The high scale nature of digital technology that expands globally has also an impact at the individual level having the risk to make humans beings more homogeneous, predictable and ultimately controllable. To preserve the core of humanity ethic must take a stand to preserve and keep promoting individual rights and uniqueness and cultural heterogeneity tackling the negative trends and impact of digitalization. Only combining human-centered and collectiveness-oriented digital development it will be possible to construct new social models and human-machine interactions that are ethical. This vision requires science to enhance ethical frameworks and principles with the actionable insights of relationships and properties of the social systems that may not be evident and need to be quantified and understood to be solved. Artificial Intelligence is both a risk and and opportunity for an ethical development, thus we need a conceptual construct that drives towards a better digitalizated world.",
    "lastUpdated": "2020-10-19T15:28:04Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CC"
    ],
    "url": "http://arxiv.org/abs/2010.10028v1"
  },
  {
    "title": "Ethics in the Software Development Process: From Codes of Conduct to Ethical Deliberation",
    "authors": [
      "Jan Gogoll",
      "Niina Zuber",
      "Severin Kacianka",
      "Timo Greger",
      "Alexander Pretschner",
      "Julian Nida-Rümelin"
    ],
    "abstract": "Software systems play an ever more important role in our lives and software engineers and their companies find themselves in a position where they are held responsible for ethical issues that may arise. In this paper, we try to disentangle ethical considerations that can be performed at the level of the software engineer from those that belong in the wider domain of business ethics. The handling of ethical problems that fall into the responsibility of the engineer have traditionally been addressed by the publication of Codes of Ethics and Conduct. We argue that these Codes are barely able to provide normative orientation in software development. The main contribution of this paper is, thus, to analyze the normative features of Codes of Ethics in software engineering and to explicate how their value-based approach might prevent their usefulness from a normative perspective. Codes of Conduct cannot replace ethical deliberation because they do not and cannot offer guidance because of their underdetermined nature. This lack of orientation, we argue, triggers reactive behavior such as \"cherry-picking\", \"risk of indifference\", \"ex-post orientation\" and the \"desire to rely on gut feeling\". In the light of this, we propose to implement ethical deliberation within software development teams as a way out.",
    "lastUpdated": "2020-11-05T18:20:20Z",
    "categories": [
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/2011.03016v1"
  },
  {
    "title": "When is it right and good for an intelligent autonomous vehicle to take over control (and hand it back)?",
    "authors": [
      "Ajit Narayanan"
    ],
    "abstract": "There is much debate in machine ethics about the most appropriate way to introduce ethical reasoning capabilities into intelligent autonomous machines. Recent incidents involving autonomous vehicles in which humans have been killed or injured have raised questions about how we ensure that such vehicles have an ethical dimension to their behaviour and are therefore trustworthy. The main problem is that hardwiring such machines with rules not to cause harm or damage is not consistent with the notion of autonomy and intelligence. Also, such ethical hardwiring does not leave intelligent autonomous machines with any course of action if they encounter situations or dilemmas for which they are not programmed or where some harm is caused no matter what course of action is taken. Teaching machines so that they learn ethics may also be problematic given recent findings in machine learning that machines pick up the prejudices and biases embedded in their learning algorithms or data. This paper describes a fuzzy reasoning approach to machine ethics. The paper shows how it is possible for an ethics architecture to reason when taking over from a human driver is morally justified. The design behind such an ethical reasoner is also applied to an ethical dilemma resolution case. One major advantage of the approach is that the ethical reasoner can generate its own data for learning moral rules (hence, autometric) and thereby reduce the possibility of picking up human biases and prejudices. The results show that a new type of metric-based ethics appropriate for autonomous intelligent machines is feasible and that our current concept of ethical reasoning being largely qualitative in nature may need revising if want to construct future autonomous machines that have an ethical dimension to their reasoning so that they become moral machines.",
    "lastUpdated": "2019-01-24T03:51:10Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1901.08221v1"
  },
  {
    "title": "Towards Verifiably Ethical Robot Behaviour",
    "authors": [
      "Louise A. Dennis",
      "Michael Fisher",
      "Alan F. T. Winfield"
    ],
    "abstract": "Ensuring that autonomous systems work ethically is both complex and difficult. However, the idea of having an additional `governor' that assesses options the system has, and prunes them to select the most ethical choices is well understood. Recent work has produced such a governor consisting of a `consequence engine' that assesses the likely future outcomes of actions then applies a Safety/Ethical logic to select actions. Although this is appealing, it is impossible to be certain that the most ethical options are actually taken. In this paper we extend and apply a well-known agent verification approach to our consequence engine, allowing us to verify the correctness of its ethical decision-making.",
    "lastUpdated": "2015-04-14T15:49:40Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1504.03592v1"
  },
  {
    "title": "From Algorithmic Black Boxes to Adaptive White Boxes: Declarative Decision-Theoretic Ethical Programs as Codes of Ethics",
    "authors": [
      "Martijn van Otterlo"
    ],
    "abstract": "Ethics of algorithms is an emerging topic in various disciplines such as social science, law, and philosophy, but also artificial intelligence (AI). The value alignment problem expresses the challenge of (machine) learning values that are, in some way, aligned with human requirements or values. In this paper I argue for looking at how humans have formalized and communicated values, in professional codes of ethics, and for exploring declarative decision-theoretic ethical programs (DDTEP) to formalize codes of ethics. This renders machine ethical reasoning and decision-making, as well as learning, more transparent and hopefully more accountable. The paper includes proof-of-concept examples of known toy dilemmas and gatekeeping domains such as archives and libraries.",
    "lastUpdated": "2017-11-16T11:29:54Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1711.06035v1"
  },
  {
    "title": "Towards a Framework Combining Machine Ethics and Machine Explainability",
    "authors": [
      "Kevin Baum",
      "Holger Hermanns",
      "Timo Speith"
    ],
    "abstract": "We find ourselves surrounded by a rapidly increasing number of autonomous and semi-autonomous systems. Two grand challenges arise from this development: Machine Ethics and Machine Explainability. Machine Ethics, on the one hand, is concerned with behavioral constraints for systems, so that morally acceptable, restricted behavior results; Machine Explainability, on the other hand, enables systems to explain their actions and argue for their decisions, so that human users can understand and justifiably trust them. In this paper, we try to motivate and work towards a framework combining Machine Ethics and Machine Explainability. Starting from a toy example, we detect various desiderata of such a framework and argue why they should and how they could be incorporated in autonomous systems. Our main idea is to apply a framework of formal argumentation theory both, for decision-making under ethical constraints and for the task of generating useful explanations given only limited knowledge of the world. The result of our deliberations can be described as a first version of an ethically motivated, principle-governed framework combining Machine Ethics and Machine Explainability",
    "lastUpdated": "2019-01-03T02:52:38Z",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1901.00590v1"
  },
  {
    "title": "The Ethics of AI Ethics -- An Evaluation of Guidelines",
    "authors": [
      "Thilo Hagendorff"
    ],
    "abstract": "Current advances in research, development and application of artificial intelligence (AI) systems have yielded a far-reaching discourse on AI ethics. In consequence, a number of ethics guidelines have been released in recent years. These guidelines comprise normative principles and recommendations aimed to harness the \"disruptive\" potentials of new AI technologies. Designed as a comprehensive evaluation, this paper analyzes and compares these guidelines highlighting overlaps but also omissions. As a result, I give a detailed overview of the field of AI ethics. Finally, I also examine to what extent the respective ethical principles and values are implemented in the practice of research, development and application of AI systems - and how the effectiveness in the demands of AI ethics can be improved.",
    "lastUpdated": "2019-10-11T08:44:31Z",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1903.03425v2"
  },
  {
    "title": "Artificial Intelligence: the global landscape of ethics guidelines",
    "authors": [
      "Anna Jobin",
      "Marcello Ienca",
      "Effy Vayena"
    ],
    "abstract": "In the last five years, private companies, research institutions as well as public sector organisations have issued principles and guidelines for ethical AI, yet there is debate about both what constitutes \"ethical AI\" and which ethical requirements, technical standards and best practices are needed for its realization. To investigate whether a global agreement on these questions is emerging, we mapped and analyzed the current corpus of principles and guidelines on ethical AI. Our results reveal a global convergence emerging around five ethical principles (transparency, justice and fairness, non-maleficence, responsibility and privacy), with substantive divergence in relation to how these principles are interpreted; why they are deemed important; what issue, domain or actors they pertain to; and how they should be implemented. Our findings highlight the importance of integrating guideline-development efforts with substantive ethical analysis and adequate implementation strategies.",
    "lastUpdated": "2019-06-24T17:59:19Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1906.11668v1"
  },
  {
    "title": "Implementing Ethics in AI: Initial Results of an Industrial Multiple Case Study",
    "authors": [
      "Ville Vakkuri",
      "Kai-Kristian Kemell",
      "Pekka Abrahamsson"
    ],
    "abstract": "Artificial intelligence (AI) is becoming increasingly widespread in system development endeavors. As AI systems affect various stakeholders due to their unique nature, the growing influence of these systems calls for ethical considerations. Academic discussion and practical examples of autonomous system failures have highlighted the need for implementing ethics in software development. However, research on methods and tools for implementing ethics into AI system design and development in practice is still lacking. This paper begins to address this focal problem by providing elements needed for producing a baseline for ethics in AI based software development. We do so by means of an industrial multiple case study on AI systems development in the healthcare sector. Using a research model based on extant, conceptual AI ethics literature, we explore the current state of practice out on the field in the absence of formal methods and tools for ethically aligned design.",
    "lastUpdated": "2020-06-16T12:49:59Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1906.12307v3"
  },
  {
    "title": "AI Ethics in Industry: A Research Framework",
    "authors": [
      "Ville Vakkuri",
      "Kai-Kristian Kemell",
      "Pekka Abrahamsson"
    ],
    "abstract": "Artificial Intelligence (AI) systems exert a growing influence on our society. As they become more ubiquitous, their potential negative impacts also become evident through various real-world incidents. Following such early incidents, academic and public discussion on AI ethics has highlighted the need for implementing ethics in AI system development. However, little currently exists in the way of frameworks for understanding the practical implementation of AI ethics. In this paper, we discuss a research framework for implementing AI ethics in industrial settings. The framework presents a starting point for empirical studies into AI ethics but is still being developed further based on its practical utilization.",
    "lastUpdated": "2019-11-25T17:07:00Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1910.12695v2"
  },
  {
    "title": "Ethics of Food Recommender Applications",
    "authors": [
      "Daniel Karpati",
      "Amro Najjar",
      "Diego Agustin Ambrossio"
    ],
    "abstract": "The recent unprecedented popularity of food recommender applications has raised several issues related to the ethical, societal and legal implications of relying on these applications. In this paper, in order to assess the relevant ethical issues, we rely on the emerging principles across the AI\\&Ethics community and define them tailored context specifically. Considering the popular Food Recommender Systems (henceforth F-RS) in the European market cannot be regarded as personalised F-RS, we show how merely this lack of feature shifts the relevance of the focal ethical concerns. We identify the major challenges and propose a scheme for how explicit ethical agendas should be explained. We also argue how a multi-stakeholder approach is indispensable to ensure producing long-term benefits for all stakeholders. After proposing eight ethical desiderata points for F-RS, we present a case-study and assess it based on our proposed desiderata points.",
    "lastUpdated": "2020-02-03T00:53:02Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2002.05679v1"
  },
  {
    "title": "Strangers in the Room: Unpacking Perceptions of 'Smartness' and Related Ethical Concerns in the Home",
    "authors": [
      "William Seymour",
      "Reuben Binns",
      "Petr Slovak",
      "Max Van Kleek",
      "Nigel Shadbolt"
    ],
    "abstract": "The increasingly widespread use of 'smart' devices has raised multifarious ethical concerns regarding their use in domestic spaces. Previous work examining such ethical dimensions has typically either involved empirical studies of concerns raised by specific devices and use contexts, or alternatively expounded on abstract concepts like autonomy, privacy or trust in relation to 'smart homes' in general. This paper attempts to bridge these approaches by asking what features of smart devices users consider as rendering them 'smart' and how these relate to ethical concerns. Through a multimethod investigation including surveys with smart device users (n=120) and semi-structured interviews (n=15), we identify and describe eight types of smartness and explore how they engender a variety of ethical concerns including privacy, autonomy, and disruption of the social order. We argue that this middle ground, between concerns arising from particular devices and more abstract ethical concepts, can better anticipate potential ethical concerns regarding smart devices.",
    "lastUpdated": "2020-05-01T09:33:42Z",
    "categories": [
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/2005.00284v1"
  },
  {
    "title": "Scruples: A Corpus of Community Ethical Judgments on 32,000 Real-Life Anecdotes",
    "authors": [
      "Nicholas Lourie",
      "Ronan Le Bras",
      "Yejin Choi"
    ],
    "abstract": "As AI systems become an increasing part of people's everyday lives, it becomes ever more important that they understand people's ethical norms. Motivated by descriptive ethics, a field of study that focuses on people's descriptive judgments rather than theoretical prescriptions on morality, we investigate a novel, data-driven approach to machine ethics. We introduce Scruples, the first large-scale dataset with 625,000 ethical judgments over 32,000 real-life anecdotes. Each anecdote recounts a complex ethical situation, often posing moral dilemmas, paired with a distribution of judgments contributed by the community members. Our dataset presents a major challenge to state-of-the-art neural language models, leaving significant room for improvement. However, when presented with simplified moral situations, the results are considerably more promising, suggesting that neural models can effectively learn simpler ethical building blocks. A key take-away of our empirical analysis is that norms are not always clean-cut; many situations are naturally divisive. We present a new method to estimate the best possible performance on such tasks with inherently diverse label distributions, and explore likelihood functions that separate intrinsic from model uncertainty.",
    "lastUpdated": "2020-08-20T17:34:15Z",
    "categories": [
      "cs.CL"
    ],
    "url": "http://arxiv.org/abs/2008.09094v1"
  },
  {
    "title": "Ethically Collecting Multi-Modal Spontaneous Conversations with People that have Cognitive Impairments",
    "authors": [
      "Angus Addlesee",
      "Pierre Albert"
    ],
    "abstract": "In order to make spoken dialogue systems (such as Amazon Alexa or Google Assistant) more accessible and naturally interactive for people with cognitive impairments, appropriate data must be obtainable. Recordings of multi-modal spontaneous conversations with vulnerable user groups are scarce however and this valuable data is challenging to collect. Researchers that call for this data are commonly inexperienced in ethical and legal issues around working with vulnerable participants. Additionally, standard recording equipment is insecure and should not be used to capture sensitive data. We spent a year consulting experts on how to ethically capture and share recordings of multi-modal spontaneous conversations with vulnerable user groups. In this paper we provide guidance, collated from these experts, on how to ethically collect such data and we present a new system - \"CUSCO\" - to capture, transport and exchange sensitive data securely. This framework is intended to be easily followed and implemented to encourage further publications of similar corpora. Using this guide and secure recording system, researchers can review and refine their ethical measures.",
    "lastUpdated": "2020-09-30T00:57:33Z",
    "categories": [
      "cs.CL",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2009.14361v1"
  },
  {
    "title": "AI virtues -- The missing link in putting AI ethics into practice",
    "authors": [
      "Thilo Hagendorff"
    ],
    "abstract": "Several seminal ethics initiatives have stipulated sets of principles and standards for good technology development in the AI sector. However, widespread criticism has pointed out a lack of practical realization of these principles. Following that, AI ethics underwent a practical turn, but without deviating from the principled approach and the many shortcomings associated with it. This paper proposes a different approach. It defines four basic AI virtues, namely justice, honesty, responsibility and care, all of which represent specific motivational settings that constitute the very precondition for ethical decision making in the AI field. Moreover, it defines two second-order AI virtues, prudence and fortitude, that bolster achieving the basic virtues by helping with overcoming bounded ethicality or the many hidden psychological forces that impair ethical decision making and that are hitherto completely disregarded in AI ethics. Lastly, the paper describes measures for successfully cultivating the mentioned virtues in organizations dealing with AI research and development.",
    "lastUpdated": "2020-11-25T14:14:47Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2011.12750v1"
  },
  {
    "title": "Taking Principles Seriously: A Hybrid Approach to Value Alignment",
    "authors": [
      "Tae Wan Kim",
      "John Hooker",
      "Thomas Donaldson"
    ],
    "abstract": "An important step in the development of value alignment (VA) systems in AI is understanding how VA can reflect valid ethical principles. We propose that designers of VA systems incorporate ethics by utilizing a hybrid approach in which both ethical reasoning and empirical observation play a role. This, we argue, avoids committing the \"naturalistic fallacy,\" which is an attempt to derive \"ought\" from \"is,\" and it provides a more adequate form of ethical reasoning when the fallacy is not committed. Using quantified model logic, we precisely formulate principles derived from deontological ethics and show how they imply particular \"test propositions\" for any given action plan in an AI rule base. The action plan is ethical only if the test proposition is empirically true, a judgment that is made on the basis of empirical VA. This permits empirical VA to integrate seamlessly with independently justified ethical principles.",
    "lastUpdated": "2020-12-21T22:05:07Z",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2012.11705v1"
  },
  {
    "title": "Ethical Considerations when Employing Fake Identities in OSN for Research",
    "authors": [
      "Yuval Elovici",
      "Michael Fire",
      "Amir Herzberg",
      "Haya Shulman"
    ],
    "abstract": "Online Social Networks (OSNs) have rapidly become a prominent and widely used service, offering a wealth of personal and sensitive information with significant security and privacy implications. Hence, OSNs are also an important - and popular - subject for research. To perform research based on real-life evidence, however, researchers may need to access OSN data, such as texts and files uploaded by users and connections among users. This raises significant ethical problems. Currently, there are no clear ethical guidelines, and researchers may end up (unintentionally) performing ethically questionable research, sometimes even when more ethical research alternatives exist. For example, several studies have employed `fake identities` to collect data from OSNs, but fake identities may be used for attacks and are considered a security issue. Is it legitimate to use fake identities for studying OSNs or for collecting OSN data for research? We present a taxonomy of the ethical challenges facing researchers of OSNs and compare different approaches. We demonstrate how ethical considerations have been taken into account in previous studies that used fake identities. In addition, several possible approaches are offered to reduce or avoid ethical misconducts. We hope this work will stimulate the development and use of ethical practices and methods in the research of online social networks.",
    "lastUpdated": "2013-10-07T01:15:05Z",
    "categories": [
      "cs.CY",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1310.1651v1"
  },
  {
    "title": "Implementing AI Ethics in Practice: An Empirical Evaluation of the RESOLVEDD Strategy",
    "authors": [
      "Ville Vakkuri",
      "Kai-Kristian Kemell"
    ],
    "abstract": "As Artificial Intelligence (AI) systems exert a growing influence on society, real-life incidents begin to underline the importance of AI Ethics. Though calls for more ethical AI systems have been voiced by scholars and the general public alike, few empirical studies on the topic exist. Similarly, few tools and methods designed for implementing AI ethics into practice currently exist. To provide empirical data into this on-going discussion, we empirically evaluate an existing method from the field of business ethics, the RESOLVEDD strategy, in the context of ethical system development. We evaluated RESOLVEDD by means of a multiple case study of five student projects where its use was given as one of the design requirements for the projects. One of our key findings is that, even though the use of the ethical method was forced upon the participants, its utilization nonetheless facilitated of ethical consideration in the projects. Specifically, it resulted in the developers displaying more responsibility, even though the use of the tool did not stem from intrinsic motivation.",
    "lastUpdated": "2020-04-21T17:58:53Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2004.10191v1"
  },
  {
    "title": "Degenerations of del Pezzo surfaces I",
    "authors": [
      "Paul Hacking",
      "Yuri Prokhorov"
    ],
    "abstract": "Let X be a surface with quotient singularities which admits a smoothing to the plane. We prove that X is a deformation of a weighted projective plane P(a^2,b^2,c^2), where a,b,c is a solution of the Markov equation a^2+b^2+c^2=3abc. We also prove a generalisation for del Pezzo surfaces of degree K^2 at least 5.",
    "lastUpdated": "2005-09-22T18:52:09Z",
    "categories": [
      "math.AG",
      "14J10; 14E30"
    ],
    "url": "http://arxiv.org/abs/math/0509529v1"
  },
  {
    "title": "Lectures on flips and minimal models",
    "authors": [
      "Alessio Corti",
      "Paul Hacking",
      "János Kollár",
      "Robert Lazarsfeld",
      "Mircea Mustaţă"
    ],
    "abstract": "This document contains notes from the lectures of Corti, Koll\\'ar, Lazarsfeld, and Musta\\c{t}\\u{a} at the workshop ``Minimal and canonical models in algebraic geometry\" at MSRI, Berkeley, April 2007. The lectures give an overview of the recent advances on canonical and minimal models of algebraic varieties obtained by Hacon--McKernan and Birkar--Cascini--Hacon--McKernan.",
    "lastUpdated": "2007-06-04T18:33:57Z",
    "categories": [
      "math.AG",
      "14E30"
    ],
    "url": "http://arxiv.org/abs/0706.0494v1"
  },
  {
    "title": "Motivation, Design, and Ubiquity: A Discussion of Research Ethics and Computer Science",
    "authors": [
      "David R. Wright"
    ],
    "abstract": "Modern society is permeated with computers, and the software that controls them can have latent, long-term, and immediate effects that reach far beyond the actual users of these systems. This places researchers in Computer Science and Software Engineering in a critical position of influence and responsibility, more than any other field because computer systems are vital research tools for other disciplines. This essay presents several key ethical concerns and responsibilities relating to research in computing. The goal is to promote awareness and discussion of ethical issues among computer science researchers. A hypothetical case study is provided, along with questions for reflection and discussion.",
    "lastUpdated": "2007-06-04T17:17:44Z",
    "categories": [
      "cs.GL",
      "K.7.4"
    ],
    "url": "http://arxiv.org/abs/0706.0484v1"
  },
  {
    "title": "Responsible Autonomy",
    "authors": [
      "Virginia Dignum"
    ],
    "abstract": "As intelligent systems are increasingly making decisions that directly affect society, perhaps the most important upcoming research direction in AI is to rethink the ethical implications of their actions. Means are needed to integrate moral, societal and legal values with technological developments in AI, both during the design process as well as part of the deliberation algorithms employed by these systems. In this paper, we describe leading ethics theories and propose alternative ways to ensure ethical behavior by artificial systems. Given that ethics are dependent on the socio-cultural context and are often only implicit in deliberation processes, methodologies are needed to elicit the values held by designers and stakeholders, and to make these explicit leading to better understanding and trust on artificial autonomous systems.",
    "lastUpdated": "2017-06-08T11:06:52Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1706.02513v1"
  },
  {
    "title": "Harnessing Higher-Order (Meta-)Logic to Represent and Reason with Complex Ethical Theories",
    "authors": [
      "David Fuenmayor",
      "Christoph Benzmüller"
    ],
    "abstract": "The computer-mechanization of an ambitious explicit ethical theory, Gewirth's Principle of Generic Consistency, is used to showcase an approach for representing and reasoning with ethical theories exhibiting complex logical features like alethic and deontic modalities, indexicals, higher-order quantification, among others. Harnessing the high expressive power of Church's type theory as a meta-logic to semantically embed a combination of quantified non-classical logics, our work pushes existing boundaries in knowledge representation and reasoning. We demonstrate that intuitive encodings of complex ethical theories and their automation on the computer are no longer antipodes.",
    "lastUpdated": "2019-06-15T15:42:25Z",
    "categories": [
      "cs.LO",
      "03B60, 03B15, 68T27, 68T30, 68T15",
      "I.2.3; I.2.4; I.2.0; F.4"
    ],
    "url": "http://arxiv.org/abs/1903.09818v2"
  },
  {
    "title": "Teaching AI, Ethics, Law and Policy",
    "authors": [
      "Asher Wilk"
    ],
    "abstract": "The cyberspace and development of intelligent systems using Artificial Intelligence (AI) creates new challenges to computer professionals, data scientists, regulators and policy makers. For example, self-driving cars raise new technical, ethical, legal and public policy issues. This paper proposes a course named Computers, Ethics, Law, and Public Policy, and suggests a curriculum for such a course. This paper presents ethical, legal, and public policy issues relevant to building and using intelligent systems.",
    "lastUpdated": "2019-08-30T16:13:44Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG",
      "cs.SE",
      "K.4; K.4.1; K.5; K.5.2; K.3.2; K.7.4; I.2; I.2.9"
    ],
    "url": "http://arxiv.org/abs/1904.12470v5"
  },
  {
    "title": "Principled Frameworks for Evaluating Ethics in NLP Systems",
    "authors": [
      "Shrimai Prabhumoye",
      "Elijah Mayfield",
      "Alan W Black"
    ],
    "abstract": "We critique recent work on ethics in natural language processing. Those discussions have focused on data collection, experimental design, and interventions in modeling. But we argue that we ought to first understand the frameworks of ethics that are being used to evaluate the fairness and justice of algorithmic systems. Here, we begin that discussion by outlining deontological ethics, and envision a research agenda prioritized by it.",
    "lastUpdated": "2019-06-14T22:52:21Z",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1906.06425v1"
  },
  {
    "title": "A Mulching Proposal",
    "authors": [
      "Os Keyes",
      "Jevan Hutson",
      "Meredith Durbin"
    ],
    "abstract": "he ethical implications of algorithmic systems have been much discussed in both HCI and the broader community of those interested in technology design, development and policy. In this paper, we explore the application of one prominent ethical framework - Fairness, Accountability, and Transparency - to a proposed algorithm that resolves various societal issues around food security and population ageing. Using various standardised forms of algorithmic audit and evaluation, we drastically increase the algorithm's adherence to the FAT framework, resulting in a more ethical and beneficent system. We discuss how this might serve as a guide to other researchers or practitioners looking to ensure better ethical outcomes from algorithmic systems in their line of work.",
    "lastUpdated": "2019-08-10T18:00:42Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1908.06166v1"
  },
  {
    "title": "Towards Contrastive Explanations for Comparing the Ethics of Plans",
    "authors": [
      "Benjamin Krarup",
      "Senka Krivic",
      "Felix Lindner",
      "Derek Long"
    ],
    "abstract": "The development of robotics and AI agents has enabled their wider usage in human surroundings. AI agents are more trusted to make increasingly important decisions with potentially critical outcomes. It is essential to consider the ethical consequences of the decisions made by these systems. In this paper, we present how contrastive explanations can be used for comparing the ethics of plans. We build upon an existing ethical framework to allow users to make suggestions to plans and receive contrastive explanations.",
    "lastUpdated": "2020-06-22T21:38:16Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2006.12632v1"
  },
  {
    "title": "Ethics of Artificial Intelligence in Surgery",
    "authors": [
      "Frank Rudzicz",
      "Raeid Saqur"
    ],
    "abstract": "Here we discuss the four key principles of bio-medical ethics from surgical context. We elaborate on the definition of 'fairness' and its implications in AI system design, with taxonomy of algorithmic biases in AI. We discuss the shifts in ethical paradigms as the degree of autonomy in AI systems continue to evolve. We also emphasize the need for continuous revisions of ethics in AI due to evolution and dynamic nature of AI systems and technologies.",
    "lastUpdated": "2020-07-28T15:16:45Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2007.14302v1"
  },
  {
    "title": "An Ethical Highlighter for People-Centric Dataset Creation",
    "authors": [
      "Margot Hanley",
      "Apoorv Khandelwal",
      "Hadar Averbuch-Elor",
      "Noah Snavely",
      "Helen Nissenbaum"
    ],
    "abstract": "Important ethical concerns arising from computer vision datasets of people have been receiving significant attention, and a number of datasets have been withdrawn as a result. To meet the academic need for people-centric datasets, we propose an analytical framework to guide ethical evaluation of existing datasets and to serve future dataset creators in avoiding missteps. Our work is informed by a review and analysis of prior works and highlights where such ethical challenges arise.",
    "lastUpdated": "2020-11-27T07:18:44Z",
    "categories": [
      "cs.CY",
      "cs.CV",
      "cs.DB"
    ],
    "url": "http://arxiv.org/abs/2011.13583v1"
  },
  {
    "title": "How to avoid ethically relevant Machine Consciousness",
    "authors": [
      "Aleksander Lodwich"
    ],
    "abstract": "This paper discusses the root cause of systems perceiving the self experience and how to exploit adaptive and learning features without introducing ethically problematic system properties.",
    "lastUpdated": "2016-06-06T10:53:16Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1606.00058v2"
  },
  {
    "title": "Building Ethically Bounded AI",
    "authors": [
      "Francesca Rossi",
      "Nicholas Mattei"
    ],
    "abstract": "The more AI agents are deployed in scenarios with possibly unexpected situations, the more they need to be flexible, adaptive, and creative in achieving the goal we have given them. Thus, a certain level of freedom to choose the best path to the goal is inherent in making AI robust and flexible enough. At the same time, however, the pervasive deployment of AI in our life, whether AI is autonomous or collaborating with humans, raises several ethical challenges. AI agents should be aware and follow appropriate ethical principles and should thus exhibit properties such as fairness or other virtues. These ethical principles should define the boundaries of AI's freedom and creativity. However, it is still a challenge to understand how to specify and reason with ethical boundaries in AI agents and how to combine them appropriately with subjective preferences and goal specifications. Some initial attempts employ either a data-driven example-based approach for both, or a symbolic rule-based approach for both. We envision a modular approach where any AI technique can be used for any of these essential ingredients in decision making or decision support systems, paired with a contextual approach to define their combination and relative weight. In a world where neither humans nor AI systems work in isolation, but are tightly interconnected, e.g., the Internet of Things, we also envision a compositional approach to building ethically bounded AI, where the ethical properties of each component can be fruitfully exploited to derive those of the overall system. In this paper we define and motivate the notion of ethically-bounded AI, we describe two concrete examples, and we outline some outstanding challenges.",
    "lastUpdated": "2018-12-10T18:58:05Z",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1812.03980v1"
  },
  {
    "title": "Ethically Aligned Design: An empirical evaluation of the RESOLVEDD-strategy in Software and Systems development context",
    "authors": [
      "Ville Vakkuri",
      "Kai-Kristian Kemell",
      "Pekka Abrahamsson"
    ],
    "abstract": "Use of artificial intelligence (AI) in human contexts calls for ethical considerations for the design and development of AI-based systems. However, little knowledge currently exists on how to provide useful and tangible tools that could help software developers and designers implement ethical considerations into practice. In this paper, we empirically evaluate a method that enables ethically aligned design in a decision-making process. Though this method, titled the RESOLVEDD-strategy, originates from the field of business ethics, it is being applied in other fields as well. We tested the RESOLVEDD-strategy in a multiple case study of five student projects where the use of ethical tools was given as one of the design requirements. A key finding from the study indicates that simply the presence of an ethical tool has an effect on ethical consideration, creating more responsibility even in instances where the use of the tool is not intrinsically motivated.",
    "lastUpdated": "2020-01-22T18:50:36Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1905.06417v4"
  },
  {
    "title": "Ethical Underpinnings in the Design and Management of ICT Projects",
    "authors": [
      "Aaditeshwar Seth"
    ],
    "abstract": "With a view towards understanding why undesirable outcomes often arise in ICT projects, we draw attention to three aspects in this essay. First, we present several examples to show that incorporating an ethical framework in the design of an ICT system is not sufficient in itself, and that ethics need to guide the deployment and ongoing management of the projects as well. We present a framework that brings together the objectives, design, and deployment management of ICT projects as being shaped by a common underlying ethical system. Second, we argue that power-based equality should be incorporated as a key underlying ethical value in ICT projects, to ensure that the project does not reinforce inequalities in power relationships between the actors directly or indirectly associated with the project. We present a method to model ICT projects to make legible its influence on the power relationships between various actors in the ecosystem. Third, we discuss that the ethical values underlying any ICT project ultimately need to be upheld by the project teams, where certain factors like political ideologies or dispersed teams may affect the rigour with which these ethical values are followed. These three aspects of having an ethical underpinning to the design and management of ICT projects, the need for having a power-based equality principle for ICT projects, and the importance of socialization of the project teams, needs increasing attention in today's age of ICT platforms where millions and billions of users interact on the same platform but which are managed by only a few people.",
    "lastUpdated": "2019-07-16T02:30:03Z",
    "categories": [
      "cs.CY",
      "cs.HC",
      "cs.SI"
    ],
    "url": "http://arxiv.org/abs/1907.06809v1"
  },
  {
    "title": "Ethical Considerations in Artificial Intelligence Courses",
    "authors": [
      "Emanuelle Burton",
      "Judy Goldsmith",
      "Sven Koenig",
      "Benjamin Kuipers",
      "Nicholas Mattei",
      "Toby Walsh"
    ],
    "abstract": "The recent surge in interest in ethics in artificial intelligence may leave many educators wondering how to address moral, ethical, and philosophical issues in their AI courses. As instructors we want to develop curriculum that not only prepares students to be artificial intelligence practitioners, but also to understand the moral, ethical, and philosophical impacts that artificial intelligence will have on society. In this article we provide practical case studies and links to resources for use by AI educators. We also provide concrete suggestions on how to integrate AI ethics into a general artificial intelligence course and how to teach a stand-alone artificial intelligence ethics course.",
    "lastUpdated": "2017-01-26T16:52:22Z",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.GL",
      "K.3.2; K.4.1; K.7.m"
    ],
    "url": "http://arxiv.org/abs/1701.07769v1"
  },
  {
    "title": "Practical Challenges in Explicit Ethical Machine Reasoning",
    "authors": [
      "Louise Dennis",
      "Michael Fisher"
    ],
    "abstract": "We examine implemented systems for ethical machine reasoning with a view to identifying the practical challenges (as opposed to philosophical challenges) posed by the area. We identify a need for complex ethical machine reasoning not only to be multi-objective, proactive, and scrutable but that it must draw on heterogeneous evidential reasoning. We also argue that, in many cases, it needs to operate in real time and be verifiable. We propose a general architecture involving a declarative ethical arbiter which draws upon multiple evidential reasoners each responsible for a particular ethical feature of the system's environment. We claim that this architecture enables some separation of concerns among the practical challenges that ethical machine reasoning poses.",
    "lastUpdated": "2018-01-04T16:19:33Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1801.01422v1"
  },
  {
    "title": "Ethical and Social Aspects of Self-Driving Cars",
    "authors": [
      "Tobias Holstein",
      "Gordana Dodig-Crnkovic",
      "Patrizio Pelliccione"
    ],
    "abstract": "As an envisaged future of transportation, self-driving cars are being discussed from various perspectives, including social, economical, engineering, computer science, design, and ethics. On the one hand, self-driving cars present new engineering problems that are being gradually successfully solved. On the other hand, social and ethical problems are typically being presented in the form of an idealized unsolvable decision-making problem, the so-called trolley problem, which is grossly misleading. We argue that an applied engineering ethical approach for the development of new technology is what is needed; the approach should be applied, meaning that it should focus on the analysis of complex real-world engineering problems. Software plays a crucial role for the control of self-driving cars; therefore, software engineering solutions should seriously handle ethical and social considerations. In this paper we take a closer look at the regulative instruments, standards, design, and implementations of components, systems, and services and we present practical social and ethical challenges that have to be met, as well as novel expectations for software engineering.",
    "lastUpdated": "2018-02-05T22:22:08Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1802.04103v1"
  },
  {
    "title": "The Key Concepts of Ethics of Artificial Intelligence - A Keyword based Systematic Mapping Study",
    "authors": [
      "Ville Vakkuri",
      "Pekka Abrahamsson"
    ],
    "abstract": "The growing influence and decision-making capacities of Autonomous systems and Artificial Intelligence in our lives force us to consider the values embedded in these systems. But how ethics should be implemented into these systems? In this study, the solution is seen on philosophical conceptualization as a framework to form practical implementation model for ethics of AI. To take the first steps on conceptualization main concepts used on the field needs to be identified. A keyword based Systematic Mapping Study (SMS) on the keywords used in AI and ethics was conducted to help in identifying, defying and comparing main concepts used in current AI ethics discourse. Out of 1062 papers retrieved SMS discovered 37 re-occurring keywords in 83 academic papers. We suggest that the focus on finding keywords is the first step in guiding and providing direction for future research in the AI ethics field.",
    "lastUpdated": "2018-09-19T07:01:53Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1809.07027v1"
  },
  {
    "title": "Peril v. Promise: IoT and the Ethical Imaginaries",
    "authors": [
      "Funda Ustek-Spilda",
      "Alison Powell",
      "Irina Shklovski",
      "Sebastian Lehuede"
    ],
    "abstract": "The future scenarios often associated with Internet of Things (IoT) oscillate between the peril of IoT for the future of humanity and the promises for an ever-connected and efficient future. Such a dichotomous positioning creates problems not only for expanding the field of application of the technology, but also ensuring ethical and responsible design and production. As part of VirtEU (Values and Ethics in Innovation for Responsible Technology in Europe) (EU Horizon 2020 FP7), we have conducted ethnographic research into the main hubs of IoT in Europe, such as London, Amsterdam, Barcelona and Belgrade, with developers and designers of IoT to identify the challenges they face in their day-to-day work. In this paper, we focus on the IoT and the ethical imaginaries explore the practical challenges IoT developers face when they are designing, producing and marketing IoT technologies. We argue that top-down ethical frameworks that overlook the situated capabilities of developers or the solutionist approaches that treat ethical issues as technical problems are unlikely to provide an alternative to the dichotomous imaginary for the future.",
    "lastUpdated": "2019-06-25T08:31:39Z",
    "categories": [
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/1906.10378v1"
  },
  {
    "title": "Grounding Value Alignment with Ethical Principles",
    "authors": [
      "Tae Wan Kim",
      "Thomas Donaldson",
      "John Hooker"
    ],
    "abstract": "An important step in the development of value alignment (VA) systems in AI is understanding how values can interrelate with facts. Designers of future VA systems will need to utilize a hybrid approach in which ethical reasoning and empirical observation interrelate successfully in machine behavior. In this article we identify two problems about this interrelation that have been overlooked by AI discussants and designers. The first problem is that many AI designers commit inadvertently a version of what has been called by moral philosophers the \"naturalistic fallacy,\" that is, they attempt to derive an \"ought\" from an \"is.\" We illustrate when and why this occurs. The second problem is that AI designers adopt training routines that fail fully to simulate human ethical reasoning in the integration of ethical principles and facts. Using concepts of quantified modal logic, we proceed to offer an approach that promises to simulate ethical reasoning in humans by connecting ethical principles on the one hand and propositions about states of affairs on the other.",
    "lastUpdated": "2019-07-11T18:55:47Z",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1907.05447v1"
  },
  {
    "title": "Whose Side are Ethics Codes On? Power, Responsibility and the Social Good",
    "authors": [
      "Anne L. Washington",
      "Rachel S. Kuo"
    ],
    "abstract": "The moral authority of ethics codes stems from an assumption that they serve a unified society, yet this ignores the political aspects of any shared resource. The sociologist Howard S. Becker challenged researchers to clarify their power and responsibility in the classic essay: Whose Side Are We On. Building on Becker's hierarchy of credibility, we report on a critical discourse analysis of data ethics codes and emerging conceptualizations of beneficence, or the \"social good\", of data technology. The analysis revealed that ethics codes from corporations and professional associations conflated consumers with society and were largely silent on agency. Interviews with community organizers about social change in the digital era supplement the analysis, surfacing the limits of technical solutions to concerns of marginalized communities. Given evidence that highlights the gulf between the documents and lived experiences, we argue that ethics codes that elevate consumers may simultaneously subordinate the needs of vulnerable populations. Understanding contested digital resources is central to the emerging field of public interest technology. We introduce the concept of digital differential vulnerability to explain disproportionate exposures to harm within data technology and suggest recommendations for future ethics codes.",
    "lastUpdated": "2020-02-04T22:05:09Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2002.01559v1"
  },
  {
    "title": "RoboTed: a case study in Ethical Risk Assessment",
    "authors": [
      "Alan F. T. Winfield",
      "Katie Winkle"
    ],
    "abstract": "Risk Assessment is a well known and powerful method for discovering and mitigating risks, and hence improving safety. Ethical Risk Assessment uses the same approach but extends the envelope of risk to cover ethical risks in addition to safety risks. In this paper we outline Ethical Risk Assessment (ERA) and set ERA within the broader framework of Responsible Robotics. We then illustrate ERA with a case study of a hypothetical smart robot toy teddy bear: RoboTed. The case study shows the value of ERA and how consideration of ethical risks can prompt design changes, resulting in a more ethical and sustainable robot.",
    "lastUpdated": "2020-09-29T13:15:39Z",
    "categories": [
      "cs.RO",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2007.15864v2"
  },
  {
    "title": "Aligning AI With Shared Human Values",
    "authors": [
      "Dan Hendrycks",
      "Collin Burns",
      "Steven Basart",
      "Andrew Critch",
      "Jerry Li",
      "Dawn Song",
      "Jacob Steinhardt"
    ],
    "abstract": "We show how to assess a language model's knowledge of basic concepts of morality. We introduce the ETHICS dataset, a new benchmark that spans concepts in justice, well-being, duties, virtues, and commonsense morality. Models predict widespread moral judgments about diverse text scenarios. This requires connecting physical and social world knowledge to value judgements, a capability that may enable us to steer chatbot outputs or eventually regularize open-ended reinforcement learning agents. With the ETHICS dataset, we find that current language models have a promising but incomplete ability to predict basic human ethical judgements. Our work shows that progress can be made on machine ethics today, and it provides a steppingstone toward AI that is aligned with human values.",
    "lastUpdated": "2021-01-12T18:57:47Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2008.02275v3"
  },
  {
    "title": "Logic Programming and Machine Ethics",
    "authors": [
      "Abeer Dyoub",
      "Stefania Costantini",
      "Francesca A. Lisi"
    ],
    "abstract": "Transparency is a key requirement for ethical machines. Verified ethical behavior is not enough to establish justified trust in autonomous intelligent agents: it needs to be supported by the ability to explain decisions. Logic Programming (LP) has a great potential for developing such perspective ethical systems, as in fact logic rules are easily comprehensible by humans. Furthermore, LP is able to model causality, which is crucial for ethical decision making.",
    "lastUpdated": "2020-09-22T00:47:18Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "cs.LO",
      "D.1.6; K.4"
    ],
    "url": "http://arxiv.org/abs/2009.11186v1"
  },
  {
    "title": "Training Ethically Responsible AI Researchers: a Case Study",
    "authors": [
      "Hang Yuan",
      "Claudia Vanea",
      "Federica Lucivero",
      "Nina Hallowell"
    ],
    "abstract": "Ethical oversight of AI research is beset by a number of problems. There are numerous ways to tackle these problems, however, they leave full responsibility for ethical reflection in the hands of review boards and committees. In this paper, we propose an alternative solution: the training of ethically responsible AI researchers. We showcase this solution through a case study of a centre for doctoral training and outline how ethics training is structured in the program. We go on to present two second-year students' reflections on their training which demonstrates some of their newly found capabilities as ethically responsible researchers.",
    "lastUpdated": "2020-11-20T14:12:50Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2011.11393v1"
  },
  {
    "title": "Investigation on Research Ethics and Building a Benchmark",
    "authors": [
      "Shun Inagaki",
      "Robert Ramirez",
      "Masaki Shimaoka",
      "Kenichi Magata"
    ],
    "abstract": "When dealing with leading edge cyber security research, especially when operating from the perspective of an attacker or a red team, it becomes necessary for one to at times consider how ethics comes into play. There are currently no cyber security-specific ethics standards, which in particular is one reason more adversarial cyber security research lags behind in Japan. In this research, using machine learning and manual methods we extracted best practices for research ethics from past top conference papers. Using this knowledge we constructed an ethics knowledge base for cyber security research. Such a knowledge base can be used to properly distinguish grey-area research so that it is not wrongly forbidden. Using a decision tree-style user interface that we created for our knowledge base, researchers may be able to efficiently identify which aspects of their research require ethical consideration. In this work, as a preliminary step we focused on only a portion of the areas of research covered by cyber security conferences, but our results are applicable to any area of research.",
    "lastUpdated": "2020-11-26T09:18:03Z",
    "categories": [
      "cs.CR",
      "68T50, 68M25",
      "I.7.5; K.4.1; H.3.1; H.3.7"
    ],
    "url": "http://arxiv.org/abs/2011.13925v1"
  },
  {
    "title": "Mapping for accessibility: A case study of ethics in data science for social good",
    "authors": [
      "Anissa Tanweer",
      "Nicholas Bolten",
      "Margaret Drouhard",
      "Jess Hamilton",
      "Anat Caspi",
      "Brittany Fiore-Gartland",
      "Kaicheng Tan"
    ],
    "abstract": "Ethics in the emerging world of data science are often discussed through cautionary tales about the dire consequences of missteps taken by high profile companies or organizations. We take a different approach by foregrounding the ways that ethics are implicated in the day-to-day work of data science, focusing on instances in which data scientists recognize, grapple with, and conscientiously respond to ethical challenges. This paper presents a case study of ethical dilemmas that arose in a \"data science for social good\" (DSSG) project focused on improving navigation for people with limited mobility. We describe how this particular DSSG team responded to those dilemmas, and how those responses gave rise to still more dilemmas. While the details of the case discussed here are unique, the ethical dilemmas they illuminate can commonly be found across many DSSG projects. These include: the risk of exacerbating disparities; the thorniness of algorithmic accountability; the evolving opportunities for mischief presented by new technologies; the subjective and value- laden interpretations at the heart of any data-intensive project; the potential for data to amplify or mute particular voices; the possibility of privacy violations; and the folly of technological solutionism. Based on our tracing of the team's responses to these dilemmas, we distill lessons for an ethical data science practice that can be more generally applied across DSSG projects. Specifically, this case experience highlights the importance of: 1) Setting the scene early on for ethical thinking 2) Recognizing ethical decision-making as an emergent phenomenon intertwined with the quotidian work of data science for social good 3) Approaching ethical thinking as a thoughtful and intentional balancing of priorities rather than a binary differentiation between right and wrong.",
    "lastUpdated": "2017-10-18T18:10:35Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1710.06882v1"
  },
  {
    "title": "The State of AI Ethics Report (October 2020)",
    "authors": [
      "Abhishek Gupta",
      "Alexandrine Royer",
      "Victoria Heath",
      "Connor Wright",
      "Camylle Lanteigne",
      "Allison Cohen",
      "Marianna Bergamaschi Ganapini",
      "Muriam Fancy",
      "Erick Galinkin",
      "Ryan Khurana",
      "Mo Akif",
      "Renjie Butalid",
      "Falaah Arif Khan",
      "Masa Sweidan",
      "Audrey Balogh"
    ],
    "abstract": "The 2nd edition of the Montreal AI Ethics Institute's The State of AI Ethics captures the most relevant developments in the field of AI Ethics since July 2020. This report aims to help anyone, from machine learning experts to human rights activists and policymakers, quickly digest and understand the ever-changing developments in the field. Through research and article summaries, as well as expert commentary, this report distills the research and reporting surrounding various domains related to the ethics of AI, including: AI and society, bias and algorithmic justice, disinformation, humans and AI, labor impacts, privacy, risk, and future of AI ethics. In addition, The State of AI Ethics includes exclusive content written by world-class AI Ethics experts from universities, research institutes, consulting firms, and governments. These experts include: Danit Gal (Tech Advisor, United Nations), Amba Kak (Director of Global Policy and Programs, NYU's AI Now Institute), Rumman Chowdhury (Global Lead for Responsible AI, Accenture), Brent Barron (Director of Strategic Projects and Knowledge Management, CIFAR), Adam Murray (U.S. Diplomat working on tech policy, Chair of the OECD Network on AI), Thomas Kochan (Professor, MIT Sloan School of Management), and Katya Klinova (AI and Economy Program Lead, Partnership on AI). This report should be used not only as a point of reference and insight on the latest thinking in the field of AI Ethics, but should also be used as a tool for introspection as we aim to foster a more nuanced conversation regarding the impacts of AI on the world.",
    "lastUpdated": "2020-11-05T12:36:16Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2011.02787v1"
  },
  {
    "title": "A quantitative perspective on ethics in large team science",
    "authors": [
      "Alexander M. Petersen",
      "Ioannis Pavlidis",
      "Ioanna Semendeferi"
    ],
    "abstract": "The gradual crowding out of singleton and small team science by large team endeavors is challenging key features of research culture. It is therefore important for the future of scientific practice to reflect upon the individual scientist's ethical responsibilities within teams. To facilitate this reflection we show labor force trends in the US revealing a skewed growth in academic ranks and increased levels of competition for promotion within the system; we analyze teaming trends across disciplines and national borders demonstrating why it is becoming difficult to distribute credit and to avoid conflicts of interest; and we use more than a century of Nobel prize data to show how science is outgrowing its old institutions of singleton awards. Of particular concern within the large team environment is the weakening of the mentor-mentee relation, which undermines the cultivation of virtue ethics across scientific generations. These trends and emerging organizational complexities call for a universal set of behavioral norms that transcend team heterogeneity and hierarchy. To this end, our expository analysis provides a survey of ethical issues in team settings to inform science ethics education and science policy.",
    "lastUpdated": "2014-07-02T09:43:18Z",
    "categories": [
      "physics.soc-ph",
      "cs.CY",
      "cs.DL"
    ],
    "url": "http://arxiv.org/abs/1404.0191v2"
  },
  {
    "title": "Ethical Implications of Social Internet of Vehicles Systems",
    "authors": [
      "Ricardo Silva",
      "Razi Iqbal"
    ],
    "abstract": "The core concept of IoT is to equip real world objects with computing, processing and communicating capabilities to enable socializing between them. Internet of Vehicles (IoV) is an adherent of IoT that has realized significant advancements using communication technologies. Vehicles connected through Internet are capable of sharing information that can substantially enhance the quality of traffic on roads. Social Internet of Things (SIoT) is an instance of IoT that deals specifically in socialization of connected objects. SIoT enables the notion of Social Internet of Vehicles (SIoV) where vehicles are the key entities for sharing information between themselves and the infrastructure (commonly known as Road Side Units (RSUs)). Vehicles in SIoV socialize by exchanging data such as traffic congestions, weather conditions, infotainment, vacant parking slots, alternate routes and discount coupons for restaurants etc. In SIoV, vehicles can communicate with other vehicles and infrastructure through traditional communication technologies like Wi-Fi, Cellular networks or through Dedicated Short Range Communication (DSRC) etc. SIoV will be confronted with ethical dilemmas and expected to function in an ethically responsible manner. This paper highlights the ethical implications of SIoV systems. Vehicle to Vehicle (V2V) and Vehicle to Infrastructure (V2I) involves autonomous decision making that requires setting ethical and moral rules before taking verdict. The article discusses the lack of ethical guidelines in designing and deploying of SIoV systems that are of utmost importance. Finally, an addition to SIoV architecture is proposed to incorporate the ethical and moral principles for scheming the SIoV systems.",
    "lastUpdated": "2018-06-24T04:28:36Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1806.09081v1"
  },
  {
    "title": "Responses to a Critique of Artificial Moral Agents",
    "authors": [
      "Adam Poulsen",
      "Michael Anderson",
      "Susan L. Anderson",
      "Ben Byford",
      "Fabio Fossa",
      "Erica L. Neely",
      "Alejandro Rosas",
      "Alan Winfield"
    ],
    "abstract": "The field of machine ethics is concerned with the question of how to embed ethical behaviors, or a means to determine ethical behaviors, into artificial intelligence (AI) systems. The goal is to produce artificial moral agents (AMAs) that are either implicitly ethical (designed to avoid unethical consequences) or explicitly ethical (designed to behave ethically). Van Wynsberghe and Robbins' (2018) paper Critiquing the Reasons for Making Artificial Moral Agents critically addresses the reasons offered by machine ethicists for pursuing AMA research; this paper, co-authored by machine ethicists and commentators, aims to contribute to the machine ethics conversation by responding to that critique. The reasons for developing AMAs discussed in van Wynsberghe and Robbins (2018) are: it is inevitable that they will be developed; the prevention of harm; the necessity for public trust; the prevention of immoral use; such machines are better moral reasoners than humans, and building these machines would lead to a better understanding of human morality. In this paper, each co-author addresses those reasons in turn. In so doing, this paper demonstrates that the reasons critiqued are not shared by all co-authors; each machine ethicist has their own reasons for researching AMAs. But while we express a diverse range of views on each of the six reasons in van Wynsberghe and Robbins' critique, we nevertheless share the opinion that the scientific study of AMAs has considerable value.",
    "lastUpdated": "2019-03-17T03:18:24Z",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.RO"
    ],
    "url": "http://arxiv.org/abs/1903.07021v1"
  },
  {
    "title": "Achieving Ethical Algorithmic Behaviour in the Internet-of-Things: a Review",
    "authors": [
      "Seng W. Loke"
    ],
    "abstract": "The Internet-of-Things is emerging as a vast inter-connected space of devices and things surrounding people, many of which are increasingly capable of autonomous action, from automatically sending data to cloud servers for analysis, changing the behaviour of smart objects, to changing the physical environment. A wide range of ethical concerns has arisen in their usage and development in recent years. Such concerns are exacerbated by the increasing autonomy given to connected things. This paper reviews, via examples, the landscape of ethical issues, and some recent approaches to address these issues, concerning connected things behaving autonomously, as part of the Internet-of-Things. We consider ethical issues in relation to device operations and accompanying algorithms. Examples of concerns include unsecured consumer devices, data collection with health related Internet-of-Things, hackable vehicles and behaviour of autonomous vehicles in dilemma situations, accountability with Internet-of-Things systems, algorithmic bias, uncontrolled cooperation among things, and automation affecting user choice and control. Current ideas towards addressing a range of ethical concerns are reviewed and compared, including programming ethical behaviour, whitebox algorithms, blackbox validation, algorithmic social contracts, enveloping IoT systems, and guidelines and code of ethics for IoT developers - a suggestion from the analysis is that a multi-pronged approach could be useful, based on the context of operation and deployment.",
    "lastUpdated": "2019-10-22T21:34:19Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1910.10241v1"
  },
  {
    "title": "Reinforcement Learning Under Moral Uncertainty",
    "authors": [
      "Adrien Ecoffet",
      "Joel Lehman"
    ],
    "abstract": "An ambitious goal for artificial intelligence is to create agents that behave ethically: The capacity to abide by human moral norms would greatly expand the context in which autonomous agents could be practically and safely deployed. While ethical agents could be trained through reinforcement, by rewarding correct behavior under a specific moral theory (e.g. utilitarianism), there remains widespread disagreement (both societally and among moral philosophers) about the nature of morality and what ethical theory (if any) is objectively correct. Acknowledging such disagreement, recent work in moral philosophy proposes that ethical behavior requires acting under moral uncertainty, i.e. to take into account when acting that one's credence is split across several plausible ethical theories. Inspired by such work, this paper proposes a formalism that translates such insights to the field of reinforcement learning. Demonstrating the formalism's potential, we then train agents in simple environments to act under moral uncertainty, highlighting how such uncertainty can help curb extreme behavior from commitment to single theories. The overall aim is to draw productive connections from the fields of moral philosophy and machine ethics to that of machine learning, to inspire further research by highlighting a spectrum of machine learning research questions relevant to training ethically capable reinforcement learning agents.",
    "lastUpdated": "2020-07-15T00:15:50Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2006.04734v2"
  },
  {
    "title": "Good AI for the Present of Humanity Democratizing AI Governance",
    "authors": [
      "Nicholas Kluge Corrêa"
    ],
    "abstract": "What does Cyberpunk and AI Ethics have to do with each other? Cyberpunk is a sub-genre of science fiction that explores the post-human relationships between human experience and technology. One similarity between AI Ethics and Cyberpunk literature is that both seek a dialogue in which the reader may inquire about the future and the ethical and social problems that our technological advance may bring upon society. In recent years, an increasing number of ethical matters involving AI have been pointed and debated, and several ethical principles and guides have been suggested as governance policies for the tech industry. However, would this be the role of AI Ethics? To serve as a soft and ambiguous version of the law? I would like to promote in this article a more Cyberpunk way of doing AI Ethics, whit a more anarchic way of governance. In this study, I will seek to expose some of the deficits of the underlying power structures of our society and suggest that AI governance be subject to public opinion, so that good AI can become good AI for all.",
    "lastUpdated": "2020-12-26T21:26:07Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2007.04477v10"
  },
  {
    "title": "Space ethics to test directed panspermia",
    "authors": [
      "Maxim A. Makukov",
      "Vladimir I. shCherbak"
    ],
    "abstract": "The hypothesis that Earth was intentionally seeded with life by a preceding extraterrestrial civilization is believed to be currently untestable. However, analysis of the situation where humans themselves embark on seeding other planetary systems motivated by survival and propagation of life reveals at least two ethical issues calling for specific solutions. Assuming that generally intelligence evolves ethically as it evolves technologically, the same considerations might be applied to test the hypothesis of directed panspermia: if life on Earth was seeded intentionally, the two ethical requirements are expected to be satisfied, what appears to be the case.",
    "lastUpdated": "2017-06-12T14:13:32Z",
    "categories": [
      "physics.pop-ph",
      "astro-ph.EP"
    ],
    "url": "http://arxiv.org/abs/1407.5618v3"
  },
  {
    "title": "An architecture for ethical robots",
    "authors": [
      "Dieter Vanderelst",
      "Alan Winfield"
    ],
    "abstract": "Robots are becoming ever more autonomous. This expanding ability to take unsupervised decisions renders it imperative that mechanisms are in place to guarantee the safety of behaviours executed by the robot. Moreover, smart autonomous robots should be more than safe; they should also be explicitly ethical -- able to both choose and justify actions that prevent harm. Indeed, as the cognitive, perceptual and motor capabilities of robots expand, they will be expected to have an improved capacity for making moral judgements. We present a control architecture that supplements existing robot controllers. This so-called Ethical Layer ensures robots behave according to a predetermined set of ethical rules by predicting the outcomes of possible actions and evaluating the predicted outcomes against those rules. To validate the proposed architecture, we implement it on a humanoid robot so that it behaves according to Asimov's laws of robotics. In a series of four experiments, using a second humanoid robot as a proxy for the human, we demonstrate that the proposed Ethical Layer enables the robot to prevent the human from coming to harm.",
    "lastUpdated": "2016-09-09T20:20:19Z",
    "categories": [
      "cs.RO"
    ],
    "url": "http://arxiv.org/abs/1609.02931v1"
  },
  {
    "title": "Ethical Artificial Intelligence - An Open Question",
    "authors": [
      "Alice Pavaloiu",
      "Utku Kose"
    ],
    "abstract": "Artificial Intelligence (AI) is an effective science which employs strong enough approaches, methods, and techniques to solve unsolvable real world based problems. Because of its unstoppable rise towards the future, there are also some discussions about its ethics and safety. Shaping an AI friendly environment for people and a people friendly environment for AI can be a possible answer for finding a shared context of values for both humans and robots. In this context, objective of this paper is to address the ethical issues of AI and explore the moral dilemmas that arise from ethical algorithms, from pre set or acquired values. In addition, the paper will also focus on the subject of AI safety. As general, the paper will briefly analyze the concerns and potential solutions to solving the ethical issues presented and increase readers awareness on AI safety as another related research interest.",
    "lastUpdated": "2017-05-16T20:57:36Z",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1706.03021v1"
  },
  {
    "title": "Children and the Data Cycle: Rights and Ethics in a Big Data World",
    "authors": [
      "Gabrielle Berman",
      "Kerry Albright"
    ],
    "abstract": "In an era of increasing dependence on data science and big data, the voices of one set of major stakeholders - the world's children and those who advocate on their behalf - have been largely absent. A recent paper estimates one in three global internet users is a child, yet there has been little rigorous debate or understanding of how to adapt traditional, offline ethical standards for research, involving data collection from children, to a big data, online environment (Livingstone et al., 2015). This paper argues that due to the potential for severe, long-lasting and differential impacts on children, child rights need to be firmly integrated onto the agendas of global debates about ethics and data science. The authors outline their rationale for a greater focus on child rights and ethics in data science and suggest steps to move forward, focussing on the various actors within the data chain including data generators, collectors, analysts and end users. It concludes by calling for a much stronger appreciation of the links between child rights, ethics and data science disciplines and for enhanced discourse between stakeholders in the data chain and those responsible for upholding the rights of children globally.",
    "lastUpdated": "2017-10-18T18:08:13Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1710.06881v1"
  },
  {
    "title": "Ethics, Information, and Our \"It-from-Bit\" Universe",
    "authors": [
      "Terrell Ward Bynum"
    ],
    "abstract": "Using information technology, humans have brought about the Information Revolution, which is changing the world faster and more profoundly than ever before. How is this possible? An answer is suggested by comments of James Moor, regarding Logical Malleability, in his classic paper, What Is Computer Ethics?, 1985. The present essay combines Moor's ideas with the hypothesis that all physical entities, including spacetime and the universe as a whole, are dynamic data structures. To show the usefulness of taking such an approach, in both physics and information ethics, a suggested it from bit model of the universe is briefly sketched, and relevant predictions are offered about the future of computer and information ethics.",
    "lastUpdated": "2018-02-26T05:38:24Z",
    "categories": [
      "physics.pop-ph",
      "physics.hist-ph"
    ],
    "url": "http://arxiv.org/abs/1802.02029v2"
  },
  {
    "title": "On Quantifying and Understanding the Role of Ethics in AI Research: A Historical Account of Flagship Conferences and Journals",
    "authors": [
      "Marcelo Prates",
      "Pedro Avelar",
      "Luis C. Lamb"
    ],
    "abstract": "Recent developments in AI, Machine Learning and Robotics have raised concerns about the ethical consequences of both academic and industrial AI research. Leading academics, businessmen and politicians have voiced an increasing number of questions about the consequences of AI not only over people, but also on the large-scale consequences on the the future of work and employment, its social consequences and the sustainability of the planet. In this work, we analyse the use and the occurrence of ethics-related research in leading AI, machine learning and robotics venues. In order to do so we perform long term, historical corpus-based analyses on a large number of flagship conferences and journals. Our experiments identify the prominence of ethics-related terms in published papers and presents several statistics on related topics. Finally, this research provides quantitative evidence on the pressing ethical concerns of the AI community.",
    "lastUpdated": "2018-09-21T21:52:34Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1809.08328v1"
  },
  {
    "title": "Robotics Rights and Ethics Rules",
    "authors": [
      "Tuncay Yigit",
      "Utku Kose",
      "Nilgun Sengoz"
    ],
    "abstract": "It is very important to adhere strictly to ethical and social influences when delivering most of our life to artificial intelligence systems. With industry 4.0, the internet of things, data analysis and automation have begun to be of great importance in our lives. With the Yapanese version of Industry 5.0, it has come to our attention that machine-human interaction and human intelligence are working in harmony with the cognitive computer. In this context, robots working on artificial intelligence algorithms co-ordinated with the development of technology have begun to enter our lives. But the consequences of the recent complaints of the Robots have been that important issues have arisen about how to be followed in terms of intellectual property and ethics. Although there are no laws regulating robots in our country at present, laws on robot ethics and rights abroad have entered into force. This means that it is important that we organize the necessary arrangements in the way that robots and artificial intelligence are so important in the new world order. In this study, it was aimed to examine the existing rules of machine and robot ethics and to set an example for the arrangements to be made in our country, and various discussions were given in this context.",
    "lastUpdated": "2018-09-24T13:02:09Z",
    "categories": [
      "cs.RO",
      "cs.AI",
      "68T40"
    ],
    "url": "http://arxiv.org/abs/1809.08885v1"
  },
  {
    "title": "A Serious Game for Introducing Software Engineering Ethics to University Students",
    "authors": [
      "Michalis Xenos",
      "Vasiliki Velli"
    ],
    "abstract": "This paper presents a game based on storytelling, in which the players are faced with ethical dilemmas related to software engineering specific issues. The players' choices have consequences on how the story unfolds and could lead to various alternative endings. This Ethics Game was used as a tool to mediate the learning activity and it was evaluated by 144 students during a Software Engineering Course on the 2017-2018 academic year. This evaluation was based on a within-subject pre-post design methodology and provided insights on the students learning gain (academic performance), as well as on the students' perceived educational experience. In addition, it provided the results of the students' usability evaluation of the Ethics Game. The results indicated that the students did improve their knowledge about software engineering ethics by playing this game. Also, they considered this game to be a useful educational tool and of high usability. Female students had statistically significant higher knowledge gain and higher evaluation scores than male students, while no statistically significant differences were measured in groups based on the year of study.",
    "lastUpdated": "2019-03-04T16:26:26Z",
    "categories": [
      "cs.HC",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1903.01333v1"
  },
  {
    "title": "Augmented Utilitarianism for AGI Safety",
    "authors": [
      "Nadisha-Marie Aliman",
      "Leon Kester"
    ],
    "abstract": "In the light of ongoing progresses of research on artificial intelligent systems exhibiting a steadily increasing problem-solving ability, the identification of practicable solutions to the value alignment problem in AGI Safety is becoming a matter of urgency. In this context, one preeminent challenge that has been addressed by multiple researchers is the adequate formulation of utility functions or equivalents reliably capturing human ethical conceptions. However, the specification of suitable utility functions harbors the risk of \"perverse instantiation\" for which no final consensus on responsible proactive countermeasures has been achieved so far. Amidst this background, we propose a novel socio-technological ethical framework denoted Augmented Utilitarianism which directly alleviates the perverse instantiation problem. We elaborate on how augmented by AI and more generally science and technology, it might allow a society to craft and update ethical utility functions while jointly undergoing a dynamical ethical enhancement. Further, we elucidate the need to consider embodied simulations in the design of utility functions for AGIs aligned with human values. Finally, we discuss future prospects regarding the usage of the presented scientifically grounded ethical framework and mention possible challenges.",
    "lastUpdated": "2019-04-02T16:54:38Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1904.01540v1"
  },
  {
    "title": "Requisite Variety in Ethical Utility Functions for AI Value Alignment",
    "authors": [
      "Nadisha-Marie Aliman",
      "Leon Kester"
    ],
    "abstract": "Being a complex subject of major importance in AI Safety research, value alignment has been studied from various perspectives in the last years. However, no final consensus on the design of ethical utility functions facilitating AI value alignment has been achieved yet. Given the urgency to identify systematic solutions, we postulate that it might be useful to start with the simple fact that for the utility function of an AI not to violate human ethical intuitions, it trivially has to be a model of these intuitions and reflect their variety $ - $ whereby the most accurate models pertaining to human entities being biological organisms equipped with a brain constructing concepts like moral judgements, are scientific models. Thus, in order to better assess the variety of human morality, we perform a transdisciplinary analysis applying a security mindset to the issue and summarizing variety-relevant background knowledge from neuroscience and psychology. We complement this information by linking it to augmented utilitarianism as a suitable ethical framework. Based on that, we propose first practical guidelines for the design of approximate ethical goal functions that might better capture the variety of human moral judgements. Finally, we conclude and address future possible challenges.",
    "lastUpdated": "2019-06-30T18:55:31Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1907.00430v1"
  },
  {
    "title": "Saving Face: Investigating the Ethical Concerns of Facial Recognition Auditing",
    "authors": [
      "Inioluwa Deborah Raji",
      "Timnit Gebru",
      "Margaret Mitchell",
      "Joy Buolamwini",
      "Joonseok Lee",
      "Emily Denton"
    ],
    "abstract": "Although essential to revealing biased performance, well intentioned attempts at algorithmic auditing can have effects that may harm the very populations these measures are meant to protect. This concern is even more salient while auditing biometric systems such as facial recognition, where the data is sensitive and the technology is often used in ethically questionable manners. We demonstrate a set of five ethical concerns in the particular case of auditing commercial facial processing technology, highlighting additional design considerations and ethical tensions the auditor needs to be aware of so as not exacerbate or complement the harms propagated by the audited system. We go further to provide tangible illustrations of these concerns, and conclude by reflecting on what these concerns mean for the role of the algorithmic audit and the fundamental product limitations they reveal.",
    "lastUpdated": "2020-01-03T20:03:44Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2001.00964v1"
  },
  {
    "title": "Integrating data science ethics into an undergraduate major",
    "authors": [
      "Benjamin S. Baumer",
      "Randi L. Garcia",
      "Albert Y. Kim",
      "Katherine M. Kinnaird",
      "Miles Q. Ott"
    ],
    "abstract": "We present a programmatic approach to incorporating ethics into an undergraduate major in statistical and data sciences. We discuss departmental-level initiatives designed to meet the National Academy of Sciences recommendation for weaving ethics into the curriculum from top-to-bottom as our majors progress from our introductory courses to our senior capstone course, as well as from side-to-side through co-curricular programming. We also provide six examples of data science ethics modules used in five different courses at our liberal arts college, each focusing on a different ethical consideration. The modules are designed to be portable such that they can be flexibly incorporated into existing courses at different levels of instruction with minimal disruption to syllabi. We conclude with next steps and preliminary assessments.",
    "lastUpdated": "2020-07-31T19:45:51Z",
    "categories": [
      "stat.OT",
      "cs.OH",
      "00A05",
      "K.7.4; K.3.2"
    ],
    "url": "http://arxiv.org/abs/2001.07649v2"
  },
  {
    "title": "Toward equipping Artificial Moral Agents with multiple ethical theories",
    "authors": [
      "George Rautenbach",
      "C. Maria Keet"
    ],
    "abstract": "Artificial Moral Agents (AMA's) is a field in computer science with the purpose of creating autonomous machines that can make moral decisions akin to how humans do. Researchers have proposed theoretical means of creating such machines, while philosophers have made arguments as to how these machines ought to behave, or whether they should even exist. Of the currently theorised AMA's, all research and design has been done with either none or at most one specified normative ethical theory as basis. This is problematic because it narrows down the AMA's functional ability and versatility which in turn causes moral outcomes that a limited number of people agree with (thereby undermining an AMA's ability to be moral in a human sense). As solution we design a three-layer model for general normative ethical theories that can be used to serialise the ethical views of people and businesses for an AMA to use during reasoning. Four specific ethical norms (Kantianism, divine command theory, utilitarianism, and egoism) were modelled and evaluated as proof of concept for normative modelling. Furthermore, all models were serialised to XML/XSD as proof of support for computerisation.",
    "lastUpdated": "2020-03-02T14:33:22Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "H.1.0; I.2.0; I.6.5; K.m"
    ],
    "url": "http://arxiv.org/abs/2003.00935v1"
  },
  {
    "title": "Ethical Guidelines for the Construction of Digital Nudges",
    "authors": [
      "Christian Meske",
      "Ireti Amojo"
    ],
    "abstract": "Under certain circumstances, humans tend to behave in irrational ways, leading to situations in which they make undesirable choices. The concept of digital nudging addresses these limitations of bounded rationality by establishing a libertarian paternalist alternative to nudge users in virtual environments towards their own preferential choices. Thereby, choice architectures are designed to address biases and heuristics involved in cognitive thinking. As research on digital nudging has become increasingly popular in the Information Systems community, an increasing necessity for ethical guidelines has emerged around this concept to safeguard its legitimization in distinction to e.g. persuasion or manipulation. However, reflecting on ethical debates regarding digital nudging in academia, we find that current conceptualizations are scare. This is where on the basis of existing literature, we provide a conceptualization of ethical guidelines for the design of digital nudges, and thereby aim to ensure the applicability of nudging mechanisms in virtual environments.",
    "lastUpdated": "2020-03-11T12:08:26Z",
    "categories": [
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/2003.05249v1"
  },
  {
    "title": "ECCOLA -- a Method for Implementing Ethically Aligned AI Systems",
    "authors": [
      "Ville Vakkuri",
      "Kai-Kristian Kemell",
      "Pekka Abrahamsson"
    ],
    "abstract": "Various recent Artificial Intelligence (AI) system failures, some of which have made the global headlines, have highlighted issues in these systems. These failures have resulted in calls for more ethical AI systems that better take into account their effects on various stakeholders. However, implementing AI ethics into practice is still an on-going challenge. High-level guidelines for doing so exist, devised by governments and private organizations alike, but lack practicality for developers. To address this issue, in this paper, we present a method for implementing AI ethics. The method, ECCOLA, has been iteratively developed using a cyclical action design research approach. The method aims at making the high-level AI ethics principles more practical, making it possible for developers to more easily implement them in practice.",
    "lastUpdated": "2020-11-09T16:09:11Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2004.08377v2"
  },
  {
    "title": "Digital tools against COVID-19: Framing the ethical challenges and how to address them",
    "authors": [
      "Urs Gasser",
      "Marcello Ienca",
      "James Scheibner",
      "Joanna Sleigh",
      "Effy Vayena"
    ],
    "abstract": "Data collection and processing via digital public health technologies are being promoted worldwide by governments and private companies as strategic remedies for mitigating the COVID-19 pandemic and loosening lockdown measures. However, the ethical and legal boundaries of deploying digital tools for disease surveillance and control purposes are unclear, and a rapidly evolving debate has emerged globally around the promises and risks of mobilizing digital tools for public health. To help scientists and policymakers navigate technological and ethical uncertainty, we present a typology of the primary digital public health applications currently in use. Namely: proximity and contact tracing, symptom monitoring, quarantine control, and flow modeling. For each, we discuss context-specific risks, cross-sectional issues, and ethical concerns. Finally, in recognition of the need for practical guidance, we propose a navigation aid for policymakers made up of ten steps for the ethical use of digital public health tools.",
    "lastUpdated": "2020-04-21T18:39:08Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2004.10236v1"
  },
  {
    "title": "Value-based Engineering for Ethics by Design",
    "authors": [
      "Sarah Spiekermann",
      "Till Winkler"
    ],
    "abstract": "This article gives a methodological overview of Value-based Engineering for ethics by design. It discusses key challenges and measures involved in eliciting, conceptualizing, prioritizing and respecting values in system design. Thereby it draws from software engineering, value sensitive design, design thinking and participatory design as well as from philosophical sources, especially Material Ethics of Value. The article recognizes timely challenges for Value-based Engineering, such as compatibility with agile forms of system development, responsibility in hardly controllable ecosystems of interconnected services, fearless integration of external stakeholders and the difficulty in measuring the ethicality of a system. Finally, the Value-based Engineering methodology presented here benefits from learnings collected in the IEEE P7000 standardization process as well as from a case study. P7000 has been set up by IEEE to establish a process model, which addresses ethical considerations throughout the various stages of system initiation, analysis and design.",
    "lastUpdated": "2020-10-23T12:28:17Z",
    "categories": [
      "cs.CY",
      "cs.GL"
    ],
    "url": "http://arxiv.org/abs/2004.13676v2"
  },
  {
    "title": "Ethical Machine Learning in Health Care",
    "authors": [
      "Irene Y. Chen",
      "Emma Pierson",
      "Sherri Rose",
      "Shalmali Joshi",
      "Kadija Ferryman",
      "Marzyeh Ghassemi"
    ],
    "abstract": "The use of machine learning (ML) in health care raises numerous ethical concerns, especially as models can amplify existing health inequities. Here, we outline ethical considerations for equitable ML in the advancement of health care. Specifically, we frame ethics of ML in health care through the lens of social justice. We describe ongoing efforts and outline challenges in a proposed pipeline of ethical ML in health, ranging from problem selection to post-deployment considerations. We close by summarizing recommendations to address these challenges.",
    "lastUpdated": "2020-10-08T03:26:31Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2009.10576v3"
  },
  {
    "title": "Good proctor or \"Big Brother\"? AI Ethics and Online Exam Supervision Technologies",
    "authors": [
      "Simon Coghlan",
      "Tim Miller",
      "Jeannie Paterson"
    ],
    "abstract": "This article philosophically analyzes online exam supervision technologies, which have been thrust into the public spotlight due to campus lockdowns during the COVID-19 pandemic and the growing demand for online courses. Online exam proctoring technologies purport to provide effective oversight of students sitting online exams, using artificial intelligence (AI) systems and human invigilators to supplement and review those systems. Such technologies have alarmed some students who see them as `Big Brother-like', yet some universities defend their judicious use. Critical ethical appraisal of online proctoring technologies is overdue. This article philosophically analyzes these technologies, focusing on the ethical concepts of academic integrity, fairness, non-maleficence, transparency, privacy, respect for autonomy, liberty, and trust. Most of these concepts are prominent in the new field of AI ethics and all are relevant to the education context. The essay provides ethical considerations that educational institutions will need to carefully review before electing to deploy and govern specific online proctoring technologies.",
    "lastUpdated": "2020-11-15T22:53:56Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2011.07647v1"
  },
  {
    "title": "Human computation requires and enables a new approach to ethical review",
    "authors": [
      "Libuše Hannah Vepřek",
      "Patricia Seymour",
      "Pietro Michelucci"
    ],
    "abstract": "With humans increasingly serving as computational elements in distributed information processing systems and in consideration of the profit-driven motives and potential inequities that might accompany the emerging thinking economy[1], we recognize the need for establishing a set of related ethics to ensure the fair treatment and wellbeing of online cognitive laborers and the conscientious use of the capabilities to which they contribute. Toward this end, we first describe human-in-the-loop computing in context of the new concerns it raises that are not addressed by traditional ethical research standards. We then describe shortcomings in the traditional approach to ethical review and introduce a dynamic approach for sustaining an ethical framework that can continue to evolve within the rapidly shifting context of disruptive new technologies.",
    "lastUpdated": "2020-11-21T09:44:29Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "68T01"
    ],
    "url": "http://arxiv.org/abs/2011.10754v1"
  },
  {
    "title": "Hack Weeks as a model for Data Science Education and Collaboration",
    "authors": [
      "Daniela Huppenkothen",
      "Anthony Arendt",
      "David W. Hogg",
      "Karthik Ram",
      "Jake VanderPlas",
      "Ariel Rokem"
    ],
    "abstract": "Across almost all scientific disciplines, the instruments that record our experimental data and the methods required for storage and data analysis are rapidly increasing in complexity. This gives rise to the need for scientific communities to adapt on shorter time scales than traditional university curricula allow for, and therefore requires new modes of knowledge transfer. The universal applicability of data science tools to a broad range of problems has generated new opportunities to foster exchange of ideas and computational workflows across disciplines. In recent years, hack weeks have emerged as an effective tool for fostering these exchanges by providing training in modern data analysis workflows. While there are variations in hack week implementation, all events consist of a common core of three components: tutorials in state-of-the-art methodology, peer-learning and project work in a collaborative environment. In this paper, we present the concept of a hack week in the larger context of scientific meetings and point out similarities and differences to traditional conferences. We motivate the need for such an event and present in detail its strengths and challenges. We find that hack weeks are successful at cultivating collaboration and the exchange of knowledge. Participants self-report that these events help them both in their day-to-day research as well as their careers. Based on our results, we conclude that hack weeks present an effective, easy-to-implement, fairly low-cost tool to positively impact data analysis literacy in academic disciplines, foster collaboration and cultivate best practices.",
    "lastUpdated": "2017-10-31T18:07:10Z",
    "categories": [
      "physics.ed-ph",
      "astro-ph.IM",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1711.00028v1"
  },
  {
    "title": "RFID et nouvelles technologies de communication; enjeux économiques incontournables et problèmes d'éthique RFID and new communication technologies - economic challenges and ethic problems",
    "authors": [
      "André Thomas"
    ],
    "abstract": "Auto ID technologies such RFID are more and more commonly used in industry and in distribution. Human are identify thanks to this technology, too. A lot of people have highlighted ethic problems relative to their utilization. This paper present first RFID technology, then it presents their opportunities in business and industry. In a second part, the paper highlights some ethic problems leading to a necessary standardization and regulation.",
    "lastUpdated": "2010-01-04T08:01:57Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1001.0453v1"
  },
  {
    "title": "Formalizing Preference Utilitarianism in Physical World Models",
    "authors": [
      "Caspar Oesterheld"
    ],
    "abstract": "Most ethical work is done at a low level of formality. This makes practical moral questions inaccessible to formal and natural sciences and can lead to misunderstandings in ethical discussion. In this paper, we use Bayesian inference to introduce a formalization of preference utilitarianism in physical world models, specifically cellular automata. Even though our formalization is not immediately applicable, it is a first step in providing ethics and ultimately the question of how to \"make the world better\" with a formal basis.",
    "lastUpdated": "2015-11-30T15:46:32Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1504.05603v3"
  },
  {
    "title": "Ethical, Legal and Social aspects of Information and Communication Technology",
    "authors": [
      "Minati Mishra"
    ],
    "abstract": "In this era of computers and communication technology where computers and internet have made their ways to every sphere of life from offices to residences, reservation counters to banks to post offices, small retail shops to big organizations, health care units to entertainment industries etc., there emerged numerous questions regarding the ethical and legal uses of Information and Communication Technology (ICT). Like any other technological inventions ICT too has created both positive and negative impacts on the society. This paper aims at exploring some of these issues in brief.",
    "lastUpdated": "2015-07-30T10:48:59Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1507.08447v1"
  },
  {
    "title": "Automated Reasoning for Robot Ethics",
    "authors": [
      "Ulrich Furbach",
      "Claudia Schon",
      "Frieder Stolzenburg"
    ],
    "abstract": "Deontic logic is a very well researched branch of mathematical logic and philosophy. Various kinds of deontic logics are considered for different application domains like argumentation theory, legal reasoning, and acts in multi-agent systems. In this paper, we show how standard deontic logic can be used to model ethical codes for multi-agent systems. Furthermore we show how Hyper, a high performance theorem prover, can be used to prove properties of these ethical codes.",
    "lastUpdated": "2015-02-20T11:38:58Z",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "url": "http://arxiv.org/abs/1502.05838v1"
  },
  {
    "title": "Ethical Dimensions of Visualization Research",
    "authors": [
      "Michael Correll"
    ],
    "abstract": "Visualizations have a potentially enormous influence on how data are used to make decisions across all areas of human endeavor. However, it is not clear how this power connects to ethical duties: what obligations do we have when it comes to visualizations and visual analytics systems, beyond our duties as scientists and engineers? Drawing on historical and contemporary examples, I address the moral components of the design and use of visualizations, identify some ongoing areas of visualization research with ethical dilemmas, and propose a set of additional moral obligations that we have as designers, builders, and researchers of visualizations.",
    "lastUpdated": "2018-12-19T23:20:03Z",
    "categories": [
      "cs.HC",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1811.07271v2"
  },
  {
    "title": "Ethics of Artificial Intelligence Demarcations",
    "authors": [
      "Anders Braarud Hanssen",
      "Stefano Nichele"
    ],
    "abstract": "In this paper we present a set of key demarcations, particularly important when discussing ethical and societal issues of current AI research and applications. Properly distinguishing issues and concerns related to Artificial General Intelligence and weak AI, between symbolic and connectionist AI, AI methods, data and applications are prerequisites for an informed debate. Such demarcations would not only facilitate much-needed discussions on ethics on current AI technologies and research. In addition sufficiently establishing such demarcations would also enhance knowledge-sharing and support rigor in interdisciplinary research between technical and social sciences.",
    "lastUpdated": "2019-05-16T11:59:10Z",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1904.10239v2"
  },
  {
    "title": "Towards Ethical Machines Via Logic Programming",
    "authors": [
      "Abeer Dyoub",
      "Stefania Costantini",
      "Francesca A. Lisi"
    ],
    "abstract": "Autonomous intelligent agents are playing increasingly important roles in our lives. They contain information about us and start to perform tasks on our behalves. Chatbots are an example of such agents that need to engage in a complex conversations with humans. Thus, we need to ensure that they behave ethically. In this work we propose a hybrid logic-based approach for ethical chatbots.",
    "lastUpdated": "2019-09-18T07:10:55Z",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.LO",
      "I.2;I.2.3;I.2.6"
    ],
    "url": "http://arxiv.org/abs/1909.08255v1"
  },
  {
    "title": "Combating The Machine Ethics Crisis: An Educational Approach",
    "authors": [
      "Tai Vu"
    ],
    "abstract": "In recent years, the availability of massive data sets and improved computing power have driven the advent of cutting-edge machine learning algorithms. However, this trend has triggered growing concerns associated with its ethical issues. In response to such a phenomenon, this study proposes a feasible solution that combines ethics and computer science materials in artificial intelligent classrooms. In addition, the paper presents several arguments and evidence in favor of the necessity and effectiveness of this integrated approach.",
    "lastUpdated": "2020-04-02T05:04:33Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2004.00817v1"
  },
  {
    "title": "Ethical Issues Regarding the Use of AI Profiling Services for Recruiting: The Japanese Rikunabi Data Scandal",
    "authors": [
      "Kudo Fumiko",
      "Hiromi Arai",
      "Arisa Ema"
    ],
    "abstract": "The ethical, legal, and social challenges involved in the use of profiling services for recruitment are the focus of many previous studies; however, the processes vary depending on the social system and cultural practices. In August 2019, a scandal occurred in Japan in which a recruitment management company was found to have breached users' and students' trust by selling their data to clients. By sharing the Japanese recruitment context and associated laws, this article contributes to our understanding of the ethical issues involved in artificial intelligence profiling and in handling sensitive personal information.",
    "lastUpdated": "2020-05-18T12:52:53Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2005.08663v1"
  },
  {
    "title": "Machine Ethics and Automated Vehicles",
    "authors": [
      "Noah J. Goodall"
    ],
    "abstract": "Road vehicle travel at a reasonable speed involves some risk, even when using computer-controlled driving with failure-free hardware and perfect sensing. A fully-automated vehicle must continuously decide how to allocate this risk without a human driver's oversight. These are ethical decisions, particularly in instances where an automated vehicle cannot avoid crashing. In this chapter, I introduce the concept of moral behavior for an automated vehicle, argue the need for research in this area through responses to anticipated critiques, and discuss relevant applications from machine ethics and moral modeling research.",
    "lastUpdated": "2020-10-29T15:14:47Z",
    "categories": [
      "cs.CY",
      "K.4.1"
    ],
    "url": "http://arxiv.org/abs/2010.15665v1"
  },
  {
    "title": "FuturICT - The Road towards Ethical ICT",
    "authors": [
      "Jeroen van den Hoven",
      "Dirk Helbing",
      "Dino Pedreschi",
      "Josep Domingo-Ferrer",
      "Fosca Gianotti",
      "Markus Christen"
    ],
    "abstract": "The pervasive use of information and communication technology (ICT) in modern societies enables countless opportunities for individuals, institutions, businesses and scientists, but also raises difficult ethical and social problems. In particular, ICT helped to make societies more complex and thus harder to understand, which impedes social and political interventions to avoid harm and to increase the common good. To overcome this obstacle, the large-scale EU flagship proposal FuturICT intends to create a platform for accessing global human knowledge as a public good and instruments to increase our understanding of the information society by making use of ICT-based research. In this contribution, we outline the ethical justification for such an endeavor. We argue that the ethical issues raised by FuturICT research projects overlap substantially with many of the known ethical problems emerging from ICT use in general. By referring to the notion of Value Sensitive Design, we show for the example of privacy how this core value of responsible ICT can be protected in pursuing research in the framework of FuturICT. In addition, we discuss further ethical issues and outline the institutional design of FuturICT allowing to address them.",
    "lastUpdated": "2012-10-30T21:44:43Z",
    "categories": [
      "cs.CY",
      "cs.DL"
    ],
    "url": "http://arxiv.org/abs/1210.8181v1"
  },
  {
    "title": "Towards Moral Autonomous Systems",
    "authors": [
      "Vicky Charisi",
      "Louise Dennis",
      "Michael Fisher",
      "Robert Lieck",
      "Andreas Matthias",
      "Marija Slavkovik",
      "Janina Sombetzki",
      "Alan F. T. Winfield",
      "Roman Yampolskiy"
    ],
    "abstract": "Both the ethics of autonomous systems and the problems of their technical implementation have by now been studied in some detail. Less attention has been given to the areas in which these two separate concerns meet. This paper, written by both philosophers and engineers of autonomous systems, addresses a number of issues in machine ethics that are located at precisely the intersection between ethics and engineering. We first discuss the main challenges which, in our view, machine ethics posses to moral philosophy. We them consider different approaches towards the conceptual design of autonomous systems and their implications on the ethics implementation in such systems. Then we examine problematic areas regarding the specification and verification of ethical behavior in autonomous systems, particularly with a view towards the requirements of future legislation. We discuss transparency and accountability issues that will be crucial for any future wide deployment of autonomous systems in society. Finally we consider the, often overlooked, possibility of intentional misuse of AI systems and the possible dangers arising out of deliberately unethical design, implementation, and use of autonomous robots.",
    "lastUpdated": "2017-10-31T13:12:16Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1703.04741v3"
  },
  {
    "title": "BERT has a Moral Compass: Improvements of ethical and moral values of machines",
    "authors": [
      "Patrick Schramowski",
      "Cigdem Turan",
      "Sophie Jentzsch",
      "Constantin Rothkopf",
      "Kristian Kersting"
    ],
    "abstract": "Allowing machines to choose whether to kill humans would be devastating for world peace and security. But how do we equip machines with the ability to learn ethical or even moral choices? Jentzsch et al.(2019) showed that applying machine learning to human texts can extract deontological ethical reasoning about \"right\" and \"wrong\" conduct by calculating a moral bias score on a sentence level using sentence embeddings. The machine learned that it is objectionable to kill living beings, but it is fine to kill time; It is essential to eat, yet one might not eat dirt; it is important to spread information, yet one should not spread misinformation. However, the evaluated moral bias was restricted to simple actions -- one verb -- and a ranking of actions with surrounding context. Recently BERT ---and variants such as RoBERTa and SBERT--- has set a new state-of-the-art performance for a wide range of NLP tasks. But has BERT also a better moral compass? In this paper, we discuss and show that this is indeed the case. Thus, recent improvements of language representations also improve the representation of the underlying ethical and moral values of the machine. We argue that through an advanced semantic representation of text, BERT allows one to get better insights of moral and ethical values implicitly represented in text. This enables the Moral Choice Machine (MCM) to extract more accurate imprints of moral choices and ethical values.",
    "lastUpdated": "2019-12-11T11:27:06Z",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1912.05238v1"
  },
  {
    "title": "The Potential Impact of Quantum Computers on Society",
    "authors": [
      "Ronald de Wolf"
    ],
    "abstract": "This paper considers the potential impact that the nascent technology of quantum computing may have on society. It focuses on three areas: cryptography, optimization, and simulation of quantum systems. We will also discuss some ethical aspects of these developments, and ways to mitigate the risks.",
    "lastUpdated": "2017-12-14T18:24:41Z",
    "categories": [
      "cs.CY",
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/1712.05380v1"
  },
  {
    "title": "Consider ethical and social challenges in smart grid research",
    "authors": [
      "Valentin Robu",
      "David Flynn",
      "Merlinda Andoni",
      "Maizura Mokhtar"
    ],
    "abstract": "Artificial Intelligence and Machine Learning are increasingly seen as key technologies for building more decentralised and resilient energy grids, but researchers must consider the ethical and social implications of their use",
    "lastUpdated": "2019-11-26T11:06:09Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1912.00783v1"
  },
  {
    "title": "Ethical Considerations for AI Researchers",
    "authors": [
      "Kyle Dent"
    ],
    "abstract": "Use of artificial intelligence is growing and expanding into applications that impact people's lives. People trust their technology without really understanding it or its limitations. There is the potential for harm and we are already seeing examples of that in the world. AI researchers have an obligation to consider the impact of intelligent applications they work on. While the ethics of AI is not clear-cut, there are guidelines we can consider to minimize the harm we might introduce.",
    "lastUpdated": "2020-06-13T04:31:42Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2006.07558v1"
  },
  {
    "title": "Practical and Ethical Considerations in the Effective use of Emotion and Sentiment Lexicons",
    "authors": [
      "Saif M. Mohammad"
    ],
    "abstract": "Lexicons of word-emotion associations are widely used in research and real-world applications. As part of my research, I have created several such lexicons (e.g., the NRC Emotion Lexicon). This paper outlines some practical and ethical considerations involved in the effective use of these lexical resources.",
    "lastUpdated": "2020-12-09T19:25:56Z",
    "categories": [
      "cs.CL"
    ],
    "url": "http://arxiv.org/abs/2011.03492v2"
  },
  {
    "title": "Semistable divisorial contractions",
    "authors": [
      "Paul Hacking"
    ],
    "abstract": "The semistable minimal model program is a special case of the minimal model program concerning 3-folds fibred over a curve and birational morphisms preserving this structure. We classify semistable divisorial contractions which contract the exceptional divisor to a normal point of a fibre. Our results can be applied to describe compact moduli spaces of surfaces.",
    "lastUpdated": "2003-10-22T14:43:11Z",
    "categories": [
      "math.AG",
      "14E30 (Primary), 14J10 (Secondary)"
    ],
    "url": "http://arxiv.org/abs/math/0208049v2"
  },
  {
    "title": "Compact moduli of plane curves",
    "authors": [
      "Paul Hacking"
    ],
    "abstract": "We construct a compactification M_d of the moduli space of plane curves of degree d. We regard a plane curve C as a surface-divisor pair (P^2,C) and define M_d as a moduli space of pairs (X,D) where X is a degeneration of the plane. We show that, if d is not divisible by 3, the stack M_d is smooth and the degenerate surfaces X can be described explicitly.",
    "lastUpdated": "2003-10-22T19:02:05Z",
    "categories": [
      "math.AG",
      "14H10, 14J10 (Primary), 14E30 (Secondary)"
    ],
    "url": "http://arxiv.org/abs/math/0310354v1"
  },
  {
    "title": "Compact moduli of hyperplane arrangements",
    "authors": [
      "Paul Hacking"
    ],
    "abstract": "The minimal model program suggests a compactification of the moduli space of hyperplane arrangements which is a moduli space of stable pairs. Here, a stable pair consists of a scheme X which is a degeneration of projective space and a divisor D=D_1+..+D_n on X which is a limit of hyperplane arrangements. For example, in the 1-dimensional case, the stable pairs are stable curves of genus 0 with n marked points. Kapranov has defined an alternative compactification using his Chow quotient construction, which may be described fairly explicitly. We prove that these two compactifications coincide. We deduce a description of all stable pairs.",
    "lastUpdated": "2003-10-30T20:12:19Z",
    "categories": [
      "math.AG",
      "math.CO",
      "14J10, 52C35"
    ],
    "url": "http://arxiv.org/abs/math/0310479v1"
  },
  {
    "title": "The moduli space of curves is rigid",
    "authors": [
      "Paul Hacking"
    ],
    "abstract": "We prove that the moduli stack of stable curves of genus g with n marked points is rigid, i.e., has no infinitesimal deformations. This confirms the first case of a principle proposed by Kapranov. It can also be viewed as a version of Mostow rigidity for the mapping class group.",
    "lastUpdated": "2008-08-28T18:36:08Z",
    "categories": [
      "math.AG",
      "14H10"
    ],
    "url": "http://arxiv.org/abs/math/0509567v2"
  },
  {
    "title": "Homology of tropical varieties",
    "authors": [
      "Paul Hacking"
    ],
    "abstract": "Given a closed subvariety of an algebraic torus, the associated tropical variety is a polyhedral fan in the space of 1-parameter subgroups of the torus which describes the behaviour of the subvariety at infinity. We show that the link of the origin has only top rational homology if a genericity condition is satisfied. Our result is obtained using work of Tevelev and Deligne's theory of mixed Hodge structures.",
    "lastUpdated": "2008-08-28T18:46:49Z",
    "categories": [
      "math.AG",
      "math.CO",
      "14"
    ],
    "url": "http://arxiv.org/abs/0711.1847v3"
  },
  {
    "title": "Smoothable del Pezzo surfaces with quotient singularities",
    "authors": [
      "Paul Hacking",
      "Yuri Prokhorov"
    ],
    "abstract": "We give a complete classification of del Pezzo surfaces with quotient singularities and Picard rank 1 which admit a Q-Gorenstein smoothing. There are 14 infinite families of toric examples. The surfaces in each family correspond to solutions of a Markov-type equation. The remaining surfaces are obtained as deformations of the toric surfaces or belong to a finite list of sporadic surfaces.",
    "lastUpdated": "2008-08-28T19:39:15Z",
    "categories": [
      "math.AG",
      "14J10, 14E30"
    ],
    "url": "http://arxiv.org/abs/0808.1550v2"
  },
  {
    "title": "Hacking the Sky",
    "authors": [
      "R. J. Simpson"
    ],
    "abstract": "In this article I present some special astronomical scripts created for Google Earth, Google Sky and Twitter. These 'hacks' are examples of the ways in which such tools can be used either alone, in on conjunction with online services. The result of a combination of multiple, online services to form a new facility is called a mash-up. Some of what follows falls into that definition. As we move into an era of online data and tools, it is the network as a whole that becomes important. Tools emerging from this network can be capable of more than the sum of their parts.",
    "lastUpdated": "2009-03-03T10:18:55Z",
    "categories": [
      "astro-ph.IM"
    ],
    "url": "http://arxiv.org/abs/0903.0484v1"
  },
  {
    "title": "Exceptional bundles associated to degenerations of surfaces",
    "authors": [
      "Paul Hacking"
    ],
    "abstract": "In 1981 J. Wahl described smoothings of surface quotient singularities with no vanishing cycles. Given a smoothing of a projective surface X of this type, we construct an associated exceptional vector bundle on the nearby fiber Y in the case H^{2,0}(Y)=H^1(Y)=0. If Y is the projective plane we show that our construction establishes a bijective correspondence between the possible degenerate surfaces X and exceptional bundles on Y modulo dualizing and tensoring by line bundles. If Y is of general type then our construction establishes a connection between components of the boundary of the moduli space of surfaces deformation equivalent to Y and exceptional bundles on Y.",
    "lastUpdated": "2011-07-13T19:47:26Z",
    "categories": [
      "math.AG",
      "14J10, 14J60"
    ],
    "url": "http://arxiv.org/abs/1107.2644v1"
  },
  {
    "title": "Compact moduli spaces of surfaces of general type",
    "authors": [
      "Paul Hacking"
    ],
    "abstract": "We give an introduction to the compactification of the moduli space of surfaces of general type introduced by Koll\\'ar and Shepherd-Barron and generalized to the case of surfaces with a divisor by Alexeev. The construction is an application of Mori's minimal model program for 3-folds. We review the example of the projective plane with a curve of degree d > 3. We explain a connection between the geometry of the boundary of the compactification of the moduli space and the classification of vector bundles on the surface in the case H^{2,0}=H^1=0.",
    "lastUpdated": "2011-07-14T02:48:40Z",
    "categories": [
      "math.AG",
      "14J10"
    ],
    "url": "http://arxiv.org/abs/1107.2717v1"
  },
  {
    "title": "Cyber Attacks and Public Embarrassment: A Survey of Some Notable Hacks",
    "authors": [
      "Jana Shakarian",
      "Paulo Shakarian",
      "Andrew Ruef"
    ],
    "abstract": "We hear it all too often in the media: an organization is attacked, its data, often containing personally identifying information, is made public, and a hacking group emerges to claim credit. In this excerpt, we discuss how such groups operate and describe the details of a few major cyber-attacks of this sort in the wider context of how they occurred. We feel that understanding how such groups have operated in the past will give organizations ideas of how to defend against them in the future.",
    "lastUpdated": "2015-01-24T02:35:04Z",
    "categories": [
      "cs.CY",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1501.05990v1"
  },
  {
    "title": "Product Offerings in Malicious Hacker Markets",
    "authors": [
      "Ericsson Marin",
      "Ahmad Diab",
      "Paulo Shakarian"
    ],
    "abstract": "Marketplaces specializing in malicious hacking products - including malware and exploits - have recently become more prominent on the darkweb and deepweb. We scrape 17 such sites and collect information about such products in a unified database schema. Using a combination of manual labeling and unsupervised clustering, we examine a corpus of products in order to understand their various categories and how they become specialized with respect to vendor and marketplace. This initial study presents how we effectively employed unsupervised techniques to this data as well as the types of insights we gained on various categories of malicious hacking products.",
    "lastUpdated": "2016-07-26T21:32:11Z",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1607.07903v1"
  },
  {
    "title": "Cluster algebras are Cox rings",
    "authors": [
      "Travis Mandel"
    ],
    "abstract": "It was recently shown by Gross, Hacking, and Keel that, in the absence of frozen indices, a cluster A-variety with generic coefficients is the universal torsor of the corresponding cluster X-variety with corresponding coefficients. We extend this to allow for frozen vectors and corresponding partial compactifications of the A- and X-spaces. When certain assumptions are satisfied, we conclude that the theta bases of Gross-Hacking-Keel-Kontsevich give bases of global sections for every line bundle on the leaves of the partially compactified X-space. We note that our arguments work without assuming that the exchange matrix is skew-symmetrizable.",
    "lastUpdated": "2017-07-18T18:57:28Z",
    "categories": [
      "math.AG",
      "13F60"
    ],
    "url": "http://arxiv.org/abs/1707.05819v1"
  },
  {
    "title": "Upconversion based receivers for quantum hacking resistant quantum key distribution",
    "authors": [
      "Nitin Jain",
      "Gregory S. Kanter"
    ],
    "abstract": "We propose a novel upconversion (sum frequency generation) based quantum-optical setup that can be employed as a receiver (Bob) in practical quantum key distribution systems. The pump governing the upconversion process is produced and utilized inside the physical receiver, making its access or control unrealistic for an external adversary (Eve). This pump facilitates several properties which permit Bob to define and control the modes that can participate in the quantum measurement. Furthermore, by manipulating and monitoring the characteristics of the pump pulses, Bob can detect a wide range of quantum hacking attacks launched by Eve.",
    "lastUpdated": "2015-12-08T03:52:29Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/1509.06328v2"
  },
  {
    "title": "Toward a Better Understanding of Leaderboard",
    "authors": [
      "Wenjie Zheng"
    ],
    "abstract": "The leaderboard in machine learning competitions is a tool to show the performance of various participants and to compare them. However, the leaderboard quickly becomes no longer accurate, due to hack or overfitting. This article gives two pieces of advice to prevent easy hack or overfitting. By following these advice, we reach the conclusion that something like the Ladder leaderboard introduced in [blum2015ladder] is inevitable. With this understanding, we naturally simplify Ladder by eliminating its redundant computation and explain how to choose the parameter and interpret it. We also prove that the sample complexity is cubic to the desired precision of the leaderboard.",
    "lastUpdated": "2017-06-07T13:12:56Z",
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.AP"
    ],
    "url": "http://arxiv.org/abs/1510.03349v2"
  },
  {
    "title": "Cosmological perturbation theory and quantum gravity",
    "authors": [
      "Romeo Brunetti",
      "Klaus Fredenhagen",
      "Thomas-Paul Hack",
      "Nicola Pinamonti",
      "Katarzyna Rejzner"
    ],
    "abstract": "It is shown how cosmological perturbation theory arises from a fully quantized perturbative theory of quantum gravity. Central for the derivation is a non-perturbative concept of gauge-invariant local observables by means of which perturbative invariant expressions of arbitrary order are generated. In particular, in the linearised theory, first order gauge-invariant observables familiar from cosmological perturbation theory are recovered. Explicit expressions of second order quantities are presented as well.",
    "lastUpdated": "2016-05-09T13:08:46Z",
    "categories": [
      "gr-qc",
      "hep-th",
      "math-ph",
      "math.MP",
      "81T20"
    ],
    "url": "http://arxiv.org/abs/1605.02573v1"
  },
  {
    "title": "Hacking the Brain: Triggering Neuroplasticity for Enhancing Musical Talent: A study on Monkey and Human behavior after Exposure to Videogames and Visual/Auditory Stimuli to Increase Musical Abilities through Neuroplasticity",
    "authors": [
      "Lucas Agudiez Roitman",
      "Poppy Crum"
    ],
    "abstract": "In this paper, we analyze the cognitive improvements that can be achieved through hacking the brain through the use of multiple methods to enhance neuroplasticity. Exposure to gaming, for example, has proven conducive for learning real-world abilities through auditory and visual stimuli. We will discuss cortical magnification and receptive field sizes, as well as topographic brain maps in the context of neuroplasticity. We finally propose more studies to be performed to improve musical talent and musical abilities.",
    "lastUpdated": "2019-07-08T13:52:57Z",
    "categories": [
      "q-bio.NC"
    ],
    "url": "http://arxiv.org/abs/1901.01362v2"
  },
  {
    "title": "Theta bases and log Gromov-Witten invariants of cluster varieties",
    "authors": [
      "Travis Mandel"
    ],
    "abstract": "Using heuristics from mirror symmetry, combinations of Gross, Hacking, Keel, Kontsevich, and Siebert have given combinatorial constructions of canonical bases of \"theta functions\" on the coordinate rings of various log Calabi-Yau spaces, including cluster varieties. We prove that the theta bases for cluster varieties are determined by certain descendant log Gromov-Witten invariants of the symplectic leaves of the mirror/Langlands dual cluster variety, as predicted in the Frobenius structure conjecture of Gross-Hacking-Keel. We further show that these Gromov-Witten counts are often given by naive counts of rational curves satisfying certain geometric conditions.",
    "lastUpdated": "2019-07-31T14:12:22Z",
    "categories": [
      "math.AG",
      "14J33 (Primary) 14N35, 13F60 (Secondary)"
    ],
    "url": "http://arxiv.org/abs/1903.03042v2"
  },
  {
    "title": "Deducibility of Identicals, Reflection Principle and Synthetic Connectives",
    "authors": [
      "Yuki Nishimuta"
    ],
    "abstract": "Sambin et al. (2000) introduced Basic Logic as an uniform framework for various logics. At the same time, they also introduced the principle of reflection as a criterion for being a connective of Basic Logic. We make explicit a relationship between Hacking's deducibility of identicals condition (Hacking, 1979) and the principle of reflection by proving the equivalence between them. Moreover, despite Sambin et al.'s conjecture that only six connectives satisfy the principle of reflection, we show the following; a logical connective satisfies the principle of reflection if and only if the connective is Girard's synthetic connective.",
    "lastUpdated": "2020-08-29T02:56:52Z",
    "categories": [
      "math.LO"
    ],
    "url": "http://arxiv.org/abs/1910.05120v2"
  },
  {
    "title": "Countermeasure against quantum hacking using detection statistics",
    "authors": [
      "Gaëtan Gras",
      "Davide Rusca",
      "Hugo Zbinden",
      "Félix Bussières"
    ],
    "abstract": "Detector blinding attacks have been proposed in the last few years, and they could potentially threaten the security of QKD systems. Even though no complete QKD system has been hacked yet, it is nevertheless important to consider countermeasures to avoid information leakage. In this paper, we present a new countermeasure against these kind of attacks based on the use of multi-pixel detectors. We show that with this method, we are able to estimate an upper bound on the information an eavesdropper could have on the key exchanged. Finally, we test a multi-pixel detector based on SNSPDs to show it can fulfill all the requirement for our countermeasure to be effective.",
    "lastUpdated": "2020-10-16T16:19:50Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/2010.08474v1"
  },
  {
    "title": "Weighted grassmannians and stable hyperplane arrangements",
    "authors": [
      "Valery Alexeev"
    ],
    "abstract": "We give a common generalization of (1) Hassett's weighted stable curves, and (2) Hacking-Keel-Tevelev's stable hyperplane arrangements.",
    "lastUpdated": "2008-06-11T19:42:26Z",
    "categories": [
      "math.AG",
      "math.RT"
    ],
    "url": "http://arxiv.org/abs/0806.0881v2"
  },
  {
    "title": "A Theory of Statistical Inference for Ensuring the Robustness of Scientific Results",
    "authors": [
      "Beau Coker",
      "Cynthia Rudin",
      "Gary King"
    ],
    "abstract": "Inference is the process of using facts we know to learn about facts we do not know. A theory of inference gives assumptions necessary to get from the former to the latter, along with a definition for and summary of the resulting uncertainty. Any one theory of inference is neither right nor wrong, but merely an axiom that may or may not be useful. Each of the many diverse theories of inference can be valuable for certain applications. However, no existing theory of inference addresses the tendency to choose, from the range of plausible data analysis specifications consistent with prior evidence, those that inadvertently favor one's own hypotheses. Since the biases from these choices are a growing concern across scientific fields, and in a sense the reason the scientific community was invented in the first place, we introduce a new theory of inference designed to address this critical problem. We introduce hacking intervals, which are the range of a summary statistic one may obtain given a class of possible endogenous manipulations of the data. Hacking intervals require no appeal to hypothetical data sets drawn from imaginary superpopulations. A scientific result with a small hacking interval is more robust to researcher manipulation than one with a larger interval, and is often easier to interpret than a classical confidence interval. Some versions of hacking intervals turn out to be equivalent to classical confidence intervals, which means they may also provide a more intuitive and potentially more useful interpretation of classical confidence intervals.",
    "lastUpdated": "2020-10-13T02:28:23Z",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1804.08646v2"
  },
  {
    "title": "Hacking Quantum Key Distribution via Injection Locking",
    "authors": [
      "Xiao-Ling Pang",
      "Ai-Lin Yang",
      "Chao-Ni Zhang",
      "Jian-Peng Dou",
      "Hang Li",
      "Jun Gao",
      "Xian-Min Jin"
    ],
    "abstract": "Unconditionally secure communication, being pursued for thousands of years, however, hasn't been reached yet due to continuous competitions between encryption and hacking. Quantum key distribution (QKD), harnessing the quantum mechanical nature of superposition and non-cloning, may promise unconditional security by incorporating the one-time pad algorithm rigorously proved by Claude Shannon. Massive efforts have been made in building practical and commercial QKD systems, in particular, decoy states are employed to detect photon-number splitting attack against single-photon source loophole, and measurement-device-independent (MDI) QKD has further closed all loopholes in detection side, which leads to a seemingly real-life application. Here, we propose and experimentally demonstrate an MDI-QKD hacking strategy on the trusted source assumption by using injection locking technique. Eve injects near off-resonance photons in randomly chosen polarization into sender's laser, where injection locking in a shifted frequency can happen only when Eve's choice matches with sender's state. By setting a shifted window and switching the frequency of photons back afterwards, Eve in principle can obtain all the keys without terminating the real-time QKD. We observe the dynamics of a semiconductor laser with injected photons, and obtain a hacking success rate reaching 60.0% of raw keys. Our results suggest that the spear-and-shield competitions on unconditional security may continue until all potential loopholes are discovered and closed ultimately.",
    "lastUpdated": "2020-03-04T20:03:15Z",
    "categories": [
      "quant-ph",
      "physics.app-ph",
      "physics.optics"
    ],
    "url": "http://arxiv.org/abs/1902.10423v3"
  },
  {
    "title": "The first SPIE software Hack Day",
    "authors": [
      "Sarah Kendrew",
      "Casey Deen",
      "Nicole Radziwill",
      "Steve Crawford",
      "James Gilbert",
      "Michael Gully-Santiago",
      "Petr Kubanek"
    ],
    "abstract": "We report here on the software Hack Day organised at the 2014 SPIE conference on Astronomical Telescopes and Instrumentation in Montreal. The first ever Hack Day to take place at an SPIE event, the aim of the day was to bring together developers to collaborate on innovative solutions to problems of their choice. Such events have proliferated in the technology community, providing opportunities to showcase, share and learn skills. In academic environments, these events are often also instrumental in building community beyond the limits of national borders, institutions and projects. We show examples of projects the participants worked on, and provide some lessons learned for future events.",
    "lastUpdated": "2014-08-06T13:48:31Z",
    "categories": [
      "astro-ph.IM",
      "cs.CY",
      "physics.optics"
    ],
    "url": "http://arxiv.org/abs/1408.1278v1"
  },
  {
    "title": "Joint Hacking and Latent Hazard Rate Estimation",
    "authors": [
      "Ziqi Liu",
      "Alexander J. Smola",
      "Kyle Soska",
      "Yu-Xiang Wang",
      "Qinghua Zheng"
    ],
    "abstract": "In this paper we describe an algorithm for predicting the websites at risk in a long range hacking activity, while jointly inferring the provenance and evolution of vulnerabilities on websites over continuous time. Specifically, we use hazard regression with a time-varying additive hazard function parameterized in a generalized linear form. The activation coefficients on each feature are continuous-time functions constrained with total variation penalty inspired by hacking campaigns. We show that the optimal solution is a 0th order spline with a finite number of adaptively chosen knots, and can be solved efficiently. Experiments on real data show that our method significantly outperforms classic methods while providing meaningful interpretability.",
    "lastUpdated": "2016-11-21T15:42:00Z",
    "categories": [
      "stat.AP"
    ],
    "url": "http://arxiv.org/abs/1611.06843v1"
  },
  {
    "title": "Steal Your Life Using 5 Cents: Hacking Android Smartphones with NFC Tags",
    "authors": [
      "Carlos Bermejo",
      "Pan Hui"
    ],
    "abstract": "Nowadays privacy in the connected world is a big user's concern. The ubiquity of mobile devices permits billions of users browse the web at anytime, anywhere. Near Field Communication (NFC) appeared as a seamlessly and simply communication protocol between devices. Commercial services such as Android Pay, and Apple Pay offer contactless payment methods that are spreading in more and more scenarios. However, we take risks while using NFC on Android devices, we can be hacked, and our privacy can be affected. In this paper we study the current vulnerabilities in the NFC-Android ecosystem. We conduct a series of experiments and we expose that with NFC and Android devices are vulnerable to URL/URI spoofing, Bank/social network information hacking, and user's device tracking via fingerprint and geo-location. It is important for the community to understand the problem and come up solution that can tackle these issues and inform the users about privacy awareness and risks on using these contactless services.",
    "lastUpdated": "2017-05-05T04:15:46Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1705.02081v1"
  },
  {
    "title": "Cyber-physical risks of hacked Internet-connected vehicles",
    "authors": [
      "Skanda Vivek",
      "David Yanni",
      "Peter J. Yunker",
      "Jesse L. Silverberg"
    ],
    "abstract": "The integration of automotive technology with Internet-connectivity promises to both dramatically improve transportation, while simultaneously introducing the potential for new unknown risks. Internet-connected vehicles are like digital data because they can be targeted for malicious hacking. Unlike digital data, however, Internet-connected vehicles are cyber-physical systems that physically interact with each other and their environment. As such, the extension of cybersecurity concerns into the cyber-physical domain introduces new possibilities for self-organized phenomena in traffic flow. Here, we study a scenario envisioned by cybersecurity experts leading to a large number of Internet-connected vehicles being suddenly and simultaneously disabled. We investigate post-hack traffic using agent-based simulations, and discover the critical relevance of percolation for probabilistically predicting the outcomes on a multi-lane road in the immediate aftermath of a vehicle-targeted cyber attack. We develop an analytic percolation-based model to rapidly assess road conditions given the density of disabled vehicles and apply it to study the street network of Manhattan (NY, USA) revealing the city's vulnerability to this particular cyber-physical attack.",
    "lastUpdated": "2019-02-28T20:35:22Z",
    "categories": [
      "cs.CR",
      "cs.NI",
      "physics.soc-ph"
    ],
    "url": "http://arxiv.org/abs/1903.00059v1"
  },
  {
    "title": "Quantum hacking perceiving for quantum key distribution using temporal ghost imaging",
    "authors": [
      "Fang-Xiang Wang",
      "Juan Wu",
      "Wei Chen",
      "Shuang Wang",
      "De-Yong He",
      "Zhen-Qiang Yin",
      "Chang-Ling Zou",
      "Guang-Can Guo",
      "Zheng-Fu Han"
    ],
    "abstract": "Quantum key distribution (QKD) can generate secure key bits between remote users with quantum mechanics. However, the gap between the theoretical model and practical realizations gives eavesdroppers opportunities to intercept secret key. The most insidious attacks, known as quantum hacking, are the ones with no significant discrepancy of the measurement results using side-channel loopholes of QKD systems. Depicting full-time-scale characteristics of the quantum signals, the quantum channel, and the QKD system can provide legitimate users extra capabilities to defeat malicious attacks. For the first time, we propose the method exploring temporal ghost imaging (TGI) scheme to perceive quantum hacking with temporal fingerprints and experimentally verify its validity. The scheme presents a common approach to promote QKD's practical security from a new perspective of signals and systems.",
    "lastUpdated": "2020-12-28T02:21:09Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/2012.14062v1"
  },
  {
    "title": "Cybermatter",
    "authors": [
      "Daniel Stern"
    ],
    "abstract": "In this paper we examine several aspects of the impact of Cyberworld onto our Reality conceptions, and their social implications.",
    "lastUpdated": "2009-11-13T12:48:42Z",
    "categories": [
      "cs.CY",
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/0911.2603v1"
  },
  {
    "title": "Ethics and Finance: the role of mathematics",
    "authors": [
      "Timothy C. Johnson"
    ],
    "abstract": "This paper presents the contemporary Fundamental Theorem of Asset Pricing as being equivalent to approaches to pricing that emerged before 1700 in the context of Virtue Ethics. This is done by considering the history of science and mathematics in the thirteenth and seventeenth century. An explanation as to why these approaches to pricing were forgotten between 1700 and 2000 is given, along with some of the implications on economics of viewing the Fundamental Theorem as a product of Virtue Ethics. The Fundamental Theorem was developed in mathematics to establish a `theory' that underpinned the Black-Scholes-Merton approach to pricing derivatives. In doing this, the Fundamental Theorem unified a number of different approaches in financial economics, this strengthened the status of neo-classical economics based on Consequentialist Ethics. We present an alternative to this narrative.",
    "lastUpdated": "2012-10-19T11:57:10Z",
    "categories": [
      "q-fin.GN",
      "math.HO",
      "math.PR",
      "q-fin.PR",
      "91G03 (Primary) 60A99, 01A65, 01A45 (Secondary)"
    ],
    "url": "http://arxiv.org/abs/1210.5390v1"
  },
  {
    "title": "Ethical Implications of IT-enabled Information Flows Conceived as Intermediaries or Mediators",
    "authors": [
      "Dubravka Cecez-Kecmanovic",
      "Olivera Marjanovic"
    ],
    "abstract": "This paper contributes to a better understanding of ethical concerns regarding the deployment of complex public sector IT systems and the information flows they instigate. The paper aims to reveal how different views on IT and IT-enabled information flows allow us to see differently their social implications and to construe different ethical questions. This is achieved by i) defining two opposing views on IT-enabled information flows as 'intermediaries' and 'mediators'; ii) by analysing the controversial case of My School - a web portal that provides performance data of 9,500 Australian schools - that introduces new information flows in the education sector; and iii) by revealing and explaining how some unintended negative social implications emerge and how the articulation of ethical concerns depends on the view on My School-enabled information flows. The paper concludes with theoretical and practical implications, with particular emphasis on responsibilities of all involved, setting up foundations for an important area of future IS research.",
    "lastUpdated": "2016-06-11T00:08:22Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1606.03506v1"
  },
  {
    "title": "Designing Commercial Therapeutic Robots for Privacy Preserving Systems and Ethical Research Practices within the Home",
    "authors": [
      "Elaine Sedenberg",
      "John Chuang",
      "Deirdre Mulligan"
    ],
    "abstract": "The migration of robots from the laboratory into sensitive home settings as commercially available therapeutic agents represents a significant transition for information privacy and ethical imperatives. We present new privacy paradigms and apply the Fair Information Practices (FIPs) to investigate concerns unique to the placement of therapeutic robots in private home contexts. We then explore the importance and utility of research ethics as operationalized by existing human subjects research frameworks to guide the consideration of therapeutic robotic users -- a step vital to the continued research and development of these platforms. Together, privacy and research ethics frameworks provide two complementary approaches to protect users and ensure responsible yet robust information sharing for technology development. We make recommendations for the implementation of these principles -- paying particular attention to specific principles that apply to vulnerable individuals (i.e., children, disabled, or elderly persons)--to promote the adoption and continued improvement of long-term, responsible, and research-enabled robotics in private settings.",
    "lastUpdated": "2016-06-29T06:03:46Z",
    "categories": [
      "cs.HC",
      "cs.RO"
    ],
    "url": "http://arxiv.org/abs/1606.04033v2"
  },
  {
    "title": "How Planners Deal with Uncomfortable Knowledge: The Dubious Ethics of the American Planning Association",
    "authors": [
      "Bent Flyvbjerg"
    ],
    "abstract": "With a point of departure in the concept \"uncomfortable knowledge,\" this article presents a case study of how the American Planning Association (APA) deals with such knowledge. APA was found to actively suppress publicity of malpractice concerns and bad planning in order to sustain a boosterish image of planning. In the process, APA appeared to disregard and violate APA's own Code of Ethics. APA justified its actions with a need to protect APA members' interests, seen as preventing planning and planners from being presented in public in a bad light. The current article argues that it is in members' interest to have malpractice critiqued and reduced, and that this best happens by exposing malpractice, not by denying or diverting attention from it as APA did in this case. Professions, organizations, and societies that stifle critique tend to degenerate and become socially and politically irrelevant \"zombie institutions.\" The article asks whether such degeneration has set in for APA and planning. Finally, it is concluded that more debate about APA's ethics and actions is needed for improving planning practice. Nine key questions are presented to constructively stimulate such debate.",
    "lastUpdated": "2013-03-28T11:04:53Z",
    "categories": [
      "q-fin.GN"
    ],
    "url": "http://arxiv.org/abs/1303.7405v1"
  },
  {
    "title": "Ethical issues of ISPs in the modern web",
    "authors": [
      "Leonardo Regano",
      "Ali Safari Khatouni",
      "Martino Trevisan",
      "Alessio Viticchie"
    ],
    "abstract": "In recent years, ethical issues in the networking field are getting moreimportant. In particular, there is a consistent debate about how Internet Service Providers (ISPs) should collect and treat network measurements. This kind of information, such as flow records, carry interesting knowledge from multiple points of view: research, traffic engineering and e-commerce can benefit from measurements retrievable through inspection of network traffic. Nevertheless, in some cases they can carry personal information about the users exposed to monitoring, and so generates several ethical issues. Modern web is very different from the one we could experience few years ago; web services converged to few protocols (i.e., HyperText Transfer Protocol (HTTP) and HTTPS) and always bigger share of encrypted traffic. The aim of this work is to provide an insight about which information is still visible to ISPs in the modern web and to what extent it carries personal information. We show ethical issues deriving by this new situation and provide general guidelines and best-practices to cope with the collection of network traffic measurements.",
    "lastUpdated": "2017-03-22T17:22:44Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1703.07757v1"
  },
  {
    "title": "Worse Than Spam: Issues In Sampling Software Developers",
    "authors": [
      "Sebastian Baltes",
      "Stephan Diehl"
    ],
    "abstract": "Background: Reaching out to professional software developers is a crucial part of empirical software engineering research. One important method to investigate the state of practice is survey research. As drawing a random sample of professional software developers for a survey is rarely possible, researchers rely on various sampling strategies. Objective: In this paper, we report on our experience with different sampling strategies we employed, highlight ethical issues, and motivate the need to maintain a collection of key demographics about software developers to ease the assessment of the external validity of studies. Method: Our report is based on data from two studies we conducted in the past. Results: Contacting developers over public media proved to be the most effective and efficient sampling strategy. However, we not only describe the perspective of researchers who are interested in reaching goals like a large number of participants or a high response rate, but we also shed light onto ethical implications of different sampling strategies. We present one specific ethical guideline and point to debates in other research communities to start a discussion in the software engineering research community about which sampling strategies should be considered ethical.",
    "lastUpdated": "2017-07-04T07:48:09Z",
    "categories": [
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/1707.00838v1"
  },
  {
    "title": "A Voting-Based System for Ethical Decision Making",
    "authors": [
      "Ritesh Noothigattu",
      "Snehalkumar 'Neil' S. Gaikwad",
      "Edmond Awad",
      "Sohan Dsouza",
      "Iyad Rahwan",
      "Pradeep Ravikumar",
      "Ariel D. Procaccia"
    ],
    "abstract": "We present a general approach to automating ethical decisions, drawing on machine learning and computational social choice. In a nutshell, we propose to learn a model of societal preferences, and, when faced with a specific ethical dilemma at runtime, efficiently aggregate those preferences to identify a desirable choice. We provide a concrete algorithm that instantiates our approach; some of its crucial steps are informed by a new theory of swap-dominance efficient voting rules. Finally, we implement and evaluate a system for ethical decision making in the autonomous vehicle domain, using preference data collected from 1.3 million people through the Moral Machine website.",
    "lastUpdated": "2018-12-18T23:16:48Z",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.GT"
    ],
    "url": "http://arxiv.org/abs/1709.06692v2"
  },
  {
    "title": "Actually, It's About Ethics in Computational Social Science: A Multi-party Risk-Benefit Framework for Online Community Research",
    "authors": [
      "Brian C. Keegan",
      "J. Nathan Matias"
    ],
    "abstract": "Managers regularly face a complex ethical dilemma over how to best govern online communities by evaluating the effectiveness of different social or technical strategies. What ethical considerations should guide researchers and managers when they employ causal research methods that make different community members bear different risks and benefits, under different levels of consent? We introduce a structural framework for evaluating the flows of risks and benefits in social systems with multiple interacting parties. This framework has implications for understanding the governmentality of managing socio-technical systems, for making research ethics discussions more commensurable, and for enumerating alternative goals researchers might pursue with interventions.",
    "lastUpdated": "2015-11-20T13:01:27Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1511.06578v1"
  },
  {
    "title": "Bots as Virtual Confederates: Design and Ethics",
    "authors": [
      "Peter M Krafft",
      "Michael Macy",
      "Alex Pentland"
    ],
    "abstract": "The use of bots as virtual confederates in online field experiments holds extreme promise as a new methodological tool in computational social science. However, this potential tool comes with inherent ethical challenges. Informed consent can be difficult to obtain in many cases, and the use of confederates necessarily implies the use of deception. In this work we outline a design space for bots as virtual confederates, and we propose a set of guidelines for meeting the status quo for ethical experimentation. We draw upon examples from prior work in the CSCW community and the broader social science literature for illustration. While a handful of prior researchers have used bots in online experimentation, our work is meant to inspire future work in this area and raise awareness of the associated ethical issues.",
    "lastUpdated": "2016-11-02T02:31:18Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "cs.SI",
      "physics.soc-ph",
      "J.4; K.4.1"
    ],
    "url": "http://arxiv.org/abs/1611.00447v1"
  },
  {
    "title": "Ethical Challenges in Data-Driven Dialogue Systems",
    "authors": [
      "Peter Henderson",
      "Koustuv Sinha",
      "Nicolas Angelard-Gontier",
      "Nan Rosemary Ke",
      "Genevieve Fried",
      "Ryan Lowe",
      "Joelle Pineau"
    ],
    "abstract": "The use of dialogue systems as a medium for human-machine interaction is an increasingly prevalent paradigm. A growing number of dialogue systems use conversation strategies that are learned from large datasets. There are well documented instances where interactions with these system have resulted in biased or even offensive conversations due to the data-driven training process. Here, we highlight potential ethical issues that arise in dialogue systems research, including: implicit biases in data-driven systems, the rise of adversarial examples, potential sources of privacy violations, safety concerns, special considerations for reinforcement learning systems, and reproducibility concerns. We also suggest areas stemming from these issues that deserve further investigation. Through this initial survey, we hope to spur research leading to robust, safe, and ethically sound dialogue systems.",
    "lastUpdated": "2017-11-24T17:14:34Z",
    "categories": [
      "cs.CL"
    ],
    "url": "http://arxiv.org/abs/1711.09050v1"
  },
  {
    "title": "The Virtuous Machine - Old Ethics for New Technology?",
    "authors": [
      "Nicolas Berberich",
      "Klaus Diepold"
    ],
    "abstract": "Modern AI and robotic systems are characterized by a high and ever-increasing level of autonomy. At the same time, their applications in fields such as autonomous driving, service robotics and digital personal assistants move closer to humans. From the combination of both developments emerges the field of AI ethics which recognizes that the actions of autonomous machines entail moral dimensions and tries to answer the question of how we can build moral machines. In this paper we argue for taking inspiration from Aristotelian virtue ethics by showing that it forms a suitable combination with modern AI due to its focus on learning from experience. We furthermore propose that imitation learning from moral exemplars, a central concept in virtue ethics, can solve the value alignment problem. Finally, we show that an intelligent system endowed with the virtues of temperance and friendship to humans would not pose a control problem as it would not have the desire for limitless self-improvement.",
    "lastUpdated": "2018-06-27T07:40:24Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1806.10322v1"
  },
  {
    "title": "An analysis of Principle 1.2 in the new ACM Code Of Ethics",
    "authors": [
      "Christoph Becker"
    ],
    "abstract": "The new ACM Code of Ethics is a much-needed update, but introduced changes to a central principle that have not been discussed widely enough. This commentary aims to contribute to an improvement of the ethical standards we want computing professionals to aspire to by analyzing how changes introduced to Principle 1.2, Avoid Harm, affect the Code as a whole. The analysis shows that the principle is now internally inconsistent in structure and externally inconsistent with Principle 2.3. It condones intentional harm too broadly and does not oblige those responsible to seek external justification. The existing Principle 2.3 clearly suggests that Principle 1.2 is unethical. As a consequence, the change introduced to Principle 1.2 in the new Code of Ethics nullifies the good intention of the code; counteracts the many good changes introduced in all three drafts; and places the ACM in a dangerous moral position. This short paper explains why and recommends concrete actions.",
    "lastUpdated": "2018-10-16T21:58:41Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1810.07290v1"
  },
  {
    "title": "Ethically Aligned Opportunistic Scheduling for Productive Laziness",
    "authors": [
      "Han Yu",
      "Chunyan Miao",
      "Yongqing Zheng",
      "Lizhen Cui",
      "Simon Fauvel",
      "Cyril Leung"
    ],
    "abstract": "In artificial intelligence (AI) mediated workforce management systems (e.g., crowdsourcing), long-term success depends on workers accomplishing tasks productively and resting well. This dual objective can be summarized by the concept of productive laziness. Existing scheduling approaches mostly focus on efficiency but overlook worker wellbeing through proper rest. In order to enable workforce management systems to follow the IEEE Ethically Aligned Design guidelines to prioritize worker wellbeing, we propose a distributed Computational Productive Laziness (CPL) approach in this paper. It intelligently recommends personalized work-rest schedules based on local data concerning a worker's capabilities and situational factors to incorporate opportunistic resting and achieve superlinear collective productivity without the need for explicit coordination messages. Extensive experiments based on a real-world dataset of over 5,000 workers demonstrate that CPL enables workers to spend 70% of the effort to complete 90% of the tasks on average, providing more ethically aligned scheduling than existing approaches.",
    "lastUpdated": "2019-01-02T09:01:07Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1901.00298v1"
  },
  {
    "title": "Artificial Intelligence Governance and Ethics: Global Perspectives",
    "authors": [
      "Angela Daly",
      "Thilo Hagendorff",
      "Li Hui",
      "Monique Mann",
      "Vidushi Marda",
      "Ben Wagner",
      "Wei Wang",
      "Saskia Witteborn"
    ],
    "abstract": "Artificial intelligence (AI) is a technology which is increasingly being utilised in society and the economy worldwide, and its implementation is planned to become more prevalent in coming years. AI is increasingly being embedded in our lives, supplementing our pervasive use of digital technologies. But this is being accompanied by disquiet over problematic and dangerous implementations of AI, or indeed, even AI itself deciding to do dangerous and problematic actions, especially in fields such as the military, medicine and criminal justice. These developments have led to concerns about whether and how AI systems adhere, and will adhere to ethical standards. These concerns have stimulated a global conversation on AI ethics, and have resulted in various actors from different countries and sectors issuing ethics and governance initiatives and guidelines for AI. Such developments form the basis for our research in this report, combining our international and interdisciplinary expertise to give an insight into what is happening in Australia, China, Europe, India and the US.",
    "lastUpdated": "2019-06-28T07:42:48Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1907.03848v1"
  },
  {
    "title": "Reporting on Decision-Making Algorithms and some Related Ethical Questions",
    "authors": [
      "Benoît Otjacques"
    ],
    "abstract": "Companies report on their financial performance for decades. More recently they have also started to report on their environmental impact and their social responsibility. The latest trend is now to deliver one single integrated report where all stakeholders of the company can easily connect all facets of the business with their impact considered in a broad sense. The main purpose of this integrated approach is to avoid delivering data related to disconnected silos, which consequently makes it very difficult to globally assess the overall performance of an entity or a business line. In this paper, we focus on how companies report on risks and ethical issues related to the increasing use of Artificial Intelligence (AI). We explain some of these risks and potential issues. Next, we identify some recent initiatives by various stakeholders to define a global ethical framework for AI. Finally, we illustrate with four cases that companies are very shy to report on these facets of AI.",
    "lastUpdated": "2019-11-04T08:13:54Z",
    "categories": [
      "cs.CY",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1911.05731v1"
  },
  {
    "title": "On the Morality of Artificial Intelligence",
    "authors": [
      "Alexandra Luccioni",
      "Yoshua Bengio"
    ],
    "abstract": "Much of the existing research on the social and ethical impact of Artificial Intelligence has been focused on defining ethical principles and guidelines surrounding Machine Learning (ML) and other Artificial Intelligence (AI) algorithms [IEEE, 2017, Jobin et al., 2019]. While this is extremely useful for helping define the appropriate social norms of AI, we believe that it is equally important to discuss both the potential and risks of ML and to inspire the community to use ML for beneficial objectives. In the present article, which is specifically aimed at ML practitioners, we thus focus more on the latter, carrying out an overview of existing high-level ethical frameworks and guidelines, but above all proposing both conceptual and practical principles and guidelines for ML research and deployment, insisting on concrete actions that can be taken by practitioners to pursue a more ethical and moral practice of ML aimed at using AI for social good.",
    "lastUpdated": "2019-12-26T23:06:54Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1912.11945v1"
  },
  {
    "title": "On Quantified Modal Theorem Proving for Modeling Ethics",
    "authors": [
      "Naveen Sundar Govindarajulu",
      "Selmer Bringsjord",
      "Matthew Peveler"
    ],
    "abstract": "In the last decade, formal logics have been used to model a wide range of ethical theories and principles with the goal of using these models within autonomous systems. Logics for modeling ethical theories, and their automated reasoners, have requirements that are different from modal logics used for other purposes, e.g. for temporal reasoning. Meeting these requirements necessitates investigation of new approaches for proof automation. Particularly, a quantified modal logic, the deontic cognitive event calculus (DCEC), has been used to model various versions of the doctrine of double effect, akrasia, and virtue ethics. Using a fragment of DCEC, we outline these distinct characteristics and present a sketches of an algorithm that can help with some aspects proof automation for DCEC.",
    "lastUpdated": "2019-12-30T15:14:21Z",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "url": "http://arxiv.org/abs/1912.12959v1"
  },
  {
    "title": "Ethics of Technology needs more Political Philosophy",
    "authors": [
      "Johannes Himmelreich"
    ],
    "abstract": "The ongoing debate on the ethics of self-driving cars typically focuses on two approaches to answering ethical questions: moral philosophy and social science. I argue that these two approaches are both lacking. We should neither deduce answers from individual moral theories nor should we expect social science to give us complete answers. To supplement these approaches, we should turn to political philosophy. The issues we face are collective decisions that we make together rather than individual decisions we make in light of what we each have reason to value. Political philosophy adds three basic concerns to our conceptual toolkit: reasonable pluralism, human agency, and legitimacy. These three concerns have so far been largely overlooked in the debate on the ethics of self-driving cars.",
    "lastUpdated": "2020-01-10T15:27:02Z",
    "categories": [
      "cs.CY",
      "K.4.0; K.4.1"
    ],
    "url": "http://arxiv.org/abs/2001.03511v1"
  },
  {
    "title": "Machine Ethics: The Creation of a Virtuous Machine",
    "authors": [
      "Mohamed Akrout",
      "Robert Steinbauer"
    ],
    "abstract": "Artificial intelligence (AI) was initially developed as an implicit moral agent to solve simple and clearly defined tasks where all options are predictable. However, it is now part of our daily life powering cell phones, cameras, watches, thermostats, vacuums, cars, and much more. This has raised numerous concerns and some scholars and practitioners stress the dangers of AI and argue against its development as moral agents that can reason about ethics (e.g., Bryson 2008; Johnson and Miller 2008; Sharkey 2017; Tonkens 2009; van Wynsberghe and Robbins 2019). Even though we acknowledge the potential threat, in line with most other scholars (e.g., Anderson and Anderson 2010; Moor 2006; Scheutz 2016; Wallach 2010), we argue that AI advancements cannot be stopped and developers need to prepare AI to sustain explicit moral agents and face ethical dilemmas in complex and morally salient environments.",
    "lastUpdated": "2020-02-07T19:04:37Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2002.00213v2"
  },
  {
    "title": "Artificial Intelligent Ethics in the Digital Era: an Engineering Ethical Framework Proposal",
    "authors": [
      "Esteban García-Cuesta"
    ],
    "abstract": "Nowadays technology is being adopted on every aspect of our lives and it is one of most important transformation driver in industry. Moreover, many of the systems and digital services that we use daily rely on artificial intelligent technology capable of modeling social or individual behaviors that in turns also modify personal decisions and actions. In this paper, we briefly discuss, from a technological perspective, a number of critical issues including the purpose of promoting trust and ensure social benefit by the proper use of Artificial Intelligent Systems. To achieve this goal we propose a generic ethical technological framework as a first attempt to define a common context towards developing real engineering ethical by design. We hope that this initial proposal to be useful for early adopters and especially for standardization teams.",
    "lastUpdated": "2020-02-18T17:09:36Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2002.07734v1"
  },
  {
    "title": "Repeated Communication with Private Lying Cost",
    "authors": [
      "Harry Pei"
    ],
    "abstract": "I study repeated communication games between a patient sender and a sequence of receivers. The sender has persistent private information about his psychological cost of lying, and in every period, can privately observe the realization of an i.i.d. state before communication takes place. I characterize every type of sender's highest equilibrium payoff. When the highest lying cost in the support of the receivers' prior belief approaches the sender's benefit from lying, every type's highest equilibrium payoff in the repeated communication game converges to his equilibrium payoff in a one-shot Bayesian persuasion game. I also show that in every sender-optimal equilibrium, no type of sender mixes between telling the truth and lying at every history. When there exist ethical types whose lying costs outweigh their benefits, I provide necessary and sufficient conditions for all non-ethical type senders to attain their optimal commitment payoffs. I identify an outside option effect through which the possibility of being ethical decreases every non-ethical type's payoff.",
    "lastUpdated": "2020-06-15T01:08:33Z",
    "categories": [
      "econ.TH"
    ],
    "url": "http://arxiv.org/abs/2006.08069v1"
  },
  {
    "title": "Public Goods From Private Data -- An Efficacy and Justification Paradox for Digital Contact Tracing",
    "authors": [
      "Andrew Buzzell"
    ],
    "abstract": "Debate about the adoption of digital contact tracing (DCT) apps to control the spread of COVID-19 has focussed on risks to individual privacy (Sharma & Bashir 2020, Tang 2020). This emphasis reveals significant challenges to ethical deployment of DCT, but generates constraints which undermine justification to implement DCT. It would be a mistake to view this result solely as the successful operation of ethical foresight analysis (Floridi & Strait 2020), preventing deployment of potentially harmful technology. Privacy-centric analysis treats data as private property, frames the relationship between individuals and governments as adversarial, entrenches technology platforms as gatekeepers, and supports a conception of emergency public health authority as limited by individual consent and considerable corporate influence that is in some tension with the more communitarian values that typically inform public health ethics. To overcome the barriers to ethical and effective DCT, and develop infrastructure and policy that supports the realization of potential public benefits of digital technology, a public resource conception of aggregate data should be developed.",
    "lastUpdated": "2020-07-14T13:08:29Z",
    "categories": [
      "cs.CY",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/2007.07016v1"
  },
  {
    "title": "Montreal AI Ethics Institute's (MAIEI) Submission to the World Intellectual Property Organization (WIPO) Conversation on Intellectual Property (IP) and Artificial Intelligence (AI) Second Session",
    "authors": [
      "Allison Cohen",
      "Abhishek Gupta"
    ],
    "abstract": "This document posits that, at best, a tenuous case can be made for providing AI exclusive IP over their \"inventions\". Furthermore, IP protections for AI are unlikely to confer the benefit of ensuring regulatory compliance. Rather, IP protections for AI \"inventors\" present a host of negative externalities and obscures the fact that the genuine inventor, deserving of IP, is the human agent. This document will conclude by recommending strategies for WIPO to bring IP law into the 21st century, enabling it to productively account for AI \"inventions\". Theme: IP Protection for AI-Generated and AI-Assisted Works Based on insights from the Montreal AI Ethics Institute (MAIEI) staff and supplemented by workshop contributions from the AI Ethics community convened by MAIEI on July 5, 2020.",
    "lastUpdated": "2020-08-11T05:31:10Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2008.04520v1"
  },
  {
    "title": "Ethical behavior in humans and machines -- Evaluating training data quality for beneficial machine learning",
    "authors": [
      "Thilo Hagendorff"
    ],
    "abstract": "Machine behavior that is based on learning algorithms can be significantly influenced by the exposure to data of different qualities. Up to now, those qualities are solely measured in technical terms, but not in ethical ones, despite the significant role of training and annotation data in supervised machine learning. This is the first study to fill this gap by describing new dimensions of data quality for supervised machine learning applications. Based on the rationale that different social and psychological backgrounds of individuals correlate in practice with different modes of human-computer-interaction, the paper describes from an ethical perspective how varying qualities of behavioral data that individuals leave behind while using digital technologies have socially relevant ramification for the development of machine learning applications. The specific objective of this study is to describe how training data can be selected according to ethical assessments of the behavior it originates from, establishing an innovative filter regime to transition from the big data rationale n = all to a more selective way of processing data for training sets in machine learning. The overarching aim of this research is to promote methods for achieving beneficial machine learning applications that could be widely useful for industry as well as academia.",
    "lastUpdated": "2020-08-26T09:48:38Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2008.11463v1"
  },
  {
    "title": "Towards Ethics by Design in Online Abusive Content Detection",
    "authors": [
      "Svetlana Kiritchenko",
      "Isar Nejadgholi"
    ],
    "abstract": "To support safety and inclusion in online communications, significant efforts in NLP research have been put towards addressing the problem of abusive content detection, commonly defined as a supervised classification task. The research effort has spread out across several closely related sub-areas, such as detection of hate speech, toxicity, cyberbullying, etc. There is a pressing need to consolidate the field under a common framework for task formulation, dataset design and performance evaluation. Further, despite current technologies achieving high classification accuracies, several ethical issues have been revealed. We bring ethical issues to forefront and propose a unified framework as a two-step process. First, online content is categorized around personal and identity-related subject matters. Second, severity of abuse is identified through comparative annotation within each category. The novel framework is guided by the Ethics by Design principle and is a step towards building more accurate and trusted models.",
    "lastUpdated": "2020-10-28T13:10:24Z",
    "categories": [
      "cs.CL"
    ],
    "url": "http://arxiv.org/abs/2010.14952v1"
  },
  {
    "title": "Away from Trolley Problems and Toward Risk Management",
    "authors": [
      "Noah J. Goodall"
    ],
    "abstract": "As automated vehicles receive more attention from the media, there has been an equivalent increase in the coverage of the ethical choices a vehicle may be forced to make in certain crash situations with no clear safe outcome. Much of this coverage has focused on a philosophical thought experiment known as the \"trolley problem,\" and substituting an automated vehicle for the trolley and the car's software for the bystander. While this is a stark and straightforward example of ethical decision making for an automated vehicle, it risks marginalizing the entire field if it is to become the only ethical problem in the public's mind. In this chapter, I discuss the shortcomings of the trolley problem, and introduce more nuanced examples that involve crash risk and uncertainty. Risk management is introduced as an alternative approach, and its ethical dimensions are discussed.",
    "lastUpdated": "2020-10-28T20:27:50Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "K.4.1"
    ],
    "url": "http://arxiv.org/abs/2010.15217v1"
  },
  {
    "title": "Approaching Ethical Guidelines for Data Scientists",
    "authors": [
      "Ursula Garzcarek",
      "Detlef Steuer"
    ],
    "abstract": "The goal of this article is to inspire data scientists to participate in the debate on the impact that their professional work has on society, and to become active in public debates on the digital world as data science professionals. How do ethical principles (e.g., fairness, justice, beneficence, and non-maleficence) relate to our professional lives? What lies in our responsibility as professionals by our expertise in the field? More specifically this article makes an appeal to statisticians to join that debate, and to be part of the community that establishes data science as a proper profession in the sense of Airaksinen, a philosopher working on professional ethics. As we will argue, data science has one of its roots in statistics and extends beyond it. To shape the future of statistics, and to take responsibility for the statistical contributions to data science, statisticians should actively engage in the discussions. First the term data science is defined, and the technical changes that have led to a strong influence of data science on society are outlined. Next the systematic approach from CNIL is introduced. Prominent examples are given for ethical issues arising from the work of data scientists. Further we provide reasons why data scientists should engage in shaping morality around and to formulate codes of conduct and codes of practice for data science. Next we present established ethical guidelines for the related fields of statistics and computing machinery. Thereafter necessary steps in the community to develop professional ethics for data science are described. Finally we give our starting statement for the debate: Data science is in the focal point of current societal development. Without becoming a profession with professional ethics, data science will fail in building trust in its interaction with and its much needed contributions to society!",
    "lastUpdated": "2019-01-14T16:13:27Z",
    "categories": [
      "stat.OT",
      "cs.AI",
      "cs.CY",
      "stat.ML",
      "62A01"
    ],
    "url": "http://arxiv.org/abs/1901.04824v1"
  },
  {
    "title": "From What to How: An Initial Review of Publicly Available AI Ethics Tools, Methods and Research to Translate Principles into Practices",
    "authors": [
      "Jessica Morley",
      "Luciano Floridi",
      "Libby Kinsey",
      "Anat Elhalal"
    ],
    "abstract": "The debate about the ethical implications of Artificial Intelligence dates from the 1960s. However, in recent years symbolic AI has been complemented and sometimes replaced by Neural Networks and Machine Learning techniques. This has vastly increased its potential utility and impact on society, with the consequence that the ethical debate has gone mainstream. Such debate has primarily focused on principles - the what of AI ethics - rather than on practices, the how. Awareness of the potential issues is increasing at a fast rate, but the AI community's ability to take action to mitigate the associated risks is still at its infancy. Therefore, our intention in presenting this research is to contribute to closing the gap between principles and practices by constructing a typology that may help practically-minded developers apply ethics at each stage of the pipeline, and to signal to researchers where further work is needed. The focus is exclusively on Machine Learning, but it is hoped that the results of this research may be easily applicable to other branches of AI. The article outlines the research method for creating this typology, the initial findings, and provides a summary of future research needs.",
    "lastUpdated": "2019-09-13T12:10:32Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1905.06876v2"
  },
  {
    "title": "Designing Trustworthy AI: A Human-Machine Teaming Framework to Guide Development",
    "authors": [
      "Carol J. Smith"
    ],
    "abstract": "Artificial intelligence (AI) holds great promise to empower us with knowledge and augment our effectiveness. We can -- and must -- ensure that we keep humans safe and in control, particularly with regard to government and public sector applications that affect broad populations. How can AI development teams harness the power of AI systems and design them to be valuable to humans? Diverse teams are needed to build trustworthy artificial intelligent systems, and those teams need to coalesce around a shared set of ethics. There are many discussions in the AI field about ethics and trust, but there are few frameworks available for people to use as guidance when creating these systems. The Human-Machine Teaming (HMT) Framework for Designing Ethical AI Experiences described in this paper, when used with a set of technical ethics, will guide AI development teams to create AI systems that are accountable, de-risked, respectful, secure, honest, and usable. To support the team's efforts, activities to understand people's needs and concerns will be introduced along with the themes to support the team's efforts. For example, usability testing can help determine if the audience understands how the AI system works and complies with the HMT Framework. The HMT Framework is based on reviews of existing ethical codes and best practices in human-computer interaction and software development. Human-machine teams are strongest when human users can trust AI systems to behave as expected, safely, securely, and understandably. Using the HMT Framework to design trustworthy AI systems will provide support to teams in identifying potential issues ahead of time and making great experiences for humans.",
    "lastUpdated": "2019-10-08T16:19:49Z",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/1910.03515v1"
  },
  {
    "title": "Trustworthy AI in the Age of Pervasive Computing and Big Data",
    "authors": [
      "Abhishek Kumar",
      "Tristan Braud",
      "Sasu Tarkoma",
      "Pan Hui"
    ],
    "abstract": "The era of pervasive computing has resulted in countless devices that continuously monitor users and their environment, generating an abundance of user behavioural data. Such data may support improving the quality of service, but may also lead to adverse usages such as surveillance and advertisement. In parallel, Artificial Intelligence (AI) systems are being applied to sensitive fields such as healthcare, justice, or human resources, raising multiple concerns on the trustworthiness of such systems. Trust in AI systems is thus intrinsically linked to ethics, including the ethics of algorithms, the ethics of data, or the ethics of practice. In this paper, we formalise the requirements of trustworthy AI systems through an ethics perspective. We specifically focus on the aspects that can be integrated into the design and development of AI systems. After discussing the state of research and the remaining challenges, we show how a concrete use-case in smart cities can benefit from these methods.",
    "lastUpdated": "2020-01-30T08:09:31Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2002.05657v1"
  },
  {
    "title": "Montreal AI Ethics Institute's Response to Scotland's AI Strategy",
    "authors": [
      "Abhishek Gupta"
    ],
    "abstract": "In January and February 2020, the Scottish Government released two documents for review by the public regarding their artificial intelligence (AI) strategy. The Montreal AI Ethics Institute (MAIEI) reviewed these documents and published a response on 4 June 2020. MAIEI's response examines several questions that touch on the proposed definition of AI; the people-centered nature of the strategy; considerations to ensure that everyone benefits from AI; the strategy's overarching vision; Scotland's AI ecosystem; the proposed strategic themes; and how to grow public confidence in AI by building responsible and ethical systems. In addition to examining the points above, MAIEI suggests that the strategy be extended to include considerations on biometric data and how that will be processed and used in the context of AI. It also highlights the importance of tackling head-on the inherently stochastic nature of deep learning systems and developing concrete guidelines to ensure that these systems are built responsibly and ethically, particularly as machine learning becomes more accessible. Finally, it concludes that any national AI strategy must clearly address the measurements of success in regards to the strategy's stated goals and vision to ensure that they are interpreted and applied consistently. To do this, there must be inclusion and transparency between those building the systems and those using them in their work.",
    "lastUpdated": "2020-06-11T10:08:17Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2006.06300v1"
  },
  {
    "title": "Ethical issues with using Internet of Things devices in citizen science research: A scoping review",
    "authors": [
      "James Scheibner",
      "Anna Jobin",
      "Effy Vayena"
    ],
    "abstract": "Our chapter presents a scoping review of published scientific studies or case studies of scientific studies that utilise both citizen scientists and Internet of Things devices. Specifically, we selected studies where the authors had included at least a short discussion of the ethical issues encountered during the research process. Having conducted a search of five databases (IEEE Xplore, Scopus, Web of Science, ProQuest, and PubMed), we identified 631 potential results. Following abstract and title screening, and then full text eligibility assessment, we identified 34 published articles that matched our criteria. We then analysed the full text for these articles inductively and deductively, coding ethical issues into three main categories. These categories were autonomy and data privacy, data quality, and intellectual property. We also analysed the full text of these articles to see what strategies researchers took to resolve these ethical issues, as well as any legal implications raised. Following this analysis, our discussion provides recommendations for researchers who wish to integrate citizen scientists and Internet of Things devices into their research. First, all citizen science projects should integrate a data privacy protocol to protect the confidentiality of participants. Secondly, scientific researchers should consider any potential issues of data quality, including whether compromises might be required, before establishing a project. Finally, all intellectual property issues should be clarified both at the start of the project and during its lifecycle. Researchers should also consider any ethical issues that might flow from the use of commercially available Internet of Things devices for research.",
    "lastUpdated": "2020-07-18T12:22:05Z",
    "categories": [
      "cs.CY",
      "K.4.1"
    ],
    "url": "http://arxiv.org/abs/2007.09416v1"
  },
  {
    "title": "Confronting Abusive Language Online: A Survey from the Ethical and Human Rights Perspective",
    "authors": [
      "Svetlana Kiritchenko",
      "Isar Nejadgholi",
      "Kathleen C. Fraser"
    ],
    "abstract": "The pervasiveness of abusive content on the internet can lead to severe psychological and physical harm. Significant effort in Natural Language Processing (NLP) research has been devoted to addressing this problem through abusive content detection and related sub-areas, such as the detection of hate speech, toxicity, cyberbullying, etc. Although current technologies achieve high classification performance in research studies, it has been observed that the real-life application of this technology can cause unintended harms, such as the silencing of under-represented groups. We review a large body of NLP research on automatic abuse detection with a new focus on ethical challenges, organized around eight established ethical principles: privacy, accountability, safety and security, transparency and explainability, fairness and non-discrimination, human control of technology, professional responsibility, and promotion of human values. In many cases, these principles relate not only to situational ethical codes, which may be context-dependent, but are in fact connected to universal human rights, such as the right to privacy, freedom from discrimination, and freedom of expression. We highlight the need to examine the broad social impacts of this technology, and to bring ethical and human rights considerations to every stage of the application life-cycle, from task formulation and dataset design, to model training and evaluation, to application deployment. Guided by these principles, we identify several opportunities for rights-respecting, socio-technical solutions to detect and confront online abuse, including 'nudging', 'quarantining', value sensitive design, counter-narratives, style transfer, and AI-driven public education applications.",
    "lastUpdated": "2020-12-22T19:27:11Z",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2012.12305v1"
  },
  {
    "title": "Digital me ontology and ethics",
    "authors": [
      "Ljupco Kocarev",
      "Jasna Koteska"
    ],
    "abstract": "This paper addresses ontology and ethics of an AI agent called digital me. We define digital me as autonomous, decision-making, and learning agent, representing an individual and having practically immortal own life. It is assumed that digital me is equipped with the big-five personality model, ensuring that it provides a model of some aspects of a strong AI: consciousness, free will, and intentionality. As computer-based personality judgments are more accurate than those made by humans, digital me can judge the personality of the individual represented by the digital me, other individuals' personalities, and other digital me-s. We describe seven ontological qualities of digital me: a) double-layer status of Digital Being versus digital me, b) digital me versus real me, c) mind-digital me and body-digital me, d) digital me versus doppelganger (shadow digital me), e) non-human time concept, f) social quality, g) practical immortality. We argue that with the advancement of AI's sciences and technologies, there exist two digital me thresholds. The first threshold defines digital me having some (rudimentarily) form of consciousness, free will, and intentionality. The second threshold assumes that digital me is equipped with moral learning capabilities, implying that, in principle, digital me could develop their own ethics which significantly differs from human's understanding of ethics. Finally we discuss the implications of digital me metaethics, normative and applied ethics, the implementation of the Golden Rule in digital me-s, and we suggest two sets of normative principles for digital me: consequentialist and duty based digital me principles.",
    "lastUpdated": "2020-12-22T09:54:04Z",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2012.14325v1"
  },
  {
    "title": "Privacy-preserving Crowd-guided AI Decision-making in Ethical Dilemmas",
    "authors": [
      "Teng Wang",
      "Jun Zhao",
      "Han Yu",
      "Jinyan Liu",
      "Xinyu Yang",
      "Xuebin Ren",
      "Shuyu Shi"
    ],
    "abstract": "With the rapid development of artificial intelligence (AI), ethical issues surrounding AI have attracted increasing attention. In particular, autonomous vehicles may face moral dilemmas in accident scenarios, such as staying the course resulting in hurting pedestrians or swerving leading to hurting passengers. To investigate such ethical dilemmas, recent studies have adopted preference aggregation, in which each voter expresses her/his preferences over decisions for the possible ethical dilemma scenarios, and a centralized system aggregates these preferences to obtain the winning decision. Although a useful methodology for building ethical AI systems, such an approach can potentially violate the privacy of voters since moral preferences are sensitive information and their disclosure can be exploited by malicious parties. In this paper, we report a first-of-its-kind privacy-preserving crowd-guided AI decision-making approach in ethical dilemmas. We adopt the notion of differential privacy to quantify privacy and consider four granularities of privacy protection by taking voter-/record-level privacy protection and centralized/distributed perturbation into account, resulting in four approaches VLCP, RLCP, VLDP, and RLDP. Moreover, we propose different algorithms to achieve these privacy protection granularities, while retaining the accuracy of the learned moral preference model. Specifically, VLCP and RLCP are implemented with the data aggregator setting a universal privacy parameter and perturbing the averaged moral preference to protect the privacy of voters' data. VLDP and RLDP are implemented in such a way that each voter perturbs her/his local moral preference with a personalized privacy parameter. Extensive experiments on both synthetic and real data demonstrate that the proposed approach can achieve high accuracy of preference aggregation while protecting individual voter's privacy.",
    "lastUpdated": "2019-09-27T13:22:08Z",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1906.01562v2"
  },
  {
    "title": "On the rigidity of moduli of curves in arbitrary characteristic",
    "authors": [
      "Barbara Fantechi",
      "Alex Massarenti"
    ],
    "abstract": "The stack $\\overline{\\mathcal{M}}_{g,n}$ of stable curves and its coarse moduli space $\\overline{M}_{g,n}$ are defined over $\\mathbb{Z}$, and therefore over any field. Over an algebraically closed field of characteristic zero, Hacking showed that $\\overline{\\mathcal{M}}_{g,n}$ is rigid (a conjecture of Kapranov). Bruno and Mella for $g=0$, and the second author for $g\\geq 1$ showed that its automorphism group is the symmetric group $S_n$, permuting marked points unless $(g,n)\\in\\{(0,4),(1,1),(1,2)\\}$. The methods used in the papers above do not extend to positive characteristic. We show that in characteristic $p>0$, the rigidity of $\\overline{\\mathcal{M}}_{g,n}$, with the same exceptions as over $\\mathbb{C}$, implies that its automorphism group is $S_n$. We prove that, over any perfect field, $\\overline{M}_{0,n}$ is rigid and deduce that, over any field, $Aut(\\overline{M}_{0,n})\\cong S_{n}$ for $n\\geq 5$. Going back to characteristic zero, we prove that for $g+n>4$, the coarse moduli space $\\overline M_{g,n}$ is rigid, extending a result of Hacking who had proven it has no locally trivial deformations. Finally, we show that $\\overline{M}_{1,2}$ is not rigid, although it does not admit locally trivial deformations, by explicitly computing his Kuranishi family.",
    "lastUpdated": "2015-11-08T18:18:51Z",
    "categories": [
      "math.AG",
      "Primary 14H10, Secondary 14D22, 14D23, 14D06"
    ],
    "url": "http://arxiv.org/abs/1407.2284v2"
  },
  {
    "title": "Hack's law in a drainage network model: A Brownian web approach",
    "authors": [
      "Rahul Roy",
      "Kumarjit Saha",
      "Anish Sarkar"
    ],
    "abstract": "Hack [Studies of longitudinal stream profiles in Virginia and Maryland (1957). Report], while studying the drainage system in the Shenandoah valley and the adjacent mountains of Virginia, observed a power law relation $l\\sim a^{0.6}$ between the length $l$ of a stream from its source to a divide and the area $a$ of the basin that collects the precipitation contributing to the stream as tributaries. We study the tributary structure of Howard's drainage network model of headward growth and branching studied by Gangopadhyay, Roy and Sarkar [Ann. Appl. Probab. 14 (2004) 1242-1266]. We show that the exponent of Hack's law is $2/3$ for Howard's model. Our study is based on a scaling of the process whereby the limit of the watershed area of a stream is area of a Brownian excursion process. To obtain this, we define a dual of the model and show that under diffusive scaling, both the original network and its dual converge jointly to the standard Brownian web and its dual.",
    "lastUpdated": "2016-06-28T07:55:19Z",
    "categories": [
      "math.PR"
    ],
    "url": "http://arxiv.org/abs/1501.01382v4"
  },
  {
    "title": "Canonical singularities of orders over surfaces",
    "authors": [
      "Daniel Chan",
      "Paul Hacking",
      "Colin Ingalls"
    ],
    "abstract": "We classify the possible ramification data and etale local structure of orders over surfaces with canonical singularities.",
    "lastUpdated": "2007-07-24T05:01:19Z",
    "categories": [
      "math.RA",
      "math.AG"
    ],
    "url": "http://arxiv.org/abs/math/0401425v3"
  },
  {
    "title": "Stable pair, tropical, and log canonical compact moduli of del Pezzo surfaces",
    "authors": [
      "Paul Hacking",
      "Sean Keel",
      "Jenia Tevelev"
    ],
    "abstract": "We give a functorial normal crossing compactification of the moduli of smooth marked cubic surfaces entirely analogous to the Grothendieck-Knudsen compactification $M_{0,n} \\subset \\bar{M}_{0,n}$.",
    "lastUpdated": "2007-09-12T18:43:59Z",
    "categories": [
      "math.AG",
      "14J10; 14E30"
    ],
    "url": "http://arxiv.org/abs/math/0702505v2"
  },
  {
    "title": "Birational geometry of cluster algebras",
    "authors": [
      "Mark Gross",
      "Paul Hacking",
      "Sean Keel"
    ],
    "abstract": "We give a geometric interpretation of cluster varieties in terms of blowups of toric varieties. This enables us to provide, among other results, an elementary geometric proof of the Laurent phenomenon for cluster algebras (of geometric type), extend Speyer's example of an upper cluster algebra which is not finitely generated, and show that the Fock-Goncharov dual basis conjecture is usually false.",
    "lastUpdated": "2014-04-15T09:44:35Z",
    "categories": [
      "math.AG"
    ],
    "url": "http://arxiv.org/abs/1309.2573v2"
  },
  {
    "title": "Integrable clusters",
    "authors": [
      "Arkady Berenstein",
      "Jacob Greenstein",
      "David Kazhdan"
    ],
    "abstract": "The goal of this note is to study quantum clusters in which cluster variables (not coefficients) commute which each other. It turns out that this property is preserved by mutations. Remarkably, this is equivalent to the celebrated sign coherence conjecture recently proved by M. Gross, P. Hacking, S. Keel and M. Kontsevich",
    "lastUpdated": "2014-11-30T22:54:04Z",
    "categories": [
      "math.QA",
      "math.RT"
    ],
    "url": "http://arxiv.org/abs/1412.0302v1"
  },
  {
    "title": "Human Indignity: From Legal AI Personhood to Selfish Memes",
    "authors": [
      "Roman V. Yampolskiy"
    ],
    "abstract": "It is possible to rely on current corporate law to grant legal personhood to Artificially Intelligent (AI) agents. In this paper, after introducing pathways to AI personhood, we analyze consequences of such AI empowerment on human dignity, human safety and AI rights. We emphasize possibility of creating selfish memes and legal system hacking in the context of artificial entities. Finally, we consider some potential solutions for addressing described problems.",
    "lastUpdated": "2018-10-02T20:01:43Z",
    "categories": [
      "cs.GL",
      "cs.AI",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1810.02724v1"
  },
  {
    "title": "E-Crime Legal Brief: A Case Study on Talk Talk Hacking",
    "authors": [
      "Bonaventure Ngala"
    ],
    "abstract": "E-crime has had various definitions for different countries and organisations. There is no universal definition of E-crime and therefore the interpretation is left to cybercrime investigators and judges to apply related crimes to within the scope where possible. E-crime legal brief should include Citation, facts of the case, issues, reasoning, decision of the judges and analysis. The analysis outlines applicable laws in e-crime, case laws relevant to the facts of the case and crime committed.",
    "lastUpdated": "2019-09-12T14:22:34Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1909.05709v1"
  },
  {
    "title": "Ethical Dilemma of Governmental Wiretapping",
    "authors": [
      "Arwen Mullikin",
      "Syed",
      "M. Rahman"
    ],
    "abstract": "USA Government wiretapping activities is a very controversial issue. Undoubtedly this technology can assist law enforced authority to detect / identify unlawful or hostile activities; however, this task raises severe privacy concerns. In this paper, we have discussed this complex information technology issue of governmental wiretapping and how it effects both public and private liberties. Legislation has had a major impact on the uses and the stigma of wiretapping for the war on terrorism. This paper also analyzes the ethical and legal concerns inherent when discussing the benefits and concerns of wiretapping. The analysis has concluded with the effects of wiretapping laws as they relate to future government actions in their fight against terrorists.",
    "lastUpdated": "2010-11-30T12:36:24Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1011.6526v1"
  },
  {
    "title": "Reciprocity as the foundation of Financial Economics",
    "authors": [
      "Timothy C. Johnson"
    ],
    "abstract": "This paper argues that the fundamental principle of contemporary financial economics is balanced reciprocity, not the principle of utility maximisation that is important in economics more generally. The argument is developed by analysing the mathematical Fundamental Theory of Asset Pricing with reference to the emergence of mathematical probability in the seventeenth century in the context of the ethical assessment of commercial contracts. This analysis is undertaken within a framework of Pragmatic philosophy and Virtue Ethics. The purpose of the paper is to mitigate future financial crises by reorienting financial economics to emphasise the objectives of market stability and social cohesion rather than individual utility maximisation.",
    "lastUpdated": "2013-10-10T12:53:39Z",
    "categories": [
      "q-fin.GN",
      "math.HO",
      "91G03 (Primary) 60A99, 01A65, 01A45 (Secondary)"
    ],
    "url": "http://arxiv.org/abs/1310.2798v1"
  },
  {
    "title": "Plagiarism: Words and ideas",
    "authors": [
      "Mathieu Bouville"
    ],
    "abstract": "Plagiarism is a crime against academy. It deceives readers, hurts plagiarized authors, and gets the plagiarist undeserved benefits. However, even though these arguments do show that copying other people's intellectual contribution is wrong, they do not apply to the copying of words. Copying a few sentences that contain no original idea (e.g. in the introduction) is of marginal importance compared to stealing the ideas of others. The two must be clearly distinguished, and the 'plagiarism' label should not be used for deeds which are very different in nature and importance. Keywords: academic dishonesty; academic integrity; academic misconduct; cheating; copyright infringement; ethics; intellectual property; research misconduct",
    "lastUpdated": "2008-03-11T07:25:57Z",
    "categories": [
      "physics.soc-ph",
      "physics.ed-ph"
    ],
    "url": "http://arxiv.org/abs/0803.1526v1"
  },
  {
    "title": "A proposal for ethically traceable artificial intelligence",
    "authors": [
      "Christopher A. Tucker"
    ],
    "abstract": "Although the problem of a critique of robotic behavior in near-unanimous agreement to human norms seems intractable, a starting point of such an ambition is a framework of the collection of knowledge a priori and experience a posteriori categorized as a set of synthetical judgments available to the intelligence, translated into computer code. If such a proposal were successful, an algorithm with ethically traceable behavior and cogent equivalence to human cognition is established. This paper will propose the application of Kant's critique of reason to current programming constructs of an autonomous intelligent system.",
    "lastUpdated": "2017-05-28T09:15:49Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1703.01908v2"
  },
  {
    "title": "A Short Review of Ethical Challenges in Clinical Natural Language Processing",
    "authors": [
      "Simon Šuster",
      "Stéphan Tulkens",
      "Walter Daelemans"
    ],
    "abstract": "Clinical NLP has an immense potential in contributing to how clinical practice will be revolutionized by the advent of large scale processing of clinical records. However, this potential has remained largely untapped due to slow progress primarily caused by strict data access policies for researchers. In this paper, we discuss the concern for privacy and the measures it entails. We also suggest sources of less sensitive data. Finally, we draw attention to biases that can compromise the validity of empirical research and lead to socially harmful applications.",
    "lastUpdated": "2017-03-29T15:12:10Z",
    "categories": [
      "cs.CL",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1703.10090v1"
  },
  {
    "title": "On an Ethical Use of Neural Networks: A Case Study on a North Indian Raga",
    "authors": [
      "Ripunjai Kumar Shukla",
      "Soubhik Chakraborty"
    ],
    "abstract": "The paper gives an artificial neural network (ANN) approach to time series modeling, the data being instance versus notes (characterized by pitch) depicting the structure of a North Indian raga, namely, Bageshree. Respecting the sentiments of the artists' community, the paper argues why it is more ethical to model a structure than try and \"manufacture\" an artist by training the neural network to copy performances of artists. Indian Classical Music centers on the ragas, where emotion and devotion are both important and neither can be substituted by such \"calculated artistry\" which the ANN generated copies are ultimately up to.",
    "lastUpdated": "2012-02-27T14:36:43Z",
    "categories": [
      "cs.NE",
      "cs.SD"
    ],
    "url": "http://arxiv.org/abs/1202.5953v1"
  },
  {
    "title": "Studying Politically Vulnerable Communities Online: Ethical Dilemmas, Questions, and Solutions",
    "authors": [
      "Robert Gorwa",
      "Philip N. Howard"
    ],
    "abstract": "This short article introduces the concept of political vulnerability for social media researchers. How are traditional notions of harm challenged by research subjects in politically vulnerable communities? Through a selection of case studies, we explore some of the trade-offs, challenges, and questions raised by research that seeks be robust and transparent while also preserving anonymity and privacy, especially in high-stakes, politically fraught contexts.",
    "lastUpdated": "2018-06-03T16:46:39Z",
    "categories": [
      "cs.CY",
      "cs.SI"
    ],
    "url": "http://arxiv.org/abs/1806.00830v1"
  },
  {
    "title": "A global consumer-led strategy to tackle climate change",
    "authors": [
      "Anthony J. Webster"
    ],
    "abstract": "A successful response to climate change needs vast investments in low-carbon research, energy, and sustainable development. Governments can drive research, provide environmental regulation, and accelerate global development, but the necessary low-carbon investments of 2-3% GDP have yet to materialise. A new strategy to tackle climate change through consumer and government action is outlined. It relies on ethical investments for sustainable development and low-carbon energy, and a voluntarily financed low-carbon fund for adaptation to climate change. Together these enable a global response through individual actions and investments. With OECD savings exceeding 5% of disposable household income, ethical savings alone have considerable potential.",
    "lastUpdated": "2018-09-25T08:28:12Z",
    "categories": [
      "physics.soc-ph",
      "q-fin.GN"
    ],
    "url": "http://arxiv.org/abs/1807.03364v2"
  },
  {
    "title": "Doing Math in Jest: Reflections on Useless Math, the Unreasonable Effectiveness of Mathematics, and the Ethical Obligations of Mathematicians",
    "authors": [
      "Gizem Karaali"
    ],
    "abstract": "Mathematicians occasionally discover interesting truths even when they are playing with mathematical ideas with no thoughts about possible consequences of their actions. This paper describes two specific instances of this phenomenon. The discussion touches upon the theme of the unreasonable effectiveness of mathematics as well as the ethical obligations of mathematicians.",
    "lastUpdated": "2018-12-22T20:37:46Z",
    "categories": [
      "math.HO"
    ],
    "url": "http://arxiv.org/abs/1812.09601v1"
  },
  {
    "title": "Modeling, discretization, and hyperchaos detection of conformable derivative approach to a financial system with market confidence and ethics risk",
    "authors": [
      "Baogui Xin",
      "Wei Peng",
      "Yekyung Kwon",
      "Yanqin Liu"
    ],
    "abstract": "A new chaotic financial system is proposed by considering ethics involvement in a four-dimensional financial system with market confidence. A five-dimensional conformable derivative financial system is presented by introducing conformable fractional calculus to the integer-order system. A discretization scheme is proposed to calculate numerical solutions of conformable derivative systems. The scheme is illustrated by testing hyperchaos for the system.",
    "lastUpdated": "2019-04-02T16:12:01Z",
    "categories": [
      "q-fin.GN"
    ],
    "url": "http://arxiv.org/abs/1903.12267v2"
  },
  {
    "title": "A Taxonomy for Virtual and Augmented Reality in Education",
    "authors": [
      "Jiri Motejlek",
      "Esat Alpay"
    ],
    "abstract": "In this paper, a taxonomy for VR/AR in education is presented that can help differentiate and categorise education experiences and provide indication as to why some applications of fail whereas others succeed. Examples will be presented to illustrate the taxonomy, including its use in developing and planning two current VR projects in our laboratory. The first project is a VR application for the training of Chemical Engineering students (and potentially industrial operators) on the use of a physical pilot plant facility. The second project involves the use of VR cinematography for enacting ethics scenarios (and thus ethical awareness and development) pertinent to engineering work situations.",
    "lastUpdated": "2019-06-28T05:56:57Z",
    "categories": [
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/1906.12051v1"
  },
  {
    "title": "Decentralising power: how we are trying to keep CALLector ethical",
    "authors": [
      "Cathy Chua",
      "Hanieh Habibi",
      "Manny Rayner",
      "Nikos Tsourakis"
    ],
    "abstract": "We present a brief overview of the CALLector project, and consider ethical questions arising from its overall goal of creating a social network to support creation and use of online CALL resources. We argue that these questions are best addressed in a decentralised, pluralistic open source architecture.",
    "lastUpdated": "2019-07-30T20:29:46Z",
    "categories": [
      "cs.HC",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1908.06877v1"
  },
  {
    "title": "Functionally Effective Conscious AI Without Suffering",
    "authors": [
      "Aman Agarwal",
      "Shimon Edelman"
    ],
    "abstract": "Insofar as consciousness has a functional role in facilitating learning and behavioral control, the builders of autonomous AI systems are likely to attempt to incorporate it into their designs. The extensive literature on the ethics of AI is concerned with ensuring that AI systems, and especially autonomous conscious ones, behave ethically. In contrast, our focus here is on the rarely discussed complementary aspect of engineering conscious AI: how to avoid condemning such systems, for whose creation we would be solely responsible, to unavoidable suffering brought about by phenomenal self-consciousness. We outline two complementary approaches to this problem, one motivated by a philosophical analysis of the phenomenal self, and the other by certain computational concepts in reinforcement learning.",
    "lastUpdated": "2020-02-13T17:59:15Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2002.05652v1"
  },
  {
    "title": "Can Society Function Without Ethical Agents? An Informational Perspective",
    "authors": [
      "Bruno Strulovici"
    ],
    "abstract": "Many facts are learned through the intermediation of individuals with special access to information, such as law enforcement officers, officials with a security clearance, or experts with specific knowledge. This paper considers whether societies can learn about such facts when information is cheap to manipulate, produced sequentially, and these individuals are devoid of ethical motive. The answer depends on an \"information attrition\" condition pertaining to the amount of evidence available which distinguishes, for example, between reproducible scientific evidence and the evidence generated in a crime. Applications to institution enforcement, social cohesion, scientific progress, and historical revisionism are discussed.",
    "lastUpdated": "2020-03-11T02:08:44Z",
    "categories": [
      "cs.GT",
      "econ.TH"
    ],
    "url": "http://arxiv.org/abs/2003.05441v1"
  },
  {
    "title": "\"EHLO WORLD\" -- Checking If Your Conversational AI Knows Right from Wrong",
    "authors": [
      "Elayne Ruane",
      "Vivek Nallur"
    ],
    "abstract": "In this paper we discuss approaches to evaluating and validating the ethical claims of a Conversational AI system. We outline considerations around both a top-down regulatory approach and bottom-up processes. We describe the ethical basis for each approach and propose a hybrid which we demonstrate by taking the case of a customer service chatbot as an example. We speculate on the kinds of top-down and bottom-up processes that would need to exist for a hybrid framework to successfully function as both an enabler as well as a shepherd among multiple use-cases and multiple competing AI solutions.",
    "lastUpdated": "2020-06-18T11:33:02Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "I.2, J.4"
    ],
    "url": "http://arxiv.org/abs/2006.10437v1"
  },
  {
    "title": "Privacy Implications of Eye Tracking in Mixed Reality",
    "authors": [
      "Diane Hosfelt",
      "Nicole Shadowen"
    ],
    "abstract": "Mixed Reality (MR) devices require a world with always-on sensors and real-time processing applied to their outputs. We have grappled with some of the ethical concerns presented by this scenario, such as bystander privacy issues with smartphones and cameras. However, MR technologies demand that we define and defend privacy in this new paradigm. This paper focuses on the challenges presented by eye tracking and gaze tracking, techniques that have commonly been deployed in the HCI community for years but are now being integrated into MR devices by default.",
    "lastUpdated": "2020-07-20T16:25:35Z",
    "categories": [
      "cs.HC",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2007.10235v1"
  },
  {
    "title": "Accounts, Accountability and Agency for Safe and Ethical AI",
    "authors": [
      "Rob Procter",
      "Mark Rouncefield",
      "Peter Tolmie"
    ],
    "abstract": "We examine the problem of explainable AI (xAI) and explore what delivering xAI means in practice, particularly in contexts that involve formal or informal and ad-hoc collaboration where agency and accountability in decision-making are achieved and sustained interactionally. We use an example from an earlier study of collaborative decision-making in screening mammography and the difficulties users faced when trying to interpret the behavior of an AI tool to illustrate the challenges of delivering usable and effective xAI. We conclude by setting out a study programme for future research to help advance our understanding of xAI requirements for safe and ethical AI.",
    "lastUpdated": "2020-10-03T10:05:58Z",
    "categories": [
      "cs.HC",
      "H.1.2"
    ],
    "url": "http://arxiv.org/abs/2010.01316v1"
  },
  {
    "title": "Asteroid Resource Utilization: Ethical Concerns and Progress",
    "authors": [
      "Andrew S. Rivkin",
      "Moses Milazzo",
      "Aparna Venkatesan",
      "Elizabeth Frank",
      "Monica R. Vidaurri",
      "Phil Metzger",
      "Chris Lewicki"
    ],
    "abstract": "As asteroid mining moves toward reality, the high bar to entering the business may limit participation and increase inequality, reducing or eliminating any benefit gained by marginalized people or developing nations. Consideration of ethical issues is urgently needed, as well as participation in international, not merely multilateral, solutions.",
    "lastUpdated": "2020-11-06T14:11:32Z",
    "categories": [
      "astro-ph.IM",
      "astro-ph.EP"
    ],
    "url": "http://arxiv.org/abs/2011.03369v1"
  },
  {
    "title": "Ethical considerations in an online community: the balancing act",
    "authors": [
      "Cécile Paris",
      "Nathalie Colineau",
      "Surya Nepal",
      "Sanat Bista",
      "Gina Beschorner"
    ],
    "abstract": "With the emergence and rapid growth of Social Media, a number of government departments in several countries have embraced Social Media as a privilege channel to interact with their constituency. We are exploring, in collaboration with the Australian Department of Human Services, the possibility to exploit the potential of social networks to support specific groups of citizens. To this end, we have developed Next Step, an online community to help people currently receiving welfare payments find a job and become financially self-sufficient. In this paper, we explore some ethical issues that arise when governments engage directly with citizens, in particular with communities in difficult situations, and when researchers are involved. We describe some of the challenges we faced and how we addressed them. Our work highlights the complexity of the problem, when an online community involves a government department and a welfare recipient group with a dependency relationship with that department. It becomes a balancing act, with the need to ensure privacy of the community members whilst still fulfilling the government's legal responsibilities. While difficult, these issues must be addressed if governments are to engage with their citizens using Social Media.",
    "lastUpdated": "2013-11-15T04:29:21Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1311.4389v1"
  },
  {
    "title": "AI for the Common Good?! Pitfalls, challenges, and Ethics Pen-Testing",
    "authors": [
      "Bettina Berendt"
    ],
    "abstract": "Recently, many AI researchers and practitioners have embarked on research visions that involve doing AI for \"Good\". This is part of a general drive towards infusing AI research and practice with ethical thinking. One frequent theme in current ethical guidelines is the requirement that AI be good for all, or: contribute to the Common Good. But what is the Common Good, and is it enough to want to be good? Via four lead questions, I will illustrate challenges and pitfalls when determining, from an AI point of view, what the Common Good is and how it can be enhanced by AI. The questions are: What is the problem / What is a problem?, Who defines the problem?, What is the role of knowledge?, and What are important side effects and dynamics? The illustration will use an example from the domain of \"AI for Social Good\", more specifically \"Data Science for Social Good\". Even if the importance of these questions may be known at an abstract level, they do not get asked sufficiently in practice, as shown by an exploratory study of 99 contributions to recent conferences in the field. Turning these challenges and pitfalls into a positive recommendation, as a conclusion I will draw on another characteristic of computer-science thinking and practice to make these impediments visible and attenuate them: \"attacks\" as a method for improving design. This results in the proposal of ethics pen-testing as a method for helping AI designs to better contribute to the Common Good.",
    "lastUpdated": "2018-11-01T12:34:32Z",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1810.12847v2"
  },
  {
    "title": "Canada Protocol: an ethical checklist for the use of Artificial Intelligence in Suicide Prevention and Mental Health",
    "authors": [
      "Carl-Maria Mörch",
      "Abhishek Gupta",
      "Brian L. Mishara"
    ],
    "abstract": "Introduction: To improve current public health strategies in suicide prevention and mental health, governments, researchers and private companies increasingly use information and communication technologies, and more specifically Artificial Intelligence and Big Data. These technologies are promising but raise ethical challenges rarely covered by current legal systems. It is essential to better identify, and prevent potential ethical risks. Objectives: The Canada Protocol - MHSP is a tool to guide and support professionals, users, and researchers using AI in mental health and suicide prevention. Methods: A checklist was constructed based upon ten international reports on AI and ethics and two guides on mental health and new technologies. 329 recommendations were identified, of which 43 were considered as applicable to Mental Health and AI. The checklist was validated, using a two round Delphi Consultation. Results: 16 experts participated in the first round of the Delphi Consultation and 8 participated in the second round. Of the original 43 items, 38 were retained. They concern five categories: \"Description of the Autonomous Intelligent System\" (n=8), \"Privacy and Transparency\" (n=8), \"Security\" (n=6), \"Health-Related Risks\" (n=8), \"Biases\" (n=8). The checklist was considered relevant by most users, and could need versions tailored to each category of target users.",
    "lastUpdated": "2019-07-17T13:14:13Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1907.07493v1"
  },
  {
    "title": "Algorithmic decision-making in AVs: Understanding ethical and technical concerns for smart cities",
    "authors": [
      "Hazel Si Min Lim",
      "Araz Taeihagh"
    ],
    "abstract": "Autonomous Vehicles (AVs) are increasingly embraced around the world to advance smart mobility and more broadly, smart, and sustainable cities. Algorithms form the basis of decision-making in AVs, allowing them to perform driving tasks autonomously, efficiently, and more safely than human drivers and offering various economic, social, and environmental benefits. However, algorithmic decision-making in AVs can also introduce new issues that create new safety risks and perpetuate discrimination. We identify bias, ethics, and perverse incentives as key ethical issues in the AV algorithms' decision-making that can create new safety risks and discriminatory outcomes. Technical issues in the AVs' perception, decision-making and control algorithms, limitations of existing AV testing and verification methods, and cybersecurity vulnerabilities can also undermine the performance of the AV system. This article investigates the ethical and technical concerns surrounding algorithmic decision-making in AVs by exploring how driving decisions can perpetuate discrimination and create new safety risks for the public. We discuss steps taken to address these issues, highlight the existing research gaps and the need to mitigate these issues through the design of AV's algorithms and of policies and regulations to fully realise AVs' benefits for smart and sustainable cities.",
    "lastUpdated": "2019-10-29T07:50:02Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "url": "http://arxiv.org/abs/1910.13122v1"
  },
  {
    "title": "Robot Rights? Let's Talk about Human Welfare Instead",
    "authors": [
      "Abeba Birhane",
      "Jelle van Dijk"
    ],
    "abstract": "The 'robot rights' debate, and its related question of 'robot responsibility', invokes some of the most polarized positions in AI ethics. While some advocate for granting robots rights on a par with human beings, others, in a stark opposition argue that robots are not deserving of rights but are objects that should be our slaves. Grounded in post-Cartesian philosophical foundations, we argue not just to deny robots 'rights', but to deny that robots, as artifacts emerging out of and mediating human being, are the kinds of things that could be granted rights in the first place. Once we see robots as mediators of human being, we can understand how the `robots rights' debate is focused on first world problems, at the expense of urgent ethical concerns, such as machine bias, machine elicited human labour exploitation, and erosion of privacy all impacting society's least privileged individuals. We conclude that, if human being is our starting point and human welfare is the primary concern, the negative impacts emerging from machinic systems, as well as the lack of taking responsibility by people designing, selling and deploying such machines, remains the most pressing ethical discussion in AI.",
    "lastUpdated": "2020-01-14T20:54:29Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2001.05046v1"
  },
  {
    "title": "No computation without representation: Avoiding data and algorithm biases through diversity",
    "authors": [
      "Caitlin Kuhlman",
      "Latifa Jackson",
      "Rumi Chunara"
    ],
    "abstract": "The emergence and growth of research on issues of ethics in AI, and in particular algorithmic fairness, has roots in an essential observation that structural inequalities in society are reflected in the data used to train predictive models and in the design of objective functions. While research aiming to mitigate these issues is inherently interdisciplinary, the design of unbiased algorithms and fair socio-technical systems are key desired outcomes which depend on practitioners from the fields of data science and computing. However, these computing fields broadly also suffer from the same under-representation issues that are found in the datasets we analyze. This disconnect affects the design of both the desired outcomes and metrics by which we measure success. If the ethical AI research community accepts this, we tacitly endorse the status quo and contradict the goals of non-discrimination and equity which work on algorithmic fairness, accountability, and transparency seeks to address. Therefore, we advocate in this work for diversifying computing as a core priority of the field and our efforts to achieve ethical AI practices. We draw connections between the lack of diversity within academic and professional computing fields and the type and breadth of the biases encountered in datasets, machine learning models, problem formulations, and interpretation of results. Examining the current fairness/ethics in AI literature, we highlight cases where this lack of diverse perspectives has been foundational to the inequity in treatment of underrepresented and protected group data. We also look to other professional communities, such as in law and health, where disparities have been reduced both in the educational diversity of trainees and among professional practices. We use these lessons to develop recommendations that provide concrete steps for the computing community to increase diversity.",
    "lastUpdated": "2020-02-26T23:07:39Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2002.11836v1"
  },
  {
    "title": "Response by the Montreal AI Ethics Institute to the Santa Clara Principles on Transparency and Accountability in Online Content Moderation",
    "authors": [
      "Marianna Bergamaschi Ganapini",
      "Camylle Lanteigne",
      "Abhishek Gupta"
    ],
    "abstract": "In April 2020, the Electronic Frontier Foundation (EFF) publicly called for comments on expanding and improving the Santa Clara Principles on Transparency and Accountability (SCP), originally published in May 2018. The Montreal AI Ethics Institute (MAIEI) responded to this call by drafting a set of recommendations based on insights and analysis by the MAIEI staff and supplemented by workshop contributions from the AI Ethics community convened during two online public consultation workshops. In its submission, MAIEI provides 12 overarching recommendations for the SCP, these include: 1) ensure there is more diversity in the content moderation process; 2) increase transparency into how platforms guide content-ranking; 3) disclose anonymized data on the training and/or cultural background of the content moderators for a platform; 4) tailor content moderation tools for specific issues; 5) draft specific guidelines for messaging applications with regards to data protection in content moderation; 6) take into account cultural differences relevant to what constitutes acceptable behavior online; 7) ensure platforms are transparent in regards to political advertising; 8) ensure greater transparency into the user-generated flagging/reporting systems deployed by a platform; 9) clarify if user content is flagged or reported through an automated system; 10) provide more data on the types of content removed from platforms; 11) provide clear guidelines on the appeal process, as well as data on prior appeals; 12) create a system for periodically revisiting the SCP so it reflects various technological advancements, modifications in law and policy, as well as changing trends or movements in content moderation.",
    "lastUpdated": "2020-07-01T18:46:08Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2007.00700v1"
  },
  {
    "title": "Precision Health Data: Requirements, Challenges and Existing Techniques for Data Security and Privacy",
    "authors": [
      "Chandra Thapa",
      "Seyit Camtepe"
    ],
    "abstract": "Precision health leverages information from various sources, including omics, lifestyle, environment, social media, medical records, and medical insurance claims to enable personalized care, prevent and predict illness, and precise treatments. It extensively uses sensing technologies (e.g., electronic health monitoring devices), computations (e.g., machine learning), and communication (e.g., interaction between the health data centers). As health data contain sensitive private information, including the identity of patient and carer and medical conditions of the patient, proper care is required at all times. Leakage of these private information affects the personal life, including bullying, high insurance premium, and loss of job due to the medical history. Thus, the security, privacy of and trust on the information are of utmost importance. Moreover, government legislation and ethics committees demand the security and privacy of healthcare data. Herein, in the light of precision health data security, privacy, ethical and regulatory requirements, finding the best methods and techniques for the utilization of the health data, and thus precision health is essential. In this regard, firstly, this paper explores the regulations, ethical guidelines around the world, and domain-specific needs. Then it presents the requirements and investigates the associated challenges. Secondly, this paper investigates secure and privacy-preserving machine learning methods suitable for the computation of precision health data along with their usage in relevant health projects. Finally, it illustrates the best available techniques for precision health data security and privacy with a conceptual system model that enables compliance, ethics clearance, consent management, medical innovations, and developments in the health domain.",
    "lastUpdated": "2020-08-24T22:17:32Z",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2008.10733v1"
  },
  {
    "title": "Is diversity good?",
    "authors": [
      "Mathieu Bouville"
    ],
    "abstract": "Prominent ethical and policy issues such as affirmative action and female enrollment in science and engineering revolve around the idea that diversity is good. However, even though diversity is an ambiguous concept, a precise definition is seldom provided. We show that diversity may be construed as a factual description, a craving for symmetry, an intrinsic good, an instrumental good, a symptom, or a side effect. These acceptions differ vastly in their nature and properties. The first one cannot lead to any action and the second one is mistaken. Diversity as intrinsic good is a mere opinion, which cannot be concretely applied; moreover, the most commonly invoked forms of diversity (sexual and racial) are not intrinsically good. On the other hand, diversity as instrumental good can be evaluated empirically and can give rise to policies, but these may be very weak. Finally, symptoms and side effects are not actually about diversity. We consider the example of female enrollment in science and engineering, interpreting the various arguments found in the literature in light of this polysemy. Keywords: ethics, policy, higher education, female students, minority students, affirmative action",
    "lastUpdated": "2007-04-19T16:03:51Z",
    "categories": [
      "physics.soc-ph"
    ],
    "url": "http://arxiv.org/abs/0704.2466v1"
  },
  {
    "title": "Incorporating Individual and Collective Ethics into Phase I Cancer Trial Designs",
    "authors": [
      "Jay Bartroff",
      "Tze Leung Lai"
    ],
    "abstract": "A general framework is proposed for Bayesian model-based designs of Phase I cancer trials, in which a general criterion for coherence (Cheung, 2005) of a design is also developed. This framework can incorporate both \"individual\" and \"collective\" ethics into the design of the trial. We propose a new design which minimizes a risk function composed of two terms, with one representing the individual risk of the current dose and the other representing the collective risk. The performance of this design, which is measured in terms of the accuracy of the estimated target dose at the end of the trial, the toxicity and overdose rates, and certain loss functions reflecting the individual and collective ethics, is studied and compared with existing Bayesian model-based designs and is shown to have better performance than existing designs.",
    "lastUpdated": "2011-08-04T21:33:53Z",
    "categories": [
      "stat.ME",
      "stat.AP"
    ],
    "url": "http://arxiv.org/abs/1108.1223v1"
  },
  {
    "title": "The Exploitation of Web Navigation Data: Ethical Issues and Alternative Scenarios",
    "authors": [
      "Luca Vassio",
      "Hassan Metwalley",
      "Danilo Giordano"
    ],
    "abstract": "Nowadays, the users' browsing activity on the Internet is not completely private due to many entities that collect and use such data, either for legitimate or illegal goals. The implications are serious, from a person who exposes unconsciously his private information to an unknown third party entity, to a company that is unable to control its information to the outside world. As a result, users have lost control over their private data in the Internet. In this paper, we present the entities involved in users' data collection and usage. Then, we highlight what are the ethical issues that arise for users, companies, scientists and governments. Finally, we present some alternative scenarios and suggestions for the entities to address such ethical issues.",
    "lastUpdated": "2016-05-02T14:43:59Z",
    "categories": [
      "cs.CY",
      "cs.CR",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1512.03211v2"
  },
  {
    "title": "A methodology for internal Web ethics",
    "authors": [
      "Michalis Vafopoulos",
      "Petros Stefaneas",
      "Ioannis Anagnostopoulos",
      "Kieron O'Hara"
    ],
    "abstract": "The vigorous impact of the Web in time and space arises from the fact that it motivates massive creation, editing and distribution of information by Users with little knowledge. This unprecedented continuum provides novel opportunities for innovation but also puts under jeopardy its survival as a stable construct that nurtures a complex system of connections. We examine the Web as an ethics determined space by demonstrating Hayek's theory of freedom in a three-leveled Web: technological, contextualized and economic. Our approach accounts for the co-dependence of code and values, and assumes that the Web is a self-contained system that exists in and by itself. This view of internal Web ethics directly connects the concept of freedom with issues like centralization of traffic and data control, rights on visiting log file, custom User profiles and the interplay among function, structure and morality of the Web. It is also demonstrated, in the case of Net Neutrality, that generic freedom-coercion trade-offs are incomplete in treating specific cases at work.",
    "lastUpdated": "2012-02-20T07:01:47Z",
    "categories": [
      "cs.CY",
      "68M14, 68M11",
      "K.4.1; H.3.5; C.2.5"
    ],
    "url": "http://arxiv.org/abs/1202.4238v1"
  },
  {
    "title": "Do Artificial Reinforcement-Learning Agents Matter Morally?",
    "authors": [
      "Brian Tomasik"
    ],
    "abstract": "Artificial reinforcement learning (RL) is a widely used technique in artificial intelligence that provides a general method for training agents to perform a wide variety of behaviours. RL as used in computer science has striking parallels to reward and punishment learning in animal and human brains. I argue that present-day artificial RL agents have a very small but nonzero degree of ethical importance. This is particularly plausible for views according to which sentience comes in degrees based on the abilities and complexities of minds, but even binary views on consciousness should assign nonzero probability to RL programs having morally relevant experiences. While RL programs are not a top ethical priority today, they may become more significant in the coming decades as RL is increasingly applied to industry, robotics, video games, and other areas. I encourage scientists, philosophers, and citizens to begin a conversation about our ethical duties to reduce the harm that we inflict on powerless, voiceless RL agents.",
    "lastUpdated": "2014-10-30T02:34:48Z",
    "categories": [
      "cs.AI",
      "I.2.0; K.4.1"
    ],
    "url": "http://arxiv.org/abs/1410.8233v1"
  },
  {
    "title": "Does the Internet deserve everybody?",
    "authors": [
      "Yehia Elkhatib",
      "Gareth Tyson",
      "Arjuna Sathiaseelan"
    ],
    "abstract": "There has been a long standing tradition amongst developed nations of influencing, both directly and indirectly, the activities of developing economies. Behind this is one of a range of aims: building/improving living standards, bettering the social status of recipient communities, etc. In some cases, this has resulted in prosperous relations, yet often this has been seen as the exploitation of a power position or a veneer for other activities (e.g. to tap into new emerging markets). In this paper, we explore whether initiatives to improve Internet connectivity in developing regions are always ethical. We draw a list of issues that would aid in formulating Internet initiatives that are ethical, effective, and sustainable.",
    "lastUpdated": "2015-11-24T00:27:54Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1511.07519v1"
  },
  {
    "title": "Unethical Research: How to Create a Malevolent Artificial Intelligence",
    "authors": [
      "Federico Pistono",
      "Roman V. Yampolskiy"
    ],
    "abstract": "Cybersecurity research involves publishing papers about malicious exploits as much as publishing information on how to design tools to protect cyber-infrastructure. It is this information exchange between ethical hackers and security experts, which results in a well-balanced cyber-ecosystem. In the blooming domain of AI Safety Engineering, hundreds of papers have been published on different proposals geared at the creation of a safe machine, yet nothing, to our knowledge, has been published on how to design a malevolent machine. Availability of such information would be of great value particularly to computer scientists, mathematicians, and others who have an interest in AI safety, and who are attempting to avoid the spontaneous emergence or the deliberate creation of a dangerous AI, which can negatively affect human activities and in the worst case cause the complete obliteration of the human species. This paper provides some general guidelines for the creation of a Malevolent Artificial Intelligence (MAI).",
    "lastUpdated": "2016-09-01T18:29:13Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1605.02817v2"
  },
  {
    "title": "The multiplicity of memory enhancement: Practical and ethical implications of the diverse neural substrates underlying human memory systems",
    "authors": [
      "Kieran C. R. Fox",
      "Nicholas S. Fitz",
      "Peter B. Reiner"
    ],
    "abstract": "The neural basis of human memory is incredibly complex. We argue that the diversity of neural systems underlying various forms of memory suggests that any discussion of enhancing 'memory' per se is too broad, thus obfuscating the biopolitical debate about human enhancement. Memory can be differentiated into at least four major (and several minor) systems with largely dissociable (i.e., non-overlapping) neural substrates. We outline each system, and discuss both the practical and the ethical implications of these diverse neural substrates. In practice, distinct neural bases imply the possibility, and likely the necessity, of specific approaches for the safe and effective enhancement of various memory systems. In the debate over the ethical and social implications of enhancement technologies, this fine-grained perspective clarifies - and may partially mitigate - certain common concerns in enhancement debates, including issues related to safety, fairness, coercion, and authenticity. While many researchers certainly appreciate the neurobiological complexity of memory, the political debate tends to revolve around a monolithic one-size-fits-all conception. The overall project - exploring how human enhancement technologies affect society - stands to benefit from a deeper appreciation of memory's neurobiological diversity.",
    "lastUpdated": "2016-09-26T17:17:04Z",
    "categories": [
      "q-bio.NC"
    ],
    "url": "http://arxiv.org/abs/1609.08083v1"
  },
  {
    "title": "A measure of authorship by publications",
    "authors": [
      "Conan Mukherje",
      "Ranojoy Basu",
      "Aftab Alam"
    ],
    "abstract": "Measuring publication success of a researcher is a complicated task as publications are often co-authored by multiple authors, and so, require comparison of solo publications with joint publications. In this paper, like \\cite{price1981multiple}, we argue for an egalitarian perspective in accomplishing this task. More specifically, we justify the need for an ethical perspective in quantifying academic author by identifying certain ethical difficulties of some popular contemporary indices used for this purpose. And then we show that for any given dataset of research papers, the unique method satisfying the ethical notions of {\\it identity independence} and performance invariance must be the egaliatarian E-index proposed by \\cite{bps} and \\cite{price1981multiple}. In our setting, this egalitarian method divides authorship of joint projects equally among authors and sums across all publications of each author.",
    "lastUpdated": "2019-10-20T06:55:32Z",
    "categories": [
      "cs.DL",
      "physics.soc-ph"
    ],
    "url": "http://arxiv.org/abs/1705.01731v4"
  },
  {
    "title": "An Online Consent Maturity Model: Moving from Acceptable Use towards Ethical Practice",
    "authors": [
      "Vivien M. Rooney",
      "Simon N. Foley"
    ],
    "abstract": "The particular characteristics associated with qualitative longitudinal research in the disciplines of psychology and social science have prompted the development of informed consent. There are analogies between these characteristics and the collection and analysis of data in online settings. How and why informed consent has developed in qualitative longitudinal research, both theoretically and practically, can provide a useful resource for considering what informed consent means in online settings. Building on this analogy, criteria are proposed that can be used to provide an ethical judgement on consent practices in an online data handling activity, and form the basis for a consent maturity model. It is argued that if we are to learn from from the history of informed consent in qualitative longitudinal research, then we should strive for an Ethics of Virtue approach to informed consent online, the highest level of maturity.",
    "lastUpdated": "2018-10-30T14:16:59Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1710.10022v2"
  },
  {
    "title": "Ethical Questions in NLP Research: The (Mis)-Use of Forensic Linguistics",
    "authors": [
      "Anil Kumar Singh",
      "Akhilesh Sudhakar"
    ],
    "abstract": "Ideas from forensic linguistics are now being used frequently in Natural Language Processing (NLP), using machine learning techniques. While the role of forensic linguistics was more benign earlier, it is now being used for purposes which are questionable. Certain methods from forensic linguistics are employed, without considering their scientific limitations and ethical concerns. While we take the specific case of forensic linguistics as an example of such trends in NLP and machine learning, the issue is a larger one and present in many other scientific and data-driven domains. We suggest that such trends indicate that some of the applied sciences are exceeding their legal and scientific briefs. We highlight how carelessly implemented practices are serving to short-circuit the due processes of law as well breach ethical codes.",
    "lastUpdated": "2017-12-20T15:03:04Z",
    "categories": [
      "cs.CL",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1712.07512v1"
  },
  {
    "title": "A Mathematical Approach to Comply with Ethical Constraints in Compassionate Use Treatments",
    "authors": [
      "F. Thomas Bruss"
    ],
    "abstract": "Patients who are seriously ill may ask doctors to treat them with unapproved medication, about which not much is known, or else with known medication in a high dosage. Apart from strict legal constraints such cases may involve difficult ethical questions as e.g. how long a series of treatments of different patients should be continued. Similar questions also arise in less serious situations. A physician trusts that a certain combination of freely available drugs are efficient against a specific disease and tries to help patients and to follow at the same time the primum-non-nocere principle. The objective of this paper is to contribute to the research on such questions in the form of mathematical models. Arguing in a step-to-step approach, we will show that certain sequential optimisation problems comply in a natural way with the true spirit of major ethical principles in medicine. We then suggest protocols and associate algorithms to find optimal, or approximately optimal, treatment strategies. Although the contribution may sometimes be difficult to apply in medical practice, the author thinks that the rational behind the approach offers a valuable alternative for finding decision support and should attract attention.",
    "lastUpdated": "2018-04-09T09:04:13Z",
    "categories": [
      "stat.OT",
      "math.PR",
      "60-01 (primary), 60G40 (secondary)"
    ],
    "url": "http://arxiv.org/abs/1804.04628v1"
  },
  {
    "title": "Research on Artificial Intelligence Ethics Based on the Evolution of Population Knowledge Base",
    "authors": [
      "Feng Liu",
      "Yong Shi"
    ],
    "abstract": "The unclear development direction of human society is a deep reason for that it is difficult to form a uniform ethical standard for human society and artificial intelligence. Since the 21st century, the latest advances in the Internet, brain science and artificial intelligence have brought new inspiration to the research on the development direction of human society. Through the study of the Internet brain model, AI IQ evaluation, and the evolution of the brain, this paper proposes that the evolution of population knowledge base is the key for judging the development direction of human society, thereby discussing the standards and norms for the construction of artificial intelligence ethics.",
    "lastUpdated": "2018-11-18T04:03:39Z",
    "categories": [
      "cs.OH",
      "cs.AI",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1806.10095v3"
  },
  {
    "title": "Ethical Aspects of Internet of Things from Islamic Perspective",
    "authors": [
      "Wazir Zada Khan",
      "Mohammed Zahid",
      "Mohammed Y Aalsalem",
      "Hussein Mohammed Zangoti",
      "Quratulain Arshad"
    ],
    "abstract": "The Internet of Things (IoTs) is an evolving new face of technology that provides state of the art services using ubiquitously connected smart objects. These smart objects are capable of sensing, processing, collaborating, communicating the events and provide services. The IoT is a collection of heterogeneous technologies like Sensor, RFID, Communication and nanotechnology. These technologies enable smart objects to identify objects, collect information about their status,communicating the collected information for taking some desired actions. Widespread adaptations of IoT based devices and services raised the ethical challenges for their users. In this paper we highlight ethical challenges raised by IoT and discuss the solutions and methods for encouraging people to properly use these technologies according to Islamic teachings.",
    "lastUpdated": "2018-06-29T12:53:17Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1806.11386v1"
  },
  {
    "title": "Can everyday AI be ethical. Fairness of Machine Learning Algorithms",
    "authors": [
      "Philippe Besse",
      "Celine Castets-Renard",
      "Aurelien Garivier",
      "Jean-Michel Loubes"
    ],
    "abstract": "Combining big data and machine learning algorithms, the power of automatic decision tools induces as much hope as fear. Many recently enacted European legislation (GDPR) and French laws attempt to regulate the use of these tools. Leaving aside the well-identified problems of data confidentiality and impediments to competition, we focus on the risks of discrimination, the problems of transparency and the quality of algorithmic decisions. The detailed perspective of the legal texts, faced with the complexity and opacity of the learning algorithms, reveals the need for important technological disruptions for the detection or reduction of the discrimination risk, and for addressing the right to obtain an explanation of the auto- matic decision. Since trust of the developers and above all of the users (citizens, litigants, customers) is essential, algorithms exploiting personal data must be deployed in a strict ethical framework. In conclusion, to answer this need, we list some ways of controls to be developed: institutional control, ethical charter, external audit attached to the issue of a label.",
    "lastUpdated": "2018-10-03T13:30:47Z",
    "categories": [
      "stat.OT",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1810.01729v1"
  },
  {
    "title": "TrolleyMod v1.0: An Open-Source Simulation and Data-Collection Platform for Ethical Decision Making in Autonomous Vehicles",
    "authors": [
      "Vahid Behzadan",
      "James Minton",
      "Arslan Munir"
    ],
    "abstract": "This paper presents TrolleyMod v1.0, an open-source platform based on the CARLA simulator for the collection of ethical decision-making data for autonomous vehicles. This platform is designed to facilitate experiments aiming to observe and record human decisions and actions in high-fidelity simulations of ethical dilemmas that occur in the context of driving. Targeting experiments in the class of trolley problems, TrolleyMod provides a seamless approach to creating new experimental settings and environments with the realistic physics-engine and the high-quality graphical capabilities of CARLA and the Unreal Engine. Also, TrolleyMod provides a straightforward interface between the CARLA environment and Python to enable the implementation of custom controllers, such as deep reinforcement learning agents. The results of such experiments can be used for sociological analyses, as well as the training and tuning of value-aligned autonomous vehicles based on social values that are inferred from observations.",
    "lastUpdated": "2018-11-14T01:50:20Z",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.RO"
    ],
    "url": "http://arxiv.org/abs/1811.05594v1"
  },
  {
    "title": "Towards Value-Sensitive Learning Analytics Design",
    "authors": [
      "Bodong Chen",
      "Haiyi Zhu"
    ],
    "abstract": "To support ethical considerations and system integrity in learning analytics, this paper introduces two cases of applying the Value Sensitive Design methodology to learning analytics design. The first study applied two methods of Value Sensitive Design, namely stakeholder analysis and value analysis, to a conceptual investigation of an existing learning analytics tool. This investigation uncovered a number of values and value tensions, leading to design trade-offs to be considered in future tool refinements. The second study holistically applied Value Sensitive Design to the design of a recommendation system for the Wikipedia WikiProjects. To proactively consider values among stakeholders, we derived a multi-stage design process that included literature analysis, empirical investigations, prototype development, community engagement, iterative testing and refinement, and continuous evaluation. By reporting on these two cases, this paper responds to a need of practical means to support ethical considerations and human values in learning analytics systems. These two cases demonstrate that Value Sensitive Design could be a viable approach for balancing a wide range of human values, which tend to encompass and surpass ethical issues, in learning analytics design.",
    "lastUpdated": "2019-01-28T16:59:32Z",
    "categories": [
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/1812.08335v2"
  },
  {
    "title": "Ethical Implications: The ACM/IEEE-CS Software Engineering Code applied to Tesla's \"Autopilot\" System",
    "authors": [
      "Kevin Vincent"
    ],
    "abstract": "On October 14, 2015, Tesla Inc. an American electric car company, released the initial version of the Autopilot system. This system promised to provide semi-autonomous driving using the existing hardware already installed on Tesla vehicles. On March 23rd, 2018, a Tesla vehicle ran into a divider at highway speed, killing the driver. This occurred under the control of the Autopilot system with no driver intervention. Critics argue that though Tesla gives drivers warnings in its owner's manual, it is ultimately unethical to release a system that is marketed as an Autopilot yet still makes grave mistakes that any human driver would not make. Others defend Tesla by stating that their advisories are suitable and that drivers should ultimately be at fault for any mistakes of the Autopilot. This paper will scrutinize the ethical implications of Tesla's choice to develop, market, and ship a beta product that requires extensive testing. It will further analyze the implications of Tesla's aggressive advertisement of the product under the name Autopilot along with associated marketing materials. By applying the joint ACM/IEEE-CS Software Engineering Code of Ethics, this paper will show that Tesla's choices and actions during this event are inconsistent with the code and are unethical since they are responsible for adequately testing and honestly marketing their product.",
    "lastUpdated": "2018-12-13T22:08:31Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1901.06244v1"
  },
  {
    "title": "Food for thought: Ethical considerations of user trust in computer vision",
    "authors": [
      "Kaylen J. Pfisterer",
      "Jennifer Boger",
      "Alexander Wong"
    ],
    "abstract": "In computer vision research, especially when novel applications of tools are developed, ethical implications around user perceptions of trust in the underlying technology should be considered and supported. Here, we describe an example of the incorporation of such considerations within the long-term care sector for tracking resident food and fluid intake. We highlight our recent user study conducted to develop a Goldilocks quality horizontal prototype designed to support trust cues in which perceived trust in our horizontal prototype was higher than the existing system in place. We discuss the importance and need for user engagement as part of ongoing computer vision-driven technology development and describe several important factors related to trust that are relevant to developing decision-making tools.",
    "lastUpdated": "2019-05-29T14:25:43Z",
    "categories": [
      "cs.CY",
      "cs.CV",
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/1905.12487v1"
  },
  {
    "title": "Ethically Aligned Design of Autonomous Systems: Industry viewpoint and an empirical study",
    "authors": [
      "Ville Vakkuri",
      "Kai-Kristian Kemell",
      "Joni Kultanen",
      "Mikko Siponen",
      "Pekka Abrahamsson"
    ],
    "abstract": "Progress in the field of artificial intelligence has been accelerating rapidly in the past two decades. Various autonomous systems from purely digital ones to autonomous vehicles are being developed and deployed out on the field. As these systems exert a growing impact on society, ethics in relation to artificial intelligence and autonomous systems have recently seen growing attention among the academia. However, the current literature on the topic has focused almost exclusively on theory and more specifically on conceptualization in the area. To widen the body of knowledge in the area, we conduct an empirical study on the current state of practice in artificial intelligence ethics. We do so by means of a multiple case study of five case companies, the results of which indicate a gap between research and practice in the area. Based on our findings we propose ways to tackle the gap.",
    "lastUpdated": "2019-06-19T07:15:51Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1906.07946v1"
  },
  {
    "title": "What is the Point of Fairness? Disability, AI and The Complexity of Justice",
    "authors": [
      "Cynthia L. Bennett",
      "Os Keyes"
    ],
    "abstract": "Work integrating conversations around AI and Disability is vital and valued, particularly when done through a lens of fairness. Yet at the same time, analyzing the ethical implications of AI for disabled people solely through the lens of a singular idea of \"fairness\" risks reinforcing existing power dynamics, either through reinforcing the position of existing medical gatekeepers, or promoting tools and techniques that benefit otherwise-privileged disabled people while harming those who are rendered outliers in multiple ways. In this paper we present two case studies from within computer vision - a subdiscipline of AI focused on training algorithms that can \"see\" - of technologies putatively intended to help disabled people but, through failures to consider structural injustices in their design, are likely to result in harms not addressed by a \"fairness\" framing of ethics. Drawing on disability studies and critical data science, we call on researchers into AI ethics and disability to move beyond simplistic notions of fairness, and towards notions of justice.",
    "lastUpdated": "2019-08-09T23:17:52Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1908.01024v3"
  },
  {
    "title": "Ethical Dilemmas in Strategic Games",
    "authors": [
      "Pavel Naumov",
      "Rui-Jie Yew"
    ],
    "abstract": "An agent, or a coalition of agents, faces an ethical dilemma between several statements if she is forced to make a conscious choice between which of these statements will be true. This paper proposes to capture ethical dilemmas as a modality in strategic game settings with and without limit on sacrifice and for perfect and imperfect information games. The authors show that the dilemma modality cannot be defined through the earlier proposed blameworthiness modality. The main technical result is a sound and complete axiomatization of the properties of this modality with sacrifice in games with perfect information.",
    "lastUpdated": "2020-12-13T22:41:18Z",
    "categories": [
      "cs.AI",
      "cs.GT",
      "cs.LO"
    ],
    "url": "http://arxiv.org/abs/1911.00786v2"
  },
  {
    "title": "Scenarios and Recommendations for Ethical Interpretive AI",
    "authors": [
      "John Licato",
      "Zaid Marji",
      "Sophia Abraham"
    ],
    "abstract": "Artificially intelligent systems, given a set of non-trivial ethical rules to follow, will inevitably be faced with scenarios which call into question the scope of those rules. In such cases, human reasoners typically will engage in interpretive reasoning, where interpretive arguments are used to support or attack claims that some rule should be understood a certain way. Artificially intelligent reasoners, however, currently lack the ability to carry out human-like interpretive reasoning, and we argue that bridging this gulf is of tremendous importance to human-centered AI. In order to better understand how future artificial reasoners capable of human-like interpretive reasoning must be developed, we have collected a dataset of ethical rules, scenarios designed to invoke interpretive reasoning, and interpretations of those scenarios. We perform a qualitative analysis of our dataset, and summarize our findings in the form of practical recommendations.",
    "lastUpdated": "2019-11-05T16:23:01Z",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "url": "http://arxiv.org/abs/1911.01917v1"
  },
  {
    "title": "On Consequentialism and Fairness",
    "authors": [
      "Dallas Card",
      "Noah A. Smith"
    ],
    "abstract": "Recent work on fairness in machine learning has primarily emphasized how to define, quantify, and encourage \"fair\" outcomes. Less attention has been paid, however, to the ethical foundations which underlie such efforts. Among the ethical perspectives that should be taken into consideration is consequentialism, the position that, roughly speaking, outcomes are all that matter. Although consequentialism is not free from difficulties, and although it does not necessarily provide a tractable way of choosing actions (because of the combined problems of uncertainty, subjectivity, and aggregation), it nevertheless provides a powerful foundation from which to critique the existing literature on machine learning fairness. Moreover, it brings to the fore some of the tradeoffs involved, including the problem of who counts, the pros and cons of using a policy, and the relative value of the distant future. In this paper we provide a consequentialist critique of common definitions of fairness within machine learning, as well as a machine learning perspective on consequentialism. We conclude with a broader discussion of the issues of learning and randomization, which have important implications for the ethics of automated decision making systems.",
    "lastUpdated": "2020-05-11T04:36:44Z",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2001.00329v2"
  },
  {
    "title": "Deontological Ethics By Monotonicity Shape Constraints",
    "authors": [
      "Serena Wang",
      "Maya Gupta"
    ],
    "abstract": "We demonstrate how easy it is for modern machine-learned systems to violate common deontological ethical principles and social norms such as \"favor the less fortunate,\" and \"do not penalize good attributes.\" We propose that in some cases such ethical principles can be incorporated into a machine-learned model by adding shape constraints that constrain the model to respond only positively to relevant inputs. We analyze the relationship between these deontological constraints that act on individuals and the consequentialist group-based fairness goals of one-sided statistical parity and equal opportunity. This strategy works with sensitive attributes that are Boolean or real-valued such as income and age, and can help produce more responsible and trustworthy AI.",
    "lastUpdated": "2020-03-13T00:20:00Z",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2001.11990v2"
  },
  {
    "title": "Diversity and Inclusion Metrics in Subset Selection",
    "authors": [
      "Margaret Mitchell",
      "Dylan Baker",
      "Nyalleng Moorosi",
      "Emily Denton",
      "Ben Hutchinson",
      "Alex Hanna",
      "Timnit Gebru",
      "Jamie Morgenstern"
    ],
    "abstract": "The ethical concept of fairness has recently been applied in machine learning (ML) settings to describe a wide range of constraints and objectives. When considering the relevance of ethical concepts to subset selection problems, the concepts of diversity and inclusion are additionally applicable in order to create outputs that account for social power and access differentials. We introduce metrics based on these concepts, which can be applied together, separately, and in tandem with additional fairness constraints. Results from human subject experiments lend support to the proposed criteria. Social choice methods can additionally be leveraged to aggregate and choose preferable sets, and we detail how these may be applied.",
    "lastUpdated": "2020-02-09T00:29:40Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2002.03256v1"
  },
  {
    "title": "Ethical Considerations and Statistical Analysis of Industry Involvement in Machine Learning Research",
    "authors": [
      "Thilo Hagendorff",
      "Kristof Meding"
    ],
    "abstract": "Industry involvement in the machine learning (ML) community seems to be increasing. However, the quantitative scale and ethical implications of this influence are rather unknown. For this purpose, we have not only carried out an informed ethical analysis of the field, but have inspected all papers of the main ML conferences NeurIPS, CVPR, and ICML of the last 5 years - almost 11,000 papers in total. Our statistical approach focuses on conflicts of interest, innovation and gender equality. We have obtained four main findings: (1) Academic-corporate collaborations are growing in numbers. At the same time, we found that conflicts of interest are rarely disclosed. (2) Industry publishes papers about trending ML topics on average two years earlier than academia does. (3) Industry papers are not lagging behind academic papers in regard to social impact considerations. (4) Finally, we demonstrate that industrial papers fall short of their academic counterparts with respect to the ratio of gender diversity. We believe that this work is a starting point for an informed debate within and outside of the ML community.",
    "lastUpdated": "2020-10-19T13:01:51Z",
    "categories": [
      "cs.CY",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2006.04541v2"
  },
  {
    "title": "Could regulating the creators deliver trustworthy AI?",
    "authors": [
      "Labhaoise Ni Fhaolain",
      "Andrew Hines"
    ],
    "abstract": "Is a new regulated profession, such as Artificial Intelligence (AI) Architect who is responsible and accountable for AI outputs necessary to ensure trustworthy AI? AI is becoming all pervasive and is often deployed in everyday technologies, devices and services without our knowledge. There is heightened awareness of AI in recent years which has brought with it fear. This fear is compounded by the inability to point to a trustworthy source of AI, however even the term \"trustworthy AI\" itself is troublesome. Some consider trustworthy AI to be that which complies with relevant laws, while others point to the requirement to comply with ethics and standards (whether in addition to or in isolation of the law). This immediately raises questions of whose ethics and which standards should be applied and whether these are sufficient to produce trustworthy AI in any event.",
    "lastUpdated": "2020-06-26T01:32:53Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2006.14750v1"
  },
  {
    "title": "Ethical Analysis on the Application of Neurotechnology for Human Augmentation in Physicians and Surgeons",
    "authors": [
      "Soaad Hossain",
      "Syed Ishtiaque Ahmed"
    ],
    "abstract": "With the shortage of physicians and surgeons and increase in demand worldwide due to situations such as the COVID-19 pandemic, there is a growing interest in finding solutions to help address the problem. A solution to this problem would be to use neurotechnology to provide them augmented cognition, senses and action for optimal diagnosis and treatment. Consequently, doing so can negatively impact them and others. We argue that applying neurotechnology for human enhancement in physicians and surgeons can cause injustices, and harm to them and patients. In this paper, we will first describe the augmentations and neurotechnologies that can be used to achieve the relevant augmentations for physicians and surgeons. We will then review selected ethical concerns discussed within literature, discuss the neuroengineering behind using neurotechnology for augmentation purposes, then conclude with an analysis on outcomes and ethical issues of implementing human augmentation via neurotechnology in medical and surgical practice.",
    "lastUpdated": "2020-07-03T16:58:58Z",
    "categories": [
      "cs.CY",
      "cs.HC",
      "physics.med-ph",
      "68-06",
      "J.3; K.4.1; K.4.2; K.4.3; J.7; J.4"
    ],
    "url": "http://arxiv.org/abs/2006.16925v2"
  },
  {
    "title": "The Future of Work Is Here: Toward a Comprehensive Approach to Artificial Intelligence and Labour",
    "authors": [
      "Julian Posada"
    ],
    "abstract": "This commentary traces contemporary discourses on the relationship between artificial intelligence and labour and explains why these principles must be comprehensive in their approach to labour and AI. First, the commentary asserts that ethical frameworks in AI alone are not enough to guarantee workers' rights since they lack enforcement mechanisms and the representation of different stakeholders. Secondly, it argues that current discussions on AI and labour focus on the deployment of these technologies in the workplace but ignore the essential role of human labour in their development, particularly in the different cases of outsourced labour around the world. Finally, it recommends using existing human rights frameworks for working conditions to provide more comprehensive ethical principles and regulations. The commentary concludes by arguing that the central question regarding the future of work should not be whether intelligent machines will replace humans, but who will own these systems and have a say in their development and operation.",
    "lastUpdated": "2020-07-15T19:23:52Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2007.05843v2"
  },
  {
    "title": "The societal and ethical relevance of computational creativity",
    "authors": [
      "Michele Loi",
      "Eleonora Viganò",
      "Lonneke van der Plas"
    ],
    "abstract": "In this paper, we provide a philosophical account of the value of creative systems for individuals and society. We characterize creativity in very broad philosophical terms, encompassing natural, existential, and social creative processes, such as natural evolution and entrepreneurship, and explain why creativity understood in this way is instrumental for advancing human well-being in the long term. We then explain why current mainstream AI tends to be anti-creative, which means that there are moral costs of employing this type of AI in human endeavors, although computational systems that involve creativity are on the rise. In conclusion, there is an argument for ethics to be more hospitable to creativity-enabling AI, which can also be in a trade-off with other values promoted in AI ethics, such as its explainability and accuracy.",
    "lastUpdated": "2020-07-23T12:39:10Z",
    "categories": [
      "cs.AI",
      "econ.GN",
      "q-fin.EC",
      "I.2.8"
    ],
    "url": "http://arxiv.org/abs/2007.11973v1"
  },
  {
    "title": "Fair Allocation of Vaccines, Ventilators and Antiviral Treatments: Leaving No Ethical Value Behind in Health Care Rationing",
    "authors": [
      "Parag A. Pathak",
      "Tayfun Sönmez",
      "M. Utku Ünver",
      "M. Bumin Yenmez"
    ],
    "abstract": "COVID-19 has revealed several limitations of existing mechanisms for rationing scarce medical resources under emergency scenarios. Many argue that they abandon various ethical values such as equity by discriminating against disadvantaged communities. Illustrating that these limitations are aggravated by a restrictive choice of mechanism, we formulate pandemic rationing of medical resources as a new application of market design and propose a reserve system as a resolution. We develop a general theory of reserve design, introduce new concepts such as cutoff equilibria and smart reserves, extend previously-known ones such as sequential reserve matching, and relate these concepts to current debates.",
    "lastUpdated": "2020-08-02T01:13:23Z",
    "categories": [
      "econ.TH"
    ],
    "url": "http://arxiv.org/abs/2008.00374v1"
  },
  {
    "title": "Security, Privacy and Ethical Concerns of IoT Implementations in Hospitality Domain",
    "authors": [
      "Suat Mercan",
      "Kemal Akkaya",
      "Lisa Cain",
      "John Thomas"
    ],
    "abstract": "The Internet of Things (IoT) has been on the rise in the last decade as it finds applications in various domains. Hospitality is one of the pioneer sectors that has adopted this technology to create novel services such as smart hotel rooms, personalized services etc. Hotels, restaurants, theme parks, and cruise ships are some specific application areas to improve customer satisfaction by creating an intense interactive environment and data collection with the use of appropriate sensors and actuators. However, applying IoT solutions in the hospitality environment has some unique challenges such as easy physical access to devices. In addition, due to the very nature of these domains, the customers are at the epicenter of these IoT technologies that result in a massive amount of data collection from them. Such data and its management along with business purposes also raises new concerns regarding privacy and ethical considerations. Therefore, this paper surveys and analyzes security, privacy and ethical issues regarding the utilization of IoT devices by focusing on the hospitality industry specifically. We explore some exemplary uses, cases, potential problems and solutions in order to contribute to better understanding and guiding the business operators in this sector.",
    "lastUpdated": "2020-09-21T21:46:21Z",
    "categories": [
      "cs.NI",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/2009.10187v1"
  },
  {
    "title": "Dark Patterns and the Legal Requirements of Consent Banners: An Interaction Criticism Perspective",
    "authors": [
      "Colin M. Gray",
      "Cristiana Santos",
      "Nataliia Bielova",
      "Michael Toth",
      "Damian Clifford"
    ],
    "abstract": "User engagement with data privacy and security through consent banners has become a ubiquitous part of interacting with internet services. While previous work has addressed consent banners from either interaction design, legal, and ethics-focused perspectives, little research addresses the connections among multiple disciplinary approaches, including tensions and opportunities that transcend disciplinary boundaries. In this paper, we draw together perspectives and commentary from HCI, design, privacy and data protection, and legal research communities, using the language and strategies of \"dark patterns\" to perform an interaction criticism reading of three different types of consent banners. Our analysis builds upon designer, interface, user, and social context lenses to raise tensions and synergies that arise together in complex, contingent, and conflicting ways in the act of designing consent banners. We conclude with opportunities for transdisciplinary dialogue across legal, ethical, computer science, and interactive systems scholarship to translate matters of ethical concern into public policy.",
    "lastUpdated": "2020-09-21T22:00:51Z",
    "categories": [
      "cs.HC",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2009.10194v1"
  },
  {
    "title": "A Methodology for Ethics-by-Design AI Systems: Dealing with Human Value Conflicts",
    "authors": [
      "Fabrice Muhlenbach"
    ],
    "abstract": "The introduction of artificial intelligence into activities traditionally carried out by human beings produces brutal changes. This is not without consequences for human values. This paper is about designing and implementing models of ethical behaviors in AI-based systems, and more specifically it presents a methodology for designing systems that take ethical aspects into account at an early stage while finding an innovative solution to prevent human values from being affected. Two case studies where AI-based innovations complement economic and social proposals with this methodology are presented: one in the field of culture and operated by a private company, the other in the field of scientific research and supported by a state organization.",
    "lastUpdated": "2020-10-15T09:14:00Z",
    "categories": [
      "cs.AI",
      "cs.HC",
      "I.2.0; H.1.2"
    ],
    "url": "http://arxiv.org/abs/2010.07610v1"
  },
  {
    "title": "Developing Augmented Reality based Gaming Model to Teach Ethical Education in Primary Schools",
    "authors": [
      "Mohammad Ali"
    ],
    "abstract": "Education sector is adopting new technologies for both teaching and learning pedagogy. Augmented Reality (AR) is a new technology that can be used in the educational pedagogy to enhance the engagement with students. Students interact with AR-based educational material for more visualization and explanation. Therefore, the use of AR in education is becoming more popular. However, most researches narrate the use of AR technologies in the field of English, Maths, Science, Culture, Arts, and History education but the absence of ethical education is visible. In our paper, we design the system and develop an AR-based mobile game model in the field of Ethical education for pre-primary students. Students from pre-primary require more interactive lessons than theoretical concepts. So, we use AR technology to develop a game which offers interactive procedures where students can learn with fun and engage with the context. Finally, we develop a prototype that works with our research objective. We conclude our paper with future works.",
    "lastUpdated": "2020-10-29T04:01:32Z",
    "categories": [
      "cs.CY",
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/2010.15346v1"
  },
  {
    "title": "Anticipatory Ethics and the Role of Uncertainty",
    "authors": [
      "Priyanka Nanayakkara",
      "Nicholas Diakopoulos",
      "Jessica Hullman"
    ],
    "abstract": "Making conjectures about future consequences of a technology is an exercise in trying to reduce various forms of uncertainty. Both to produce and reason about these conjectures requires understanding their potential limitations. In other words, we need systematic ways of considering uncertainty associated with given conjectures for downstream consequences. In this work, we frame the task of considering future consequences as an anticipatory ethics problem, where the goal is to develop scenarios that reflect plausible outcomes and their ethical implications following a technology's introduction into society. In order to shed light on how various forms of uncertainty might inform how we reason about a resulting scenario, we provide a characterization of the types of uncertainty that arise in a potential scenario-building process.",
    "lastUpdated": "2020-11-26T08:12:00Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2011.13170v1"
  },
  {
    "title": "A Compactification of the Space of Plane Curves",
    "authors": [
      "Paul Hacking"
    ],
    "abstract": "We define a geometrically meaningful compactification of the moduli space of smooth plane curves, which can be calculated explicitly. The basic idea is to regard a plane curve D in P^2 as a pair (P^2,D) of a surface together with a divisor, and allow both the surface and the curve to degenerate. For plane curves of degree d at least 4, we obtain a compactification M_d which is a moduli space of stable pairs (X,D) using the log minimal model program. A stable pair (X,D) consists of a surface X such that -K_X is ample and a divisor D in a given linear system on X with specified singularities. Note that X may be non-normal, and K_X is Q-Cartier but not Cartier in general. We give a rough classification of stable pairs of arbitrary degree, a complete classification in degrees 4 and 5, and a partial classification in degree 6. The compactification is particularly simple if d is not a multiple of 3 - in particular the surface X has at most 2 components. We give a characterisation of these surfaces in terms of the singularities and the Picard numbers of the components. Moreover, we show that M_d is smooth in this case.",
    "lastUpdated": "2001-04-19T16:24:52Z",
    "categories": [
      "math.AG",
      "14H10, 14H50"
    ],
    "url": "http://arxiv.org/abs/math/0104193v1"
  },
  {
    "title": "Chow Quotients of Grassmannians II",
    "authors": [
      "Sean Keel",
      "Jenia Tevelev"
    ],
    "abstract": "We consider Kapranov's Chow quotient compactification of the moduli space of ordered n-tuples of hyperplanes in P^{r-1} in linear general position. For r=2 this is canonically identified with the Grothendieck-Knudsen compactification of M_{0,n} which has among others the nice properties 1) Modular meaning: stable pointed rational curves 2) Canonical description of limits of one parameter degenerations 3) Natural Mori theoretic meaning: log canonical compactification. We prove (1-2) generalize naturally to all (r,n), but that (3), which we view as the deepest, fails except possibly in the cases (2,n),(3,6),(3,7),(3,8), where we conjecture it holds. The same generalization of (1) was given recently (and independently) by Hacking.",
    "lastUpdated": "2004-08-20T14:42:36Z",
    "categories": [
      "math.AG"
    ],
    "url": "http://arxiv.org/abs/math/0401159v5"
  },
  {
    "title": "Compactification of the moduli space of hyperplane arrangements",
    "authors": [
      "Paul Hacking",
      "Sean Keel",
      "Jenia Tevelev"
    ],
    "abstract": "Consider the moduli space M^0 of arrangements of n hyperplanes in general position in projective (r-1)-space. When r=2 the space has a compactification given by the moduli space of stable curves of genus 0 with n marked points. In higher dimensions, the analogue of the moduli space of stable curves is the moduli space of stable pairs: pairs (S,B) consisting of a variety S (possibly reducible) and a divisor B=B_1+..+B_n, satisfying various additional assumptions. We identify the closure of M^0 in the moduli space of stable pairs as Kapranov's Chow quotient compactification of M^0, and give an explicit description of the pairs at the boundary. We also construct additional irreducible components of the moduli space of stable pairs.",
    "lastUpdated": "2005-01-14T15:45:52Z",
    "categories": [
      "math.AG",
      "14J10; 52C35"
    ],
    "url": "http://arxiv.org/abs/math/0501227v1"
  },
  {
    "title": "A novel approach for e-payment using virtual password system",
    "authors": [
      "Vishal Vadgama",
      "Bhavin Tanti",
      "Chirag Modi",
      "Nishant Doshi"
    ],
    "abstract": "In today's world of E-Commerce everything comes online like Music, E-Books, Shopping all most everything is online. If you are using some service or buying things online then you have to pay for that. For that you have to do Net Banking or you have to use Credit card which will do online payment for you. In today's environment when everything is online, the service you are using for E-Payment must be secure and you must protect your banking information like debit card or credit card information from possible threat of hacking. There were lots way to threat like Key logger, Forgery Detection, Phishing, Shoulder surfing. Therefore, we reveal our actual information of Bank and Credit Card then there will be a chance to lose data and same credit card and hackers can use banking information for malicious purpose. In this paper we discuss available E-Payment protocols, examine its advantages and delimitation's and shows that there are steel needs to design a more secure E-Payment protocol. The suggested protocol is based on using hash function and using dynamic or virtual password, which protects your banking or credit card information from possible threat of hacking when doing online transactions.",
    "lastUpdated": "2012-08-19T16:17:53Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1208.3859v1"
  },
  {
    "title": "Optimised quantum hacking of superconducting nanowire single-photon detectors",
    "authors": [
      "Michael G. Tanner",
      "Vadim Makarov",
      "Robert H. Hadfield"
    ],
    "abstract": "We explore bright-light control of superconducting nanowire single-photon detectors (SNSPDs) in the shunted configuration (a practical measure to avoid latching). In an experiment, we simulate an illumination pattern the SNSPD would receive in a typical quantum key distribution system under hacking attack. We show that it effectively blinds and controls the SNSPD. The transient blinding illumination lasts for a fraction of a microsecond and produces several deterministic fake clicks during this time. This attack does not lead to elevated timing jitter in the spoofed output pulse, and hence does not introduce significant errors. Five different SNSPD chip designs were tested. We consider possible countermeasures to this attack.",
    "lastUpdated": "2014-04-07T14:06:17Z",
    "categories": [
      "quant-ph",
      "physics.ins-det"
    ],
    "url": "http://arxiv.org/abs/1305.5989v3"
  },
  {
    "title": "Quantum field theory on curved spacetime and the standard cosmological model",
    "authors": [
      "Klaus Fredenhagen",
      "Thomas-Paul Hack"
    ],
    "abstract": "The aim of this review is to outline a full route from the fundamental principles of algebraic quantum field theory on curved spacetime in its present-day form to explicit phenomenological applications which allow for comparison with experimental data. We give a brief account on the quantization of the free scalar field and its Wick powers in terms of an algebra of functionals on configuration space. Afterwards we demonstrate that there exist states on this algebra in which the energy momentum tensor is qualitatively and quantitatively of the perfect fluid form assumed in the standard model of cosmology up to small corrections. We indicate the potential relevance of one of these corrections for the actively debated phenomenon of Dark Radiation.",
    "lastUpdated": "2013-08-30T15:38:33Z",
    "categories": [
      "math-ph",
      "gr-qc",
      "math.MP"
    ],
    "url": "http://arxiv.org/abs/1308.6773v1"
  },
  {
    "title": "Hacking on decoy-state quantum key distribution system with partial phase randomization",
    "authors": [
      "Shi-Hai Sun",
      "Mu-Sheng Jiang",
      "Xiang-Chun Ma",
      "Chun-Yan Li",
      "Lin-Mei Liang"
    ],
    "abstract": "Quantum key distribution (QKD) provides means for unconditional secure key transmission between two distant parties. However, in practical implementations, it suffers from quantum hacking due to device imperfections. Here we propose a hybrid measurement attack, with only linear optics, homodyne detection, and single photon detection, to the widely used vacuum+weak decoy state QKD system when the phase of source is partially randomized. Our analysis shows that, in some parameter regimes, the proposed attack would result in an entanglement breaking channel but still be able to trick the legitimate users to believe they have transmitted secure keys. That is, the eavesdropper is able to steal all the key information without discovered by the users. Thus, our proposal reveals that partial phase randomization is not sufficient to guarantee the security of phase-encoding QKD systems with weak coherent states.",
    "lastUpdated": "2014-07-15T01:56:02Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/1407.3862v1"
  },
  {
    "title": "Environment Based Secure Transfer of Data in Wireless Sensor Networks",
    "authors": [
      "B. Vidhya",
      "Mary Joseph",
      "D. Rajini Girinath",
      "A. Malathi"
    ],
    "abstract": "Most critical sensor readings (Top-k Monitoring) in environment monitoring system are important to many wireless sensor applications. In such applications, sensor nodes transmit the data continuously for a specific time period to the storage nodes. It is responsible for transferring the received results to the Authority on Top-k Query request from them. Dummy data's were added into the original text data to secure the data against adversary in case of hacking the sensor and storage nodes. If storage node gets hacked by adversary, false details will be sent to the authority. An effective technique named aggregate signature to validate the source of the message and also to protect the data against latest security attacks, cryptography technique combined with steganography has been introduced. Indexed based scheme for the database access has also been proposed, to validate the resources against availability before forwarding the data fetch request to storage nodes from Authority.",
    "lastUpdated": "2015-03-11T08:31:26Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1503.03215v1"
  },
  {
    "title": "The Lambda CDM-model in quantum field theory on curved spacetime and Dark Radiation",
    "authors": [
      "Thomas-Paul Hack"
    ],
    "abstract": "In the standard model of cosmology, the universe is described by a Robertson-Walker spacetime, while its matter/energy content is modeled by a perfect fluid with three components corresponding to matter/dust, radiation and a cosmological constant. On the other hand, in particle physics matter and radiation are described in terms of quantum field theory on Minkowski spacetime. We unify these seemingly different theoretical frameworks by analysing the standard model of cosmology from first principles within quantum field theory on curved spacetime: assuming that the universe is homogeneous and isotropic on large scales, we specify a class of quantum states whose expectation value of the energy density is qualitatively and quantitatively of the standard perfect fluid form up to potential corrections. Qualitatively, these corrections depend on new parameters not present in the standard Lambda CDM-model and can account for e.g. the phenomenon of Dark Radiation (N_eff>3.046), having a characteristic signature which clearly deviates from other potential Dark Radiation sources such as e.g. sterile neutrinos. Quantitatively, we find that our more fundamental model can be perfectly matched to observational data, such that we arrive at a natural and fundamental extension of the Lambda CDM-model.",
    "lastUpdated": "2013-06-13T10:58:27Z",
    "categories": [
      "gr-qc",
      "astro-ph.CO",
      "hep-th"
    ],
    "url": "http://arxiv.org/abs/1306.3074v1"
  },
  {
    "title": "Quantization of the linearised Einstein-Klein-Gordon system on arbitrary backgrounds and the special case of perturbations in Inflation",
    "authors": [
      "Thomas-Paul Hack"
    ],
    "abstract": "We quantize the linearised Einstein-Klein-Gordon system on arbitrary on-shell backgrounds in a manifestly covariant and gauge-invariant manner. For the special case of perturbations in Inflation, i.e. on-shell backgrounds of Friedmann-Lema\\^itre-Robertson-Walker type, we compare our general quantization construction with the standard approach to the quantum theory of perturbations in Inflation. We find that not all local quantum observables of the linearised Einstein-Klein-Gordon system can be split into local observables of scalar and tensor type as in the standard approach. However, we argue that this subclass of observables is sufficient for measuring perturbations which vanish at spatial infinity, which is in line with standard assumptions. Finally, we comment on a recent observation that, upon standard quantization, the quantum Bardeen potentials display a non-local behaviour and argue that a similar phenomenon occurs in any local quantum field theory.",
    "lastUpdated": "2016-01-20T23:12:56Z",
    "categories": [
      "gr-qc",
      "hep-th",
      "math-ph",
      "math.MP",
      "81T20"
    ],
    "url": "http://arxiv.org/abs/1403.3957v2"
  },
  {
    "title": "Carrier-envelope phase controlled isolated attosecond pulses in the nm wavelength range, based on superradiant nonlinear Thomson-backscattering",
    "authors": [
      "Szabolcs Hack",
      "Sándor Varró",
      "Attila Czirják"
    ],
    "abstract": "A proposal for a novel source of isolated attosecond XUV -- soft X-ray pulses with a well controlled carrier-envelope phase difference (CEP) is presented in the framework of nonlinear Thomson-backscattering. Based on the analytic solution of the Newton-Lorentz equations, the motion of a relativistic electron is calculated explicitly, for head-on collision with an intense fs laser pulse. By using the received formulae, the collective spectrum and the corresponding temporal shape of the radiation emitted by a mono-energetic electron bunch can be easily computed. For certain suitable and realistic parameters, single-cycle isolated pulses of ca. 20 as length are predicted in the XUV -- soft X-ray spectral range, including the 2.33-4.37 nm water window. According to our analysis, the generated almost linearly polarized beam is extremely well collimated around the initial velocity of the electron bunch, with considerable intensity and with its CEP locked to that of the fs laser pulse.",
    "lastUpdated": "2017-12-18T12:25:38Z",
    "categories": [
      "physics.atom-ph",
      "physics.optics",
      "physics.plasm-ph"
    ],
    "url": "http://arxiv.org/abs/1709.02277v2"
  },
  {
    "title": "On the Stress-Energy Tensor of Quantum Fields in Curved Spacetimes - Comparison of Different Regularization Schemes and Symmetry of the Hadamard/Seeley-DeWitt Coefficients",
    "authors": [
      "Thomas-Paul Hack",
      "Valter Moretti"
    ],
    "abstract": "We review a few rigorous and partly unpublished results on the regularisation of the stress-energy in quantum field theory on curved spacetimes: 1) the symmetry of the Hadamard/Seeley-DeWitt coefficients in smooth Riemannian and Lorentzian spacetimes 2) the equivalence of the local $\\zeta$-function and the Hadamard-point-splitting procedure in smooth static spacetimes 3) the equivalence of the DeWitt-Schwinger- and the Hadamard-point-splitting procedure in smooth Riemannian and Lorentzian spacetimes.",
    "lastUpdated": "2012-05-24T15:52:04Z",
    "categories": [
      "gr-qc",
      "hep-th",
      "math-ph",
      "math.MP",
      "81T20"
    ],
    "url": "http://arxiv.org/abs/1202.5107v2"
  },
  {
    "title": "On the geometry of anticanonical pairs",
    "authors": [
      "Robert Friedman"
    ],
    "abstract": "The systematic study of rational surfaces $Y$ with an anticanonical cycle $D$ dates back to a fundamental paper of Looijenga in 1981. Recently, Gross, Hacking and Keel have introduced new ideas into the subject. The goal of this mainly expository paper is to survey some results about such surfaces, old and new. We discuss the birational geometry and deformation theory of such pairs as well as the behavior of nef and big linear systems. We prove a theorem of Torelli type due to Gross-Hacking-Keel and describe some consequences. Among the new results in this paper are (1) a proof that the diffeomorphism type of a pair $(Y,D)$ is the same as its deformation type, and (2) a new characterization of the roots of the pair, i.e. the integral classes of square $-2$ in $H^2(Y)$ orthogonal to the components of $D$ which become the class of a smooth rational curve in some deformation.",
    "lastUpdated": "2016-07-22T18:37:20Z",
    "categories": [
      "math.AG",
      "14J26"
    ],
    "url": "http://arxiv.org/abs/1502.02560v2"
  },
  {
    "title": "An analytic regularisation scheme on curved spacetimes with applications to cosmological spacetimes",
    "authors": [
      "Antoine Géré",
      "Thomas-Paul Hack",
      "Nicola Pinamonti"
    ],
    "abstract": "We develop a renormalisation scheme for time--ordered products in interacting field theories on curved spacetimes which consists of an analytic regularisation of Feynman amplitudes and a minimal subtraction of the resulting pole parts. This scheme is directly applicable to spacetimes with Lorentzian signature, manifestly generally covariant, invariant under any spacetime isometries present and constructed to all orders in perturbation theory. Moreover, the scheme captures correctly the non--geometric state--dependent contribution of Feynman amplitudes and it is well--suited for practical computations. To illustrate this last point, we compute explicit examples on a generic curved spacetime, and demonstrate how momentum space computations in cosmological spacetimes can be performed in our scheme. In this work, we discuss only scalar fields in four spacetime dimensions, but we argue that the renormalisation scheme can be directly generalised to other spacetime dimensions and field theories with higher spin, as well as to theories with local gauge invariance.",
    "lastUpdated": "2015-11-12T11:48:34Z",
    "categories": [
      "math-ph",
      "gr-qc",
      "hep-th",
      "math.MP",
      "81T20"
    ],
    "url": "http://arxiv.org/abs/1505.00286v3"
  },
  {
    "title": "Predicting Cyber Events by Leveraging Hacker Sentiment",
    "authors": [
      "Ashok Deb",
      "Kristina Lerman",
      "Emilio Ferrara"
    ],
    "abstract": "Recent high-profile cyber attacks exemplify why organizations need better cyber defenses. Cyber threats are hard to accurately predict because attackers usually try to mask their traces. However, they often discuss exploits and techniques on hacking forums. The community behavior of the hackers may provide insights into groups' collective malicious activity. We propose a novel approach to predict cyber events using sentiment analysis. We test our approach using cyber attack data from 2 major business organizations. We consider 3 types of events: malicious software installation, malicious destination visits, and malicious emails that surpassed the target organizations' defenses. We construct predictive signals by applying sentiment analysis on hacker forum posts to better understand hacker behavior. We analyze over 400K posts generated between January 2016 and January 2018 on over 100 hacking forums both on surface and Dark Web. We find that some forums have significantly more predictive power than others. Sentiment-based models that leverage specific forums can outperform state-of-the-art deep learning and time-series models on forecasting cyber attacks weeks ahead of the events.",
    "lastUpdated": "2018-04-14T20:56:58Z",
    "categories": [
      "cs.CL"
    ],
    "url": "http://arxiv.org/abs/1804.05276v1"
  },
  {
    "title": "Hacking Alice's box in CV-QKD",
    "authors": [
      "Jason Pereira",
      "Stefano Pirandola"
    ],
    "abstract": "Security analyses of quantum cryptographic protocols typically rely on certain conditions; one such condition is that the sender (Alice) and receiver (Bob) have isolated devices inaccessible to third parties. If an eavesdropper (Eve) has a side-channel into one of the devices, then the key rate may be sensibly reduced. In this paper, we consider an attack on a coherent-state protocol, where Eve not only taps the main communication channel but also hacks Alice's device. This is done by introducing a Trojan horse mode with low mean number of photons $\\bar{n}$ which is then modulated in a similar way to the signal state. First we show that this strategy can be reduced to an attack without side channels but with higher loss and noise in the main channel. Then we show how the key rate rapidly deteriorates for increasing photons $\\bar{n}$, being halved at long distances each time $\\bar{n}+1$ doubles. Our work suggests that Alice's device should also be equipped with sensing systems that are able to detect and estimate the total number of incoming and outgoing photons.",
    "lastUpdated": "2020-10-05T12:14:06Z",
    "categories": [
      "quant-ph",
      "cond-mat.other",
      "physics.ins-det",
      "physics.optics"
    ],
    "url": "http://arxiv.org/abs/1807.04287v2"
  },
  {
    "title": "Printing wet-on-wet: attraction and repulsion of drops on a viscous film",
    "authors": [
      "M. A. Hack",
      "M. Costalonga",
      "T. Segers",
      "S. A. Karpitschka",
      "H. Wijshoff",
      "J. H. Snoeijer"
    ],
    "abstract": "Wet-on-wet printing is frequently used in inkjet printing for graphical and industrial applications, where substrates can be coated with a thin liquid film prior to ink drop deposition. Two drops placed close together are expected to interact via deformations of the thin viscous film, but the nature of these capillary interactions is unknown. Here we show that the interaction can be attractive or repulsive depending on the distance separating the two drops. The distance at which the interaction changes from attraction to repulsion is found to depend on the thickness of the film, and increases over time. We reveal the origin of the non-monotonic interactions, which lies in the appearance of a visco-capillary wave on the thin film induced by the drops. Using the thin-film equation we identify the scaling law for the spreading of the waves, and demonstrate that this governs the range over which interaction is observed.",
    "lastUpdated": "2018-11-12T08:09:30Z",
    "categories": [
      "physics.flu-dyn",
      "cond-mat.soft"
    ],
    "url": "http://arxiv.org/abs/1807.06401v2"
  },
  {
    "title": "Thermodynamics of Quantum Fields in Nonstationary Spacetimes",
    "authors": [
      "Klaus Fredenhagen",
      "Thomas-Paul Hack",
      "Nicola Pinamonti"
    ],
    "abstract": "Quantum field theory (QFT) on non-stationary spacetimes is well understood from the side of the algebra of observables. The state space, however, is largely unexplored, due to the non-existence of distinguished states (vacuum, scattering states, thermal states). Project C7 of the SFB 676 was focused on characterisations of states by asymptotic conditions, e.g. holography (in case the boundary has sufficiently many symmetries), on a precise version of an approximate particle interpretation (for instance in Robertson--Walker spacetimes) and on the determination in terms of expectation values of locally covariant fields. Additionally, the backreaction of quantum matter fields on the curvature as well as the perturbative quantisation of the Einstein--Klein--Gordon system in the case of a cosmological background have been investigated. Finally, a detailed analysis and construction of equilibrium states for interacting field theories has been performed.",
    "lastUpdated": "2018-09-23T08:58:59Z",
    "categories": [
      "gr-qc",
      "hep-th",
      "math-ph",
      "math.MP",
      "81T20"
    ],
    "url": "http://arxiv.org/abs/1809.08557v1"
  },
  {
    "title": "Multiparty Dynamics and Failure Modes for Machine Learning and Artificial Intelligence",
    "authors": [
      "David Manheim"
    ],
    "abstract": "An important challenge for safety in machine learning and artificial intelligence systems is a~set of related failures involving specification gaming, reward hacking, fragility to distributional shifts, and Goodhart's or Campbell's law. This paper presents additional failure modes for interactions within multi-agent systems that are closely related. These multi-agent failure modes are more complex, more problematic, and less well understood than the single-agent case, and are also already occurring, largely unnoticed. After motivating the discussion with examples from poker-playing artificial intelligence (AI), the paper explains why these failure modes are in some senses unavoidable. Following this, the paper categorizes failure modes, provides definitions, and cites examples for each of the modes: accidental steering, coordination failures, adversarial misalignment, input spoofing and filtering, and goal co-option or direct hacking. The paper then discusses how extant literature on multi-agent AI fails to address these failure modes, and identifies work which may be useful for the mitigation of these failure modes.",
    "lastUpdated": "2019-04-14T07:39:06Z",
    "categories": [
      "cs.MA",
      "cs.AI",
      "91E45, 91A06"
    ],
    "url": "http://arxiv.org/abs/1810.10862v4"
  },
  {
    "title": "Cybercrime and You: How Criminals Attack and the Human Factors That They Seek to Exploit",
    "authors": [
      "Jason R. C. Nurse"
    ],
    "abstract": "Cybercrime is a significant challenge to society, but it can be particularly harmful to the individuals who become victims. This chapter engages in a comprehensive and topical analysis of the cybercrimes that target individuals. It also examines the motivation of criminals that perpetrate such attacks and the key human factors and psychological aspects that help to make cybercriminals successful. Key areas assessed include social engineering (e.g., phishing, romance scams, catfishing), online harassment (e.g., cyberbullying, trolling, revenge porn, hate crimes), identity-related crimes (e.g., identity theft, doxing), hacking (e.g., malware, cryptojacking, account hacking), and denial-of-service crimes. As a part of its contribution, the chapter introduces a summary taxonomy of cybercrimes against individuals and a case for why they will continue to occur if concerted interdisciplinary efforts are not pursued.",
    "lastUpdated": "2018-11-15T23:16:37Z",
    "categories": [
      "cs.CR",
      "cs.CY",
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/1811.06624v1"
  },
  {
    "title": "Discovering Eastern European PCs by hacking them. Today",
    "authors": [
      "Stefano Bodrato",
      "Fabrizio Caruso",
      "Giovanni A. Cignoni"
    ],
    "abstract": "Computer science would not be the same without personal computers. In the West the so called PC revolution started in the late '70s and has its roots in hobbyists and do-it-yourself clubs. In the following years the diffusion of home and personal computers has made the discipline closer to many people. A bit later, to a lesser extent, yet in a similar way, the revolution took place also in East European countries. Today, the scenario of personal computing has completely changed, however the computers of the '80s are still objects of fascination for a number of retrocomputing fans who enjoy using, programming and hacking the old 8-bits. The paper highlights the continuity between yesterday's hobbyists and today's retrocomputing enthusiasts, particularly focusing on East European PCs. Besides the preservation of old hardware and software, the community is engaged in the development of emulators and cross compilers. Such tools can be used for historical investigation, for example to trace the origins of the BASIC interpreters loaded in the ROMs of East European PCs.",
    "lastUpdated": "2019-01-21T13:19:49Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1901.06922v1"
  },
  {
    "title": "Gathering Insights from Teenagers' Hacking Experience with Authentic Cybersecurity Tools",
    "authors": [
      "Valdemar Švábenský",
      "Jan Vykopal"
    ],
    "abstract": "This Work-In-Progress Paper for the Innovative Practice Category presents a novel experiment in active learning of cybersecurity. We introduced a new workshop on hacking for an existing science-popularizing program at our university. The workshop participants, 28 teenagers, played a cybersecurity game designed for training undergraduates and professionals in penetration testing. Unlike in learning environments that are simplified for young learners, the game features a realistic virtual network infrastructure. This allows exploring security tools in an authentic scenario, which is complemented by a background story. Our research aim is to examine how young players approach using cybersecurity tools by interacting with the professional game. A preliminary analysis of the game session showed several challenges that the workshop participants faced. Nevertheless, they reported learning about security tools and exploits, and 61% of them reported wanting to learn more about cybersecurity after the workshop. Our results support the notion that young learners should be allowed more hands-on experience with security topics, both in formal education and informal extracurricular events.",
    "lastUpdated": "2019-03-11T08:43:44Z",
    "categories": [
      "cs.CY",
      "K.3.2"
    ],
    "url": "http://arxiv.org/abs/1903.04174v1"
  },
  {
    "title": "Hacking Nonverbal Communication Between Pedestrians and Vehicles in Virtual Reality",
    "authors": [
      "Henri Schmidt",
      "Jack Terwilliger",
      "Dina AlAdawy",
      "Lex Fridman"
    ],
    "abstract": "We use an immersive virtual reality environment to explore the intricate social cues that underlie non-verbal communication involved in a pedestrian's crossing decision. We \"hack\" non-verbal communication between pedestrian and vehicle by engineering a set of 15 vehicle trajectories, some of which follow social conventions and some that break them. By subverting social expectations of vehicle behavior we show that pedestrians may use vehicle kinematics to infer social intentions and not merely as the state of a moving object. We investigate human behavior in this virtual world by conducting a study of 22 subjects, with each subject experiencing and responding to each of the trajectories by moving their body, legs, arms, and head in both the physical and the virtual world. Both quantitative and qualitative responses are collected and analyzed, showing that, in fact, social cues can be engineered through vehicle trajectory manipulation. In addition, we demonstrate that immersive virtual worlds which allow the pedestrian to move around freely, provide a powerful way to understand both the mechanisms of human perception and the social signaling involved in pedestrian-vehicle interaction.",
    "lastUpdated": "2019-04-02T00:34:32Z",
    "categories": [
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/1904.01931v1"
  },
  {
    "title": "Towards the Definition of Enterprise Architecture Debts",
    "authors": [
      "Simon Hacks",
      "Hendrik Höfert",
      "Johannes Salentin",
      "Yoon Chow Yeong",
      "Horst Lichter"
    ],
    "abstract": "In the software development industry, technical debt is regarded as a critical issue in term of the negative consequences such as increased software development cost, low product quality, decreased maintainability, and slowed progress to the long-term success of developing software. However, despite the vast research contributions in technical debt management for software engineering, the idea of technical debt fails to provide a holistic consideration to include both IT and business aspects. Further, implementing an enterprise architecture (EA) project might not always be a success due to uncertainty and unavailability of resources. Therefore, we relate the consequences of EA implementation failure with a new metaphor --Enterprise Architecture Debt (EA Debt). We anticipate that the accumulation of EA Debt will negatively influence EA quality, also expose the business into risk.",
    "lastUpdated": "2019-06-28T07:21:51Z",
    "categories": [
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/1907.00677v1"
  },
  {
    "title": "The Frobenius structure theorem for affine log Calabi-Yau varieties containing a torus",
    "authors": [
      "Sean Keel",
      "Tony Yue Yu"
    ],
    "abstract": "We show that the naive counts of rational curves in any affine log Calabi-Yau variety $U$, containing an open algebraic torus, determine in a surprisingly simple way, a family of log Calabi-Yau varieties, as the spectrum of a commutative associative algebra equipped with a compatible multilinear form. This is directly inspired by a very similar conjecture of Gross-Hacking-Keel in mirror symmetry, known as the Frobenius structure conjecture. Although the statement involves only elementary algebraic geometry, our proof employs Berkovich non-archimedean analytic methods. We construct the structure constants of the algebra via counting non-archimedean analytic disks in the analytification of $U$. We establish various properties of the counting, notably deformation invariance, symmetry, gluing formula and convexity. In the special case when $U$ is a Fock-Goncharov skew-symmetric X-cluster variety, we prove that our algebra generalizes, and in particular gives a direct geometric construction of, the mirror algebra of Gross-Hacking-Keel-Kontsevich.",
    "lastUpdated": "2019-08-26T18:05:23Z",
    "categories": [
      "math.AG",
      "math.RT",
      "math.SG",
      "Primary 14J33, Secondary 14G22, 14N35, 14J32, 14T05, 13F60"
    ],
    "url": "http://arxiv.org/abs/1908.09861v1"
  },
  {
    "title": "Hacking the quantum key distribution system by exploiting the avalanche transition region of single photon detectors",
    "authors": [
      "Yong-Jun Qian",
      "De-Yong He",
      "Shuang Wang",
      "Wei Chen",
      "Zhen-Qiang Yin",
      "Guang-Can Guo",
      "Zheng-Fu Han"
    ],
    "abstract": "Avalanche photodiode based single photon detectors, as crucial and practical components, are widely used in quantum key distribution (QKD) systems. For effective detection, most of these SPDs are operated in the gated mode, in which the gate is added to obtain high avalanche gain, and is removed to quench the avalanche. The avalanche transition region (ATR) is a certain existence in the process of adding and removing the gate. We first experimentally investigate the characteristic of the ATR, including in the commercial SPD and high-speed SPD, and then propose an ATR attack to control the detector. In the experiment of hacking the plug-and-play QKD system, Eve only introduces less than 0.5 % quantum bit error rate, and almost leaves no traces of her presence including the photocurrent and afterpulse probability. We finally give possible countermeasures against this attack.",
    "lastUpdated": "2019-09-24T09:27:54Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/1909.10001v2"
  },
  {
    "title": "Novel method for handling Ethereum attack",
    "authors": [
      "G. Hall",
      "M. Mansi",
      "I. Makrant"
    ],
    "abstract": "Block-chain world is very dynamic and there is need for strong governance and underlying technology architecture to be robust to face challenges. This paper considers Ethereum, a leading block chain. We deep dive into the nature of this block chain, wherein for software upgrades forks are performed. They types of forks and impact is discussed. A specific Ethereum hack led to a hard fork and focus is provided on understanding the hack and overcoming it from a novel approach. The current model has been unable to handle multiple Ethereum attacks. Thus the current approach is compared against a novel approach providing a security and scaling solution. Here the architecture draws upon combining block-chain layers into operating system level. The approach can have tremendous benefits to block chain world and improve the way decentralized application teams perform. The benefits of the novel architecture is discussed. The approach helps safe guard block chain projects, making them safer and chain agnostic.",
    "lastUpdated": "2019-10-18T06:51:23Z",
    "categories": [
      "cs.DC",
      "cs.CY",
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/1909.12934v2"
  },
  {
    "title": "On the Topology of Fano Smoothings",
    "authors": [
      "Tom Coates",
      "Alessio Corti",
      "Genival da Silva Jr"
    ],
    "abstract": "Suppose that X is a Fano manifold that corresponds under Mirror Symmetry to a Laurent polynomial f, and that P is the Newton polytope of f. In this setting it is expected that there is a family of algebraic varieties over the unit disc with general fiber X and special fiber the toric variety defined by the spanning fan of P. Building on recent work and conjectures by Corti--Hacking--Petracci, who construct such families of varieties, we determine the topology of the general fiber from combinatorial data on P. This provides evidence for the Corti--Hacking--Petracci conjectures, and verifies that their construction is compatible with expectations from Mirror Symmetry.",
    "lastUpdated": "2019-12-09T21:28:40Z",
    "categories": [
      "math.AG"
    ],
    "url": "http://arxiv.org/abs/1912.04383v1"
  },
  {
    "title": "Self-Similar Liquid Lens Coalescence",
    "authors": [
      "Michiel A. Hack",
      "Walter Tewes",
      "Qingguang Xie",
      "Charu Datt",
      "Kirsten Harth",
      "Jens Harting",
      "Jacco H. Snoeijer"
    ],
    "abstract": "A basic feature of liquid drops is that they can merge upon contact to form a larger drop. In spite of its importance to various applications, drop coalescence on pre-wetted substrates has received little attention. Here, we experimentally and theoretically reveal the dynamics of drop coalescence on a thick layer of a low-viscosity liquid. It is shown that these so-called \"liquid lenses\" merge by the self-similar vertical growth of a bridge connecting the two lenses. Using a slender analysis, we derive similarity solutions corresponding to the viscous and inertial limits. Excellent agreement is found with the experiments without any adjustable parameters, capturing both the spatial and temporal structure of the flow during coalescence. Finally, we consider the crossover between the two regimes and show that all data of different lens viscosities collapse on a single curve capturing the full range of the coalescence dynamics.",
    "lastUpdated": "2020-03-09T07:52:09Z",
    "categories": [
      "physics.flu-dyn"
    ],
    "url": "http://arxiv.org/abs/1912.06420v3"
  },
  {
    "title": "Att-HACK: An Expressive Speech Database with Social Attitudes",
    "authors": [
      "Clément Le Moine",
      "Nicolas Obin"
    ],
    "abstract": "This paper presents Att-HACK, the first large database of acted speech with social attitudes. Available databases of expressive speech are rare and very often restricted to the primary emotions: anger, joy, sadness, fear. This greatly limits the scope of the research on expressive speech. Besides, a fundamental aspect of speech prosody is always ignored and missing from such databases: its variety, i.e. the possibility to repeat an utterance while varying its prosody. This paper represents a first attempt to widen the scope of expressivity in speech, by providing a database of acted speech with social attitudes: friendly, seductive, dominant, and distant. The proposed database comprises 25 speakers interpreting 100 utterances in 4 social attitudes, with 3-5 repetitions each per attitude for a total of around 30 hours of speech. The Att-HACK is freely available for academic research under a Creative Commons Licence.",
    "lastUpdated": "2020-04-09T08:09:59Z",
    "categories": [
      "eess.AS"
    ],
    "url": "http://arxiv.org/abs/2004.04410v1"
  },
  {
    "title": "Hacking the Waveform: Generalized Wireless Adversarial Deep Learning",
    "authors": [
      "Francesco Restuccia",
      "Salvatore D'Oro",
      "Amani Al-Shawabka",
      "Bruno Costa Rendon",
      "Kaushik Chowdhury",
      "Stratis Ioannidis",
      "Tommaso Melodia"
    ],
    "abstract": "This paper advances the state of the art by proposing the first comprehensive analysis and experimental evaluation of adversarial learning attacks to wireless deep learning systems. We postulate a series of adversarial attacks, and formulate a Generalized Wireless Adversarial Machine Learning Problem (GWAP) where we analyze the combined effect of the wireless channel and the adversarial waveform on the efficacy of the attacks. We propose a new neural network architecture called FIRNet, which can be trained to \"hack\" a classifier based only on its output. We extensively evaluate the performance on (i) a 1,000-device radio fingerprinting dataset, and (ii) a 24-class modulation dataset. Results obtained with several channel conditions show that our algorithms can decrease the classifier accuracy up to 3x. We also experimentally evaluate FIRNet on a radio testbed, and show that our data-driven blackbox approach can confuse the classifier up to 97% while keeping the waveform distortion to a minimum.",
    "lastUpdated": "2020-05-05T15:05:41Z",
    "categories": [
      "cs.NI",
      "eess.SP"
    ],
    "url": "http://arxiv.org/abs/2005.02270v1"
  },
  {
    "title": "Homological mirror symmetry for log Calabi-Yau surfaces",
    "authors": [
      "Paul Hacking",
      "Ailsa Keating"
    ],
    "abstract": "Given a log Calabi-Yau surface $Y$ with maximal boundary $D$ and distinguished complex structure, we explain how to construct a mirror Lefschetz fibration $w: M \\to \\mathbb{C}$, where $M$ is a Weinstein four-manifold, such that the directed Fukaya category of $w$ is isomorphic to $D^b \\text{Coh}(Y)$, and the wrapped Fukaya category $\\mathcal{W} (M)$ is isomorphic to $D^b \\text{Coh}(Y \\backslash D)$. We construct an explicit isomorphism between $M$ and the total space of the almost-toric fibration arising in the work of Gross-Hacking-Keel; when $D$ is negative definite this is expected to be the Milnor fibre of a smoothing of the dual cusp of $D$. We also match our mirror potential $w$ with existing constructions for a range of special cases of $(Y,D)$, notably in work of Auroux-Katzarkov-Orlov and Abouzaid.",
    "lastUpdated": "2020-05-11T11:44:06Z",
    "categories": [
      "math.SG",
      "math.AG",
      "53D37 (Primary) 14B05, 53D40 (Secondary)"
    ],
    "url": "http://arxiv.org/abs/2005.05010v1"
  },
  {
    "title": "Wetting of two-component drops: Marangoni contraction versus autophobing",
    "authors": [
      "Michiel A. Hack",
      "Wojciech Kwieciński",
      "Olinka Ramírez-Soto",
      "Tim Segers",
      "Stefan Karpitschka",
      "E. Stefan Kooij",
      "Jacco H. Snoeijer"
    ],
    "abstract": "The wetting properties of multi-component liquids are crucial to numerous industrial applications. The mechanisms that determine the contact angles for such liquids remain poorly understood, with many intricacies arising due to complex physical phenomena, for example due to the presence of surfactants. Here, we consider two-component drops that consist of mixtures of vicinal alkane diols and water. These diols behave surfactant-like in water. However, the contact angles of such mixtures on solid substrates are surprisingly large. We experimentally reveal that the contact angle is determined by two separate mechanisms of completely different nature, namely Marangoni contraction (hydrodynamic) and autophobing (molecular). It turns out that the length of the alkyl tail of the alkane diol determines which mechanism is dominant, highlighting the intricate coupling between molecular physics and the macroscopic wetting of complex fluids.",
    "lastUpdated": "2020-05-20T07:10:58Z",
    "categories": [
      "physics.flu-dyn",
      "cond-mat.soft"
    ],
    "url": "http://arxiv.org/abs/2005.09883v1"
  },
  {
    "title": "Online Discoverability and Vulnerabilities of ICS/SCADA Devices in the Netherlands",
    "authors": [
      "Joao M. Ceron",
      "Justyna J. Chromik",
      "Jair Santanna",
      "Aiko Pras"
    ],
    "abstract": "On a regular basis, we read in the news about cyber-attacks on critical infrastructures, such as power plants. Such infrastructures rely on the so-called Industrial Control Systems (ICS) / Supervisory Control And Data Acquisition (SCADA) networks. By hacking the devices in such systems and networks, attackers may take over the control of critical infrastructures, with potentially devastating consequences. This report focusses on critical infrastructures in the Netherlands and investigates three main questions: 1) How many ICS/SCADA devices located in the Netherlands can be easily found by potential attackers?, 2) How many of these devices are vulnerable to cyber-attacks?, and 3) What measures should be taken to prevent these devices from being hacked?",
    "lastUpdated": "2020-11-03T21:50:56Z",
    "categories": [
      "cs.NI",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/2011.02019v1"
  },
  {
    "title": "Stealthy hacking and secrecy of controlled state estimation systems with random dropouts",
    "authors": [
      "Jingyi Lu",
      "Daniel Quevedo",
      "Vijay Gupta",
      "Subhrakanti Dey"
    ],
    "abstract": "We study the maximum information gain that an adversary may obtain through hacking without being detected. Consider a dynamical process observed by a sensor that transmits a local estimate of the system state to a remote estimator according to some reference transmission policy across a packet-dropping wireless channel equipped with acknowledgments (ACK). An adversary overhears the transmissions and proactively hijacks the sensor to reprogram its transmission policy. We define perfect secrecy as keeping the averaged expected error covariance bounded at the legitimate estimator and unbounded at the adversary. By analyzing the stationary distribution of the expected error covariance, we show that perfect secrecy can be attained for unstable systems only if the ACK channel has no packet dropouts. In other situations, we prove that independent of the reference policy and the detection methods, perfect secrecy is not attainable. For this scenario, we formulate a constrained Markov decision process to derive the optimal transmission policy that the adversary should implement at the sensor, and devise a Stackelberg game to derive the optimal reference policy for the legitimate estimator.",
    "lastUpdated": "2020-11-07T10:40:17Z",
    "categories": [
      "eess.SY",
      "cs.SY"
    ],
    "url": "http://arxiv.org/abs/2011.03745v1"
  },
  {
    "title": "FLEAM: A Federated Learning Empowered Architecture to Mitigate DDoS in Industrial IoT",
    "authors": [
      "J. Li",
      "L. Lyu",
      "X. Liu",
      "X. Zhang",
      "X. Lyu"
    ],
    "abstract": "The distributed denial of service (DDoS) attack is detrimental to the industrial Internet of things (IIoT) as it triggers severe resource starvation on networked objects. Recent dynamics demonstrate that it is a highly profitable business for attackers using botnets. Current centralized mitigation solutions concentrate on detection and mitigation at a victim's side, paying inadequate attention to hacking costs and the collaboration of defenders. Thus, we propose the federated learning empowered mitigation architecture (FLEAM) to advocate joint defense, incurring a higher hacking expense. FLEAM combines FL and fog computing to reduce mitigation time and improve detection accuracy, enabling defenders to jointly combatting botnets. Our comprehensive evaluations showcase that the attacking expense incurred is 2.5 times higher, the mitigation delay is about 72% lower, and the accuracy is 47% greater on average than classic solutions.",
    "lastUpdated": "2020-12-11T06:22:15Z",
    "categories": [
      "cs.CR",
      "cs.IT",
      "math.IT"
    ],
    "url": "http://arxiv.org/abs/2012.06150v1"
  },
  {
    "title": "Conceptual Design of LiFi Audio Transmission Using Pre-Programmed Modules",
    "authors": [
      "Auwal Tijjani Amshi"
    ],
    "abstract": "We all know that Wi-Fi is presently the most commonly used technology for data transmission and connecting devices to the Internet, at the same time due to much reasonable concern, (such as Wi-Fi can be vulnerable when it comes to hacking, health concern, and low latency, etc.) the concept of Li-Fi is becoming very popular as a new way of data transmission that use light waves to transmit data rather than radio waves. Light-emitting diodes LED are used when transmitting the data in the visible light spectrum. Li-fi uses visible light communication and it has a promising future. Unlike Wi-fi, Li-Fi has low latency, high efficiency, accessible spectrum, and high data can be achieved. It is highly secured so the data cannot be hacked. In this paper, we design a concept of Li-fi audio signal transmission by reusing and repurposing pre-programmed modules to simplify and discuss visible light communication (VLC) in other to give a new researcher the idea on how the concept of LiFi and VLC. In addition to designing the concept we experiment to test the concept and we illustrated the result within this paper.",
    "lastUpdated": "2021-01-05T21:06:50Z",
    "categories": [
      "eess.SP"
    ],
    "url": "http://arxiv.org/abs/2101.01783v1"
  },
  {
    "title": "The Ethics of Robotics",
    "authors": [
      "Kush Agrawal"
    ],
    "abstract": "The three laws of Robotics first appeared together in Isaac Asimov's story 'Runaround' after being mentioned in some form or the other in previous works by Asimov. These three laws commonly known as the three laws of robotics are the earliest forms of depiction for the needs of ethics in Robotics. In simplistic language Isaac Asimov is able to explain what rules a robot must confine itself to in order to maintain societal sanctity. However, even though they are outdated they still represent some of our innate fears which are beginning to resurface in present day 21st Century. Our society is on the advent of a new revolution; a revolution led by advances in Computer Science, Artificial Intelligence & Nanotechnology. Some of our advances have been so phenomenal that we surpassed what was predicted by the Moore's law. With these advancements comes the fear that our future may be at the mercy of these androids. Humans today are scared that we, ourselves, might create something which we cannot control. We may end up creating something which can not only learn much faster than anyone of us can, but also evolve faster than what the theory of evolution has allowed us to. The greatest fear is not only that we might lose our jobs to these intelligent beings, but that these beings might end up replacing us at the top of the cycle. The public hysteria has been heightened more so by a number of cultural works which depict annihilation of the human race by robots. Right from Frankenstein to I, Robot mass media has also depicted such issues. This paper is an effort to understand the need for ethics in Robotics or simply termed as Roboethics. This is achieved by the study of artificial beings and the thought being put behind them. By the end of the paper, however, it is concluded that there isn't a need for ethical robots but more so ever a need for ethical roboticists.",
    "lastUpdated": "2010-12-27T11:14:56Z",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "url": "http://arxiv.org/abs/1012.5594v1"
  },
  {
    "title": "The State of AI Ethics Report (June 2020)",
    "authors": [
      "Abhishek Gupta",
      "Camylle Lanteigne",
      "Victoria Heath",
      "Marianna Bergamaschi Ganapini",
      "Erick Galinkin",
      "Allison Cohen",
      "Tania De Gasperis",
      "Mo Akif",
      "Renjie Butalid"
    ],
    "abstract": "These past few months have been especially challenging, and the deployment of technology in ways hitherto untested at an unrivalled pace has left the internet and technology watchers aghast. Artificial intelligence has become the byword for technological progress and is being used in everything from helping us combat the COVID-19 pandemic to nudging our attention in different directions as we all spend increasingly larger amounts of time online. It has never been more important that we keep a sharp eye out on the development of this field and how it is shaping our society and interactions with each other. With this inaugural edition of the State of AI Ethics we hope to bring forward the most important developments that caught our attention at the Montreal AI Ethics Institute this past quarter. Our goal is to help you navigate this ever-evolving field swiftly and allow you and your organization to make informed decisions. This pulse-check for the state of discourse, research, and development is geared towards researchers and practitioners alike who are making decisions on behalf of their organizations in considering the societal impacts of AI-enabled solutions. We cover a wide set of areas in this report spanning Agency and Responsibility, Security and Risk, Disinformation, Jobs and Labor, the Future of AI Ethics, and more. Our staff has worked tirelessly over the past quarter surfacing signal from the noise so that you are equipped with the right tools and knowledge to confidently tread this complex yet consequential domain.",
    "lastUpdated": "2020-06-25T19:00:41Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2006.14662v1"
  },
  {
    "title": "Recovering the History of Informed Consent for Data Science and Internet Industry Research Ethics",
    "authors": [
      "Elaine Sedenberg",
      "Anna Lauren Hoffmann"
    ],
    "abstract": "Respect for persons is a cornerstone value for any conception of research ethics--though how to best realize respect in practice is an ongoing question. In the late 19th and early 20th centuries, \"informed consent\" emerged as a particular way to operationalize respect in medical and behavioral research contexts. Today, informed consent has been challenged by increasingly advanced networked information and communication technologies (ICTs) and the massive amounts of data they produce--challenges that have led many researchers and private companies to abandon informed consent as untenable or infeasible online. Against any easy dismissal, we aim to recover insights from the history of informed consent as it developed from the late 19th century to today. With a particular focus on the United States policy context, we show how informed consent is not a fixed or monolithic concept that should be abandoned in view of new data-intensive and technological practices, but rather it is a mechanism that has always been fluid--it has constantly evolved alongside the specific contexts and practices it is intended to regulate. Building on this insight, we articulate some specific challenges and lessons from the history of informed consent that stand to benefit current discussions of informed consent and research ethics in the context of data science and Internet industry research.",
    "lastUpdated": "2016-09-12T04:54:10Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1609.03266v1"
  },
  {
    "title": "Towards Composable Bias Rating of AI Services",
    "authors": [
      "Biplav Srivastava",
      "Francesca Rossi"
    ],
    "abstract": "A new wave of decision-support systems are being built today using AI services that draw insights from data (like text and video) and incorporate them in human-in-the-loop assistance. However, just as we expect humans to be ethical, the same expectation needs to be met by automated systems that increasingly get delegated to act on their behalf. A very important aspect of an ethical behavior is to avoid (intended, perceived, or accidental) bias. Bias occurs when the data distribution is not representative enough of the natural phenomenon one wants to model and reason about. The possibly biased behavior of a service is hard to detect and handle if the AI service is merely being used and not developed from scratch, since the training data set is not available. In this situation, we envisage a 3rd party rating agency that is independent of the API producer or consumer and has its own set of biased and unbiased data, with customizable distributions. We propose a 2-step rating approach that generates bias ratings signifying whether the AI service is unbiased compensating, data-sensitive biased, or biased. The approach also works on composite services. We implement it in the context of text translation and report interesting results.",
    "lastUpdated": "2019-01-14T19:26:28Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1808.00089v2"
  },
  {
    "title": "Designing Normative Theories for Ethical and Legal Reasoning: LogiKEy Framework, Methodology, and Tool Support",
    "authors": [
      "Christoph Benzmüller",
      "Xavier Parent",
      "Leendert van der Torre"
    ],
    "abstract": "A framework and methodology---termed LogiKEy---for the design and engineering of ethical reasoners, normative theories and deontic logics is presented. The overall motivation is the development of suitable means for the control and governance of intelligent autonomous systems. LogiKEy's unifying formal framework is based on semantical embeddings of deontic logics, logic combinations and ethico-legal domain theories in expressive classic higher-order logic (HOL). This meta-logical approach enables the provision of powerful tool support in LogiKEy: off-the-shelf theorem provers and model finders for HOL are assisting the LogiKEy designer of ethical intelligent agents to flexibly experiment with underlying logics and their combinations, with ethico-legal domain theories, and with concrete examples---all at the same time. Continuous improvements of these off-the-shelf provers, without further ado, leverage the reasoning performance in LogiKEy. Case studies, in which the LogiKEy framework and methodology has been applied and tested, give evidence that HOL's undecidability often does not hinder efficient experimentation.",
    "lastUpdated": "2020-05-24T09:21:53Z",
    "categories": [
      "cs.AI",
      "03B60, 03B15, 68T27, 68T30, 68T15",
      "I.2.3; I.2.4; I.2.0; F.4"
    ],
    "url": "http://arxiv.org/abs/1903.10187v6"
  },
  {
    "title": "Global AI Ethics: A Review of the Social Impacts and Ethical Implications of Artificial Intelligence",
    "authors": [
      "Alexa Hagerty",
      "Igor Rubinov"
    ],
    "abstract": "The ethical implications and social impacts of artificial intelligence have become topics of compelling interest to industry, researchers in academia, and the public. However, current analyses of AI in a global context are biased toward perspectives held in the U.S., and limited by a lack of research, especially outside the U.S. and Western Europe. This article summarizes the key findings of a literature review of recent social science scholarship on the social impacts of AI and related technologies in five global regions. Our team of social science researchers reviewed more than 800 academic journal articles and monographs in over a dozen languages. Our review of the literature suggests that AI is likely to have markedly different social impacts depending on geographical setting. Likewise, perceptions and understandings of AI are likely to be profoundly shaped by local cultural and social context. Recent research in U.S. settings demonstrates that AI-driven technologies have a pattern of entrenching social divides and exacerbating social inequality, particularly among historically-marginalized groups. Our literature review indicates that this pattern exists on a global scale, and suggests that low- and middle-income countries may be more vulnerable to the negative social impacts of AI and less likely to benefit from the attendant gains. We call for rigorous ethnographic research to better understand the social impacts of AI around the world. Global, on-the-ground research is particularly critical to identify AI systems that may amplify social inequality in order to mitigate potential harms. Deeper understanding of the social impacts of AI in diverse social settings is a necessary precursor to the development, implementation, and monitoring of responsible and beneficial AI technologies, and forms the basis for meaningful regulation of these technologies.",
    "lastUpdated": "2019-07-18T06:34:08Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1907.07892v1"
  },
  {
    "title": "Towards a framework for understanding societal and ethical implications of Artificial Intelligence",
    "authors": [
      "Richard Benjamins",
      "Idoia Salazar"
    ],
    "abstract": "Artificial Intelligence (AI) is one of the most discussed technologies today. There are many innovative applications such as the diagnosis and treatment of cancer, customer experience, new business, education, contagious diseases propagation and optimization of the management of humanitarian catastrophes. However, with all those opportunities also comes great responsibility to ensure good and fair practice of AI. The objective of this paper is to identify the main societal and ethical challenges implied by a massive uptake of AI. We have surveyed the literature for the most common challenges and classified them in seven groups: 1) Non-desired effects, 2) Liability, 3) Unknown consequences, 4) Relation people-robots, 5) Concentration of power and wealth, 6) Intentional bad uses, and 7) AI for weapons and warfare. The challenges should be dealt with in different ways depending on their origin; some have technological solutions, while others require ethical, societal, or political answers. Depending on the origin, different stakeholders might need to act. Whatever the identified stakeholder, not treating those issues will lead to uncertainty and unforeseen consequences with potentially large negative societal impact, hurting especially the most vulnerable groups of societies. Technology is helping to take better decisions, and AI is promoting data-driven decisions in addition to experience- and intuition-based discussion, with many improvements happening. However, the negative side effects of this technology need to be well understood and acted upon before we launch them massively into the world.",
    "lastUpdated": "2020-01-03T17:55:15Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2001.09750v1"
  },
  {
    "title": "Cardiovascular risk and work stress in biomedical researchers in China: An observational, big data study protocol",
    "authors": [
      "Fang Zhu",
      "Qian Zhang",
      "Hao Chen",
      "Guocheng Shi",
      "Chen Wen",
      "Zhongqun Zhu",
      "Huiwen Chen"
    ],
    "abstract": "Introduction: Internet technologies could strengthen data collection and integration and have been used extensively in public health research. It is necessary to apply this technology to further investigate the behaviour and health of biomedical researchers. A browser-based extension was developed by researchers and clinicians to promote the collection and analysis of researchers' behavioural and psychological data. This protocol illustrates an observational study aimed at (1) characterising the health status of biomedical researchers in China and assessing work stress, job satisfaction, role conflict, role ambiguity, and family support; (2) identifying the association between work, behaviour, and health; and (3) investigating the association between behaviour and mental status. Our findings will contribute to the understanding of the influences of job, work environment, and family support on the mental and physical health of biomedical researchers. Methods and analysis: This is a prospective observational study; all candidates will be recruited from China. Participants will install an extension on their Internet browsers, which will collect data when they are accessing PubMed. A web-based survey will be sent to the user interfaces every 6 months that will involve sociodemographic variables, perceived stress scale, job satisfaction scale, role conflict and ambiguity scale, and family support scale. Machine-learning algorithms will analyse the data generated during daily access. Ethics and dissemination: This study received ethical approval from the ethics committee of the Shanghai Children's Medical Centre (reference number SCMCIRB-K2018082). Study results will be disseminated through peer-reviewed publications and conference presentations.",
    "lastUpdated": "2020-03-19T14:15:32Z",
    "categories": [
      "cs.CY",
      "cs.SI"
    ],
    "url": "http://arxiv.org/abs/2003.08800v1"
  },
  {
    "title": "Ethics, Data Science, and Health and Human Services: Embedded Bias in Policy Approaches to Teen Pregnancy Prevention",
    "authors": [
      "Davon Woodard",
      "Huthaifa I. Ashqar",
      "Taoran Ji"
    ],
    "abstract": "Background: This study aims to evaluate the Chicago Teen Pregnancy Prevention Initiative delivery optimization outcomes given policy-neutral and policy-focused approaches to deliver this program to at-risk teens across the City of Chicago. Methods: We collect and compile several datasets from public sources including: Chicago Department of Public Health clinic locations, two public health statistics datasets, census data of Chicago, list of Chicago public high schools, and their Locations. Our policy-neutral approach will consist of an equal distribution of funds and resources to schools and centers, regardless of past trends and outcomes. The policy-focused approaches will evaluate two models: first, a funding model based on prediction models from historical data; and second, a funding model based on economic and social outcomes for communities. Results: Results of this study confirms our initial hypothesis, that even though the models are optimized from a machine learning perspective, there is still possible that the models will produce wildly different results in the real-world application. Conclusions: When ethics and ethical considerations are extended beyond algorithmic optimization to encompass output and societal optimization, the foundation and philosophical grounding of the decision-making process become even more critical in the knowledge discovery process.",
    "lastUpdated": "2020-06-07T03:04:50Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2006.04029v1"
  },
  {
    "title": "The Tragedy of the AI Commons",
    "authors": [
      "Travis LaCroix",
      "Aydin Mohseni"
    ],
    "abstract": "Policy and guideline proposals for ethical artificial-intelligence research have proliferated in recent years. These are supposed to guide the socially-responsible development of AI for the common good. However, there typically exist incentives for non-cooperation (i.e., non-adherence to such policies and guidelines); and, these proposals often lack effective mechanisms to enforce their own normative claims. The situation just described constitutes a social dilemma---namely, a situation where no one has an individual incentive to cooperate, though mutual cooperation would lead to the best outcome for all involved. In this paper, we use stochastic evolutionary game dynamics to model this social dilemma in the context of the ethical development of artificial intelligence. This formalism allows us to isolate variables that may be intervened upon, thus providing actionable suggestions for increased cooperation amongst numerous stakeholders in AI. Our results show how stochastic effects can help make cooperation viable in such a scenario. They suggest that coordination for a common good should be attempted in smaller groups in which the cost for cooperation is low, and the perceived risk of failure is high. This provides insight into the conditions under which we should expect such ethics proposals to be successful with regard to their scope, scale, and content.",
    "lastUpdated": "2020-06-09T12:01:01Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.GT",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2006.05203v1"
  },
  {
    "title": "Data-Driven Game Development: Ethical Considerations",
    "authors": [
      "Magy Seif El-Nasr",
      "Erica Kleinman"
    ],
    "abstract": "In recent years, the games industry has made a major move towards data-driven development, using data analytics and player modeling to inform design decisions. Data-driven techniques are beneficial as they allow for the study of player behavior at scale, making them very applicable to modern digital game development. However, with this move towards data driven decision-making comes a number of ethical concerns. Previous work in player modeling as well as work in the fields of AI and machine learning have demonstrated several ways in which algorithmic decision-making can be flawed due to data or algorithmic bias or lack of data from specific groups. Further, black box algorithms create a trust problem due to lack of interpretability and transparency of the results or models developed based on the data, requiring blind faith in the results. In this position paper, we discuss several factors affecting the use of game data in the development cycle. In addition to issues raised by previous work, we also raise issues with algorithms marginalizing certain player groups and flaws in the resulting models due to their inability to reason about situational factors affecting players' decisions. Further, we outline some work that seeks to address these problems and identify some open problems concerning ethics and game data science.",
    "lastUpdated": "2020-06-18T19:01:33Z",
    "categories": [
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/2006.10808v1"
  },
  {
    "title": "Enhanced well-being assessment as basis for the practical implementation of ethical and rights-based normative principles for AI",
    "authors": [
      "Marek Havrda",
      "Bogdana Rakova"
    ],
    "abstract": "Artificial Intelligence (AI) has an increasing impact on all areas of people's livelihoods. A detailed look at existing interdisciplinary and transdisciplinary metrics frameworks could bring new insights and enable practitioners to navigate the challenge of understanding and assessing the impact of Autonomous and Intelligent Systems (A/IS). There has been emerging consensus on fundamental ethical and rights-based AI principles proposed by scholars, governments, civil rights organizations, and technology companies. In order to move from principles to real-world implementation, we adopt a lens motivated by regulatory impact assessments and the well-being movement in public policy. Similar to public policy interventions, outcomes of AI systems implementation may have far-reaching complex impacts. In public policy, indicators are only part of a broader toolbox, as metrics inherently lead to gaming and dissolution of incentives and objectives. Similarly, in the case of A/IS, there's a need for a larger toolbox that allows for the iterative assessment of identified impacts, inclusion of new impacts in the analysis, and identification of emerging trade-offs. In this paper, we propose the practical application of an enhanced well-being impact assessment framework for A/IS that could be employed to address ethical and rights-based normative principles in AI. This process could enable a human-centered algorithmically-supported approach to the understanding of the impacts of AI systems. Finally, we propose a new testing infrastructure which would allow for governments, civil rights organizations, and others, to engage in cooperating with A/IS developers towards implementation of enhanced well-being impact assessments.",
    "lastUpdated": "2020-09-15T15:15:16Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2007.14826v2"
  },
  {
    "title": "Combining distributive ethics and causal Inference to make trade-offs between austerity and population health",
    "authors": [
      "Adel Daoud",
      "Anders Herlitz",
      "SV Subramanian"
    ],
    "abstract": "The International Monetary Fund (IMF) provides financial assistance to its member-countries in economic turmoil, but requires at the same time that these countries reform their public policies. In several contexts, these reforms are at odds with population health. While researchers have empirically analyzed the consequences of these reforms on health, no analysis exist on identifying fair tradeoffs between consequences on population health and economic outcomes. Our article analyzes and identifies the principles governing these tradeoffs. First, this article reviews existing policy-evaluation studies, which show, on balance, that IMF policies frequently cause adverse effects on child health and material standards in the pursuit of macroeconmic improvement. Second, this article discusses four theories in distributive ethics (maximization, egalitarianianism, prioritarianiasm, and sufficientarianism) to identify which is the most compatible with the core mission of the IMF, that is, improved macroeconomics (Articles of Agreement) while at the same time balancing consequences on health. Using a distributive-ethics analyses of IMF polices, we argue that sufficientarianism is the most compatible theory. Third, this article offer a qualitative rearticulation of the Articles of Agreement, and formalize sufficientarian principles in the language of causal inference. We also offer a framework on how to empirically measure, from observational data, the extent that IMF policies trade off fairly between population health and economic outcomes. We conclude with policy recommendations and suggestions for future research.",
    "lastUpdated": "2020-08-10T09:56:33Z",
    "categories": [
      "econ.GN",
      "cs.CY",
      "q-fin.EC"
    ],
    "url": "http://arxiv.org/abs/2007.15550v2"
  },
  {
    "title": "Expected Utilitarianism",
    "authors": [
      "Heather M. Roff"
    ],
    "abstract": "We want artificial intelligence (AI) to be beneficial. This is the grounding assumption of most of the attitudes towards AI research. We want AI to be \"good\" for humanity. We want it to help, not hinder, humans. Yet what exactly this entails in theory and in practice is not immediately apparent. Theoretically, this declarative statement subtly implies a commitment to a consequentialist ethics. Practically, some of the more promising machine learning techniques to create a robust AI, and perhaps even an artificial general intelligence (AGI) also commit one to a form of utilitarianism. In both dimensions, the logic of the beneficial AI movement may not in fact create \"beneficial AI\" in either narrow applications or in the form of AGI if the ethical assumptions are not made explicit and clear. Additionally, as it is likely that reinforcement learning (RL) will be an important technique for machine learning in this area, it is also important to interrogate how RL smuggles in a particular type of consequentialist reasoning into the AI: particularly, a brute form of hedonistic act utilitarianism. Since the mathematical logic commits one to a maximization function, the result is that an AI will inevitably be seeking more and more rewards. We have two conclusions that arise from this. First, is that if one believes that a beneficial AI is an ethical AI, then one is committed to a framework that posits 'benefit' is tantamount to the greatest good for the greatest number. Second, if the AI relies on RL, then the way it reasons about itself, the environment, and other agents, will be through an act utilitarian morality. This proposition may, or may not, in fact be actually beneficial for humanity.",
    "lastUpdated": "2020-07-19T15:44:04Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2008.07321v1"
  },
  {
    "title": "Persuasion Meets AI: Ethical Considerations for the Design of Social Engineering Countermeasures",
    "authors": [
      "Nicolas E. Díaz Ferreyra",
      "Esma Aïmeur",
      "Hicham Hage",
      "Maritta Heisel",
      "Catherine García van Hoogstraten"
    ],
    "abstract": "Privacy in Social Network Sites (SNSs) like Facebook or Instagram is closely related to people's self-disclosure decisions and their ability to foresee the consequences of sharing personal information with large and diverse audiences. Nonetheless, online privacy decisions are often based on spurious risk judgements that make people liable to reveal sensitive data to untrusted recipients and become victims of social engineering attacks. Artificial Intelligence (AI) in combination with persuasive mechanisms like nudging is a promising approach for promoting preventative privacy behaviour among the users of SNSs. Nevertheless, combining behavioural interventions with high levels of personalization can be a potential threat to people's agency and autonomy even when applied to the design of social engineering countermeasures. This paper elaborates on the ethical challenges that nudging mechanisms can introduce to the development of AI-based countermeasures, particularly to those addressing unsafe self-disclosure practices in SNSs. Overall, it endorses the elaboration of personalized risk awareness solutions as i) an ethical approach to counteract social engineering, and ii) as an effective means for promoting reflective privacy decisions.",
    "lastUpdated": "2020-09-27T14:24:29Z",
    "categories": [
      "cs.CY",
      "cs.HC",
      "cs.SI"
    ],
    "url": "http://arxiv.org/abs/2009.12853v1"
  },
  {
    "title": "Mathematicians take a stand",
    "authors": [
      "Douglas N. Arnold",
      "Henry Cohn"
    ],
    "abstract": "We survey the reasons for the ongoing boycott of the publisher Elsevier. We examine Elsevier's pricing and bundling policies, restrictions on dissemination by authors, and lapses in ethics and peer review, and we conclude with thoughts about the future of mathematical publishing.",
    "lastUpdated": "2012-06-20T20:37:56Z",
    "categories": [
      "math.HO",
      "cs.GL"
    ],
    "url": "http://arxiv.org/abs/1204.1351v2"
  },
  {
    "title": "A Theory of Scientific Practice",
    "authors": [
      "Hisham Ghassib"
    ],
    "abstract": "This paper avers that science is not demarcated from other disciplines by a specific unique methodology, but by its specific scientific rationality and rational grounds. In this context, the notion and structure of scientific reason are explicated. Four rational grounds of science are identified: the epistemological. Ontological, ethical and sociological grounds. They are discussed in detail within the context of classical physics, relativistic physics and quantum physics.",
    "lastUpdated": "2012-08-26T09:19:35Z",
    "categories": [
      "physics.hist-ph"
    ],
    "url": "http://arxiv.org/abs/1208.5206v1"
  },
  {
    "title": "Living Labs - An Ethical Challenge for Researchers and Platform Providers",
    "authors": [
      "Philipp Schaer"
    ],
    "abstract": "The infamous Facebook emotion contagion experiment is one of the most prominent and best-known online experiments based on the concept of what we here call \"living labs\". In these kinds of experiments, real-world applications such as social web platforms trigger experimental switches inside their system to present experimental changes to their users - most of the time without the users being aware of their role as virtual guinea pigs. In the Facebook example the researches changed the way users' personal timeline was compiled to test the influence on the users' moods and feelings. The reactions to these experiments showed the inherent ethical issues such living labs settings bring up, mainly the study's lack of informed consent procedures, as well as a more general critique of the flaws in the experimental design. In this chapter, we describe additional use cases: The so-called living labs that focus on experimentation with information systems such as search engines and wikis and especially on their real-world usage. The living labs paradigm allows researchers to conduct research in real-world environments or systems. In the field of information science and especially information retrieval - which is the scientific discipline that is concerned with the research of search engines, information systems, and search related algorithms and techniques - it is still common practice to perform in vitro or offline evaluations using static test collections. Living labs are widely unknown or unavailable to academic researchers in these fields. A main benefit of living labs is their potential to offer new ways and possibilities to experiment with information systems and especially their users, but on the other hand they introduce a whole set of ethical issues that we would like to address in this chapter.",
    "lastUpdated": "2017-06-22T08:09:34Z",
    "categories": [
      "cs.CY",
      "cs.IR"
    ],
    "url": "http://arxiv.org/abs/1706.07202v1"
  },
  {
    "title": "Fair lending needs explainable models for responsible recommendation",
    "authors": [
      "Jiahao Chen"
    ],
    "abstract": "The financial services industry has unique explainability and fairness challenges arising from compliance and ethical considerations in credit decisioning. These challenges complicate the use of model machine learning and artificial intelligence methods in business decision processes.",
    "lastUpdated": "2018-09-12T21:29:20Z",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "stat.AP",
      "stat.ML",
      "91G40, 68T01",
      "J.1; I.5.1"
    ],
    "url": "http://arxiv.org/abs/1809.04684v1"
  },
  {
    "title": "Wireless Lan to Support Multimedia Communication Using Spread Spectrum Technology",
    "authors": [
      "Sourav Dhar",
      "Rabindranath Bera",
      "K. Mal"
    ],
    "abstract": "Wireless LAN is currently enjoying rapid deployment in University departments, business offices, hospitals and homes. It becomes an inexpensive technology and allows multiple numbers of the households to simultaneously access the internet while roaming about the house. In the present work, the design and development of a wireless LAN is highlighted which utilizes direct sequence spread spectrum (DSSS) technology at 900MHz RF carrier frequency in its physical layer. This provides enormous security in the physical layer and hence it is very difficult to hack or jam the network. The installation cost is also less due to the use of 900 MHz RF carrier frequency..",
    "lastUpdated": "2007-03-22T11:07:45Z",
    "categories": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/cs/0703108v1"
  },
  {
    "title": "Limits of stable pairs",
    "authors": [
      "Valery Alexeev"
    ],
    "abstract": "Let (X_0,B_0) be the canonical limit of a one-parameter family of stable pairs, provided by the log Minimal Model Program. We prove that X_0 is S2 and that [B_0] is S_1, as an application of a general local statement: if (X,B+\\epsilon D) is log canonical and D is Q-Cartier then D is S2 and [B] \\cap D is S1, i.e. has no embedded components. When B has coefficients smaller than 1, examples due to Hacking and Hassett show that B_0 may indeed have embedded primes. We resolve this problem by introducing a category of stable branchpairs. We prove that the corresponding moduli functor is proper for families with normal generic fiber.",
    "lastUpdated": "2007-11-05T02:57:46Z",
    "categories": [
      "math.AG",
      "math.AC"
    ],
    "url": "http://arxiv.org/abs/math/0607684v2"
  },
  {
    "title": "Signatures of the Pair-Coherent State",
    "authors": [
      "A. Gilchrist",
      "W. J. Munro"
    ],
    "abstract": "We explore in detail the possibility of generating a pair-coherent state in the non-degenerate parametric oscillator when decoherence is included. Such states are predicted in the transient regime in parametric oscillation where the pump mode is adiabatically eliminated. Two specific signatures are examined to indicate whether the state of interest has been generated, the Schrodinger cat state - like signatures, and the fidelity. Solutions in a transient regime reveal interference fringes which are indicative of the formation of a Schrodinger cat state. The fidelity indicates the purity of our prepared state compared to the ideal pair-coherent state.",
    "lastUpdated": "2001-02-12T01:26:23Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/quant-ph/0102059v1"
  },
  {
    "title": "The extended algebra of observables for Dirac fields and the trace anomaly of their stress-energy tensor",
    "authors": [
      "Claudio Dappiaggi",
      "Thomas-Paul Hack",
      "Nicola Pinamonti"
    ],
    "abstract": "We discuss from scratch the classical structure of Dirac spinors on an arbitrary globally hyperbolic, Lorentzian spacetime, their formulation as a locally covariant quantum field theory, and the associated notion of a Hadamard state. Eventually, we develop the notion of Wick polynomials for spinor fields, and we employ the latter to construct a covariantly conserved stress-energy tensor suited for back-reaction computations. We shall explicitly calculate its trace anomaly in particular.",
    "lastUpdated": "2009-04-03T16:08:54Z",
    "categories": [
      "math-ph",
      "gr-qc",
      "hep-th",
      "math.MP"
    ],
    "url": "http://arxiv.org/abs/0904.0612v1"
  },
  {
    "title": "Dark Energy from Quantum Matter",
    "authors": [
      "Claudio Dappiaggi",
      "Thomas-Paul Hack",
      "Jan Möller",
      "Nicola Pinamonti"
    ],
    "abstract": "We study the backreaction of free quantum fields on a flat Robertson-Walker spacetime. Apart from renormalization freedom, the vacuum energy receives contributions from both the trace anomaly and the thermal nature of the quantum state. The former represents a dynamical realisation of dark energy, while the latter mimics an effective dark matter component. The semiclassical dynamics yield two classes of asymptotically stable solutions. The first reproduces the concordance model in a suitable regime. The second lacks a classical counterpart, but is in excellent agreement with recent observations.",
    "lastUpdated": "2010-07-28T15:33:17Z",
    "categories": [
      "astro-ph.CO",
      "gr-qc",
      "hep-th"
    ],
    "url": "http://arxiv.org/abs/1007.5009v1"
  },
  {
    "title": "Analysis of Differential Phase Shift Quantum Key Distribution",
    "authors": [
      "Monica Lavale"
    ],
    "abstract": "We review the implementation of two QKD protocols (BB84 and B92) keeping in mind that their implementations do not easily satisfy the requirement of use of single photons. We argue that current models do not take into account issues raised by the Uncertainty Principle related to time-location and transmission characteristics of single photons. This indicates that security proofs of current implementations even after the fixes for the recent successful hacks are made will be hard to obtain.",
    "lastUpdated": "2011-10-21T15:20:42Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1110.4820v1"
  },
  {
    "title": "Theta functions and mirror symmetry",
    "authors": [
      "Mark Gross",
      "Bernd Siebert"
    ],
    "abstract": "This is a survey covering aspects of varied work of the authors with Mohammed Abouzaid, Paul Hacking, and Sean Keel. While theta functions are traditionally canonical sections of ample line bundles on abelian varieties, we motivate, using mirror symmetry, the idea that theta functions exist in much greater generality. This suggestion originates with the work of the late Andrei Tyurin. We outline how to construct theta functions on the degenerations of varieties constructed in previous work of the authors, and then explain applications of this construction to homological mirror symmetry and constructions of broad classes of mirror varieties.",
    "lastUpdated": "2012-04-09T21:14:08Z",
    "categories": [
      "math.AG",
      "math.SG",
      "14J33"
    ],
    "url": "http://arxiv.org/abs/1204.1991v1"
  },
  {
    "title": "Moduli of surfaces with an anti-canonical cycle",
    "authors": [
      "Mark Gross",
      "Paul Hacking",
      "Sean Keel"
    ],
    "abstract": "We prove a global Torelli theorem for pairs (Y,D), where Y is a smooth projective rational surface and D is an effective anti-canonical divisor which is a cycle of rational curves. This Torelli theorem was conjectured by Friedman in 1984. In addition, we construct natural universal families for such pairs.",
    "lastUpdated": "2014-06-30T10:04:28Z",
    "categories": [
      "math.AG",
      "14J10, 14J26"
    ],
    "url": "http://arxiv.org/abs/1211.6367v5"
  },
  {
    "title": "Mutations of fake weighted projective planes",
    "authors": [
      "Mohammad Akhtar",
      "Alexander Kasprzyk"
    ],
    "abstract": "In previous work by Coates, Galkin, and the authors, the notion of mutation between lattice polytopes was introduced. Such a mutation gives rise to a deformation between the corresponding toric varieties. In this paper we study one-step mutations that correspond to deformations between weighted projective planes, giving a complete characterisation of such mutations in terms of T-singularities. We show also that the weights involved satisfy Diophantine equations, generalising results of Hacking-Prokhorov.",
    "lastUpdated": "2014-11-02T14:12:54Z",
    "categories": [
      "math.AG",
      "math.CO",
      "52B20 (Primary), 14J45, 11D99 (Secondary)"
    ],
    "url": "http://arxiv.org/abs/1302.1152v2"
  },
  {
    "title": "Tropical compactification in log-regular varieties",
    "authors": [
      "Martin Ulirsch"
    ],
    "abstract": "In this article we define a natural tropicalization procedure for closed subsets of log-regular varieties in the case of constant coefficients and study its basic properties. This framework allows us to generalize some of Tevelev's results on tropical compactification as well as Hacking's result on the cohomology of the link of a tropical variety to log-regular varieties.",
    "lastUpdated": "2014-11-13T16:19:57Z",
    "categories": [
      "math.AG",
      "14T05, 32P05, 20M14"
    ],
    "url": "http://arxiv.org/abs/1309.4011v3"
  },
  {
    "title": "The existence of a maximal green sequence is not invariant under quiver mutation",
    "authors": [
      "Greg Muller"
    ],
    "abstract": "This note provides a quiver which does not admit a maximal green sequence, but which is mutation-equivalent to a quiver which does admit a maximal green sequence. The proof uses the `scattering diagrams' of Gross-Hacking-Keel-Kontsevich to show that a maximal green sequence for a quiver determines a maximal green sequence for any induced subquiver.",
    "lastUpdated": "2016-06-27T17:51:54Z",
    "categories": [
      "math.QA",
      "math.CO"
    ],
    "url": "http://arxiv.org/abs/1503.04675v4"
  },
  {
    "title": "The greedy basis equals the theta basis",
    "authors": [
      "Man Wai Cheung",
      "Mark Gross",
      "Greg Muller",
      "Gregg Musiker",
      "Dylan Rupel",
      "Salvatore Stella",
      "Harold Williams"
    ],
    "abstract": "We prove the equality of two canonical bases of a rank 2 cluster algebra, the greedy basis of Lee-Li-Zelevinsky and the theta basis of Gross-Hacking-Keel-Kontsevich.",
    "lastUpdated": "2015-08-07T19:36:11Z",
    "categories": [
      "math.QA",
      "math.AG",
      "math.CO"
    ],
    "url": "http://arxiv.org/abs/1508.01404v2"
  },
  {
    "title": "POLYANA - A tool for the calculation of molecular radial distribution functions based on Molecular Dynamics trajectories",
    "authors": [
      "Christos Dimitroulis",
      "Theophanes Raptis",
      "Vasilios Raptis"
    ],
    "abstract": "We present an application for the calculation of radial distribution functions for molecular centres of mass, based on trajectories generated by molecular simulation methods (Molecular Dynamics, Monte Carlo). When designing this application, the emphasis was placed on ease of use as well as ease of further development. In its current version, the program can read trajectories generated by the well-known DL_POLY package, but it can be easily extended to treat other formats. It is also very easy to 'hack' the program so it can compute intermolecular radial distribution functions for groups of interaction sites rather than whole molecules.",
    "lastUpdated": "2015-05-11T19:11:56Z",
    "categories": [
      "cs.MS"
    ],
    "url": "http://arxiv.org/abs/1508.05374v1"
  },
  {
    "title": "Securing Web Services Using XML Signature and XML Encryption",
    "authors": [
      "RA. K. Saravanaguru",
      "George Abraham",
      "Krishnakumar Ventakasubramanian",
      "Kiransinh Borasia"
    ],
    "abstract": "This paper is aimed to evaluate the importance of XML Signature and XML Encryption in Web Service Security. In today's business scenario, organizations are investing huge amount of resources in Web Services. Web Service Transactions are done mainly through plain-text XML formats like SOAP and WSDL, hence hacking into them is not a tedious task. XML Signature and XML Encryption ensure security to XML documents as well as retain the structure of documents, thereby making it easy to implement them. These two methods are evaluated on the parameters of authentication, authorization, integration, confidentiality and non-repudiation.",
    "lastUpdated": "2013-03-05T02:35:49Z",
    "categories": [
      "cs.CR",
      "H.3.5"
    ],
    "url": "http://arxiv.org/abs/1303.0910v1"
  },
  {
    "title": "Degenerations of Godeaux surfaces and exceptional vector bundles",
    "authors": [
      "Anna Kazanova"
    ],
    "abstract": "A recent construction of Hacking relates the classification of stable vector bundles on a surface of general type with $p_g = 0$ and the boundary of the moduli space of deformations of the surface. In the present paper we analyze this relation for Godeaux surfaces. We provide a description of certain boundary components of the moduli space of Godeaux surfaces. Also we explicitly construct certain exceptional vector bundles of rank 2 on Godeaux surfaces, stable with respect to the canonical class, and examine the correspondence between the boundary components and such exceptional vector bundles.",
    "lastUpdated": "2014-02-02T22:08:18Z",
    "categories": [
      "math.AG",
      "14J10, 14J29, 14J60"
    ],
    "url": "http://arxiv.org/abs/1402.0254v1"
  },
  {
    "title": "Looijenga's Conjecture via Integral-affine Geometry",
    "authors": [
      "Philip Engel"
    ],
    "abstract": "A cusp singularity is an elliptic surface singularity whose minimal resolution is a cycle of smooth rational curves meeting transversely. Cusp singularities come in naturally dual pairs. In 1981, Looijenga proved that whenever a cusp singularity is smoothable, the minimal resolution of the dual cusp is an anticanonical divisor of some smooth rational surface. He conjectured the converse. Recent work of Gross, Hacking, and Keel has proven Looijenga's conjecture using methods from mirror symmetry. This paper provides an alternative proof of Looijenga's conjecture based on a combinatorial criterion for smoothability given by Friedman and Miranda in 1983.",
    "lastUpdated": "2018-07-17T16:48:38Z",
    "categories": [
      "math.AG",
      "math.SG"
    ],
    "url": "http://arxiv.org/abs/1409.7676v2"
  },
  {
    "title": "Secure Quantum Key Distribution",
    "authors": [
      "Hoi-Kwong Lo",
      "Marcos Curty",
      "Kiyoshi Tamaki"
    ],
    "abstract": "Secure communication plays a crucial role in the Internet Age. Quantum mechanics may revolutionise cryptography as we know it today. In this Review Article, we introduce the motivation and the current state of the art of research in quantum cryptography. In particular, we discuss the present security model together with its assumptions, strengths and weaknesses. After a brief introduction to recent experimental progress and challenges, we survey the latest developments in quantum hacking and counter-measures against it.",
    "lastUpdated": "2015-05-20T10:14:32Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/1505.05303v1"
  },
  {
    "title": "Theta bases are atomic",
    "authors": [
      "Travis Mandel"
    ],
    "abstract": "Fock and Goncharov conjectured that the indecomposable universally positive (i.e., atomic) elements of a cluster algebra should form a basis for the algebra. This was shown to be false by Lee-Li-Zelevinsky. However, we find that the theta bases of Gross-Hacking-Keel-Kontsevich do satisfy this conjecture for a slightly modified definition of universal positivity in which one replaces the positive atlas consisting of the clusters by an enlargement we call the scattering atlas. In particular, this uniquely characterizes the theta functions.",
    "lastUpdated": "2018-06-29T19:47:36Z",
    "categories": [
      "math.QA",
      "math.AG",
      "13F60"
    ],
    "url": "http://arxiv.org/abs/1605.03202v2"
  },
  {
    "title": "Backflash light characterization to prevent QKD zero-error hacking",
    "authors": [
      "A. Meda",
      "I. P. Degiovanni",
      "A. Tosi",
      "Z. L. Yuan",
      "G. Brida",
      "M. Genovese"
    ],
    "abstract": "Single photon avalanche diodes (SPADs) are the most commercially diffused solution for single-photon counting in quantum key distribution (QKD) applications. However, the secondary photon emission, arising from the avalanche of charge carriers during a photon detection, may be exploited by an eavesdropper to gain information without forcing errors in the transmission key. In this paper, we characterise such backflash light in gated InGaAs/InP SPADs, and its spectral and temporal characterization for different detector models and different operating parameters. We qualitatively bound the maximum information leakage due to backflash light, and propose a solution.",
    "lastUpdated": "2016-05-18T12:54:52Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/1605.05562v1"
  },
  {
    "title": "An Inductive Proof Method for Simulation-based Compiler Correctness",
    "authors": [
      "Sigurd Schneider",
      "Gert Smolka",
      "Sebastian Hack"
    ],
    "abstract": "We study induction on the program structure as a proof method for bisimulation-based compiler correctness. We consider a first-order language with mutually recursive function definitions, system calls, and an environment semantics. The proof method relies on a generalization of compatibility of function definition with the bisimulation. We use the inductive method to show correctness of a form of dead code elimination. This is an interesting case study because the transformation removes function, variable, and parameter definitions from the program. While such transformations require modification of the simulation in a coinductive proof, the inductive method deals with them naturally. All our results are formalized in Coq.",
    "lastUpdated": "2016-11-29T12:47:15Z",
    "categories": [
      "cs.PL"
    ],
    "url": "http://arxiv.org/abs/1611.09606v1"
  },
  {
    "title": "Initial degenerations of Grassmannians",
    "authors": [
      "Daniel Corey"
    ],
    "abstract": "We construct closed immersions from initial degenerations of $\\operatorname*{Gr}_{0}(d,n)$---the open cell in the Grassmannian $\\operatorname*{Gr}(d,n)$ given by the nonvanishing of all Pl\\\"ucker coordinates---to limits of thin Schubert cells associated to diagrams induced by the face poset of the corresponding tropical linear space. These are isomorphisms when $(d,n)$ equals $(2,n)$, $(3,6)$ and $(3,7)$. As an application we prove $\\operatorname*{Gr}_0(3,7)$ is sch\\\"on, and the Chow quotient of $\\operatorname*{Gr}(3,7)$ by the maximal torus in $ \\operatorname*{PGL}(7)$ is the log canonical compactification of the moduli space of 7 points in $\\mathbb{P}^2$ in linear general position, making progress on a conjecture of Hacking, Keel, and Tevelev.",
    "lastUpdated": "2020-04-24T03:17:26Z",
    "categories": [
      "math.AG",
      "14T05 (primary), 14M15, 14E25 (secondary)"
    ],
    "url": "http://arxiv.org/abs/1708.03060v2"
  },
  {
    "title": "Polyhedral parametrizations of canonical bases & cluster duality",
    "authors": [
      "Volker Genz",
      "Gleb Koshevoy",
      "Bea Schumann"
    ],
    "abstract": "We establish the relation of the potential function constructed by Gross-Hacking-Keel-Kontsevich's and Berenstein-Kazhdan's decoration function on the open double Bruhat cell in the base affine space $G/\\mathcal{N}$ of a simple, simply connected, simply laced algebraic group $G$. As a byproduct we derive explicit identifications of polyhedral parametrization of canonical bases of the ring of regular functions on $G/\\mathcal{N}$ arising from the tropicalizations of the potential and decoration function with the classical string and Lusztig parametrizations.",
    "lastUpdated": "2017-11-20T07:35:54Z",
    "categories": [
      "math.RT",
      "math.AG",
      "math.CO",
      "math.QA"
    ],
    "url": "http://arxiv.org/abs/1711.07176v1"
  },
  {
    "title": "Quantum mirrors of log Calabi-Yau surfaces and higher genus curve counting",
    "authors": [
      "Pierrick Bousseau"
    ],
    "abstract": "Gross, Hacking, and Keel have constructed mirrors of log Calabi-Yau surfaces in terms of counts of rational curves. Using $q$-deformed scattering diagrams defined in terms of higher genus log Gromov-Witten invariants, we construct deformation quantizations of these mirrors and we produce canonical bases of the corresponding noncommutative algebras of functions.",
    "lastUpdated": "2020-12-23T14:03:23Z",
    "categories": [
      "math.AG",
      "hep-th",
      "math.QA",
      "math.SG"
    ],
    "url": "http://arxiv.org/abs/1808.07336v2"
  },
  {
    "title": "A note on deformations and mutations of fake weighted projective planes",
    "authors": [
      "Irem Portakal"
    ],
    "abstract": "It has been shown by Hacking and Prokhorov that if the projective surface X with quotient singularities and self-intersection number 9 has a smoothing to the projective plane, then X is the general fiber of a Q-Gorenstein deformation of the weighted projective plane with weights giving solutions to the Markov equation. This result has been understood and generalized by combinatorial mutations of Fano triangles by Akhtar, Coates, Galkin, and Kasprzyk. In this note, we study this result by utilizing polarized T-varieties and describe the associated deformation explicitly in terms of certain Minkowski summands of so-called divisorial polytopes.",
    "lastUpdated": "2018-09-12T14:09:43Z",
    "categories": [
      "math.AG",
      "math.CO",
      "14M25, 14B07, 52B20, 14J45"
    ],
    "url": "http://arxiv.org/abs/1809.04470v1"
  },
  {
    "title": "Coroutines with Higher Order Functions",
    "authors": [
      "Dimitri Racordon"
    ],
    "abstract": "Coroutines are non-preemptive concurrent subroutines that, unlike preemptive threads, voluntarily transfer control between each others. Introduced in the 60s before loosing in popularity in the 80s, they have seen a regain of interest in recent years, thanks to how elegantly they can solve numerous algorithmic problems. Unfortunately, some mainstream languages still lack support for coroutines, hence requiring either the use of non-standard interpreter/compilers, or elaborate hacks in thrid-party libraries. In this short paper, we propose a very simple way to implement coroutine-like components on the top of any language that support or can emulate higher order functions. We accompany our explanations with a handful of examples in JavaScript.",
    "lastUpdated": "2018-12-19T22:37:59Z",
    "categories": [
      "cs.PL"
    ],
    "url": "http://arxiv.org/abs/1812.08278v1"
  },
  {
    "title": "Spherical centroid bodies",
    "authors": [
      "Florian Besau",
      "Thomas Hack",
      "Peter Pivovarov",
      "Franz E. Schuster"
    ],
    "abstract": "The spherical centroid body of a centrally-symmetric convex body in the Euclidean unit sphere is introduced. Two alternative definitions - one geometric, the other probabilistic in nature - are given and shown to lead to the same objects. The geometric approach is then used to establish a number of basic properties of spherical centroid bodies, while the probabilistic approach inspires the proof of a spherical analogue of the classical polar Busemann-Petty centroid inequality.",
    "lastUpdated": "2019-02-27T16:14:08Z",
    "categories": [
      "math.MG",
      "52A55, 28A75, 52A22, 52A40"
    ],
    "url": "http://arxiv.org/abs/1902.10614v1"
  },
  {
    "title": "Fano mirror periods from the Frobenius structure conjecture",
    "authors": [
      "Travis Mandel"
    ],
    "abstract": "The Fano classification program proposed by Coates-Corti-Galkin-Golyshev-Kasprzyk is based on the mirror symmetry prediction that the regularized quantum period of a Fano should be equivalent to the classical period of its mirror Landau-Ginzburg potential. We prove that this mirror equivalence follows from versions of the Frobenius structure conjecture of Gross-Hacking-Keel. We also find that the regularized quantum period, which is defined in terms of descendant Gromov-Witten numbers, is in fact given by certain naive curve counts.",
    "lastUpdated": "2019-03-28T14:44:56Z",
    "categories": [
      "math.AG",
      "14J33 (Primary) 14J45, 14N35 (Secondary)"
    ],
    "url": "http://arxiv.org/abs/1903.12014v1"
  },
  {
    "title": "Reconstruction of tunnel exit time and exit momentum in strong field ionization, based on phase space methods",
    "authors": [
      "Szabolcs Hack",
      "Szilárd Majorosi",
      "Mihály Benedict",
      "Attila Czirják"
    ],
    "abstract": "We analyze tunnel ionization of a single atom based on the Wigner function over the classical phase space which inspires improved classical electron trajectories: these start with exit momenta based on the quantum momentum function and correspond very well to the subsequent quantum evolution. We derive an approximate analytic formula to reconstruct the tunnel exit time and exit momentum from electron momentum data that can be measured e.g. with a usual time-of-flight electron detector.",
    "lastUpdated": "2019-04-10T22:29:41Z",
    "categories": [
      "quant-ph",
      "physics.atom-ph"
    ],
    "url": "http://arxiv.org/abs/1904.05465v1"
  },
  {
    "title": "Low-cost spectrogram based counterfeit medicine detection",
    "authors": [
      "Amit Kumar Mishra",
      "Mohamed Hoosain Essop"
    ],
    "abstract": "Contaminated substances such as counterfeit medication and food contami-nated with pesticide residue is a pandemic of utmost urgency. Spectroscopy and chromatography methods are often used but are expensive and complex and as such a need exists for a device that can be easily operated in developing commu-nities. We present a hacked visible spectrometer based contaminated substance detector using machine learning. The Support Vector Machine (SVM), Logistic Regression, linear Regression and Convolutional Neural Network (CNN) models have been implemented and are trained on the acquired spectrum data. Our results show that a lowcost method of identifying contaminated substances is achievable with very high accuracy.",
    "lastUpdated": "2019-04-10T09:07:50Z",
    "categories": [
      "eess.SP"
    ],
    "url": "http://arxiv.org/abs/1904.07152v1"
  },
  {
    "title": "Simulation-Based Cyber Data Collection Efficacy",
    "authors": [
      "David Thaw",
      "Bret Barkley",
      "Gerry Bella",
      "Carrie Gardner"
    ],
    "abstract": "Building upon previous research in honeynets and simulations, we present efforts from a two-and-a-half-year study using a representative simulation to collect cybersecurity data. Unlike traditional honeypots or honeynets, our experiment utilizes a full-scale operational network to model a small business environment. The simulation uses default security configurations to defend the network, testing the assumption that given standard security baseline, devices networked to the public Internet will necessarily be hacked. Given network activity appropriate for its context, results support the conclusion that no actors where able to break in, despite only default security settings.",
    "lastUpdated": "2019-05-22T19:22:17Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1905.09336v1"
  },
  {
    "title": "Hacking VMAF with Video Color and Contrast Distortion",
    "authors": [
      "Anastasia Zvezdakova",
      "Sergey Zvezdakov",
      "Dmitriy Kulikov",
      "Dmitriy Vatolin"
    ],
    "abstract": "Video quality measurement takes an important role in many applications. Full-reference quality metrics which are usually used in video codecs comparisons are expected to reflect any changes in videos. In this article, we consider different color corrections of compressed videos which increase the values of full-reference metric VMAF and almost don't decrease other widely-used metric SSIM. The proposed video contrast enhancement approach shows the metric inapplicability in some cases for video codecs comparisons, as it may be used for cheating in the comparisons via tuning to improve this metric values.",
    "lastUpdated": "2019-08-29T13:35:31Z",
    "categories": [
      "cs.MM",
      "cs.GR",
      "eess.IV"
    ],
    "url": "http://arxiv.org/abs/1907.04807v2"
  },
  {
    "title": "Next Generation Resilient Cyber-Physical Systems",
    "authors": [
      "Michel Barbeau",
      "Georg Carle",
      "Joaquin Garcia-Alfaro",
      "Vicenç Torra"
    ],
    "abstract": "Cyber-Physical Systems (CPS) consist of distributed engineered environments where the monitoring and surveillance tasks are governed by tightly integrated computing, communication and control technologies. CPS are omnipresent in our everyday life. Hacking and failures of such systems have impact on critical services with potentially significant and lasting consequences. In this paper, we review which requirements a CPS must meet to address the challenges of tomorrow. Two key challenges are understanding and reinforcing the resilience of CPS.",
    "lastUpdated": "2019-11-08T15:16:01Z",
    "categories": [
      "cs.CR",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1907.08849v3"
  },
  {
    "title": "Randomized Urysohn-type inequalities",
    "authors": [
      "Thomas Hack",
      "Peter Pivovarov"
    ],
    "abstract": "As a natural analog of Urysohn's inequality in Euclidean space, Gao, Hug, and Schneider showed in 2003 that in spherical or hyperbolic space, the total measure of totally geodesic hypersurfaces meeting a given convex body K is minimized when K is a geodesic ball. We present a random extension of this result by taking K to be the convex hull of finitely many points drawn according to a probability distribution and by showing that the minimum is attained for uniform distributions on geodesic balls. As a corollary, we obtain a randomized Blaschke--Santalo inequality on the sphere.",
    "lastUpdated": "2019-10-25T12:30:25Z",
    "categories": [
      "math.PR"
    ],
    "url": "http://arxiv.org/abs/1910.11654v1"
  },
  {
    "title": "Strong positivity for quantum theta bases of quantum cluster algebras",
    "authors": [
      "Ben Davison",
      "Travis Mandel"
    ],
    "abstract": "We construct \"quantum theta bases,\" extending the set of quantum cluster monomials, for various versions of skew-symmetric quantum cluster algebras. These bases consist precisely of the indecomposable universally positive elements of the algebras they generate, and the structure constants for their multiplication are Laurent polynomials in the quantum parameter with non-negative integer coefficients, proving the quantum strong cluster positivity conjecture for these algebras. The classical limits recover the theta bases considered by Gross-Hacking-Keel-Kontsevich. Our approach combines the scattering diagram techniques used in loc. cit. with the Donaldson-Thomas theory of quivers.",
    "lastUpdated": "2020-05-25T14:52:30Z",
    "categories": [
      "math.RT",
      "math.AG",
      "math.CO",
      "math.QA",
      "13F60 (Primary) 14N35, 16G20 (secondary)"
    ],
    "url": "http://arxiv.org/abs/1910.12915v2"
  },
  {
    "title": "Hacking Neural Networks: A Short Introduction",
    "authors": [
      "Michael Kissner"
    ],
    "abstract": "A large chunk of research on the security issues of neural networks is focused on adversarial attacks. However, there exists a vast sea of simpler attacks one can perform both against and with neural networks. In this article, we give a quick introduction on how deep learning in security works and explore the basic methods of exploitation, but also look at the offensive capabilities deep learning enabled tools provide. All presented attacks, such as backdooring, GPU-based buffer overflows or automated bug hunting, are accompanied by short open-source exercises for anyone to try out.",
    "lastUpdated": "2019-12-01T12:35:02Z",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1911.07658v2"
  },
  {
    "title": "Heart rate variability code: Does it exist and can we hack it?",
    "authors": [
      "Martin G. Frasch"
    ],
    "abstract": "Heart rate variability (HRV) has been studied for over 50 years, yet what remains lacking from the puzzle is an integrative concept of what HRV represents physiologically. Here I introduce the notion of HRV code as an attempt to address this challenge systematically. I review the existing evidence from physiological studies in various species to support this concept and propose experiments to help validate it.",
    "lastUpdated": "2020-05-06T22:25:50Z",
    "categories": [
      "q-bio.TO"
    ],
    "url": "http://arxiv.org/abs/2001.08264v3"
  },
  {
    "title": "RTM: Blockchain That Support Revocable Transaction Model",
    "authors": [
      "Victor Gates"
    ],
    "abstract": "In many typical application scenarios, it is necessary to revoke the incorrect account operations caused by user mis-operation, financial fraud, illegal hacking, etc. Unfortunately, users often blur the lines between the concept of \"transaction state revocable\" and \"business status revocable\", which result in revocable transaction not universally supported in blockchain systems at present. In this work, we propose GateChain , a blockchain that support revocable transaction model (RTM) on distributed ledger. Specifically, based on the state-of-the-art blockchain technologies, GateChain can safely withdraw the account status change operations by leveraging an improved account model and extra designed transaction types. On that basis, GateChain exploit the characteristics of functional completeness, easy to deployment and lower complexity.",
    "lastUpdated": "2020-01-30T11:26:58Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/2001.11259v1"
  },
  {
    "title": "Breaking RSA Security With A Low Noise D-Wave 2000Q Quantum Annealer: Computational Times, Limitations And Prospects",
    "authors": [
      "Riccardo Mengoni",
      "Daniele Ottaviani",
      "Paolino Iorio"
    ],
    "abstract": "The RSA cryptosystem could be easily broken with large scale general purpose quantum computers running Shor's factorization algorithm. Being such devices still in their infancy, a quantum annealing approach to integer factorization has recently gained attention. In this work, we analyzed the most promising strategies for RSA hacking via quantum annealing with an extensive study of the low noise D-Wave 2000Q computational times, current hardware limitations and challenges for future developments.",
    "lastUpdated": "2020-05-05T15:04:45Z",
    "categories": [
      "quant-ph",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/2005.02268v1"
  },
  {
    "title": "Our Evaluation Metric Needs an Update to Encourage Generalization",
    "authors": [
      "Swaroop Mishra",
      "Anjana Arunkumar",
      "Chris Bryan",
      "Chitta Baral"
    ],
    "abstract": "Models that surpass human performance on several popular benchmarks display significant degradation in performance on exposure to Out of Distribution (OOD) data. Recent research has shown that models overfit to spurious biases and `hack' datasets, in lieu of learning generalizable features like humans. In order to stop the inflation in model performance -- and thus overestimation in AI systems' capabilities -- we propose a simple and novel evaluation metric, WOOD Score, that encourages generalization during evaluation.",
    "lastUpdated": "2020-07-14T08:15:19Z",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2007.06898v1"
  },
  {
    "title": "A Gromov-Witten theory for simple normal-crossing pairs without log geometry",
    "authors": [
      "Hsian-Hua Tseng",
      "Fenglong You"
    ],
    "abstract": "We define a new Gromov-Witten theory relative to simple normal crossing divisors as a limit of Gromov-Witten theory of multi-root stacks. Several structural properties are proved including relative quantum cohomology, Givental formalism, Virasoro constraints (genus zero) and a partial cohomological field theory. Furthermore, we use the degree zero part of the relative quantum cohomology to provide an alternative mirror construction of Gross-Siebert and to prove the Frobenius structure conjecture of Gross-Hacking-Keel.",
    "lastUpdated": "2020-08-11T16:44:23Z",
    "categories": [
      "math.AG"
    ],
    "url": "http://arxiv.org/abs/2008.04844v1"
  },
  {
    "title": "Compactifications of moduli of points and lines in the projective plane",
    "authors": [
      "Luca Schaffler",
      "Jenia Tevelev"
    ],
    "abstract": "Projective duality identifies the moduli spaces $\\mathbf{B}_n$ and $\\mathbf{X}(3,n)$ parametrizing linearly general configurations of $n$ points in $\\mathbb{P}^2$ and $n$ lines in the dual $\\mathbb{P}^2$, respectively. The space $\\mathbf{X}(3,n)$ admits Kapranov's Chow quotient compactification $\\overline{\\mathbf{X}}(3,n)$, studied also by Lafforgue, Hacking, Keel, Tevelev, and Alexeev, which gives an example of a KSBA moduli space of stable surfaces: it carries a family of certain reducible degenerations of $\\mathbb{P}^2$ with $n$ \"broken lines\". Gerritzen and Piwek proposed a dual perspective, a compact moduli space parametrizing certain reducible degenerations of $\\mathbb{P}^2$ with $n$ smooth points. We investigate the relation between these approaches, answering a question of Kapranov from 2003.",
    "lastUpdated": "2020-10-07T16:56:26Z",
    "categories": [
      "math.AG",
      "14J10, 14D06, 52C35, 52B40, 51E24, 14T05"
    ],
    "url": "http://arxiv.org/abs/2010.03519v1"
  },
  {
    "title": "On the GHKS compactification of the moduli space of K3 surfaces of degree two",
    "authors": [
      "Klaus Hulek",
      "Christian Lehn",
      "Carsten Liese"
    ],
    "abstract": "We investigate a toroidal compactification of the moduli space of K3 surfaces of degree $2$ originating from the program formulated by Gross-Hacking-Keel-Siebert. This construction uses Dolgachev's formulation of mirror symmetry and the birational geometry of the mirror family. Our main result in an analysis of the toric fan. For this we use the methods developed by two of us in a previous paper.",
    "lastUpdated": "2020-10-14T10:04:07Z",
    "categories": [
      "math.AG",
      "math.CV",
      "14J10, 14J28 (Primary), 14D06, 14D20, 14E30, (Secondary)"
    ],
    "url": "http://arxiv.org/abs/2010.06922v1"
  },
  {
    "title": "A No-Go Theorem for the Consistent Quantization of Spin 3/2 Fields on General Curved Spacetimes",
    "authors": [
      "Thomas-Paul Hack",
      "Mathias Makedonski"
    ],
    "abstract": "It is well-known that coupling a spin $\\frac32$-field to a gravitational or electromagnetic background leads to potential problems both in the classical and in the quantum theory. Various solutions to these problems have been proposed so far, which are all restricted to a limited class of backgrounds. On the other hand, negative results for general gravitational backgrounds have been reported only for a limited set of couplings to the background to date. Hence, to our knowledge, a comprehensive analysis of all possible couplings to the gravitational field and general gravitational backgrounds including off-shell ones has not been performed so far. In this work we analyse whether it is possible to couple a spin $\\frac32$-field to a gravitational field in such a way that the resulting quantum theory is consistent on arbitrary gravitational backgrounds. We find that this is impossible as all couplings require the background to be an Einstein spacetime for consistency. This enforces the widespread belief that supergravity theories are the only meaningful models which contain spin $\\frac32$ fields as in these models such restrictions of the gravitational background appear naturally as on-shell conditions.",
    "lastUpdated": "2012-09-20T19:06:17Z",
    "categories": [
      "hep-th",
      "gr-qc",
      "hep-ph",
      "math-ph",
      "math.MP"
    ],
    "url": "http://arxiv.org/abs/1106.6327v3"
  },
  {
    "title": "Unproceedings of the Fourth .Astronomy Conference (.Astronomy 4), Heidelberg, Germany, July 9-11 2012",
    "authors": [
      "Robert J. Simpson",
      "Chris Lintott",
      "Amanda Bauer",
      "Bruce Berriman",
      "Edward Gomez",
      "Sarah Kendrew",
      "Thomas Kitching",
      "August Muench",
      "Demitri Muna",
      "Thomas Robitaille",
      "Megan E. Schwamb",
      "Brooke Simmons"
    ],
    "abstract": "The goal of the .Astronomy conference series is to bring together astronomers, educators, developers and others interested in using the Internet as a medium for astronomy. Attendance at the event is limited to approximately 50 participants, and days are split into mornings of scheduled talks, followed by 'unconference' afternoons, where sessions are defined by participants during the course of the event. Participants in unconference sessions are discouraged from formal presentations, with discussion, workshop-style formats or informal practical tutorials encouraged. The conference also designates one day as a 'hack day', in which attendees collaborate in groups on day-long projects for presentation the following morning. These hacks are often a way of concentrating effort, learning new skills, and exploring ideas in a practical fashion. The emphasis on informal, focused interaction makes recording proceedings more difficult than for a normal meeting. While the first .Astronomy conference is preserved formally in a book, more recent iterations are not documented. We therefore, in the spirit of .Astronomy, report 'unproceedings' from .Astronomy 4, which was held in Heidelberg in July 2012.",
    "lastUpdated": "2013-01-16T21:00:07Z",
    "categories": [
      "astro-ph.IM"
    ],
    "url": "http://arxiv.org/abs/1301.5193v1"
  },
  {
    "title": "Analysis of Increasing Malwares and Cyber Crimes Using Economic Approach",
    "authors": [
      "Umer Asgher",
      "Fahad Moazzam Dar",
      "Ali Hamza",
      "Abdul Moeed Paracha"
    ],
    "abstract": "The economics of an internet crime has newly developed into a field of controlling black money. This economic approach not only provides estimated technique of analyzing internet crimes but also gives details to analyzers of system dependability and divergence. This paper will highlight on the subject of online crime, which has formed its industry since. It all started from amateur hackers who cracked websites and wrote malicious software in pursuit of fun or achieving limited objectives to professional hacking. In the past days, electronic fraud was main objective but now it has been changed into electronic hacking. This study focuses the issue through an economic analysis of available web forum to deals in malware and private information. The findings of this survey research provide considerable in-depth sight into the functions of malware economy spinning around computer impositions and compromise. In this regard, the survey research paper may benefit particularly computer security officials, the law enforcement agencies, and in general prospective anyone involved in better understanding cybercrime from the offender standpoint.",
    "lastUpdated": "2014-01-21T05:17:18Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1401.5178v1"
  },
  {
    "title": "Classification of Rank 2 Cluster Varieties",
    "authors": [
      "Travis Mandel"
    ],
    "abstract": "We classify rank $2$ cluster varieties (those for which the span of the rows of the exchange matrix is $2$-dimensional) according to the deformation type of a generic fiber $U$ of their ${\\mathcal X}$-spaces, as defined by Fock and Goncharov [Ann. Sci. \\'Ec. Norm. Sup\\'er. (4) 42 (2009), 865-930]. Our approach is based on the work of Gross, Hacking, and Keel for cluster varieties and log Calabi-Yau surfaces. Call $U$ positive if $\\dim[\\Gamma(U,{\\mathcal O}_U)] = \\dim(U)$ (which equals 2 in these rank 2 cases). This is the condition for the Gross-Hacking-Keel construction [Publ. Math. Inst. Hautes \\'Etudes Sci. 122 (2015), 65-168] to produce an additive basis of theta functions on $\\Gamma(U,{\\mathcal O}_U)$. We find that $U$ is positive and either finite-type or non-acyclic (in the usual cluster sense) if and only if the inverse monodromy of the tropicalization $U^{\\rm trop}$ of $U$ is one of Kodaira's monodromies. In these cases we prove uniqueness results about the log Calabi-Yau surfaces whose tropicalization is $U^{\\rm trop}$. We also describe the action of the cluster modular group on $U^{\\rm trop}$ in the positive cases.",
    "lastUpdated": "2019-05-27T19:19:27Z",
    "categories": [
      "math.AG",
      "13F60, 14J32"
    ],
    "url": "http://arxiv.org/abs/1407.6241v5"
  },
  {
    "title": "SClib, a hack for straightforward embedded C functions in Python",
    "authors": [
      "Esteban Fuentes",
      "Hector E. Martinez"
    ],
    "abstract": "We present SClib, a simple hack that allows easy and straightforward evaluation of C functions within Python code, boosting flexibility for better trade-off between computation power and feature availability, such as visualization and existing computation routines in SciPy. We also present two cases were SClib has been used. In the first set of applications we use SClib to write a port to Python of a Schr\\\"odinger equation solver that has been extensively used the literature, the resulting script presents a speed-up of about 150x with respect to the original one. A review of the situations where the speeded-up script has been used is presented. We also describe the solution to the related problem of solving a set of coupled Schr\\\"odinger-like equations where SClib is used to implement the speed-critical parts of the code. We argue that when using SClib within IPython we can use NumPy and Matplotlib for the manipulation and visualization of the solutions in an interactive environment with no performance compromise. The second case is an engineering application. We use SClib to evaluate the control and system derivatives in a feedback control loop for electrical motors. With this and the integration routines available in SciPy, we can run simulations of the control loop a la Simulink. The use of C code not only boosts the speed of the simulations, but also enables to test the exact same code that we use in the test rig to get experimental results. Again, integration with IPython gives us the flexibility to analyze and visualize the data.",
    "lastUpdated": "2014-12-19T15:51:21Z",
    "categories": [
      "cs.MS",
      "physics.comp-ph"
    ],
    "url": "http://arxiv.org/abs/1412.6395v1"
  },
  {
    "title": "Experimental measurement-device-independent quantum key distribution",
    "authors": [
      "Yang Liu",
      "Teng-Yun Chen",
      "Liu-Jun Wang",
      "Hao Liang",
      "Guo-Liang Shentu",
      "Jian Wang",
      "Ke Cui",
      "Hua-Lei Yin",
      "Nai-Le Liu",
      "Li Li",
      "Xiongfeng Ma",
      "Jason S. Pelc",
      "M. M. Fejer",
      "Qiang Zhang",
      "Jian-Wei Pan"
    ],
    "abstract": "Throughout history, every advance in encryption has been defeated by advances in hacking with severe consequences. Quantum cryptography holds the promise to end this battle by offering unconditional security when ideal single-photon sources and detectors are employed. Unfortunately, ideal devices never exist in practice and device imperfections have become the targets of various attacks. By developing up-conversion single-photon detectors with high efficiency and low noise, we build up a measurement-device-independent quantum key distribution (MDI-QKD) system, which is immune to all hacking strategies on detection. Meanwhile, we employ the decoy-state method to defeat attacks on non-ideal source. By closing the loopholes in both source and detection, our practical system, which generates more than 25 kbit secure key over a 50-km fiber link, provides an ultimate solution for communication security.",
    "lastUpdated": "2012-09-27T10:05:13Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/1209.6178v1"
  },
  {
    "title": "Darknet and Deepnet Mining for Proactive Cybersecurity Threat Intelligence",
    "authors": [
      "Eric Nunes",
      "Ahmad Diab",
      "Andrew Gunn",
      "Ericsson Marin",
      "Vineet Mishra",
      "Vivin Paliath",
      "John Robertson",
      "Jana Shakarian",
      "Amanda Thart",
      "Paulo Shakarian"
    ],
    "abstract": "In this paper, we present an operational system for cyber threat intelligence gathering from various social platforms on the Internet particularly sites on the darknet and deepnet. We focus our attention to collecting information from hacker forum discussions and marketplaces offering products and services focusing on malicious hacking. We have developed an operational system for obtaining information from these sites for the purposes of identifying emerging cyber threats. Currently, this system collects on average 305 high-quality cyber threat warnings each week. These threat warnings include information on newly developed malware and exploits that have not yet been deployed in a cyber-attack. This provides a significant service to cyber-defenders. The system is significantly augmented through the use of various data mining and machine learning techniques. With the use of machine learning models, we are able to recall 92% of products in marketplaces and 80% of discussions on forums relating to malicious hacking with high precision. We perform preliminary analysis on the data collected, demonstrating its application to aid a security expert for better threat analysis.",
    "lastUpdated": "2016-07-28T19:30:04Z",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1607.08583v1"
  },
  {
    "title": "Hacking Smart Machines with Smarter Ones: How to Extract Meaningful Data from Machine Learning Classifiers",
    "authors": [
      "Giuseppe Ateniese",
      "Giovanni Felici",
      "Luigi V. Mancini",
      "Angelo Spognardi",
      "Antonio Villani",
      "Domenico Vitali"
    ],
    "abstract": "Machine Learning (ML) algorithms are used to train computers to perform a variety of complex tasks and improve with experience. Computers learn how to recognize patterns, make unintended decisions, or react to a dynamic environment. Certain trained machines may be more effective than others because they are based on more suitable ML algorithms or because they were trained through superior training sets. Although ML algorithms are known and publicly released, training sets may not be reasonably ascertainable and, indeed, may be guarded as trade secrets. While much research has been performed about the privacy of the elements of training sets, in this paper we focus our attention on ML classifiers and on the statistical information that can be unconsciously or maliciously revealed from them. We show that it is possible to infer unexpected but useful information from ML classifiers. In particular, we build a novel meta-classifier and train it to hack other classifiers, obtaining meaningful information about their training sets. This kind of information leakage can be exploited, for example, by a vendor to build more effective classifiers or to simply acquire trade secrets from a competitor's apparatus, potentially violating its intellectual property rights.",
    "lastUpdated": "2013-06-19T07:51:49Z",
    "categories": [
      "cs.CR",
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1306.4447v1"
  },
  {
    "title": "Cosmological Applications of Algebraic Quantum Field Theory in Curved Spacetimes",
    "authors": [
      "Thomas-Paul Hack"
    ],
    "abstract": "This monograph provides a largely self--contained and broadly accessible exposition of two cosmological applications of algebraic quantum field theory (QFT) in curved spacetime: a fundamental analysis of the cosmological evolution according to the Standard Model of Cosmology and a fundamental study of the perturbations in Inflation. The two central sections of the book dealing with these applications are preceded by sections containing a pedagogical introduction to the subject as well as introductory material on the construction of linear QFTs on general curved spacetimes with and without gauge symmetry in the algebraic approach, physically meaningful quantum states on general curved spacetimes, and the backreaction of quantum fields in curved spacetimes via the semiclassical Einstein equation. The target reader should have a basic understanding of General Relativity and QFT on Minkowski spacetime, but does not need to have a background in QFT on curved spacetimes or the algebraic approach to QFT. In particular, I took a great deal of care to provide a thorough motivation for all concepts of algebraic QFT touched upon in this monograph, as they partly may seem rather abstract at first glance. Thus, it is my hope that this work can help non--experts to make `first contact' with the algebraic approach to QFT.",
    "lastUpdated": "2015-06-05T11:27:33Z",
    "categories": [
      "gr-qc",
      "hep-th",
      "math-ph",
      "math.MP",
      "81T20"
    ],
    "url": "http://arxiv.org/abs/1506.01869v1"
  },
  {
    "title": "Safeguarding Quantum Key Distribution through Detection Randomization",
    "authors": [
      "Thiago Ferreira da Silva",
      "Gustavo C. do Amaral",
      "Guilherme B. Xavier",
      "Guilherme P. Temporão",
      "Jean Pierre von der Weid"
    ],
    "abstract": "We propose and experimentally demonstrate a scheme to render the detection apparatus of a Quantum Key Distribution system immune to the main classes of hacking attacks in which the eavesdropper explores the back-door opened by the single-photon detectors. The countermeasure is based on the creation of modes that are not deterministically accessible to the eavesdropper. We experimentally show that the use of beamsplitters and extra single-photon detectors at the receiver station passively creates randomized spatial modes that erase any knowledge the eavesdropper might have gained when using bright-light faked states. Additionally, we experimentally show a detector-scrambling approach where the random selection of the detector used for each measurement - equivalent to an active spatial mode randomization - hashes out the side-channel open by the detection efficiency mismatch-based attacks. The proposed combined countermeasure represents a practical and readily implementable solution against the main classes of quantum hacking attacks aimed on the single-photon detector so far, without intervening on the inner working of the devices.",
    "lastUpdated": "2014-10-02T20:15:26Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/1410.0701v1"
  },
  {
    "title": "The generalised principle of perturbative agreement and the thermal mass",
    "authors": [
      "Nicolò Drago",
      "Thomas-Paul Hack",
      "Nicola Pinamonti"
    ],
    "abstract": "The Principle of Perturbative Agreement, as introduced by Hollands & Wald, is a renormalisation condition in quantum field theory on curved spacetimes. This principle states that the perturbative and exact constructions of a field theoretic model given by the sum of a free and an exactly tractable interaction Lagrangean should agree. We develop a proof of the validity of this principle in the case of scalar fields and quadratic interactions without derivatives which differs in strategy from the one given by Hollands & Wald for the case of quadratic interactions encoding a change of metric. Thereby we profit from the observation that, in the case of quadratic interactions, the composition of the inverse classical M{\\o}ller map and the quantum M{\\o}ller map is a contraction exponential of a particular type. Afterwards, we prove a generalisation of the Principle of Perturbative Agreement and show that considering an arbitrary quadratic contribution of a general interaction either as part of the free theory or as part of the perturbation gives equivalent results. Motivated by the thermal mass idea, we use our findings in order to extend the construction of massive interacting thermal equilibrium states in Minkowski spacetime developed by Fredenhagen & Lindner to the massless case. In passing, we also prove a property of the construction of Fredenhagen & Lindner which was conjectured by these authors.",
    "lastUpdated": "2015-07-01T09:25:55Z",
    "categories": [
      "math-ph",
      "math.MP"
    ],
    "url": "http://arxiv.org/abs/1502.02705v3"
  },
  {
    "title": "A Short Note on P-Value Hacking",
    "authors": [
      "Nassim Nicholas Taleb"
    ],
    "abstract": "We present the expected values from p-value hacking as a choice of the minimum p-value among $m$ independents tests, which can be considerably lower than the \"true\" p-value, even with a single trial, owing to the extreme skewness of the meta-distribution. We first present an exact probability distribution (meta-distribution) for p-values across ensembles of statistically identical phenomena. We derive the distribution for small samples $2<n \\leq n^*\\approx 30$ as well as the limiting one as the sample size $n$ becomes large. We also look at the properties of the \"power\" of a test through the distribution of its inverse for a given p-value and parametrization. The formulas allow the investigation of the stability of the reproduction of results and \"p-hacking\" and other aspects of meta-analysis. P-values are shown to be extremely skewed and volatile, regardless of the sample size $n$, and vary greatly across repetitions of exactly same protocols under identical stochastic copies of the phenomenon; such volatility makes the minimum $p$ value diverge significantly from the \"true\" one. Setting the power is shown to offer little remedy unless sample size is increased markedly or the p-value is lowered by at least one order of magnitude.",
    "lastUpdated": "2018-01-25T20:15:34Z",
    "categories": [
      "stat.AP",
      "q-fin.ST"
    ],
    "url": "http://arxiv.org/abs/1603.07532v4"
  },
  {
    "title": "Attributing Hacks",
    "authors": [
      "Ziqi Liu",
      "Alexander J. Smola",
      "Kyle Soska",
      "Yu-Xiang Wang",
      "Qinghua Zheng",
      "Jun Zhou"
    ],
    "abstract": "In this paper we describe an algorithm for estimating the provenance of hacks on websites. That is, given properties of sites and the temporal occurrence of attacks, we are able to attribute individual attacks to joint causes and vulnerabilities, as well as estimating the evolution of these vulnerabilities over time. Specifically, we use hazard regression with a time-varying additive hazard function parameterized in a generalized linear form. The activation coefficients on each feature are continuous-time functions over time. We formulate the problem of learning these functions as a constrained variational maximum likelihood estimation problem with total variation penalty and show that the optimal solution is a 0th order spline (a piecewise constant function) with a finite number of known knots. This allows the inference problem to be solved efficiently and at scale by solving a finite dimensional optimization problem. Extensive experiments on real data sets show that our method significantly outperforms Cox's proportional hazard model. We also conduct a case study and verify that the fitted functions are indeed recovering vulnerable features and real-life events such as the release of code to exploit these features in hacker blogs.",
    "lastUpdated": "2017-08-14T18:25:34Z",
    "categories": [
      "cs.LG",
      "cs.CR",
      "stat.AP"
    ],
    "url": "http://arxiv.org/abs/1611.03021v2"
  },
  {
    "title": "Collective behavior and emergent risks in a model of human- and autonomously-driven vehicles",
    "authors": [
      "Skanda Vivek",
      "David Yanni",
      "Peter J. Yunker",
      "Jesse L. Silverberg"
    ],
    "abstract": "While much effort has been invested in studies of traffic flow as a physics problem, two emerging trends in technology have broadened the subject for new investigations. The first trend is the development of self-driving vehicles. This highly-anticipated shift from human- to autonomous-drivers is expected to offer substantial benefits for traffic throughput by streamlining large-scale collective behavior. The second trend is the widespread hacking of Internet-connected devices, which as of 2015, includes vehicles. While the first proof-of-concept automobile hack was done at the single-vehicle scale, undesirable collective effects can easily arise if this activity becomes more common. Motivated by these two trends, we explore the phenomena that arise in an active matter model with lanes and lane-changing behavior. Our model incorporates a simplified minimal description of essential differences between human- and autonomous-drivers. We study the emergent collective behavior as the population of vehicles shifts from all-human to all-autonomous. Within the context of our model, we explore a worst-case scenario where Internet-connected autonomous vehicles are disabled simultaneously and \\textit{en masse}. Our approach reveals a model-independent role for percolation in interpreting the results. A broad lesson our work highlights is that seemingly minor malicious activity can ultimately have major impacts when magnified through the action of collective behavior.",
    "lastUpdated": "2018-03-06T07:52:45Z",
    "categories": [
      "physics.soc-ph",
      "nlin.AO"
    ],
    "url": "http://arxiv.org/abs/1708.03791v2"
  },
  {
    "title": "Vehicle Security: Risk Assessment in Transportation",
    "authors": [
      "Kaveh Bakhsh Kelarestaghi",
      "Mahsa Foruhandeh",
      "Kevin Heaslip",
      "Ryan Gerdes"
    ],
    "abstract": "Intelligent Transportation Systems (ITS) are critical infrastructure that are not immune to both physical and cyber threats. Vehicles are cyber/physical systems which are a core component of ITS, can be either a target or a launching point for an attack on the ITS network. Unknown vehicle security vulnerabilities trigger a race among adversaries to exploit the weaknesses and security experts to mitigate the vulnerability. In this study, we identified opportunities for adversaries to take control of the in-vehicle network, which can compromise the safety, privacy, reliability, efficiency, and security of the transportation system. This study contributes in three ways to the literature of ITS security and resiliency. First, we aggregate individual risks that are associated with hacking the in-vehicle network to determine system-level risk. Second, we employ a risk-based model to conduct a qualitative vulnerability-oriented risk assessment. Third, we identify the consequences of hacking the in-vehicle network through a risk-based approach, using an impact-likelihood matrix. The qualitative assessment communicates risk outcomes for policy analysis. The outcome of this study would be of interest and usefulness to policymakers and engineers concerned with the potential vulnerabilities of the critical infrastructures.",
    "lastUpdated": "2018-08-07T18:46:02Z",
    "categories": [
      "cs.CR",
      "cs.SY"
    ],
    "url": "http://arxiv.org/abs/1804.07381v2"
  },
  {
    "title": "Using AI to Hack IA: A New Stealthy Spyware Against Voice Assistance Functions in Smart Phones",
    "authors": [
      "Rongjunchen Zhang",
      "Xiao Chen",
      "Jianchao Lu",
      "Sheng Wen",
      "Surya Nepal",
      "Yang Xiang"
    ],
    "abstract": "Intelligent Personal Assistant (IA), also known as Voice Assistant (VA), has become increasingly popular as a human-computer interaction mechanism. Most smartphones have built-in voice assistants that are granted high privilege, which is able to access system resources and private information. Thus, once the voice assistants are exploited by attackers, they become the stepping stones for the attackers to hack into the smartphones. Prior work shows that the voice assistant can be activated by inter-component communication mechanism, through an official Android API. However, this attack method is only effective on Google Assistant, which is the official voice assistant developed by Google. Voice assistants in other operating systems, even custom Android systems, cannot be activated by this mechanism. Prior work also shows that the attacking voice commands can be inaudible, but it requires additional instruments to launch the attack, making it unrealistic for real-world attack. We propose an attacking framework, which records the activation voice of the user, and launch the attack by playing the activation voice and attack commands via the built-in speaker. An intelligent stealthy module is designed to decide on the suitable occasion to launch the attack, preventing the attack being noticed by the user. We demonstrate proof-of-concept attacks on Google Assistant, showing the feasibility and stealthiness of the proposed attack scheme. We suggest to revise the activation logic of voice assistant to be resilient to the speaker based attack.",
    "lastUpdated": "2018-05-16T08:22:57Z",
    "categories": [
      "cs.CR",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1805.06187v1"
  },
  {
    "title": "Non-equilibrium steady states for the interacting Klein-Gordon field in 1+3 dimensions",
    "authors": [
      "Thomas-Paul Hack",
      "Rainer Verch"
    ],
    "abstract": "Non-equilibrium steady states (NESS) describe particularly simple and stationary non-equilibrium situations. A possibility to obtain such states is to consider the asymptotic evolution of two infinite heat baths brought into thermal contact. In this work we generalise corresponding results of Doyon~et.~al. (J.\\ Phys.\\ A 18 (2015) no.9) for free Klein-Gordon fields in several directions. Our analysis is carried out directly at the level of correlation functions and in the algebraic approach to QFT. We discuss non-trivial chemical potentials, condensates, inhomogeneous linear models and homogeneous interacting ones. We shall not consider a sharp contact at initial time, but a smooth transition region. As a consequence, the states we construct will be of Hadamard type, and thus sufficiently regular for the perturbative treatment of interacting models. Our analysis shows that perturbatively constructed interacting NESS display thermodynamic properties similar to the ones of the NESS in linear models. In particular, perturbation theory appears to be insufficient to describe full thermalisation in non-linear QFT. Notwithstanding, we find that the NESS for linear and interacting models is stable under small perturbations, which is one of the characteristic features of equilibrium states.",
    "lastUpdated": "2018-06-01T18:36:38Z",
    "categories": [
      "math-ph",
      "cond-mat.stat-mech",
      "hep-th",
      "math.MP",
      "82C10, 81T28"
    ],
    "url": "http://arxiv.org/abs/1806.00504v1"
  },
  {
    "title": "The Second Amendment and Cyber Weapons - The Constitutional Relevance of Digital Gun Rights",
    "authors": [
      "Jan Kallberg"
    ],
    "abstract": "In the future, the United States government can seek to limit the ownership and usage of cyber weapons. The question is whether the Second Amendment to the United States Constitution gives a right to bear and own military-grade cyber weapons, and if so, under which conditions. The framers of the Bill of Rights, ratified in 1791, did not limit the right to bear arms to defined weapons such as long rifles and pistols, but instead chose the broader word arms. The United States Supreme Court, in the case District of Columbia v. Heller, upheld a demarcation between dangerous and unusual weapons that are not permissible to own and weapons protected by the Second Amendment. Cyber weapons take the form of dual-use software, often shared and globally distributed that in most cases can be weaponized for harmful purposes. In recent years, major corporations have sought to hack back, and if the hack back is authorized, the question becomes whether corporations have digital gun rights. Even if corporations are considered US persons, they do not automatically obtain digital gun rights based on the Second Amendment. This article discusses the core constitutional challenges for the United States government in prohibiting individual ownership of cyber weapons and the rationale for why corporations are in a weaker position regarding ownership of cyber arms. The argument brought forward is that individuals can claim Second Amendment protection of their right to own military-grade software tools, but corporations must meet additional criteria to do so.",
    "lastUpdated": "2018-08-02T02:03:39Z",
    "categories": [
      "cs.CY",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1807.11041v2"
  },
  {
    "title": "Toric degenerations of cluster varieties and cluster duality",
    "authors": [
      "Lara Bossinger",
      "Bosco Frías-Medina",
      "Timothy Magee",
      "Alfredo Nájera Chávez"
    ],
    "abstract": "We introduce the notion of a $Y$-pattern with coefficients and its geometric counterpart: a cluster $\\mathcal{X}$-variety with coefficients. We use these constructions to build a flat degeneration of every skew-symmetrizable specially completed cluster $\\mathcal{X}$-variety $\\widehat{\\mathcal{X}}$ to the toric variety associated to its $\\mathbf{g}$-fan. Moreover, we show that the fibers of this family are stratified in a natural way, with strata the specially completed $\\mathcal{X}$-varieties encoded by $\\mathrm{Star}(\\tau)$ for each cone $\\tau$ of the $\\mathbf{g}$-fan. These strata degenerate to the associated toric strata of the central fiber. We further show that the family is cluster dual to $\\mathcal{A}_{\\mathrm{prin}}$ of Gross-Hacking-Keel-Kontsevich, and the fibers cluster dual to $\\mathcal{A}_t$. Finally, we give two applications. First, we use our construction to identify the Rietsch-Williams toric degeneration of Grassmannians with the Gross-Hacking-Keel-Kontsevich degeneration in the case of $\\mathrm{Gr}_2(\\mathbb{C}^5)$. Next, we use it to link cluster duality to Batyrev-Borisov duality of Gorenstein toric Fanos in the context of mirror symmetry.",
    "lastUpdated": "2020-11-02T20:43:18Z",
    "categories": [
      "math.AG",
      "math.CO",
      "math.RA",
      "math.RT",
      "13F60, 14M25, 14D06"
    ],
    "url": "http://arxiv.org/abs/1809.08369v4"
  },
  {
    "title": "\"Cartesian light\": unconventional propagation of light in a 3D superlattice of coupled cavities within a 3D photonic band gap",
    "authors": [
      "Sjoerd A. Hack",
      "Jaap J. W. van der Vegt",
      "Willem L. Vos"
    ],
    "abstract": "We explore the unconventional propagation of light in a three-dimensional (3D) superlattice of coupled resonant cavities in a 3D photonic band gap crystal. Such a 3D cavity superlattice is the photonic analogue of the Anderson model for spins and electrons in the limit of zero disorder. Using the plane-wave expansion method, we calculate the dispersion relations of the 3D cavity superlattice with the cubic inverse woodpile structure that reveal five coupled-cavity bands, typical of quadrupole-like resonances. For three out of five bands, we observe that the dispersion bandwidth is significantly larger in the $(k_x, k_z)$-diagonal directions than in other directions. To explain the directionality of the dispersion bandwidth, we employ the tight-binding method from which we derive coupling coefficients in 3D. For all converged coupled-cavity bands, we find that light hops predominantly in a few high-symmetry directions including the Cartesian $(x, y, z)$ directions, therefore we propose the name \"Cartesian light\". Such 3D Cartesian hopping of light in a band gap yields propagation as superlattice Bloch modes that differ fundamentally from the conventional 3D spatially-extended Bloch wave propagation in crystals, from light tunneling through a band gap, from coupled-resonator optical waveguiding, and also from light diffusing at the edge of a gap.",
    "lastUpdated": "2018-12-11T15:40:51Z",
    "categories": [
      "physics.optics",
      "cond-mat.mes-hall"
    ],
    "url": "http://arxiv.org/abs/1812.04472v1"
  },
  {
    "title": "A universal approach for drainage basins",
    "authors": [
      "Erneson A. Oliveira",
      "Rilder S. Pires",
      "Rubens S. Oliveira",
      "Vasco Furtado",
      "Hans J. Herrmann",
      "José S. Andrade Jr"
    ],
    "abstract": "Drainage basins are essential to Geohydrology and Biodiversity. Defining those regions in a simple, robust and efficient way is a constant challenge in Earth Science. Here, we introduce a model to delineate multiple drainage basins through an extension of the Invasion Percolation-Based Algorithm (IPBA). In order to prove the potential of our approach, we apply it to real and artificial datasets. We observe that the perimeter and area distributions of basins and anti-basins display long tails extending over several orders of magnitude and following approximately power-law behaviors. Moreover, the exponents of these power laws depend on spatial correlations and are invariant under the landscape orientation, not only for terrestrial, but lunar and martian landscapes. The terrestrial and martian results are statistically identical, which suggests that a hypothetical martian river would present similarity to the terrestrial rivers. Finally, we propose a theoretical value for the Hack's exponent based on the fractal dimension of watersheds, $\\gamma=D/2$. We measure $\\gamma=0.54 \\pm 0.01$ for Earth, which is close to our estimation of $\\gamma \\approx 0.55$. Our study suggests that Hack's law can have its origin purely in the maximum and minimum lines of the landscapes.",
    "lastUpdated": "2019-07-08T18:30:28Z",
    "categories": [
      "physics.comp-ph"
    ],
    "url": "http://arxiv.org/abs/1812.08737v2"
  },
  {
    "title": "Data breaches in the catastrophe framework & beyond",
    "authors": [
      "Spencer Wheatley",
      "Annette Hofmann",
      "Didier Sornette"
    ],
    "abstract": "Development of sustainable insurance for cyber risks, with associated benefits, inter alia requires reduction of ambiguity of the risk. Considering cyber risk, and data breaches in particular, as a man-made catastrophe clarifies the actuarial need for multiple levels of analysis - going beyond claims-driven loss statistics alone to include exposure, hazard, breach size, and so on - and necessitating specific advances in scope, quality, and standards of both data and models. The prominent human element, as well as dynamic, networked, and multi-type nature, of cyber risk makes it perhaps uniquely challenging. Complementary top-down statistical, and bottom-up analytical approaches are discussed. Focusing on data breach severity, measured in private information items ('ids') extracted, we exploit relatively mature open data for U.S. data breaches. We show that this extremely heavy-tailed risk is worsening for external attacker ('hack') events - both in frequency and severity. Writing in Q2-2018, the median predicted number of ids breached in the U.S. due to hacking, for the last 6 months of 2018, is 0.5 billion. But with a 5% chance that the figure exceeds 7 billion - doubling the historical total. 'Fortunately' the total breach in that period turned out to be near the median.",
    "lastUpdated": "2019-05-16T17:16:47Z",
    "categories": [
      "stat.AP",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1901.00699v2"
  },
  {
    "title": "The 2nd Workshop on Hacking and Making at Time-Bounded Events",
    "authors": [
      "Ei Pa Pa Pe-Than",
      "Alexander Nolte"
    ],
    "abstract": "In hackathons, small teams work together over a specified period of time to complete a project of interest. Such time-bounded hackathon-style events have become increasingly popular across different domains in recent years. Collegiate hackathons, just one of the many variants of hackathons, that are supported by the largest hackathon league (https://mlh.io/) alone attract over 65,000 participants among more than 200 events each year. Variously known as data dives, codefests, hack-days, sprints, edit-a-thons, mapathons, and so on, such events vary depending on different audiences and with divergent aims: for example, whether teams know each other beforehand, whether the event is structured as a competition with prizes, whether the event is open or requires membership or invitations, and whether the desired outcome is primarily a product innovation, learning a new skill, forming a community around a cause, solving a technical problem that requires intensive focus by a group, or just having fun. Taken together, hackathons offer new opportunities and challenges for collaboration by affording explicit, predictable, time-bounded spaces for collaborative work and engaging with new audiences. With the goal of discussing opportunities and challenges surrounding hackathons of different kinds, this one-day workshop brought together researchers, experienced event organizers, and practitioners to share and discuss their practical experiences. Empirical insights from studying these events may help position the CHI community to better study, plan and design hackathon-style events as socio-technical systems that support new modes of production and collaboration.",
    "lastUpdated": "2019-01-03T19:50:57Z",
    "categories": [
      "cs.CY",
      "cs.SE",
      "physics.ed-ph",
      "H.5.3; H.1.2"
    ],
    "url": "http://arxiv.org/abs/1901.02710v1"
  },
  {
    "title": "Dirac Metamaterial Assembled by Pyrene Derivative and its Topological Photonics",
    "authors": [
      "Kyoung Hwan Choi",
      "Da Young Hwang",
      "Dong Hack Suh"
    ],
    "abstract": "Over the past decade, topology has garnered great attention in a wide area of physics. In particular, it has exerted influence on photonics because carefully engineered photonic crystals and metamaterials can help explore the non-trivial state of materials. In this regard, all dielectric metamaterials with large anisotropy, and dipole and multipole Mie resonators have played an increasingly important role in topological photonics. Advantages of Mie resonators make it possible to quest for non-trivial states in three dimensions and theoretical calculation supports its potential. However, it is very difficult to demonstrate this experimentally because it is hard to make the metacrystal by anisotropic meta-atoms despite much effort. Here we report a Dirac metamaterial for 3D topological photonics. It is implemented by a metacrystal self-assembled by a molecule, HYLION-12 which has both anisotropic polarizability and ring current. As its peculiar properties, it has an exotic optical constant that can be used for the electric and magnetic hyperbolic metamaterial, and the double hyperbolic metamaterial in the ultraviolet region. It also showed 142% of reflectance at 242nm as an amplified reflector and asymmetric transmittance up to 30% through the opaque substrate as a Huygens source under 300nm. Furthermore, it demonstrated various phenomena of topological photonics such as Pancharatnam-Berry and waveguide phase merging, wavefront shaping and waveguide on edges as a 3D topological photonic material. The new strategy using polyaromatic hydrocarbons (PAHs) is expected to be an effective way to realize 3D topological photonics.",
    "lastUpdated": "2021-01-12T09:13:53Z",
    "categories": [
      "physics.optics",
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci",
      "cond-mat.other"
    ],
    "url": "http://arxiv.org/abs/2101.04359v1"
  },
  {
    "title": "Backward Causation, Isolation and the Pursuit of Justice",
    "authors": [
      "Milan M. Cirkovic",
      "Suzana Cveticanin"
    ],
    "abstract": "The recent operationalization of the famous Newcomb's game by Schmidt (1998) offers an interesting and thought-provoking look at the plausibility of backward causation in a Newtonian universe. Hereby we investigate two details of the Schmidt's scenario which may, at least in principle, invalidate his conclusion in two different domains: one dealing with the issue of Newtonian predictability in specific instance of human actions, and the other stemming from a possible strategy aimed at obviating the anthropically oriented view of backward causation as applied to a judicial and ethical problem posed by a version of the scenario. We conclude that the scenario is at least to be more complex than originally presented in order to remain viable. However, it points to a very deep and delicate question of compatibility of backward causation with the conventional ethical standards.",
    "lastUpdated": "2001-07-13T13:51:13Z",
    "categories": [
      "physics.class-ph"
    ],
    "url": "http://arxiv.org/abs/physics/0107028v1"
  },
  {
    "title": "Should there be more women in science and engineering?",
    "authors": [
      "Mathieu Bouville"
    ],
    "abstract": "Many people hold this truth to be self-evident, that there should be more female students in science and engineering. Typical arguments include possible benefits to women, possible benefits to the economy, and the unfairness of the current female under-representation. However, these justifications are never explicitly and thoroughly presented. Clearly stating and scrutinizing them, we show that they in fact have logical flaws. When made consistent, these arguments do not unconditionally justify enrolling more women in scientific disciplines. In particular, what women want must be taken into account. Outreach programs towards K-12 girls must therefore purport to allow them to choose a field freely, rather than try to draw as many of them to scientific disciplines as possible. This change of mindset must be accompanied by a close examination of the purpose and effects of these programs. Keywords: female students, higher education, university, ethics, policy, outreach programs, minority students",
    "lastUpdated": "2007-03-27T09:04:19Z",
    "categories": [
      "physics.soc-ph",
      "physics.ed-ph"
    ],
    "url": "http://arxiv.org/abs/physics/0611089v3"
  },
  {
    "title": "Handling Covariates in the Design of Clinical Trials",
    "authors": [
      "William F. Rosenberger",
      "Oleksandr Sverdlov"
    ],
    "abstract": "There has been a split in the statistics community about the need for taking covariates into account in the design phase of a clinical trial. There are many advocates of using stratification and covariate-adaptive randomization to promote balance on certain known covariates. However, balance does not always promote efficiency or ensure more patients are assigned to the better treatment. We describe these procedures, including model-based procedures, for incorporating covariates into the design of clinical trials, and give examples where balance, efficiency and ethical considerations may be in conflict. We advocate a new class of procedures, covariate-adjusted response-adaptive (CARA) randomization procedures that attempt to optimize both efficiency and ethical considerations, while maintaining randomization. We review all these procedures, present a few new simulation studies, and conclude with our philosophy.",
    "lastUpdated": "2011-02-18T07:58:49Z",
    "categories": [
      "stat.ME"
    ],
    "url": "http://arxiv.org/abs/1102.3773v1"
  },
  {
    "title": "Multi-objective optimal designs in comparative clinical trials with covariates: The reinforced doubly adaptive biased coin design",
    "authors": [
      "Alessandro Baldi Antognini",
      "Maroussa Zagoraiou"
    ],
    "abstract": "The present paper deals with the problem of allocating patients to two competing treatments in the presence of covariates or prognostic factors in order to achieve a good trade-off among ethical concerns, inferential precision and randomness in the treatment allocations. In particular we suggest a multipurpose design methodology that combines efficiency and ethical gain when the linear homoscedastic model with both treatment/covariate interactions and interactions among covariates is adopted. The ensuing compound optimal allocations of the treatments depend on the covariates and their distribution on the population of interest, as well as on the unknown parameters of the model. Therefore, we introduce the reinforced doubly adaptive biased coin design, namely a general class of covariate-adjusted response-adaptive procedures that includes both continuous and discontinuous randomization functions, aimed to target any desired allocation proportion. The properties of this proposal are described both theoretically and through simulations.",
    "lastUpdated": "2012-08-16T11:02:41Z",
    "categories": [
      "stat.ME",
      "math.ST",
      "stat.TH"
    ],
    "url": "http://arxiv.org/abs/1206.0576v2"
  },
  {
    "title": "Universal Empathy and Ethical Bias for Artificial General Intelligence",
    "authors": [
      "Alexey Potapov",
      "Sergey Rodionov"
    ],
    "abstract": "Rational agents are usually built to maximize rewards. However, AGI agents can find undesirable ways of maximizing any prior reward function. Therefore value learning is crucial for safe AGI. We assume that generalized states of the world are valuable - not rewards themselves, and propose an extension of AIXI, in which rewards are used only to bootstrap hierarchical value learning. The modified AIXI agent is considered in the multi-agent environment, where other agents can be either humans or other \"mature\" agents, which values should be revealed and adopted by the \"infant\" AGI agent. General framework for designing such empathic agent with ethical bias is proposed also as an extension of the universal intelligence model. Moreover, we perform experiments in the simple Markov environment, which demonstrate feasibility of our approach to value learning in safe AGI.",
    "lastUpdated": "2013-08-03T14:40:36Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1308.0702v1"
  },
  {
    "title": "Wrong side of the tracks: Big Data and Protected Categories",
    "authors": [
      "Simon DeDeo"
    ],
    "abstract": "When we use machine learning for public policy, we find that many useful variables are associated with others on which it would be ethically problematic to base decisions. This problem becomes particularly acute in the Big Data era, when predictions are often made in the absence of strong theories for underlying causal mechanisms. We describe the dangers to democratic decision-making when high-performance algorithms fail to provide an explicit account of causation. We then demonstrate how information theory allows us to degrade predictions so that they decorrelate from protected variables with minimal loss of accuracy. Enforcing total decorrelation is at best a near-term solution, however. The role of causal argument in ethical debate urges the development of new, interpretable machine-learning algorithms that reference causal mechanisms.",
    "lastUpdated": "2016-06-24T02:14:48Z",
    "categories": [
      "cs.IT",
      "cs.CY",
      "math.IT",
      "physics.soc-ph",
      "stat.ME"
    ],
    "url": "http://arxiv.org/abs/1412.4643v3"
  },
  {
    "title": "Is it morally acceptable for a system to lie to persuade me?",
    "authors": [
      "Marco Guerini",
      "Fabio Pianesi",
      "Oliviero Stock"
    ],
    "abstract": "Given the fast rise of increasingly autonomous artificial agents and robots, a key acceptability criterion will be the possible moral implications of their actions. In particular, intelligent persuasive systems (systems designed to influence humans via communication) constitute a highly sensitive topic because of their intrinsically social nature. Still, ethical studies in this area are rare and tend to focus on the output of the required action. Instead, this work focuses on the persuasive acts themselves (e.g. \"is it morally acceptable that a machine lies or appeals to the emotions of a person to persuade her, even if for a good end?\"). Exploiting a behavioral approach, based on human assessment of moral dilemmas -- i.e. without any prior assumption of underlying ethical theories -- this paper reports on a set of experiments. These experiments address the type of persuader (human or machine), the strategies adopted (purely argumentative, appeal to positive emotions, appeal to negative emotions, lie) and the circumstances. Findings display no differences due to the agent, mild acceptability for persuasion and reveal that truth-conditional reasoning (i.e. argument validity) is a significant dimension affecting subjects' judgment. Some implications for the design of intelligent persuasive systems are discussed.",
    "lastUpdated": "2014-04-15T15:41:34Z",
    "categories": [
      "cs.CY",
      "cs.CL"
    ],
    "url": "http://arxiv.org/abs/1404.3959v1"
  },
  {
    "title": "Logical Limitations to Machine Ethics with Consequences to Lethal Autonomous Weapons",
    "authors": [
      "Matthias Englert",
      "Sandra Siebert",
      "Martin Ziegler"
    ],
    "abstract": "Lethal Autonomous Weapons promise to revolutionize warfare -- and raise a multitude of ethical and legal questions. It has thus been suggested to program values and principles of conduct (such as the Geneva Conventions) into the machines' control, thereby rendering them both physically and morally superior to human combatants. We employ mathematical logic and theoretical computer science to explore fundamental limitations to the moral behaviour of intelligent machines in a series of \"Gedankenexperiments\": Refining and sharpening variants of the Trolley Problem leads us to construct an (admittedly artificial but) fully deterministic situation where a robot is presented with two choices: one morally clearly preferable over the other -- yet, based on the undecidability of the Halting problem, it provably cannot decide algorithmically which one. Our considerations have surprising implications to the question of responsibility and liability for an autonomous system's actions and lead to specific technical recommendations.",
    "lastUpdated": "2014-11-11T15:05:01Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "K.4.1; I.2.0"
    ],
    "url": "http://arxiv.org/abs/1411.2842v1"
  },
  {
    "title": "Ethics of autonomous information systems towards an artificial thinking",
    "authors": [
      "Joël Colloc"
    ],
    "abstract": "Many projects relies on cognitives sciences, neurosciences, computer sciences and robotics. They concerned today the building of autonomous artificial beings able to think. This paper shows a model to compare the human thinking with an hypothetic numerical way of thinking based on four hierarchies : the information system classification, the cognitive pyramid, the linguistic pyramid and the digital information hierarchy. After a state of art on the nature of human thinking, feasibility of autonomous multi-agent systems provided with artificial consciousness which are able to think is discussed. The ethical aspects and consequences for humanity of such systems is evaluated. These systems lead the scientific community to react.",
    "lastUpdated": "2017-07-12T11:44:09Z",
    "categories": [
      "cs.OH"
    ],
    "url": "http://arxiv.org/abs/1707.05259v1"
  },
  {
    "title": "Society-in-the-Loop: Programming the Algorithmic Social Contract",
    "authors": [
      "Iyad Rahwan"
    ],
    "abstract": "Recent rapid advances in Artificial Intelligence (AI) and Machine Learning have raised many questions about the regulatory and governance mechanisms for autonomous machines. Many commentators, scholars, and policy-makers now call for ensuring that algorithms governing our lives are transparent, fair, and accountable. Here, I propose a conceptual framework for the regulation of AI and algorithmic systems. I argue that we need tools to program, debug and maintain an algorithmic social contract, a pact between various human stakeholders, mediated by machines. To achieve this, we can adapt the concept of human-in-the-loop (HITL) from the fields of modeling and simulation, and interactive machine learning. In particular, I propose an agenda I call society-in-the-loop (SITL), which combines the HITL control paradigm with mechanisms for negotiating the values of various stakeholders affected by AI systems, and monitoring compliance with the agreement. In short, `SITL = HITL + Social Contract.'",
    "lastUpdated": "2017-07-26T03:39:40Z",
    "categories": [
      "cs.CY",
      "K.4.1, K.5.2"
    ],
    "url": "http://arxiv.org/abs/1707.07232v2"
  },
  {
    "title": "Friendly Artificial Intelligence: the Physics Challenge",
    "authors": [
      "Max Tegmark"
    ],
    "abstract": "Relentless progress in artificial intelligence (AI) is increasingly raising concerns that machines will replace humans on the job market, and perhaps altogether. Eliezer Yudkowski and others have explored the possibility that a promising future for humankind could be guaranteed by a superintelligent \"Friendly AI\", designed to safeguard humanity and its values. I argue that, from a physics perspective where everything is simply an arrangement of elementary particles, this might be even harder than it appears. Indeed, it may require thinking rigorously about the meaning of life: What is \"meaning\" in a particle arrangement? What is \"life\"? What is the ultimate ethical imperative, i.e., how should we strive to rearrange the particles of our Universe and shape its future? If we fail to answer the last question rigorously, this future is unlikely to contain humans.",
    "lastUpdated": "2014-09-03T15:05:07Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1409.0813v2"
  },
  {
    "title": "Big Data: Opportunities and Privacy Challenges",
    "authors": [
      "Hervais Simo Fhom"
    ],
    "abstract": "Recent advances in data collection and computational statistics coupled with increases in computer processing power, along with the plunging costs of storage are making technologies to effectively analyze large sets of heterogeneous data ubiquitous. Applying such technologies (often referred to as big data technologies) to an ever growing number and variety of internal and external data sources, businesses and institutions can discover hidden correlations between data items, and extract actionable insights needed for innovation and economic growth. While on one hand big data technologies yield great promises, on the other hand, they raise critical security, privacy, and ethical issues, which if left unaddressed may become significant barriers to the fulfillment of expected opportunities and long-term success of big data. In this paper, we discuss the benefits of big data to individuals and society at large, focusing on seven key use cases: Big data for business optimization and customer analytics, big data and science, big data and health care, big data and finance, big data and the emerging energy distribution systems, big/open data as enablers of openness and efficiency in government, and big data security. In addition to benefits and opportunities, we discuss the security, privacy, and ethical issues at stake.",
    "lastUpdated": "2015-02-03T12:03:08Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1502.00823v1"
  },
  {
    "title": "Quantum Hocus Pocus",
    "authors": [
      "Karl Svozil"
    ],
    "abstract": "The claims made in a manifesto resulting in the European quantum technologies flagship initiative in quantum technology and similar enterprises are taken as starting point to critically review some potential quantum resources, such as coherent superposition and entanglement, and their potential usefulness for parallelism and communication. Claims of absolute, irreducible (non-epistemic) randomness are argued to be metaphysical. Cryptanalytic man-in-the-middle attacks on quantum cryptography are well known to be feasible, but hardly mentioned. If all of this is taken into account, a more sober perspective on quantum capacities emerges, but one that may be ethically more justified than the \"hype and magic\" that drives many current initiatives.",
    "lastUpdated": "2016-11-28T14:32:02Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/1605.08569v3"
  },
  {
    "title": "The Dem@Care Experiments and Datasets: a Technical Report",
    "authors": [
      "Anastasios Karakostas",
      "Alexia Briassouli",
      "Konstantinos Avgerinakis",
      "Ioannis Kompatsiaris",
      "Magda Tsolaki"
    ],
    "abstract": "The objective of Dem@Care is the development of a complete system providing personal health services to people with dementia, as well as medical professionals and caregivers, by using a multitude of sensors, for context-aware, multi-parametric monitoring of lifestyle, ambient environment, and health parameters. Multi-sensor data analysis, combined with intelligent decision making mechanisms, will allow an accurate representation of the person's current status and will provide the appropriate feedback, both to the person and the associated caregivers, enhancing the standard clinical workflow. Within the project framework, several data collection activities have taken place to assist technical development and evaluation tasks. In all these activities, particular attention has been paid to adhere to ethical guidelines and preserve the participants' privacy. This technical report describes shorty the (a) the main objectives of the project, (b) the main ethical principles and (c) the datasets that have been already created.",
    "lastUpdated": "2016-12-17T19:43:18Z",
    "categories": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1701.01142v1"
  },
  {
    "title": "Contextual Consent: Ethical Mining of Social Media for Health Research",
    "authors": [
      "Chris Norval",
      "Tristan Henderson"
    ],
    "abstract": "Social media are a rich source of insight for data mining and user-centred research, but the question of consent arises when studying such data without the express knowledge of the creator. Case studies that mine social data from users of online services such as Facebook and Twitter are becoming increasingly common. This has led to calls for an open discussion into how researchers can best use these vast resources to make innovative findings while still respecting fundamental ethical principles. In this position paper we highlight some key considerations for this topic and argue that the conditions of informed consent are often not being met, and that using social media data that some deem free to access and analyse may result in undesirable consequences, particularly within the domain of health research and other sensitive topics. We posit that successful exploitation of online personal data, particularly for health and other sensitive research, requires new and usable methods of obtaining consent from the user.",
    "lastUpdated": "2017-01-26T16:32:47Z",
    "categories": [
      "cs.HC",
      "cs.CY",
      "cs.SI"
    ],
    "url": "http://arxiv.org/abs/1701.07765v1"
  },
  {
    "title": "Is it ethical to avoid error analysis?",
    "authors": [
      "Eva García-Martín",
      "Niklas Lavesson"
    ],
    "abstract": "Machine learning algorithms tend to create more accurate models with the availability of large datasets. In some cases, highly accurate models can hide the presence of bias in the data. There are several studies published that tackle the development of discriminatory-aware machine learning algorithms. We center on the further evaluation of machine learning models by doing error analysis, to understand under what conditions the model is not working as expected. We focus on the ethical implications of avoiding error analysis, from a falsification of results and discrimination perspective. Finally, we show different ways to approach error analysis in non-interpretable machine learning algorithms such as deep learning.",
    "lastUpdated": "2017-06-30T15:24:42Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1706.10237v1"
  },
  {
    "title": "Replication Ethics",
    "authors": [
      "Adrian Kent"
    ],
    "abstract": "Suppose some future technology enables the same consciously experienced human life to be repeated, identically or nearly so, N times, in series or in parallel. Is this roughly N times as valuable as enabling the same life once, because each life has value and values are additive? Or is it of roughly equal value as enabling the life once, because only one life is enabled, albeit in a physically unusual way? Does it matter whether the lives are contemporaneous or successive? We argue that these questions highlight a hitherto neglected facet of population ethics that may become relevant in the not necessarily far distant future.",
    "lastUpdated": "2019-01-05T16:47:04Z",
    "categories": [
      "cs.CY",
      "physics.hist-ph",
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/1712.03079v3"
  },
  {
    "title": "MATE robots simplifying my work: benefits and socio-ethical implications",
    "authors": [
      "Valeria Villani",
      "Lorenzo Sabattini",
      "Julia N. Czerniak",
      "Alexander Mertens",
      "Cesare Fantuzzi"
    ],
    "abstract": "With the increasing complexity of modern industrial automatic and robotic systems, an increasing burden is put on the operators, who are requested to supervise and interact with very complex systems, typically under challenging and stressful conditions. To overcome this issue, it is necessary to adopt a responsible approach based on the anthropocentric design methodology, such that machines adapt to the humans capabilities, and not vice versa. Moving along these lines, in this paper we consider an integrated methodological design approach, which we call MATE, consisting in devising complex automatic or robotic solutions that measure current operator's status, adapting the interaction accordingly, and providing her/him with proper training to improve the interaction and learn lacking skills and expertise. Accordingly, a MATE system is intended to be easily usable for all users, thus meeting the principles of inclusive design. Using such a MATE system gives rise to several ethical and social implications, which are discussed in this paper. Additionally, a discussion about which factors in the organization of companies are critical with respect to the introduction of a MATE system is presented.",
    "lastUpdated": "2018-02-19T09:14:39Z",
    "categories": [
      "cs.HC",
      "cs.RO"
    ],
    "url": "http://arxiv.org/abs/1712.07610v2"
  },
  {
    "title": "Ideas from Developmental Robotics and Embodied AI on the Questions of Ethics in Robots",
    "authors": [
      "Alexandre Pitti"
    ],
    "abstract": "Advances in Artificial Intelligence and robotics are currently questioning theethical framework of their applications to deal with potential drifts, as well as the way inwhich these algorithms learn because they will have a strong impact on the behavior ofrobots and the type of robots. interactions with people. We would like to highlight someprinciples and ideas from cognitive neuroscience and development sciences based on theimportance of the body for intelligence, contrary to the theory of the all-brain or all-algorithm, to represent the world and interacting with others, and their current applicationsin embodied AI and developmental robotics to propose models of architectures andmechanisms for agency, representation of the body, recognition of the intention of others,predictive coding, active inference, the role of feedback and error, imitation, artificialcuriosity and contextual learning. We will explain how these are important for the design ofautonomous systems and beyond what they can tell us for the ethics of systems.",
    "lastUpdated": "2018-03-20T16:15:24Z",
    "categories": [
      "cs.RO",
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/1803.07506v1"
  },
  {
    "title": "What About Applied Fairness?",
    "authors": [
      "Jared Sylvester",
      "Edward Raff"
    ],
    "abstract": "Machine learning practitioners are often ambivalent about the ethical aspects of their products. We believe anything that gets us from that current state to one in which our systems are achieving some degree of fairness is an improvement that should be welcomed. This is true even when that progress does not get us 100% of the way to the goal of \"complete\" fairness or perfectly align with our personal belief on which measure of fairness is used. Some measure of fairness being built would still put us in a better position than the status quo. Impediments to getting fairness and ethical concerns applied in real applications, whether they are abstruse philosophical debates or technical overhead such as the introduction of ever more hyper-parameters, should be avoided. In this paper we further elaborate on our argument for this viewpoint and its importance.",
    "lastUpdated": "2018-06-13T20:15:28Z",
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1806.05250v1"
  },
  {
    "title": "Privacy, ethics, and data access: A case study of the Fragile Families Challenge",
    "authors": [
      "Ian Lundberg",
      "Arvind Narayanan",
      "Karen Levy",
      "Matthew J. Salganik"
    ],
    "abstract": "Stewards of social science data face a fundamental tension. On one hand, they want to make their data accessible to as many researchers as possible to facilitate new discoveries. At the same time, they want to restrict access to their data as much as possible in order to protect the people represented in the data. In this paper, we provide a case study addressing this common tension in an uncommon setting: the Fragile Families Challenge, a scientific mass collaboration designed to yield insights that could improve the lives of disadvantaged children in the United States. We describe our process of threat modeling, threat mitigation, and third-party guidance. We also describe the ethical principles that formed the basis of our process. We are open about our process and the trade-offs that we made in the hopes that others can improve on what we have done.",
    "lastUpdated": "2018-09-01T02:42:04Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1809.00103v1"
  },
  {
    "title": "Certified Ethical Hacker v.10 Online Course - a Case Study",
    "authors": [
      "Tam N. Nguyen"
    ],
    "abstract": "CEH v.10 Certification Self-study Course is an online course preparing learners for one of the most prestige cyber security certifications in the world - the Certified Ethical Hacker (CEH) v.10 Certification. Due to a pay wall and the practical rather than theoretical nature, most researchers have limited exposure to this course. For the first time, this paper will analyze the course's instructional design based on the highest national standards and related peer-reviewed published research works. The sole intention is to push the course to a higher ground, making it the best online course for cyber security. More importantly, the paper's instructional design evaluation strategy can well be extended and applied to any other online course' instructional design review and/or evaluation process.",
    "lastUpdated": "2018-10-17T23:40:00Z",
    "categories": [
      "cs.CY",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1811.02887v1"
  },
  {
    "title": "Building Jiminy Cricket: An Architecture for Moral Agreements Among Stakeholders",
    "authors": [
      "Beishui Liao",
      "Marija Slavkovik",
      "Leendert van der Torre"
    ],
    "abstract": "An autonomous system is constructed by a manufacturer, operates in a society subject to norms and laws, and is interacting with end-users. We address the challenge of how the moral values and views of all stakeholders can be integrated and reflected in the moral behaviour of the autonomous system. We propose an artificial moral agent architecture that uses techniques from normative systems and formal argumentation to reach moral agreements among stakeholders. We show how our architecture can be used not only for ethical practical reasoning and collaborative decision-making, but also for the explanation of such moral behavior.",
    "lastUpdated": "2019-03-06T15:23:15Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1812.04741v2"
  },
  {
    "title": "Liability, Ethics, and Culture-Aware Behavior Specification using Rulebooks",
    "authors": [
      "Andrea Censi",
      "Konstantin Slutsky",
      "Tichakorn Wongpiromsarn",
      "Dmitry Yershov",
      "Scott Pendleton",
      "James Fu",
      "Emilio Frazzoli"
    ],
    "abstract": "The behavior of self-driving cars must be compatible with an enormous set of conflicting and ambiguous objectives, from law, from ethics, from the local culture, and so on. This paper describes a new way to conveniently define the desired behavior for autonomous agents, which we use on the self-driving cars developed at nuTonomy. We define a \"rulebook\" as a pre-ordered set of \"rules\", each akin to a violation metric on the possible outcomes (\"realizations\"). The rules are partially ordered by priority. The semantics of a rulebook imposes a pre-order on the set of realizations. We study the compositional properties of the rulebooks, and we derive which operations we can allow on the rulebooks to preserve previously-introduced constraints. While we demonstrate the application of these techniques in the self-driving domain, the methods are domain-independent.",
    "lastUpdated": "2019-03-01T07:09:30Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1902.09355v2"
  },
  {
    "title": "Transparency, Fairness, Data Protection, Neutrality: Data Management Challenges in the Face of New Regulation",
    "authors": [
      "Serge Abiteboul",
      "Julia Stoyanovich"
    ],
    "abstract": "The data revolution continues to transform every sector of science, industry and government. Due to the incredible impact of data-driven technology on society, we are becoming increasingly aware of the imperative to use data and algorithms responsibly -- in accordance with laws and ethical norms. In this article we discuss three recent regulatory frameworks: the European Union's General Data Protection Regulation (GDPR), the New York City Automated Decisions Systems (ADS) Law, and the Net Neutrality principle, that aim to protect the rights of individuals who are impacted by data collection and analysis. These frameworks are prominent examples of a global trend: Governments are starting to recognize the need to regulate data-driven algorithmic technology. Our goal in this paper is to bring these regulatory frameworks to the attention of the data management community, and to underscore the technical challenges they raise and which we, as a community, are well-equipped to address. The main take-away of this article is that legal and ethical norms cannot be incorporated into data-driven systems as an afterthought. Rather, we must think in terms of responsibility by design, viewing it as a systems requirement.",
    "lastUpdated": "2019-03-08T22:12:12Z",
    "categories": [
      "cs.DB",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1903.03683v1"
  },
  {
    "title": "Theories of Parenting and their Application to Artificial Intelligence",
    "authors": [
      "Sky Croeser",
      "Peter Eckersley"
    ],
    "abstract": "As machine learning (ML) systems have advanced, they have acquired more power over humans' lives, and questions about what values are embedded in them have become more complex and fraught. It is conceivable that in the coming decades, humans may succeed in creating artificial general intelligence (AGI) that thinks and acts with an open-endedness and autonomy comparable to that of humans. The implications would be profound for our species; they are now widely debated not just in science fiction and speculative research agendas but increasingly in serious technical and policy conversations. Much work is underway to try to weave ethics into advancing ML research. We think it useful to add the lens of parenting to these efforts, and specifically radical, queer theories of parenting that consciously set out to nurture agents whose experiences, objectives and understanding of the world will necessarily be very different from their parents'. We propose a spectrum of principles which might underpin such an effort; some are relevant to current ML research, while others will become more important if AGI becomes more likely. These principles may encourage new thinking about the development, design, training, and release into the world of increasingly autonomous agents.",
    "lastUpdated": "2019-03-14T22:13:14Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1903.06281v1"
  },
  {
    "title": "Responsible and Representative Multimodal Data Acquisition and Analysis: On Auditability, Benchmarking, Confidence, Data-Reliance & Explainability",
    "authors": [
      "Alice Baird",
      "Simone Hantke",
      "Björn Schuller"
    ],
    "abstract": "The ethical decisions behind the acquisition and analysis of audio, video or physiological human data, harnessed for (deep) machine learning algorithms, is an increasing concern for the Artificial Intelligence (AI) community. In this regard, herein we highlight the growing need for responsible, and representative data collection and analysis, through a discussion of modality diversification. Factors such as Auditability, Benchmarking, Confidence, Data-reliance, and Explainability (ABCDE), have been touched upon within the machine learning community, and here we lay out these ABCDE sub-categories in relation to the acquisition and analysis of multimodal data, to weave through the high priority ethical concerns currently under discussion for AI. To this end, we propose how these five subcategories can be included in early planning of such acquisition paradigms.",
    "lastUpdated": "2019-03-17T21:13:22Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1903.07171v1"
  },
  {
    "title": "Software Engineering for Fairness: A Case Study with Hyperparameter Optimization",
    "authors": [
      "Joymallya Chakraborty",
      "Tianpei Xia",
      "Fahmid M. Fahid",
      "Tim Menzies"
    ],
    "abstract": "We assert that it is the ethical duty of software engineers to strive to reduce software discrimination. This paper discusses how that might be done. This is an important topic since machine learning software is increasingly being used to make decisions that affect people's lives. Potentially, the application of that software will result in fairer decisions because (unlike humans) machine learning software is not biased. However, recent results show that the software within many data mining packages exhibits \"group discrimination\"; i.e. their decisions are inappropriately affected by \"protected attributes\"(e.g., race, gender, age, etc.). There has been much prior work on validating the fairness of machine-learning models (by recognizing when such software discrimination exists). But after detection, comes mitigation. What steps can ethical software engineers take to reduce discrimination in the software they produce? This paper shows that making \\textit{fairness} as a goal during hyperparameter optimization can (a) preserve the predictive power of a model learned from a data miner while also (b) generates fairer results. To the best of our knowledge, this is the first application of hyperparameter optimization as a tool for software engineers to generate fairer software.",
    "lastUpdated": "2019-10-30T15:06:13Z",
    "categories": [
      "cs.SE",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1905.05786v2"
  },
  {
    "title": "Complexity Analysis of Approaching Clinical Psychiatry with Predictive Analytics and Neural Networks",
    "authors": [
      "Soaad Hossain"
    ],
    "abstract": "As the emerging field of predictive analytics in psychiatry generated and continues to generate massive interest overtime with its major promises to positively change and revolutionize clinical psychiatry, health care and medical professionals are greatly looking forward to its integration and application into psychiatry. However, by directly applying predictive analytics to the practice of psychiatry, this could cause detrimental damage to those that use predictive analytics through creating or worsening existing medical issues. In both cases, medical ethics issues arise, and need to be addressed. This paper will use literature to provide descriptions of selected stages in the treatment of mental disorders and phases in a predictive analytics project, approach mental disorder diagnoses using predictive models that rely on neural networks, analyze the complexities in clinical psychiatry, neural networks and predictive analytics, and conclude with emphasizing and elaborating on limitations and medical ethics issues of applying neural networks and predictive analytics to clinical psychiatry.",
    "lastUpdated": "2019-05-23T08:03:15Z",
    "categories": [
      "cs.CY",
      "68Uxx"
    ],
    "url": "http://arxiv.org/abs/1905.12471v1"
  },
  {
    "title": "Age and gender bias in pedestrian detection algorithms",
    "authors": [
      "Martim Brandao"
    ],
    "abstract": "Pedestrian detection algorithms are important components of mobile robots, such as autonomous vehicles, which directly relate to human safety. Performance disparities in these algorithms could translate into disparate impact in the form of biased accident outcomes. To evaluate the need for such concerns, we characterize the age and gender bias in the performance of state-of-the-art pedestrian detection algorithms. Our analysis is based on the INRIA Person Dataset extended with child, adult, male and female labels. We show that all of the 24 top-performing methods of the Caltech Pedestrian Detection Benchmark have higher miss rates on children. The difference is significant and we analyse how it varies with the classifier, features and training data used by the methods. Algorithms were also gender-biased on average but the performance differences were not significant. We discuss the source of the bias, the ethical implications, possible technical solutions and barriers.",
    "lastUpdated": "2019-06-25T13:01:29Z",
    "categories": [
      "cs.CY",
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1906.10490v1"
  },
  {
    "title": "Towards Automatic Screening of Typical and Atypical Behaviors in Children With Autism",
    "authors": [
      "Andrew Cook",
      "Bappaditya Mandal",
      "Donna Berry",
      "Matthew Johnson"
    ],
    "abstract": "This paper has been withdrawn by the authors due to insufficient or definition error(s) in the ethics approval protocol. Autism spectrum disorders (ASD) impact the cognitive, social, communicative and behavioral abilities of an individual. The development of new clinical decision support systems is of importance in reducing the delay between presentation of symptoms and an accurate diagnosis. In this work, we contribute a new database consisting of video clips of typical (normal) and atypical (such as hand flapping, spinning or rocking) behaviors, displayed in natural settings, which have been collected from the YouTube video website. We propose a preliminary non-intrusive approach based on skeleton keypoint identification using pretrained deep neural networks on human body video clips to extract features and perform body movement analysis that differentiates typical and atypical behaviors of children. Experimental results on the newly contributed database show that our platform performs best with decision tree as the classifier when compared to other popular methodologies and offers a baseline against which alternate approaches may developed and tested.",
    "lastUpdated": "2019-09-17T14:00:52Z",
    "categories": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1907.12537v2"
  },
  {
    "title": "Coercion, Consent, and Participation in Citizen Science",
    "authors": [
      "Alison Reiheld",
      "Pamela L. Gay"
    ],
    "abstract": "Throughout history, everyday people have contributed to science through a myriad of volunteer activities. This early participation required training and often involved mentorship from scientists or senior citizen scientists (or, as they were often called, gentleman scientists). During this learning process, participants learned how they and their data would be used both to advance science, and in some cases, advance the careers of professional collaborators. Modern, online citizen science, allows participation with just a few clicks, and people may participate without understanding what they are contributing to. Too often, they happily see what they are doing as the privilege of painting Tom Sawyer's fence without realizing they are actually being used as merely a means to a scientific end. This paper discusses the ethical dilemmas that plague modern citizen science, including: the issues of informed consent, such as not requiring logins; the issues of coercion inherent in mandatory classroom assignments requiring data submission; and the issues of using people merely as a means to an end that are inherent in technonationalism, and projects that do not provide utility to the users beyond the knowledge they helped. This work is tested within the context of astronomy citizen science.",
    "lastUpdated": "2019-07-29T03:48:21Z",
    "categories": [
      "cs.CY",
      "physics.ed-ph"
    ],
    "url": "http://arxiv.org/abs/1907.13061v1"
  },
  {
    "title": "AI and Accessibility: A Discussion of Ethical Considerations",
    "authors": [
      "Meredith Ringel Morris"
    ],
    "abstract": "According to the World Health Organization, more than one billion people worldwide have disabilities. The field of disability studies defines disability through a social lens; people are disabled to the extent that society creates accessibility barriers. AI technologies offer the possibility of removing many accessibility barriers; for example, computer vision might help people who are blind better sense the visual world, speech recognition and translation technologies might offer real time captioning for people who are hard of hearing, and new robotic systems might augment the capabilities of people with limited mobility. Considering the needs of users with disabilities can help technologists identify high-impact challenges whose solutions can advance the state of AI for all users; however, ethical challenges such as inclusivity, bias, privacy, error, expectation setting, simulated data, and social acceptability must be considered.",
    "lastUpdated": "2020-06-03T16:33:42Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/1908.08939v3"
  },
  {
    "title": "Towards Ethical Content-Based Detection of Online Influence Campaigns",
    "authors": [
      "Evan Crothers",
      "Nathalie Japkowicz",
      "Herna Viktor"
    ],
    "abstract": "The detection of clandestine efforts to influence users in online communities is a challenging problem with significant active development. We demonstrate that features derived from the text of user comments are useful for identifying suspect activity, but lead to increased erroneous identifications when keywords over-represented in past influence campaigns are present. Drawing on research in native language identification (NLI), we use \"named entity masking\" (NEM) to create sentence features robust to this shortcoming, while maintaining comparable classification accuracy. We demonstrate that while NEM consistently reduces false positives when key named entities are mentioned, both masked and unmasked models exhibit increased false positive rates on English sentences by Russian native speakers, raising ethical considerations that should be addressed in future research.",
    "lastUpdated": "2019-08-29T03:18:21Z",
    "categories": [
      "cs.CY",
      "cs.CL"
    ],
    "url": "http://arxiv.org/abs/1908.11030v1"
  },
  {
    "title": "Automating dynamic consent decisions for the processing of social media data in health research",
    "authors": [
      "Chris Norval",
      "Tristan Henderson"
    ],
    "abstract": "Social media have become a rich source of data, particularly in health research. Yet, the use of such data raises significant ethical questions about the need for the informed consent of those being studied. Consent mechanisms, if even obtained, are typically broad and inflexible, or place a significant burden on the participant. Machine learning algorithms show much promise for facilitating a 'middle ground' approach: using trained models to predict and automate granular consent decisions. Such techniques, however, raise a myriad of follow-on ethical and technical considerations. In this paper, we present an exploratory user study (n = 67) in which we find that we can predict the appropriate flow of health-related social media data with reasonable accuracy, while minimising undesired data leaks. We then attempt to deconstruct the findings of this study, identifying and discussing a number of real-world implications if such a technique were put into practice.",
    "lastUpdated": "2019-10-11T15:57:00Z",
    "categories": [
      "cs.HC",
      "cs.CY",
      "cs.LG",
      "cs.SI"
    ],
    "url": "http://arxiv.org/abs/1910.05265v1"
  },
  {
    "title": "Solidarity should be a core ethical principle of Artificial Intelligence",
    "authors": [
      "Miguel Luengo-Oroz"
    ],
    "abstract": "Solidarity is one of the fundamental values at the heart of the construction of peaceful societies and present in more than one third of world's constitutions. Still, solidarity is almost never included as a principle in ethical guidelines for the development of AI. Solidarity as an AI principle (1) shares the prosperity created by AI, implementing mechanisms to redistribute the augmentation of productivity for all; and shares the burdens, making sure that AI does not increase inequality and no human is left behind. Solidarity as an AI principle (2) assesses the long term implications before developing and deploying AI systems so no groups of humans become irrelevant because of AI systems. Considering solidarity as a core principle for AI development will provide not just an human-centric but a more humanity-centric approach to AI.",
    "lastUpdated": "2019-10-22T15:21:42Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1910.12583v1"
  },
  {
    "title": "AI Ethics for Systemic Issues: A Structural Approach",
    "authors": [
      "Agnes Schim van der Loeff",
      "Iggy Bassi",
      "Sachin Kapila",
      "Jevgenij Gamper"
    ],
    "abstract": "The debate on AI ethics largely focuses on technical improvements and stronger regulation to prevent accidents or misuse of AI, with solutions relying on holding individual actors accountable for responsible AI development. While useful and necessary, we argue that this \"agency\" approach disregards more indirect and complex risks resulting from AI's interaction with the socio-economic and political context. This paper calls for a \"structural\" approach to assessing AI's effects in order to understand and prevent such systemic risks where no individual can be held accountable for the broader negative impacts. This is particularly relevant for AI applied to systemic issues such as climate change and food security which require political solutions and global cooperation. To properly address the wide range of AI risks and ensure 'AI for social good', agency-focused policies must be complemented by policies informed by a structural approach.",
    "lastUpdated": "2019-11-08T12:31:49Z",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1911.03216v1"
  },
  {
    "title": "Taking Ethics, Fairness, and Bias Seriously in Machine Learning for Disaster Risk Management",
    "authors": [
      "Robert Soden",
      "Dennis Wagenaar",
      "Dave Luo",
      "Annegien Tijssen"
    ],
    "abstract": "This paper highlights an important, if under-examined, set of questions about the deployment of machine learning technologies in the field of disaster risk management (DRM). While emerging tools show promising capacity to support scientific efforts to better understand and mitigate the threats posed by disasters and climate change, our field must undertake a much more careful assessment of the potential negative impacts that machine learning technologies may create. We also argue that attention to these issues in the context of machine learning affords the opportunity to have discussions about potential ethics, bias, and fairness concerns within disaster data more broadly. In what follows, we first describe some of the uses and potential benefits of machine-learning technology in disaster risk management. We then draw on research from other fields to speculate about potential negative impacts. Finally, we outline a research agenda for how our disaster risk management can begin to take these issues seriously and ensure that deployments of machine-learning tools are conducted in a responsible and beneficial manner.",
    "lastUpdated": "2019-12-18T18:17:41Z",
    "categories": [
      "cs.CY",
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/1912.05538v2"
  },
  {
    "title": "Algorithmic Injustices: Towards a Relational Ethics",
    "authors": [
      "Abeba Birhane",
      "Fred Cummins"
    ],
    "abstract": "It has become trivial to point out how decision-making processes in various social, political and economical sphere are assisted by automated systems. Improved efficiency, the hallmark of these systems, drives the mass scale integration of automated systems into daily life. However, as a robust body of research in the area of algorithmic injustice shows, algorithmic tools embed and perpetuate societal and historical biases and injustice. In particular, a persistent recurring trend within the literature indicates that society's most vulnerable are disproportionally impacted. When algorithmic injustice and bias is brought to the fore, most of the solutions on offer 1) revolve around technical solutions and 2) do not focus centre disproportionally impacted groups. This paper zooms out and draws the bigger picture. It 1) argues that concerns surrounding algorithmic decision making and algorithmic injustice require fundamental rethinking above and beyond technical solutions, and 2) outlines a way forward in a manner that centres vulnerable groups through the lens of relational ethics.",
    "lastUpdated": "2019-12-16T14:04:42Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1912.07376v1"
  },
  {
    "title": "Lessons from Archives: Strategies for Collecting Sociocultural Data in Machine Learning",
    "authors": [
      "Eun Seo Jo",
      "Timnit Gebru"
    ],
    "abstract": "A growing body of work shows that many problems in fairness, accountability, transparency, and ethics in machine learning systems are rooted in decisions surrounding the data collection and annotation process. In spite of its fundamental nature however, data collection remains an overlooked part of the machine learning (ML) pipeline. In this paper, we argue that a new specialization should be formed within ML that is focused on methodologies for data collection and annotation: efforts that require institutional frameworks and procedures. Specifically for sociocultural data, parallels can be drawn from archives and libraries. Archives are the longest standing communal effort to gather human information and archive scholars have already developed the language and procedures to address and discuss many challenges pertaining to data collection such as consent, power, inclusivity, transparency, and ethics & privacy. We discuss these five key approaches in document collection practices in archives that can inform data collection in sociocultural ML. By showing data collection practices from another field, we encourage ML research to be more cognizant and systematic in data collection and draw from interdisciplinary expertise.",
    "lastUpdated": "2019-12-22T05:56:55Z",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "I.2.0",
      "I.2.0"
    ],
    "url": "http://arxiv.org/abs/1912.10389v1"
  },
  {
    "title": "Perspectives and Ethics of the Autonomous Artificial Thinking Systems",
    "authors": [
      "Joël Colloc"
    ],
    "abstract": "The feasibility of autonomous artificial thinking systems needs to compare the way the human beings acquire their information and develops the thought with the current capacities of the autonomous information systems. Our model uses four hierarchies: the hierarchy of information systems, the cognitive hierarchy, the linguistic hierarchy and the digital informative hierarchy that combines artificial intelligence, the power of computers models, methods and tools to develop autonomous information systems. The question of the capability of autonomous system to provide a form of artificial thought arises with the ethical consequences on the social life and the perspective of transhumanism.",
    "lastUpdated": "2020-01-13T14:23:21Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2001.04270v1"
  },
  {
    "title": "Beyond Near- and Long-Term: Towards a Clearer Account of Research Priorities in AI Ethics and Society",
    "authors": [
      "Carina Prunkl",
      "Jess Whittlestone"
    ],
    "abstract": "One way of carving up the broad \"AI ethics and society\" research space that has emerged in recent years is to distinguish between \"near-term\" and \"long-term\" research. While such ways of breaking down the research space can be useful, we put forward several concerns about the near/long-term distinction gaining too much prominence in how research questions and priorities are framed. We highlight some ambiguities and inconsistencies in how the distinction is used, and argue that while there are differing priorities within this broad research community, these differences are not well-captured by the near/long-term distinction. We unpack the near/long-term distinction into four different dimensions, and propose some ways that researchers can communicate more clearly about their work and priorities using these dimensions. We suggest that moving towards a more nuanced conversation about research priorities can help establish new opportunities for collaboration, aid the development of more consistent and coherent research agendas, and enable identification of previously neglected research areas.",
    "lastUpdated": "2020-01-21T12:18:20Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2001.04335v2"
  },
  {
    "title": "Effects of Persuasive Dialogues: Testing Bot Identities and Inquiry Strategies",
    "authors": [
      "Weiyan Shi",
      "Xuewei Wang",
      "Yoo Jung Oh",
      "Jingwen Zhang",
      "Saurav Sahay",
      "Zhou Yu"
    ],
    "abstract": "Intelligent conversational agents, or chatbots, can take on various identities and are increasingly engaging in more human-centered conversations with persuasive goals. However, little is known about how identities and inquiry strategies influence the conversation's effectiveness. We conducted an online study involving 790 participants to be persuaded by a chatbot for charity donation. We designed a two by four factorial experiment (two chatbot identities and four inquiry strategies) where participants were randomly assigned to different conditions. Findings showed that the perceived identity of the chatbot had significant effects on the persuasion outcome (i.e., donation) and interpersonal perceptions (i.e., competence, confidence, warmth, and sincerity). Further, we identified interaction effects among perceived identities and inquiry strategies. We discuss the findings for theoretical and practical implications for developing ethical and effective persuasive chatbots. Our published data, codes, and analyses serve as the first step towards building competent ethical persuasive chatbots.",
    "lastUpdated": "2020-01-18T19:13:23Z",
    "categories": [
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/2001.04564v2"
  },
  {
    "title": "Activism by the AI Community: Analysing Recent Achievements and Future Prospects",
    "authors": [
      "Haydn Belfield"
    ],
    "abstract": "The artificial intelligence community (AI) has recently engaged in activism in relation to their employers, other members of the community, and their governments in order to shape the societal and ethical implications of AI. It has achieved some notable successes, but prospects for further political organising and activism are uncertain. We survey activism by the AI community over the last six years; apply two analytical frameworks drawing upon the literature on epistemic communities, and worker organising and bargaining; and explore what they imply for the future prospects of the AI community. Success thus far has hinged on a coherent shared culture, and high bargaining power due to the high demand for a limited supply of AI talent. Both are crucial to the future of AI activism and worthy of sustained attention.",
    "lastUpdated": "2020-01-17T20:53:10Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "I.2; K.4; K.7"
    ],
    "url": "http://arxiv.org/abs/2001.06528v1"
  },
  {
    "title": "Give Me Convenience and Give Her Death: Who Should Decide What Uses of NLP are Appropriate, and on What Basis?",
    "authors": [
      "Kobi Leins",
      "Jey Han Lau",
      "Timothy Baldwin"
    ],
    "abstract": "As part of growing NLP capabilities, coupled with an awareness of the ethical dimensions of research, questions have been raised about whether particular datasets and tasks should be deemed off-limits for NLP research. We examine this question with respect to a paper on automatic legal sentencing from EMNLP 2019 which was a source of some debate, in asking whether the paper should have been allowed to be published, who should have been charged with making such a decision, and on what basis. We focus in particular on the role of data statements in ethically assessing research, but also discuss the topic of dual use, and examine the outcomes of similar debates in other scientific disciplines.",
    "lastUpdated": "2020-05-27T07:31:57Z",
    "categories": [
      "cs.CL"
    ],
    "url": "http://arxiv.org/abs/2005.13213v1"
  },
  {
    "title": "A blindspot of AI ethics: anti-fragility in statistical prediction",
    "authors": [
      "Michele Loi",
      "Lonneke van der Plas"
    ],
    "abstract": "With this paper, we aim to put an issue on the agenda of AI ethics that in our view is overlooked in the current discourse. The current discussions are dominated by topics suchas trustworthiness and bias, whereas the issue we like to focuson is counter to the debate on trustworthiness. We fear that the overuse of currently dominant AI systems that are driven by short-term objectives and optimized for avoiding error leads to a society that loses its diversity and flexibility needed for true progress. We couch our concerns in the discourse around the term anti-fragility and show with some examples what threats current methods used for decision making pose for society.",
    "lastUpdated": "2020-06-21T14:46:55Z",
    "categories": [
      "cs.AI",
      "62P25",
      "K.4.2; I.2.0; K.7.4"
    ],
    "url": "http://arxiv.org/abs/2006.11814v1"
  },
  {
    "title": "Artificial intelligence in space",
    "authors": [
      "George Anthony Gal",
      "Cristiana Santos",
      "Lucien Rapp",
      "Réeka Markovich",
      "Leendert van der Torre"
    ],
    "abstract": "In the next coming years, space activities are expected to undergo a radical transformation with the emergence of new satellite systems or new services which will incorporate the contributions of artificial intelligence and machine learning defined as covering a wide range of innovations from autonomous objects with their own decision-making power to increasingly sophisticated services exploiting very large volumes of information from space. This chapter identifies some of the legal and ethical challenges linked to its use. These legal and ethical challenges call for solutions which the international treaties in force are not sufficient to determine and implement. For this reason, a legal methodology must be developed that makes it possible to link intelligent systems and services to a system of rules applicable thereto. It discusses existing legal AI-based tools amenable for making space law actionable, interoperable and machine readable for future compliance tools.",
    "lastUpdated": "2020-06-22T16:00:44Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2006.12362v1"
  },
  {
    "title": "Fairness in machine learning: against false positive rate equality as a measure of fairness",
    "authors": [
      "Robert Long"
    ],
    "abstract": "As machine learning informs increasingly consequential decisions, different metrics have been proposed for measuring algorithmic bias or unfairness. Two popular fairness measures are calibration and equality of false positive rate. Each measure seems intuitively important, but notably, it is usually impossible to satisfy both measures. For this reason, a large literature in machine learning speaks of a fairness tradeoff between these two measures. This framing assumes that both measures are, in fact, capturing something important. To date, philosophers have not examined this crucial assumption, and examined to what extent each measure actually tracks a normatively important property. This makes this inevitable statistical conflict, between calibration and false positive rate equality, an important topic for ethics. In this paper, I give an ethical framework for thinking about these measures and argue that, contrary to initial appearances, false positive rate equality does not track anything about fairness, and thus sets an incoherent standard for evaluating the fairness of algorithms.",
    "lastUpdated": "2020-07-06T17:03:58Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2007.02890v1"
  },
  {
    "title": "A non-discriminatory approach to ethical deep learning",
    "authors": [
      "Enzo Tartaglione",
      "Marco Grangetto"
    ],
    "abstract": "Artificial neural networks perform state-of-the-art in an ever-growing number of tasks, nowadays they are used to solve an incredibly large variety of tasks. However, typical training strategies do not take into account lawful, ethical and discriminatory potential issues the trained ANN models could incur in. In this work we propose NDR, a non-discriminatory regularization strategy to prevent the ANN model to solve the target task using some discriminatory features like, for example, the ethnicity in an image classification task for human faces. In particular, a part of the ANN model is trained to hide the discriminatory information such that the rest of the network focuses in learning the given learning task. Our experiments show that NDR can be exploited to achieve non-discriminatory models with both minimal computational overhead and performance loss.",
    "lastUpdated": "2020-08-04T09:33:02Z",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2008.01430v1"
  },
  {
    "title": "Beyond Our Behavior: The GDPR and Humanistic Personalization",
    "authors": [
      "Travis Greene",
      "Galit Shmueli"
    ],
    "abstract": "Personalization should take the human person seriously. This requires a deeper understanding of how recommender systems can shape both our self-understanding and identity. We unpack key European humanistic and philosophical ideas underlying the General Data Protection Regulation (GDPR) and propose a new paradigm of humanistic personalization. Humanistic personalization responds to the IEEE's call for Ethically Aligned Design (EAD) and is based on fundamental human capacities and values. Humanistic personalization focuses on narrative accuracy: the subjective fit between a person's self-narrative and both the input (personal data) and output of a recommender system. In doing so, we re-frame the distinction between implicit and explicit data collection as one of nonconscious (\"organismic\") behavior and conscious (\"reflective\") action. This distinction raises important ethical and interpretive issues related to agency, self-understanding, and political participation. Finally, we discuss how an emphasis on narrative accuracy can reduce opportunities for epistemic injustice done to data subjects.",
    "lastUpdated": "2020-08-31T07:40:09Z",
    "categories": [
      "cs.CY",
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/2008.13404v1"
  },
  {
    "title": "Explainability Case Studies",
    "authors": [
      "Ben Zevenbergen",
      "Allison Woodruff",
      "Patrick Gage Kelley"
    ],
    "abstract": "Explainability is one of the key ethical concepts in the design of AI systems. However, attempts to operationalize this concept thus far have tended to focus on approaches such as new software for model interpretability or guidelines with checklists. Rarely do existing tools and guidance incentivize the designers of AI systems to think critically and strategically about the role of explanations in their systems. We present a set of case studies of a hypothetical AI-enabled product, which serves as a pedagogical tool to empower product designers, developers, students, and educators to develop a holistic explainability strategy for their own products.",
    "lastUpdated": "2020-10-03T03:46:48Z",
    "categories": [
      "cs.CY",
      "K.4; K.3.2; I.2"
    ],
    "url": "http://arxiv.org/abs/2009.00246v2"
  },
  {
    "title": "A Framework for Fairer Machine Learning in Organizations",
    "authors": [
      "Lily Morse",
      "Mike H. M. Teodorescu",
      "Yazeed Awwad",
      "Gerald Kane"
    ],
    "abstract": "With the increase in adoption of machine learning tools by organizations risks of unfairness abound, especially when human decision processes in outcomes of socio-economic importance such as hiring, housing, lending, and admissions are automated. We reveal sources of unfair machine learning, review fairness criteria, and provide a framework which, if implemented, would enable an organization to both avoid implementing an unfair machine learning model, but also to avoid the common situation that as an algorithm learns with more data it can become unfair over time. Issues of behavioral ethics in machine learning implementations by organizations have not been thoroughly addressed in the literature, because many of the necessary concepts are dispersed across three literatures: ethics, machine learning, and management. Further, tradeoffs between fairness criteria in machine learning have not been addressed with regards to organizations. We advance the research by introducing an organizing framework for selecting and implementing fair algorithms in organizations.",
    "lastUpdated": "2020-09-10T04:07:10Z",
    "categories": [
      "cs.CY",
      "cs.LG",
      "68T05",
      "I.2.6"
    ],
    "url": "http://arxiv.org/abs/2009.04661v1"
  },
  {
    "title": "The Short Anthropological Guide to the Study of Ethical AI",
    "authors": [
      "Alexandrine Royer"
    ],
    "abstract": "Over the next few years, society as a whole will need to address what core values it wishes to protect when dealing with technology. Anthropology, a field dedicated to the very notion of what it means to be human, can provide some interesting insights into how to cope and tackle these changes in our Western society and other areas of the world. It can be challenging for social science practitioners to grasp and keep up with the pace of technological innovation, with many being unfamiliar with the jargon of AI. This short guide serves as both an introduction to AI ethics and social science and anthropological perspectives on the development of AI. It intends to provide those unfamiliar with the field with an insight into the societal impact of AI systems and how, in turn, these systems can lead us to rethink how our world operates.",
    "lastUpdated": "2020-10-07T12:25:03Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2010.03362v1"
  },
  {
    "title": "Not Judging a User by Their Cover: Understanding Harm in Multi-Modal Processing within Social Media Research",
    "authors": [
      "Jiachen Jiang",
      "Soroush Vosoughi"
    ],
    "abstract": "Social media has shaken the foundations of our society, unlikely as it may seem. Many of the popular tools used to moderate harmful digital content, however, have received widespread criticism from both the academic community and the public sphere for middling performance and lack of accountability. Though social media research is thought to center primarily on natural language processing, we demonstrate the need for the community to understand multimedia processing and its unique ethical considerations. Specifically, we identify statistical differences in the performance of Amazon Turk (MTurk) annotators when different modalities of information are provided and discuss the patterns of harm that arise from crowd-sourced human demographic prediction. Finally, we discuss the consequences of those biases through auditing the performance of a toxicity detector called Perspective API on the language of Twitter users across a variety of demographic categories.",
    "lastUpdated": "2020-10-19T18:13:16Z",
    "categories": [
      "cs.SI"
    ],
    "url": "http://arxiv.org/abs/2010.09768v1"
  },
  {
    "title": "A New Charter of Ethics and Rights of Artificial Consciousness in a Human World",
    "authors": [
      "Markian Hromiak"
    ],
    "abstract": "Taking the stance that artificially conscious agents should be given human-like rights, in this paper we attempt to define consciousness, aggregate existing universal human rights, analyze robotic laws with roots in both reality and science fiction, and synthesize everything to create a new robot-ethical charter. By restricting the problem-space of possible levels of conscious beings to human-like, we succeed in developing a working definition of consciousness for social strong AI which focuses on human-like creativity being exhibited as a third-person observable phenomenon. Creativity is then extrapolated to represent first-person functionality, fulfilling the first/third-person feature of consciousness. Next, several sources of existing rights and rules, both for humans and robots, are analyzed and, along with supplementary informal reports, synthesized to create articles for an additive charter which compliments the United Nation's Universal Declaration of Human Rights. Finally, the charter is presented and the paper concludes with the conditions for amending the charter, as well as recommendations for further charters.",
    "lastUpdated": "2020-11-13T06:26:17Z",
    "categories": [
      "cs.CY",
      "I.2.0"
    ],
    "url": "http://arxiv.org/abs/2010.12019v2"
  },
  {
    "title": "Generating Intelligible Plumitifs Descriptions: Use Case Application with Ethical Considerations",
    "authors": [
      "David Beauchemin",
      "Nicolas Garneau",
      "Eve Gaumond",
      "Pierre-Luc Déziel",
      "Richard Khoury",
      "Luc Lamontagne"
    ],
    "abstract": "Plumitifs (dockets) were initially a tool for law clerks. Nowadays, they are used as summaries presenting all the steps of a judicial case. Information concerning parties' identity, jurisdiction in charge of administering the case, and some information relating to the nature and the course of the preceding are available through plumitifs. They are publicly accessible but barely understandable; they are written using abbreviations and referring to provisions from the Criminal Code of Canada, which makes them hard to reason about. In this paper, we propose a simple yet efficient multi-source language generation architecture that leverages both the plumitif and the Criminal Code's content to generate intelligible plumitifs descriptions. It goes without saying that ethical considerations rise with these sensitive documents made readable and available at scale, legitimate concerns that we address in this paper.",
    "lastUpdated": "2020-11-24T16:02:36Z",
    "categories": [
      "cs.CL"
    ],
    "url": "http://arxiv.org/abs/2011.12183v1"
  },
  {
    "title": "Ethical Testing in the Real World: Evaluating Physical Testing of Adversarial Machine Learning",
    "authors": [
      "Kendra Albert",
      "Maggie Delano",
      "Jonathon Penney",
      "Afsaneh Rigot",
      "Ram Shankar Siva Kumar"
    ],
    "abstract": "This paper critically assesses the adequacy and representativeness of physical domain testing for various adversarial machine learning (ML) attacks against computer vision systems involving human subjects. Many papers that deploy such attacks characterize themselves as \"real world.\" Despite this framing, however, we found the physical or real-world testing conducted was minimal, provided few details about testing subjects and was often conducted as an afterthought or demonstration. Adversarial ML research without representative trials or testing is an ethical, scientific, and health/safety issue that can cause real harms. We introduce the problem and our methodology, and then critique the physical domain testing methodologies employed by papers in the field. We then explore various barriers to more inclusive physical testing in adversarial ML and offer recommendations to improve such testing notwithstanding these challenges.",
    "lastUpdated": "2020-12-03T16:28:45Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2012.02048v1"
  },
  {
    "title": "The Managerial Effects of Algorithmic Fairness Activism",
    "authors": [
      "Bo Cowgill",
      "Fabrizio Dell'Acqua",
      "Sandra Matz"
    ],
    "abstract": "How do ethical arguments affect AI adoption in business? We randomly expose business decision-makers to arguments used in AI fairness activism. Arguments emphasizing the inescapability of algorithmic bias lead managers to abandon AI for manual review by humans and report greater expectations about lawsuits and negative PR. These effects persist even when AI lowers gender and racial disparities and when engineering investments to address AI fairness are feasible. Emphasis on status quo comparisons yields opposite effects. We also measure the effects of \"scientific veneer\" in AI ethics arguments. Scientific veneer changes managerial behavior but does not asymmetrically benefit favorable (versus critical) AI activism.",
    "lastUpdated": "2020-12-04T04:11:31Z",
    "categories": [
      "econ.GN",
      "cs.CY",
      "q-fin.EC"
    ],
    "url": "http://arxiv.org/abs/2012.02393v1"
  },
  {
    "title": "The Future of Artificial Intelligence and its Social, Economic and Ethical Consequences",
    "authors": [
      "Burhan Rashid Hussein",
      "Chongomweru Halimu",
      "Muhammad Tariq Siddique"
    ],
    "abstract": "Recent development in AI has enabled the expansion of its application to multiple domains. From medical treatment, gaming, manufacturing to daily business processes. A huge amount of money has been poured into AI research due to its exciting discoveries. Technology giants like Google, Facebook, Amazon, and Baidu are the driving forces in the field today. But the rapid growth and excitement that the technology offers obscure us from looking at the impact it brings on our society. This short paper gives a brief history of AI and summarizes various social, economic and ethical issues that are impacting our society today. We hope that this work will provide a useful starting point and perhaps reference for newcomers and stakeholders of the field.",
    "lastUpdated": "2021-01-09T14:21:54Z",
    "categories": [
      "cs.OH"
    ],
    "url": "http://arxiv.org/abs/2101.03366v1"
  },
  {
    "title": "Counting on Beauty: The role of aesthetic, ethical, and physical universal principles for interstellar communication",
    "authors": [
      "Guillermo A. Lemarchand"
    ],
    "abstract": "SETI researchers believe that the basic principles of our science and the science of extraterrestrial beings should be fundamentally the same, and we should be able to communicate with them by referring to those things we share, such as the principles of mathematics, physics, and chemistry (a similar cognitive map of nature). This view assumes that there is only one way to conceptualize the laws of nature. Consequently, mathematics and the language of nature should be universal. In this essay, we discuss the epistemological bases of the last assumptions. We describe all the hypotheses behind the universality of the laws of nature and the restrictions that any technology should have to establish contact with other galactic technological civilization. We introduce some discussions about the limitations of homocentric views. We discuss about the possible use of aesthetic cognitive universals as well as ethical ones in the design of interstellar messages. We discuss the role of symmetry as a universal cognitive map. We give a specific example on how to use the Golden Section principles to design a hypothetical interstellar message based in physical and aesthetical cognitive universals. We build a space of configuration matrix, representing all the variables to be taken into account for designing an electromagnetic interstellar message (e.g. frequency, polarization, bandwidth, transmitting power, modulation, rate of information, galactic coordinates, etc.) against the limitations imposed by physical, technological, aesthetical and ethical constraints. We show how to use it, in order to make hypotheses about the characteristics and properties of hypothetical extraterrestrial artificial signals and their detection by existing SETI projects.",
    "lastUpdated": "2008-07-28T18:33:18Z",
    "categories": [
      "physics.pop-ph",
      "astro-ph"
    ],
    "url": "http://arxiv.org/abs/0807.4518v1"
  },
  {
    "title": "Machine learning and AI research for Patient Benefit: 20 Critical Questions on Transparency, Replicability, Ethics and Effectiveness",
    "authors": [
      "Sebastian Vollmer",
      "Bilal A. Mateen",
      "Gergo Bohner",
      "Franz J Király",
      "Rayid Ghani",
      "Pall Jonsson",
      "Sarah Cumbers",
      "Adrian Jonas",
      "Katherine S. L. McAllister",
      "Puja Myles",
      "David Granger",
      "Mark Birse",
      "Richard Branson",
      "Karel GM Moons",
      "Gary S Collins",
      "John P. A. Ioannidis",
      "Chris Holmes",
      "Harry Hemingway"
    ],
    "abstract": "Machine learning (ML), artificial intelligence (AI) and other modern statistical methods are providing new opportunities to operationalize previously untapped and rapidly growing sources of data for patient benefit. Whilst there is a lot of promising research currently being undertaken, the literature as a whole lacks: transparency; clear reporting to facilitate replicability; exploration for potential ethical concerns; and, clear demonstrations of effectiveness. There are many reasons for why these issues exist, but one of the most important that we provide a preliminary solution for here is the current lack of ML/AI- specific best practice guidance. Although there is no consensus on what best practice looks in this field, we believe that interdisciplinary groups pursuing research and impact projects in the ML/AI for health domain would benefit from answering a series of questions based on the important issues that exist when undertaking work of this nature. Here we present 20 questions that span the entire project life cycle, from inception, data analysis, and model evaluation, to implementation, as a means to facilitate project planning and post-hoc (structured) independent evaluation. By beginning to answer these questions in different settings, we can start to understand what constitutes a good answer, and we expect that the resulting discussion will be central to developing an international consensus framework for transparent, replicable, ethical and effective research in artificial intelligence (AI-TREE) for health.",
    "lastUpdated": "2018-12-21T18:11:20Z",
    "categories": [
      "cs.CY",
      "cs.LG",
      "stat.AP",
      "stat.ML",
      "68T01"
    ],
    "url": "http://arxiv.org/abs/1812.10404v1"
  },
  {
    "title": "Response to Office of the Privacy Commissioner of Canada Consultation Proposals pertaining to amendments to PIPEDA relative to Artificial Intelligence",
    "authors": [
      "Mirka Snyder Caron",
      "Abhishek Gupta"
    ],
    "abstract": "In February 2020, the Montreal AI Ethics Institute (MAIEI) was invited by the Office of the Privacy Commissioner of Canada (OPCC) to provide for comments both at a closed roundtable and in writing on the OPCC consultation proposal for amendments relative to Artificial Intelligence (AI), to the Canadian privacy legislation, the Personal Information Protection and Electronic Documents Act (PIPEDA). The present document includes MAIEI comments and recommendations in writing. Per MAIEI's mission and mandate to act as a catalyst for public feedback pertaining to AI Ethics and regulatory technology developments, as well as to provide for public competence-building workshops on critical topics in such domains, the reader will also find such public feedback and propositions by Montrealers who participated at MAIEI's workshops, submitted as Schedule 1 to the present report. For each of OPCC 12 proposals, and underlying questions, as described on its website, MAIEI provides a short reply, a summary list of recommendations, as well as comments relevant to the question at hand. We leave you with three general statements to keep in mind while going through the next pages: 1) AI systems should be used to augment human capacity for meaningful and purposeful connections and associations, not as a substitute for trust. 2) Humans have collectively accepted to uphold the rule of law, but for machines, the code is rule. Where socio-technical systems are deployed to make important decisions, profiles or inferences about individuals, we will increasingly have to attempt the difficult exercise of drafting and encoding our law in a manner learnable by machines. 3) Let us work collectively towards a world where Responsible AI becomes the rule, before our socio-technical systems become \"too connected to fail\".",
    "lastUpdated": "2020-06-12T09:20:04Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2006.07025v1"
  },
  {
    "title": "Response by the Montreal AI Ethics Institute to the European Commission's Whitepaper on AI",
    "authors": [
      "Abhishek Gupta",
      "Camylle Lanteigne"
    ],
    "abstract": "In February 2020, the European Commission (EC) published a white paper entitled, On Artificial Intelligence - A European approach to excellence and trust. This paper outlines the EC's policy options for the promotion and adoption of artificial intelligence (AI) in the European Union. The Montreal AI Ethics Institute (MAIEI) reviewed this paper and published a response addressing the EC's plans to build an \"ecosystem of excellence\" and an \"ecosystem of trust,\" as well as the safety and liability implications of AI, the internet of things (IoT), and robotics. MAIEI provides 15 recommendations in relation to the sections outlined above, including: 1) focus efforts on the research and innovation community, member states, and the private sector; 2) create alignment between trading partners' policies and EU policies; 3) analyze the gaps in the ecosystem between theoretical frameworks and approaches to building trustworthy AI; 4) focus on coordination and policy alignment; 5) focus on mechanisms that promote private and secure sharing of data; 6) create a network of AI research excellence centres to strengthen the research and innovation community; 7) promote knowledge transfer and develop AI expertise through Digital Innovation Hubs; 8) add nuance to the discussion regarding the opacity of AI systems; 9) create a process for individuals to appeal an AI system's decision or output; 10) implement new rules and strengthen existing regulations; 11) ban the use of facial recognition technology; 12) hold all AI systems to similar standards and compulsory requirements; 13) ensure biometric identification systems fulfill the purpose for which they are implemented; 14) implement a voluntary labelling system for systems that are not considered high-risk; 15) appoint individuals to the oversight process who understand AI systems well and are able to communicate potential risks.",
    "lastUpdated": "2020-06-16T18:16:51Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2006.09428v1"
  },
  {
    "title": "Report prepared by the Montreal AI Ethics Institute (MAIEI) on Publication Norms for Responsible AI",
    "authors": [
      "Abhishek Gupta",
      "Camylle Lanteigne",
      "Victoria Heath"
    ],
    "abstract": "The history of science and technology shows that seemingly innocuous developments in scientific theories and research have enabled real-world applications with significant negative consequences for humanity. In order to ensure that the science and technology of AI is developed in a humane manner, we must develop research publication norms that are informed by our growing understanding of AI's potential threats and use cases. Unfortunately, it's difficult to create a set of publication norms for responsible AI because the field of AI is currently fragmented in terms of how this technology is researched, developed, funded, etc. To examine this challenge and find solutions, the Montreal AI Ethics Institute (MAIEI) co-hosted two public consultations with the Partnership on AI in May 2020. These meetups examined potential publication norms for responsible AI, with the goal of creating a clear set of recommendations and ways forward for publishers. In its submission, MAIEI provides six initial recommendations, these include: 1) create tools to navigate publication decisions, 2) offer a page number extension, 3) develop a network of peers, 4) require broad impact statements, 5) require the publication of expected results, and 6) revamp the peer-review process. After considering potential concerns regarding these recommendations, including constraining innovation and creating a \"black market\" for AI research, MAIEI outlines three ways forward for publishers, these include: 1) state clearly and consistently the need for established norms, 2) coordinate and build trust as a community, and 3) change the approach.",
    "lastUpdated": "2020-10-04T07:50:39Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2009.07262v2"
  },
  {
    "title": "Ethical Exploration and the Role of Planetary Protection in Disrupting Colonial Practices",
    "authors": [
      "Frank Tavares",
      "Denise Buckner",
      "Dana Burton",
      "Jordan McKaig",
      "Parvathy Prem",
      "Eleni Ravanis",
      "Natalie Trevino",
      "Aparna Venkatesan",
      "Steven D. Vance",
      "Monica Vidaurri",
      "Lucianne Walkowicz",
      "Mary Beth Wilhelm"
    ],
    "abstract": "We recommend that the planetary science and space exploration community engage in a robust reevaluation concerning the ethics of how future crewed and uncrewed missions to the Moon and Mars will interact with those planetary environments. This should occur through a process of community input, with emphasis on how such missions can resist colonial structures. Such discussions must be rooted in the historical context of the violent colonialism in the Americas and across the globe that has accompanied exploration of Earth. The structures created by settler colonialism are very much alive today, impact the scientific community, and are currently replicated in the space exploration communities' plans for human exploration and in-situ resource utilization. These discussions must lead to enforceable planetary protection policies that create a framework for ethical exploration of other worlds. Current policy does not adequately address questions related to in-situ resource utilization and environmental preservation and is without enforcement mechanisms. Further, interactions with potential extraterrestrial life have scientific and moral stakes. Decisions on these topics will be made in the coming decade as the Artemis program enables frequent missions to the Moon and crewed missions to Mars. Those first choices will have irreversible consequences for the future of human space exploration and must be extremely well considered, with input from those beyond the scientific community, including expertise from the humanities and members of the general public. Without planetary protection policy that actively resists colonial practices, they will be replicated in our interactions and exploration of other planetary bodies. The time is now to engage in these difficult conversations and disrupt colonial practices within our field so that they are not carried to other worlds.",
    "lastUpdated": "2020-10-27T21:46:15Z",
    "categories": [
      "astro-ph.IM",
      "astro-ph.EP"
    ],
    "url": "http://arxiv.org/abs/2010.08344v2"
  },
  {
    "title": "Developing Future Human-Centered Smart Cities: Critical Analysis of Smart City Security, Interpretability, and Ethical Challenges",
    "authors": [
      "Kashif Ahmad",
      "Majdi Maabreh",
      "Mohamed Ghaly",
      "Khalil Khan",
      "Junaid Qadir",
      "Ala Al-Fuqaha"
    ],
    "abstract": "As we make tremendous advances in machine learning and artificial intelligence technosciences, there is a renewed understanding in the AI community that we must ensure that humans being are at the center of our deliberations so that we don't end in technology-induced dystopias. As strongly argued by Green in his book Smart Enough City, the incorporation of technology in city environs does not automatically translate into prosperity, wellbeing, urban livability, or social justice. There is a great need to deliberate on the future of the cities worth living and designing. There are philosophical and ethical questions involved along with various challenges that relate to the security, safety, and interpretability of AI algorithms that will form the technological bedrock of future cities. Several research institutes on human centered AI have been established at top international universities. Globally there are calls for technology to be made more humane and human-compatible. For example, Stuart Russell has a book called Human Compatible AI. The Center for Humane Technology advocates for regulators and technology companies to avoid business models and product features that contribute to social problems such as extremism, polarization, misinformation, and Internet addiction. In this paper, we analyze and explore key challenges including security, robustness, interpretability, and ethical challenges to a successful deployment of AI or ML in human-centric applications, with a particular emphasis on the convergence of these challenges. We provide a detailed review of existing literature on these key challenges and analyze how one of these challenges may lead to others or help in solving other challenges. The paper also advises on the current limitations, pitfalls, and future directions of research in these domains, and how it can fill the current gaps and lead to better solutions.",
    "lastUpdated": "2020-12-14T18:54:05Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2012.09110v1"
  },
  {
    "title": "On the unitary transformation between non-quasifree and quasifree state spaces and its application to quantum field theory on curved spacetimes",
    "authors": [
      "H. Gottschalk",
      "T. Hack"
    ],
    "abstract": "Using $\\star$-calculus on the dual of the Borchers-Uhlmann algebra endowed with a combinatorial co-product, we develop a method to calculate a unitary transformation relating the GNS representations of a non-quasifree and a quasifree state of the free hermitian scalar field. The motivation for such an analysis and a further result is the fact that a unitary transformation of this kind arises naturally in scattering theory on non-stationary backgrounds. Indeed, employing the perturbation theory of the Yang-Feldman equations with a free CCR field in a quasifree state as an initial condition and making use of extended Feynman graphs, we are able to calculate the Wightman functions of the interacting and outgoing fields in a $\\phi^p$-theory on arbitrary curved spacetimes. A further examination then reveals two major features of the aforementioned theory: firstly, the interacting Wightman functions fulfil the basic axioms of hermiticity, invariance, spectrality (on stationary spacetimes), perturbative positivity, and locality. Secondly, the outgoing field is free and fulfils the CCR, but is in general not in a quasifree state in the case of a non-stationary spacetime. In order to obtain a sensible particle picture for the outgoing field and, hence, a description of the scattering process in terms of particles (in asymptotically flat spacetimes), it is thus necessary to compute a unitary transformation of the abovementioned type.",
    "lastUpdated": "2009-12-02T18:02:51Z",
    "categories": [
      "math-ph",
      "gr-qc",
      "math.MP",
      "81T20"
    ],
    "url": "http://arxiv.org/abs/math-ph/0610041v4"
  },
  {
    "title": "On the Backreaction of Scalar and Spinor Quantum Fields in Curved Spacetimes - From the Basic Foundations to Cosmological Applications",
    "authors": [
      "Thomas-Paul Hack"
    ],
    "abstract": "First, the present work is concerned with generalising constructions and results in quantum field theory on curved spacetimes from the well-known case of the Klein-Gordon field to Dirac fields. To this end, the enlarged algebra of observables of the Dirac field is constructed in the algebraic framework. This algebra contains normal-ordered Wick polynomials in particular, and an extended analysis of one of its elements, the stress-energy tensor, is performed. Based on detailed calculations of the Hadamard coefficients of the Dirac field, it is found that a construction of a stress-energy tensor fulfilling necessary physical properties is possible. Additionally, the mathematically sound Hadamard regularisation prescription of the stress-energy tensor is compared to the mathematically less rigorous DeWitt-Schwinger regularisation and it is found that both prescriptions are essentially equivalent in rigorous terms. While the aforementioned results hold in generic curved spacetimes, particular attention is also devoted to a specific class of Robertson-Walker spacetimes with a lightlike Big Bang hypersurface. Employing holographic methods, Hadamard states for the Klein-Gordon and the Dirac field are constructed. These states are preferred in the sense that they constitute asymptotic equilibrium states in the limit to the Big Bang hypersurface. Finally, solutions of the semiclassical Einstein equation for quantum fields of arbitrary spin are analysed in the flat Robertson-Walker case. One finds that these solutions explain the measured supernova Ia data as good as the $\\La$CDM model. Hence, one arrives at a natural explanation of dark energy and a simple quantum model of cosmological dark matter. It is the hope of the author that the present thesis can serve as an accessible introduction to the field of (algebraic) quantum field theory on curved spacetimes and its recent developments.",
    "lastUpdated": "2010-08-10T19:21:24Z",
    "categories": [
      "gr-qc",
      "hep-th",
      "math-ph",
      "math.MP"
    ],
    "url": "http://arxiv.org/abs/1008.1776v1"
  },
  {
    "title": "Statistical Analysis Driven Optimized Deep Learning System for Intrusion Detection",
    "authors": [
      "Cosimo Ieracitano",
      "Ahsan Adeel",
      "Mandar Gogate",
      "Kia Dashtipour",
      "Francesco Carlo Morabito",
      "Hadi Larijani",
      "Ali Raza",
      "Amir Hussain"
    ],
    "abstract": "Attackers have developed ever more sophisticated and intelligent ways to hack information and communication technology systems. The extent of damage an individual hacker can carry out upon infiltrating a system is well understood. A potentially catastrophic scenario can be envisaged where a nation-state intercepting encrypted financial data gets hacked. Thus, intelligent cybersecurity systems have become inevitably important for improved protection against malicious threats. However, as malware attacks continue to dramatically increase in volume and complexity, it has become ever more challenging for traditional analytic tools to detect and mitigate threat. Furthermore, a huge amount of data produced by large networks has made the recognition task even more complicated and challenging. In this work, we propose an innovative statistical analysis driven optimized deep learning system for intrusion detection. The proposed intrusion detection system (IDS) extracts optimized and more correlated features using big data visualization and statistical analysis methods (human-in-the-loop), followed by a deep autoencoder for potential threat detection. Specifically, a pre-processing module eliminates the outliers and converts categorical variables into one-hot-encoded vectors. The feature extraction module discard features with null values and selects the most significant features as input to the deep autoencoder model (trained in a greedy-wise manner). The NSL-KDD dataset from the Canadian Institute for Cybersecurity is used as a benchmark to evaluate the feasibility and effectiveness of the proposed architecture. Simulation results demonstrate the potential of our proposed system and its outperformance as compared to existing state-of-the-art methods and recently published novel approaches. Ongoing work includes further optimization and real-time evaluation of our proposed IDS.",
    "lastUpdated": "2018-08-16T18:24:12Z",
    "categories": [
      "cs.CR",
      "K.6.5; I.2.1; I.5.1"
    ],
    "url": "http://arxiv.org/abs/1808.05633v1"
  },
  {
    "title": "Automated Identification of On-hold Self-admitted Technical Debt",
    "authors": [
      "Rungroj Maipradit",
      "Bin Lin",
      "Csaba Nagy",
      "Gabriele Bavota",
      "Michele Lanza",
      "Hideaki Hata",
      "Kenichi Matsumoto"
    ],
    "abstract": "Modern software is developed under considerable time pressure, which implies that developers more often than not have to resort to compromises when it comes to code that is well written and code that just does the job. This has led over the past decades to the concept of \"technical debt\", a short-term hack that potentially generates long-term maintenance problems. Self-admitted technical debt (SATD) is a particular form of technical debt: developers consciously perform the hack but also document it in the code by adding comments as a reminder (or as an admission of guilt). We focus on a specific type of SATD, namely \"On-hold\" SATD, in which developers document in their comments the need to halt an implementation task due to conditions outside of their scope of work (e.g., an open issue must be closed before a function can be implemented). We present an approach, based on regular expressions and machine learning, which is able to detect issues referenced in code comments, and to automatically classify the detected instances as either \"On-hold\" (the issue is referenced to indicate the need to wait for its resolution before completing a task), or as \"cross-reference\", (the issue is referenced to document the code, for example to explain the rationale behind an implementation choice). Our approach also mines the issue tracker of the projects to check if the On-hold SATD instances are \"superfluous\" and can be removed (i.e., the referenced issue has been closed, but the SATD is still in the code). Our evaluation confirms that our approach can indeed identify relevant instances of On-hold SATD. We illustrate its usefulness by identifying superfluous On-hold SATD instances in open source projects as confirmed by the original developers.",
    "lastUpdated": "2020-09-28T07:44:58Z",
    "categories": [
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/2009.13113v1"
  },
  {
    "title": "SHARKS: Smart Hacking Approaches for RisK Scanning in Internet-of-Things and Cyber-Physical Systems based on Machine Learning",
    "authors": [
      "Tanujay Saha",
      "Najwa Aaraj",
      "Neel Ajjarapu",
      "Niraj K. Jha"
    ],
    "abstract": "Cyber-physical systems (CPS) and Internet-of-Things (IoT) devices are increasingly being deployed across multiple functionalities, ranging from healthcare devices and wearables to critical infrastructures, e.g., nuclear power plants, autonomous vehicles, smart cities, and smart homes. These devices are inherently not secure across their comprehensive software, hardware, and network stacks, thus presenting a large attack surface that can be exploited by hackers. In this article, we present an innovative technique for detecting unknown system vulnerabilities, managing these vulnerabilities, and improving incident response when such vulnerabilities are exploited. The novelty of this approach lies in extracting intelligence from known real-world CPS/IoT attacks, representing them in the form of regular expressions, and employing machine learning (ML) techniques on this ensemble of regular expressions to generate new attack vectors and security vulnerabilities. Our results show that 10 new attack vectors and 122 new vulnerability exploits can be successfully generated that have the potential to exploit a CPS or an IoT ecosystem. The ML methodology achieves an accuracy of 97.4% and enables us to predict these attacks efficiently with an 87.2% reduction in the search space. We demonstrate the application of our method to the hacking of the in-vehicle network of a connected car. To defend against the known attacks and possible novel exploits, we discuss a defense-in-depth mechanism for various classes of attacks and the classification of data targeted by such attacks. This defense mechanism optimizes the cost of security measures based on the sensitivity of the protected resource, thus incentivizing its adoption in real-world CPS/IoT by cybersecurity practitioners.",
    "lastUpdated": "2021-01-07T22:01:30Z",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2101.02780v1"
  },
  {
    "title": "Cosmic Irony: SETI Optimism from Catastrophes?",
    "authors": [
      "Milan M. Cirkovic"
    ],
    "abstract": "Classical arguments for skepticism regarding the Search for ExtraTerrestrial Intelligence (SETI) are critically examined. It is suggested that the emerging class of \"phase transition\" astrobiological models can simultaneously account for all available astrophysical and biological evidence, explain several unresolved puzzle in Earth sciences, and rationally justify current and future SETI projects. In particular, the hypothesis of Annis that local gamma-ray bursts drive the astrobiological phase transition deserves to be further quantitatively elucidated. Some epistemological and ethical ramifications of such a model are briefly discussed.",
    "lastUpdated": "2003-09-29T09:09:18Z",
    "categories": [
      "astro-ph"
    ],
    "url": "http://arxiv.org/abs/astro-ph/0309769v1"
  },
  {
    "title": "Should Cyberspace Chat Rooms be closed to protect Children?",
    "authors": [
      "Vita Hinze-Hoare"
    ],
    "abstract": "The explosion of people networking in cyberspace, disseminating terabytes of information, is being promoted through the use of broadband, bluetooth technology, and wireless mobile computing facilities. New communities within such venues as virtual chat rooms discussion groups, newsgroups etc are being created daily and even hourly. This is raising issues of cyberethics concerning privacy,security, crime, human needs, e-business, e-healthcare, e-government and intellectual property among others that need to be evaluated and reflected upon. With this new freedom come new moral and ethical responsibilities, which raise questions as to whether anything can be published or whether there should be restrictions. This paper addresses one specific area, that has come into the public eye, the closure by Microsoft of all of its free chat rooms.",
    "lastUpdated": "2004-09-11T19:23:21Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/cs/0409021v1"
  },
  {
    "title": "Making sense of Physics in the first year of study",
    "authors": [
      "Shirley Booth",
      "Ake Ingerman"
    ],
    "abstract": "We address the question \"How do students make sense of Physics from the point of view of constituting physics knowledge?\". A phenomenographic study is described as a result of which we present six qualitatively different ways in which students experience the first year of Physics. The variation is analysed in terms of the structure of experience, the nature of knowlege and an ethical aspect related to the identification of authority. Three of these ways of experiencing the first year are considered to be unproductive in terms of making sense of physics, while the other three support, to an increasing degree, the formation of a well-grounded physics knowledge object. Implications for practice are considered.",
    "lastUpdated": "1999-11-26T16:47:19Z",
    "categories": [
      "physics.ed-ph"
    ],
    "url": "http://arxiv.org/abs/physics/9911071v1"
  },
  {
    "title": "Science as a Culture - Its Implications",
    "authors": [
      "Shyamal Sengupta"
    ],
    "abstract": "This is a lecture on the ethics and role of science in promoting rational and objective thinking in society. It was delivered by Prof. Shyamal Sengupta of Kolkata, India. Prof. Sengupta, who passed away recently, has inspired generations of Indian physicists by his rational viewpoints on science and by teaching his students the importance of a scientific outlook. We, some of his former students dedicate this small corner of the archive to his fond memory.",
    "lastUpdated": "2003-10-30T22:51:05Z",
    "categories": [
      "physics.soc-ph"
    ],
    "url": "http://arxiv.org/abs/physics/0310161v1"
  },
  {
    "title": "Towards a New Democracy: Consensus Through Quantum Parliament",
    "authors": [
      "Diederik Aerts"
    ],
    "abstract": "We compare different actual forms of democracy and analyse in which way they are variations of a 'natural consensus decision process'. We analyse how 'consensus decision followed by majority voting' is open to 'false play' by the majority, and investigate how other types of false play appear in alternative types of democratic decision procedures. We introduce the combined notion of 'quantum parliament' and 'quantum decision procedure', and prove it to be the only one, when applied after consensus decision, that is immune to false play.",
    "lastUpdated": "2005-03-09T19:04:49Z",
    "categories": [
      "physics.soc-ph"
    ],
    "url": "http://arxiv.org/abs/physics/0503078v1"
  },
  {
    "title": "Societal and ethical interactions with nanotechnology (\"SEIN\") -- an introduction",
    "authors": [
      "Davis Baird",
      "Tom Vogt"
    ],
    "abstract": "We identify 6 important issues tied to the continued development of nantechnology: (1) environmental issues, (2) equity issues relating to the possible emergence of a \"nanodivide\", (3) legal, regulatory and insurance challenges, (4) privacy issues, (5) the interaction between nanomedicine and medical issues and (6) \"hypertechnology, or the pace of nanotechnological change. We conclude that continued efforts are needed to build upon an emerging inclusice dialogue engaging all of nano's stakeholders - from various publics to entrepreneurs, industrialists, venture capitalists, scientists and engineers-to ensure a mutually beneficial relationship between nanotechnology and society.",
    "lastUpdated": "2005-04-01T15:06:33Z",
    "categories": [
      "physics.soc-ph"
    ],
    "url": "http://arxiv.org/abs/physics/0504007v1"
  },
  {
    "title": "Taking nanotechnology to schools",
    "authors": [
      "Akhlesh Lakhtakia"
    ],
    "abstract": "After a primer on nanotechnology and a review of current educational practices in secondary schools, the concept of just-in-time education is proposed to integrate technosciences and humanities so that both future technoscientists and non-technoscientists develop a common understanding, possibly even a common language, to deal with social, ethical, legal, and political issues that arise from the development of nanotechnology and its convergence with other technoscientific developments.",
    "lastUpdated": "2005-05-06T17:11:36Z",
    "categories": [
      "physics.soc-ph",
      "physics.ed-ph"
    ],
    "url": "http://arxiv.org/abs/physics/0505007v2"
  },
  {
    "title": "A Map of the Nanoworld: Sizing up the Science, Politics, and Business of the Infinitesimal",
    "authors": [
      "Debashish Munshi",
      "Priya Kurian",
      "Robert V. Bartlett",
      "Akhlesh Lakhtakia"
    ],
    "abstract": "Mapping out the eight main nodes of nanotechnology discourse that have emerged in the past decade, we explore how various scientific, social, and ethical islands of discussion have developed, been recognized, and are being continually renegotiated. We do so by (1) identifying the ways in which scientists, policy makers, entrepreneurs, educators, and environmental groups have drawn boundaries on issues relating to nanotechnology; (2) describing concisely the perspectives from which these boundaries are drawn; and (3) exploring how boundaries on nanotechnology are marked and negotiated by various nodes of nanotechnology discourse.",
    "lastUpdated": "2005-10-24T01:58:18Z",
    "categories": [
      "physics.soc-ph",
      "physics.ed-ph",
      "physics.optics"
    ],
    "url": "http://arxiv.org/abs/physics/0510209v1"
  },
  {
    "title": "Analysis of Free Will and Determinism in Physics",
    "authors": [
      "Edgar Jose Candales Dugarte"
    ],
    "abstract": "It is considered the study of determinism in the theories of physics. Based on fundamental postulates of physics, it is proved that the evolution of the universe is univocally determined, proving ultimately that free will does not exist. In addition, it is presented some contradictions and weaknesses of quantum mechanics, suggesting paradoxes in the theory. It is also analyzed some consequences of the postulates in justice and ethics.",
    "lastUpdated": "2014-06-27T14:20:40Z",
    "categories": [
      "physics.gen-ph",
      "physics.hist-ph"
    ],
    "url": "http://arxiv.org/abs/1407.1804v1"
  },
  {
    "title": "Why is cheating wrong?",
    "authors": [
      "Mathieu Bouville"
    ],
    "abstract": "Since cheating is obviously wrong, arguments against it (it provides an unfair advantage, it hinders learning) need only be mentioned in passing. But the argument of unfair advantage absurdly takes education to be essentially a race of all against all; moreover, it ignores that many cases of unfair (dis)advantages are widely accepted. That cheating can hamper learning does not mean that punishing cheating will necessarily favor learning, so that this argument does not obviously justify sanctioning cheaters. -- Keywords: academic dishonesty, academic integrity, academic misconduct, education, ethics, homework, plagiarism",
    "lastUpdated": "2008-09-02T19:53:31Z",
    "categories": [
      "physics.ed-ph"
    ],
    "url": "http://arxiv.org/abs/0803.1530v2"
  },
  {
    "title": "Crime and punishment in scientific research",
    "authors": [
      "Mathieu Bouville"
    ],
    "abstract": "Typical arguments against scientific misconduct generally fail to support current policies on research fraud: they may not prove wrong what is usually considered research misconduct and they tend to make wrong things that are not normally seen as scientific fraud, in particular honest errors. I also point out that sanctions are not consistent with the reasons why scientific fraud is supposed to be wrong either. Moreover honestly seeking truth should not be contrived as a moral rule -- it is instead a necessary condition for work to qualify as scientific. Keywords: cheating; ethics; fabrication; falsification; integrity; plagiarism; research fraud; scientific misconduct.",
    "lastUpdated": "2008-09-17T14:53:47Z",
    "categories": [
      "physics.soc-ph",
      "physics.hist-ph"
    ],
    "url": "http://arxiv.org/abs/0803.4058v3"
  },
  {
    "title": "Apuntes sobre teoría del comportamiento corrupto: nociones cibernéticas e informáticas para una actualización de la ecuación de Klitgaard",
    "authors": [
      "Rodrigo Lopez-Pablos"
    ],
    "abstract": "This essay presents an exploration of elements from information theory and cibernetics on the struggle against corruption behavior in public sector and beyond; the existence of an exemplary or corrupt ethical equilibriums are explored by updating Klitgaard corruption formula along with the presence of information pressure, entropy and cibernetics servomechanisms in digital societies, including alternatives and sistemics approaches for further anti-corruption policies implementation.",
    "lastUpdated": "2015-04-01T18:32:02Z",
    "categories": [
      "cs.IT",
      "math.IT",
      "J.4; K.4.1"
    ],
    "url": "http://arxiv.org/abs/1503.06842v3"
  },
  {
    "title": "Medical Wearable Technologies: Applications, Problems and Solutions",
    "authors": [
      "Erkan Bostanci"
    ],
    "abstract": "The focus of this paper is on wearable technologies which are increasingly being employed in the medical field. From smart watches to smart glasses, from electronic textile to data gloves; several gadgets are playing important roles in diagnosis and treatment of various medical conditions. The threats posed by these technologies are another matter of concern that must be seriously taken into account. Numerous threats ranging from data privacy to big data problems are facing us as adverse effects of these technologies. The paper analyses the application areas and challenges of wearable technologies from a technical and ethical point of view and presents solutions to possible threats.",
    "lastUpdated": "2015-12-08T06:29:27Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1512.02347v1"
  },
  {
    "title": "A Case-Based Look at Integrating Social Context into Software Quality",
    "authors": [
      "Nicole Radziwill",
      "Morgan Benton",
      "Kenneth Boadu",
      "Wilson Perdomo"
    ],
    "abstract": "Ensuring high-quality software requires considering the social climate within which the applications will be deployed and used. This can be done by designing quality goals and objectives that are consistent with changing social and ethical landscapes. Using principles of technological determinism, this article presents three cases that illustrate why it is becoming even more important to integrate these concerns into software design and quality assurance. With these examples in mind, this article explains how to consider technological determinism in software design and quality assurance practices to achieve this enhanced sensitivity on a practical level.",
    "lastUpdated": "2015-12-09T01:00:34Z",
    "categories": [
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/1512.02708v1"
  },
  {
    "title": "Reflections on Cyberethics Education for Millennial Software Engineers",
    "authors": [
      "Claudia de O. Melo",
      "Thiago C. de Sousa"
    ],
    "abstract": "Software is a key component of solutions for 21st Century problems. These problems are often \"wicked\", complex, and unpredictable. To provide the best possible solution, millennial software engineers must be prepared to make ethical decisions, thinking critically, and acting systematically. This reality demands continuous changes in educational systems and curricula delivery, as misjudgment might have serious social impact. This study aims to investigate and reflect on Software Engineering (SE) Programs, proposing a conceptual framework for analyzing cyberethics education and a set of suggestions on how to integrate it into the SE undergraduate curriculum.",
    "lastUpdated": "2017-03-02T05:00:50Z",
    "categories": [
      "cs.SE",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1703.00619v1"
  },
  {
    "title": "Goal Conflict in Designing an Autonomous Artificial System",
    "authors": [
      "Mark Muraven"
    ],
    "abstract": "Research on human self-regulation has shown that people hold many goals simultaneously and have complex self-regulation mechanisms to deal with this goal conflict. Artificial autonomous systems may also need to find ways to cope with conflicting goals. Indeed, the intricate interplay among different goals may be critical to the design as well as long-term safety and stability of artificial autonomous systems. I discuss some of the critical features of the human self-regulation system and how it might be applied to an artificial system. Furthermore, the implications of goal conflict for the reliability and stability of artificial autonomous systems and ensuring their alignment with human goals and ethics is examined.",
    "lastUpdated": "2017-03-18T21:25:29Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1703.06354v1"
  },
  {
    "title": "Une réflexion à partir de la Nature de Spinoza : \"La substance ou la Nature comme Treillis\"",
    "authors": [
      "Mohammed Bachir",
      "Mohammed Bachir En Hommage À Baruch"
    ],
    "abstract": "We propose a simple mathematical model based on two axioms and the set theory to approach the problem developed by the philosopher B. Spinoza in \"the Ethics\". We then use the Knaster-Tarski Theorem to prove the existence and uniqueness of the Substance asserted by Spinoza.",
    "lastUpdated": "2018-03-12T14:30:43Z",
    "categories": [
      "math.GM"
    ],
    "url": "http://arxiv.org/abs/1707.03291v3"
  },
  {
    "title": "Robotics Technology in Mental Health Care",
    "authors": [
      "Laurel D. Riek"
    ],
    "abstract": "This chapter discusses the existing and future use of robotics and intelligent sensing technology in mental health care. While the use of this technology is nascent in mental health care, it represents a potentially useful tool in the practitioner's toolbox. The goal of this chapter is to provide a brief overview of the field, discuss the recent use of robotics technology in mental health care practice, explore some of the design issues and ethical issues of using robots in this space, and finally to explore the potential of emerging technology.",
    "lastUpdated": "2015-11-07T01:58:51Z",
    "categories": [
      "cs.RO",
      "cs.CY",
      "cs.HC",
      "I.2.9; J.3"
    ],
    "url": "http://arxiv.org/abs/1511.02281v1"
  },
  {
    "title": "Don't Fear the Reaper: Refuting Bostrom's Superintelligence Argument",
    "authors": [
      "Sebastian Benthall"
    ],
    "abstract": "In recent years prominent intellectuals have raised ethical concerns about the consequences of artificial intelligence. One concern is that an autonomous agent might modify itself to become \"superintelligent\" and, in supremely effective pursuit of poorly specified goals, destroy all of humanity. This paper considers and rejects the possibility of this outcome. We argue that this scenario depends on an agent's ability to rapidly improve its ability to predict its environment through self-modification. Using a Bayesian model of a reasoning agent, we show that there are important limitations to how an agent may improve its predictive ability through self-modification alone. We conclude that concern about this artificial intelligence outcome is misplaced and better directed at policy questions around data access and storage.",
    "lastUpdated": "2017-03-04T20:43:32Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1702.08495v2"
  },
  {
    "title": "Static Gesture Recognition using Leap Motion",
    "authors": [
      "Babak Toghiani-Rizi",
      "Christofer Lind",
      "Maria Svensson",
      "Marcus Windmark"
    ],
    "abstract": "In this report, an automated bartender system was developed for making orders in a bar using hand gestures. The gesture recognition of the system was developed using Machine Learning techniques, where the model was trained to classify gestures using collected data. The final model used in the system reached an average accuracy of 95%. The system raised ethical concerns both in terms of user interaction and having such a system in a real world scenario, but it could initially work as a complement to a real bartender.",
    "lastUpdated": "2017-05-16T19:38:20Z",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.CV",
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/1705.05884v1"
  },
  {
    "title": "Group Sequential Clinical Trial Designs for Normally Distributed Outcome Variables",
    "authors": [
      "Michael Grayling",
      "James Wason",
      "Adrian Mander"
    ],
    "abstract": "In a group sequential clinical trial, accumulated data are analysed at numerous time-points in order to allow early decisions about a hypothesis of interest. These designs have historically been recommended for their ethical, administrative and economic benefits. In this work, we discuss a collection of new Stata commands for computing the stopping boundaries and required group size of various classical group sequential designs, assuming a normally distributed outcome variable. Following this, we demonstrate how the performance of several designs can be compared graphically.",
    "lastUpdated": "2017-11-28T09:09:35Z",
    "categories": [
      "stat.CO"
    ],
    "url": "http://arxiv.org/abs/1710.03127v2"
  },
  {
    "title": "A Cross-Country Comparison of Crowdworker Motivations",
    "authors": [
      "Lisa Posch",
      "Arnim Bleier",
      "Fabian Flöck",
      "Markus Strohmaier"
    ],
    "abstract": "Crowd employment is a new form of short term employment that has been rapidly becoming a source of income for a vast number of people around the globe. It differs considerably from more traditional forms of work, yet similar ethical and optimization issues arise. One key to tackle such challenges is to understand what motivates the international crowd workforce. In this work, we study the motivation of workers involved in one particularly prevalent type of crowd employment: micro-tasks. We report on the results of applying the Multidimensional Crowdworker Motivation Scale (MCMS) in ten countries, which unveil significant international differences.",
    "lastUpdated": "2017-11-08T19:00:58Z",
    "categories": [
      "cs.SI",
      "cs.CY",
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/1711.03115v1"
  },
  {
    "title": "Demystifying Deception Technology:A Survey",
    "authors": [
      "Daniel Fraunholz",
      "Simon Duque Anton",
      "Christoph Lipps",
      "Daniel Reti",
      "Daniel Krohmer",
      "Frederic Pohl",
      "Matthias Tammen",
      "Hans Dieter Schotten"
    ],
    "abstract": "Deception boosts security for systems and components by denial, deceit, misinformation, camouflage and obfuscation. In this work an extensive overview of the deception technology environment is presented. Taxonomies, theoretical backgrounds, psychological aspects as well as concepts, implementations, legal aspects and ethics are discussed and compared.",
    "lastUpdated": "2018-04-17T12:25:39Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1804.06196v1"
  },
  {
    "title": "Building Data Science Capabilities into University Data Warehouse to Predict Graduation",
    "authors": [
      "Joonas Pesonen",
      "Anna Fomkin",
      "Lauri Jokipii"
    ],
    "abstract": "The discipline of data science emerged to combine statistical methods with computing. At Aalto University, Finland, we have taken first steps to bring educational data science as a part of daily operations of Management Information Services. This required changes in IT environment: we enhanced data warehouse infrastructure with a data science lab, where we can read predictive model training data from data warehouse database and use the created predictive models in database queries. We then conducted a data science pilot with an objective to predict students' graduation probability and time-to-degree with student registry data. Further ethical and legal considerations are needed before using predictions in daily operations of the university.",
    "lastUpdated": "2018-05-04T12:28:03Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1805.05401v1"
  },
  {
    "title": "Quasi-Dilemmas for Artificial Moral Agents",
    "authors": [
      "Daniel Kasenberg",
      "Vasanth Sarathy",
      "Thomas Arnold",
      "Matthias Scheutz",
      "Tom Williams"
    ],
    "abstract": "In this paper we describe moral quasi-dilemmas (MQDs): situations similar to moral dilemmas, but in which an agent is unsure whether exploring the plan space or the world may reveal a course of action that satisfies all moral requirements. We argue that artificial moral agents (AMAs) should be built to handle MQDs (in particular, by exploring the plan space rather than immediately accepting the inevitability of the moral dilemma), and that MQDs may be useful for evaluating AMA architectures.",
    "lastUpdated": "2018-07-06T21:34:48Z",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1807.02572v1"
  },
  {
    "title": "BriarPatches: Pixel-Space Interventions for Inducing Demographic Parity",
    "authors": [
      "Alexey A. Gritsenko",
      "Alex D'Amour",
      "James Atwood",
      "Yoni Halpern",
      "D. Sculley"
    ],
    "abstract": "We introduce the BriarPatch, a pixel-space intervention that obscures sensitive attributes from representations encoded in pre-trained classifiers. The patches encourage internal model representations not to encode sensitive information, which has the effect of pushing downstream predictors towards exhibiting demographic parity with respect to the sensitive information. The net result is that these BriarPatches provide an intervention mechanism available at user level, and complements prior research on fair representations that were previously only applicable by model developers and ML experts.",
    "lastUpdated": "2018-12-17T16:13:42Z",
    "categories": [
      "cs.LG",
      "cs.CV",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1812.06869v1"
  },
  {
    "title": "Proceedings of the Workshop on Social Robots in Therapy: Focusing on Autonomy and Ethical Challenges",
    "authors": [
      "Pablo G. Esteban",
      "Daniel Hernández García",
      "Hee Rin Lee",
      "Pauline Chevalier",
      "Paul Baxter",
      "Cindy L. Bethel",
      "Jainendra Shukla",
      "Joan Oliver",
      "Domènec Puig",
      "Jason R. Wilson",
      "Linda Tickle-Degnen",
      "Madeleine Bartlett",
      "Tony Belpaeme",
      "Serge Thill",
      "Kim Baraka",
      "Francisco S. Melo",
      "Manuela Veloso",
      "David Becerra",
      "Maja Matarić",
      "Eduard Fosch-Villaronga",
      "Jordi Albo-Canals",
      "Gloria Beraldo",
      "Emanuele Menegatti",
      "Valentina De Tommasi",
      "Roberto Mancin",
      "Franca Benini",
      "Zachary Henkel",
      "Kenna Baugus",
      "David C. May",
      "Lucile Dupuy",
      "Wendy A. Rogers",
      "Ronit Feingold Polak",
      "Shelly Levy-Tzedek",
      "Dagoberto Cruz-Sandoval",
      "Jesus Favela",
      "Michelle J. Johnson",
      "Mayumi Mohan",
      "Rochelle Mendonca"
    ],
    "abstract": "Robot-Assisted Therapy (RAT) has successfully been used in HRI research by including social robots in health-care interventions by virtue of their ability to engage human users both social and emotional dimensions. Research projects on this topic exist all over the globe in the USA, Europe, and Asia. All of these projects have the overall ambitious goal to increase the well-being of a vulnerable population. Typical work in RAT is performed using remote controlled robots; a technique called Wizard-of-Oz (WoZ). The robot is usually controlled, unbeknownst to the patient, by a human operator. However, WoZ has been demonstrated to not be a sustainable technique in the long-term. Providing the robots with autonomy (while remaining under the supervision of the therapist) has the potential to lighten the therapists burden, not only in the therapeutic session itself but also in longer-term diagnostic tasks. Therefore, there is a need for exploring several degrees of autonomy in social robots used in therapy. Increasing the autonomy of robots might also bring about a new set of challenges. In particular, there will be a need to answer new ethical questions regarding the use of robots with a vulnerable population, as well as a need to ensure ethically-compliant robot behaviours. Therefore, in this workshop we want to gather findings and explore which degree of autonomy might help to improve health-care interventions and how we can overcome the ethical challenges inherent to it.",
    "lastUpdated": "2018-12-18T19:30:04Z",
    "categories": [
      "cs.RO"
    ],
    "url": "http://arxiv.org/abs/1812.07613v1"
  },
  {
    "title": "A Logic of Objective and Subjective Oughts (full paper with proofs)",
    "authors": [
      "Aldo Iván Ramírez Abarca",
      "Jan Broersen"
    ],
    "abstract": "The relation between agentive action, knowledge, and obligation is central to the understanding of responsibility --a main topic in Artificial Intelligence. Based on the view that an appropriate formalization of said relation would contribute to the development of ethical AI, we point out the main characteristics of a logic for objective and subjective oughts that was recently introduced in the literature. This logic extends the traditional stit paradigm with deontic and epistemic operators, and provides a semantics that deals with Horty's puzzles for knowledge and obligation. We provide an axiomatization for this logic, and address its soundness and completeness with respect to a class of relevant models.",
    "lastUpdated": "2019-03-25T20:05:25Z",
    "categories": [
      "math.LO"
    ],
    "url": "http://arxiv.org/abs/1903.10577v1"
  },
  {
    "title": "Uniqueness of Medical Data Mining: How the new technologies and data they generate are transforming medicine",
    "authors": [
      "Krzysztof J. Cios",
      "Bartosz Krawczyk",
      "Jacquelyne Cios",
      "Kevin J. Staley"
    ],
    "abstract": "The paper describes how the new technologies and data they generate are transforming medicine. It stresses the uniqueness of heterogeneous medical data and the ways of dealing with them. It lists different sources that generate big medical data, their security, legal and ethical issues, as well as machine learning/AI methods of dealing with them. A unique feature of the paper is use of case studies to illustrate how the new technologies influence medical practice.",
    "lastUpdated": "2019-05-22T15:52:08Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1905.09203v1"
  },
  {
    "title": "Raiders of the Lost Art",
    "authors": [
      "Anthony Bourached",
      "George Cann"
    ],
    "abstract": "Neural style transfer, first proposed by Gatys et al. (2015), can be used to create novel artistic work through rendering a content image in the form of a style image. We present a novel method of reconstructing lost artwork, by applying neural style transfer to x-radiographs of artwork with secondary interior artwork beneath a primary exterior, so as to reconstruct lost artwork. Finally we reflect on AI art exhibitions and discuss the social, cultural, ethical, and philosophical impact of these technical innovations.",
    "lastUpdated": "2019-09-10T12:14:04Z",
    "categories": [
      "cs.CV",
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1909.05677v1"
  },
  {
    "title": "A Formal Approach to Explainability",
    "authors": [
      "Lior Wolf",
      "Tomer Galanti",
      "Tamir Hazan"
    ],
    "abstract": "We regard explanations as a blending of the input sample and the model's output and offer a few definitions that capture various desired properties of the function that generates these explanations. We study the links between these properties and between explanation-generating functions and intermediate representations of learned models and are able to show, for example, that if the activations of a given layer are consistent with an explanation, then so do all other subsequent layers. In addition, we study the intersection and union of explanations as a way to construct new explanations.",
    "lastUpdated": "2020-01-15T10:06:47Z",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2001.05207v1"
  },
  {
    "title": "Towards organizational guidelines for the responsible use of AI",
    "authors": [
      "Richard Benjamins"
    ],
    "abstract": "In the past few years, several large companies have published ethical principles of Artificial Intelligence (AI). National governments, the European Commission, and inter-governmental organizations have come up with requirements to ensure the good use of AI. However, individual organizations that want to join this effort, are faced with many unsolved questions. This paper proposes guidelines for organizations committed to the responsible use of AI, but lack the required knowledge and experience. The guidelines consist of two parts: i) helping organizations to decide what principles to adopt, and ii) a methodology for implementing the principles in organizational processes. In case of future AI regulation, organizations following this approach will be well-prepared.",
    "lastUpdated": "2020-05-05T11:26:57Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2001.09758v2"
  },
  {
    "title": "Hacia los Comités de Ética en Inteligencia Artificial",
    "authors": [
      "Sofía Trejo",
      "Ivan Meza",
      "Fernanda López-Escobedo"
    ],
    "abstract": "The goal of Artificial Intelligence based systems is to take decisions that have an effect in their environment and impact society. This points out to the necessity of mechanism that regulate the impact of this type of system in society. For this reason, it is priority to create the rules and specialized organizations that can oversight the following of such rules, particularly that human rights precepts at local and international level. This work proposes the creation, at the universities, of Ethical Committees or Commissions specialized on Artificial Intelligence that would be in charge of define the principles and will guarantee the following of good practices in the field Artificial Intelligence.",
    "lastUpdated": "2020-02-11T23:48:31Z",
    "categories": [
      "cs.CY",
      "K.m"
    ],
    "url": "http://arxiv.org/abs/2002.05673v1"
  },
  {
    "title": "On the Emerging Area of Biocybersecurity and Relevant Considerations",
    "authors": [
      "Xavier-Lewis Palmer",
      "Lucas Potter",
      "Saltuk Karahan"
    ],
    "abstract": "Biocybersecurity is a novel space for the 21st century that meets our innovations in biotechnology and computing head on. Within this space, many considerations are open for and demand consideration as groups endeavor to develop products and policies that adequately ensure asset management and protection. Herein, simplified and brief exploration is given followed by some surface discussion of impacts. These impacts concern the end user, ethical and legal considerations, international proceedings, business, and limitations. It is hoped that this will be helpful in future considerations towards biocybersecurity policy developments and implementations. Notice: This article has been queued for publication in the Proceedings of the 2020 Future of Information and Communication Conference (FICC)",
    "lastUpdated": "2020-03-25T03:44:51Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2003.12132v1"
  },
  {
    "title": "Theoretical Physics and Indian Philosophy: Conceptual Coherence",
    "authors": [
      "Anna Sidorova-Biryukova"
    ],
    "abstract": "The paper addresses the phenomenon of cross-cultural resonance, which arises when ideas coming from different cultures and view systems show mutual correlation, or coherence. We particularly dwell on the parallels between modern physics and Indian classical philosophy. The coherence in ideological, methodological, and ethical spheres is noted and exemplified. Interpretation of correlations in terms of the Jaspers 'ciphers of transcendence' is proposed. A brief survey of studies also dealing with coherence between modern science and ancient teachings is given. In conclusion, a broader perspective of interrelations between rational science and spiritual tradition is discussed.",
    "lastUpdated": "2020-04-05T10:32:59Z",
    "categories": [
      "physics.hist-ph"
    ],
    "url": "http://arxiv.org/abs/2004.02150v1"
  },
  {
    "title": "On the Ethics of Building AI in a Responsible Manner",
    "authors": [
      "Shai Shalev-Shwartz",
      "Shaked Shammah",
      "Amnon Shashua"
    ],
    "abstract": "The AI-alignment problem arises when there is a discrepancy between the goals that a human designer specifies to an AI learner and a potential catastrophic outcome that does not reflect what the human designer really wants. We argue that a formalism of AI alignment that does not distinguish between strategic and agnostic misalignments is not useful, as it deems all technology as un-safe. We propose a definition of a strategic-AI-alignment and prove that most machine learning algorithms that are being used in practice today do not suffer from the strategic-AI-alignment problem. However, without being careful, today's technology might lead to strategic misalignment.",
    "lastUpdated": "2020-03-30T04:11:08Z",
    "categories": [
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2004.04644v1"
  },
  {
    "title": "Fair navigation planning: a humanitarian robot use case",
    "authors": [
      "Martim Brandao"
    ],
    "abstract": "In this paper we investigate potential issues of fairness related to the motion of mobile robots. We focus on the particular use case of humanitarian mapping and disaster response. We start by showing that there is a fairness dimension to robot navigation, and use a walkthrough example to bring out design choices and issues that arise during the development of a fair system. We discuss indirect discrimination, fairness-efficiency trade-offs, the existence of counter-productive fairness definitions, privacy and other issues. Finally, we conclude with a discussion of the potential of our methodology as a concrete responsible innovation tool for eliciting ethical issues in the design of autonomous systems.",
    "lastUpdated": "2020-06-25T15:23:15Z",
    "categories": [
      "cs.CY",
      "cs.RO"
    ],
    "url": "http://arxiv.org/abs/2006.14479v1"
  },
  {
    "title": "Nice guys don't always finish last: succeeding in hierarchical organizations",
    "authors": [
      "Doron Klunover"
    ],
    "abstract": "What are the chances of an ethical individual rising through the ranks of a political party or a corporation in the presence of unethical peers? To answer this question, I consider a four-player two-stage elimination tournament, in which players are partitioned into those willing to be involved in sabotage behavior and those who are not. I show that, under certain conditions, the latter are more likely to win the tournament.",
    "lastUpdated": "2020-09-07T14:43:34Z",
    "categories": [
      "econ.GN",
      "q-fin.EC"
    ],
    "url": "http://arxiv.org/abs/2007.04435v4"
  },
  {
    "title": "Addressing the Privacy Implications of Mixed Reality: A Regulatory Approach",
    "authors": [
      "Nicole Shadowen",
      "Diane Hosfelt"
    ],
    "abstract": "Mixed reality (MR) technologies are emerging into the mainstream with affordable devices like the Oculus Quest. These devices blend the physical and virtual in novel ways that blur the lines that exist in legal precedent, like those between speech and conduct. In this paper, we discuss the challenges of regulating immersive technologies, focusing on the potential for extensive data collection, and examine the trade-offs of three potential approaches to protecting data privacy in the context of mixed reality environments.",
    "lastUpdated": "2020-07-20T16:35:17Z",
    "categories": [
      "cs.CR",
      "cs.CY",
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/2007.10246v1"
  },
  {
    "title": "Comment on: \"The interaction of neutrons with 7Be at BBN temperatures: Lack of Standard Nuclear Solution to the Primordial 7Li Problem\" by M. Gai et al",
    "authors": [
      "M. Paul",
      "R. Dressler",
      "U. Koester",
      "D. Schumann"
    ],
    "abstract": "The article recently published by M. Gai et al. claims to reach conclusions from a collaborative experiment dedicated to the study of the 7Be(n,alpha) reaction. These claims were published with no authorization from key collaborators, including a PI of the experiment. The Authors of the present Comment reject the conclusions of M. Gai et et al. and condemn the scientific and ethical misconduct involved in their publication. A formal Comment, similarly expressing the Authors' rejection of these conclusions was submitted to EPJ Web of Conferences who published the above article.",
    "lastUpdated": "2020-10-27T23:19:30Z",
    "categories": [
      "nucl-ex"
    ],
    "url": "http://arxiv.org/abs/2008.06049v2"
  },
  {
    "title": "Bias and Discrimination in AI: a cross-disciplinary perspective",
    "authors": [
      "Xavier Ferrer",
      "Tom van Nuenen",
      "Jose M. Such",
      "Mark Coté",
      "Natalia Criado"
    ],
    "abstract": "With the widespread and pervasive use of Artificial Intelligence (AI) for automated decision-making systems, AI bias is becoming more apparent and problematic. One of its negative consequences is discrimination: the unfair, or unequal treatment of individuals based on certain characteristics. However, the relationship between bias and discrimination is not always clear. In this paper, we survey relevant literature about bias and discrimination in AI from an interdisciplinary perspective that embeds technical, legal, social and ethical dimensions. We show that finding solutions to bias and discrimination in AI requires robust cross-disciplinary collaborations.",
    "lastUpdated": "2020-08-11T10:02:04Z",
    "categories": [
      "cs.CY",
      "cs.LG",
      "68T01"
    ],
    "url": "http://arxiv.org/abs/2008.07309v1"
  },
  {
    "title": "Ethical conceptual replication of visualization research considering sources of methodological bias and practical significance",
    "authors": [
      "Ian T. Ruginski"
    ],
    "abstract": "General design principles for visualization have been relatively well-established based on a combination of cognitive and perceptual theory and empirical evaluations over the past 20 years. To determine how these principles hold up across use contexts and end-users, I argue that we should emphasize conceptual replication focused on determining practical significance and reducing methodological biases. This shift in thinking aims to determine how design principles interact with methodological approaches, laying the groundwork for visualization meta-science.",
    "lastUpdated": "2020-09-25T12:02:15Z",
    "categories": [
      "cs.HC",
      "H.5.2; H.1.2"
    ],
    "url": "http://arxiv.org/abs/2009.12152v1"
  },
  {
    "title": "Examining the Feasibility of Off-the-Shelf Algorithms for Masking Directly Identifiable Information in Social Media Data",
    "authors": [
      "Rachel Dorn",
      "Alicia L. Nobles",
      "Masoud Rouhizadeh",
      "Mark Dredze"
    ],
    "abstract": "The identification and removal/replacement of protected information from social media data is an understudied problem, despite being desirable from an ethical and legal perspective. This paper identifies types of potentially directly identifiable information (inspired by protected health information in clinical texts) contained in tweets that may be readily removed using off-the-shelf algorithms, introduces an English dataset of tweets annotated for identifiable information, and compiles these off-the-shelf algorithms into a tool (Nightjar) to evaluate the feasibility of using Nightjar to remove directly identifiable information from the tweets. Nightjar as well as the annotated data can be retrieved from https://bitbucket.org/mdredze/nightjar.",
    "lastUpdated": "2020-11-16T22:55:49Z",
    "categories": [
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/2011.08324v1"
  },
  {
    "title": "An Experiment on Leveraging SHAP Values to Investigate Racial Bias",
    "authors": [
      "Ramon Vilarino",
      "Renato Vicente"
    ],
    "abstract": "We design a series of experiments on credit scoring and employ SHAP values to demonstrate that the use of location information may introduce racial biases. The analysis relies on race statistics collected from Brazilian Institute of Geography and Statistics (IBGE) and on fully anonymized credit information. The present work helps to discuss how to track racial biases when protected attributes are not available and points in interesting directions towards the development of procedures to yield more ethical credit scoring models in the Brazilian context.",
    "lastUpdated": "2020-11-11T02:14:32Z",
    "categories": [
      "cs.CY",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2011.09865v1"
  },
  {
    "title": "Beyond kinetic harm and towards a dynamic conceptualization of cyberterrorism",
    "authors": [
      "Vince J. Straub"
    ],
    "abstract": "After more than two decades of discussion, the concept of cyberterrorism remains plagued by confusion. This article presents the result of an integrative review which maps the development of the term and situates the epistemic communities that have shaped the debate. After critically assessing existing accounts and highlighting the key ethical, social, and legal dimensions at stake in preventing cyberterrorist attacks, it calls for a more dynamic conceptualization that views cyberterrorism as more abstract, difficult to predict, and hard to isolate; and which embraces a different conception of sufficient harm. In concluding it proposes a novel definition of cyberterrorism, intended to catalyse a new research programme, and sketches a roadmap for further research.",
    "lastUpdated": "2020-12-16T16:23:11Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2012.09056v1"
  },
  {
    "title": "Big Data",
    "authors": [
      "Andreas L Opdahl",
      "Vimala Nunavath"
    ],
    "abstract": "The Internet of Things, crowdsourcing, social media, public authorities, and other sources generate bigger and bigger data sets. Big and open data offers many benefits for emergency management, but also pose new challenges. This chapter will review the sources of big data and their characteristics. We then discuss potential benefits of big data for emergency management along with the technological and societal challenges it poses. We review central technologies for big-data storage and processing in general, before presenting the Spark big-data engine in more detail. Finally, we review ethical and societal threats that big data pose.",
    "lastUpdated": "2020-12-15T16:18:52Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2012.09109v1"
  },
  {
    "title": "The Impact of Net Culture on Mainstream Societies: a Global Analysis",
    "authors": [
      "Tapas Kumar Das"
    ],
    "abstract": "In this work the impact of the Internet culture on standard mainstream societies has been analyzed. After analytically establishing the fact that the Net can be viewed as a pan-societal superstructure which supports its own distinct culture, an ethnographic analysis is provided to find out the key aspects of this culture. The elements of this culture which have an empowering impacts on the standard mainstream societies, as well as the elements in it which can cause discouraging social effects are then discussed by a global investigation of the present status of various fundamental aspects (e,g, education, economics, politics, entertainment etc) of the mainstream societies as well as their links with the Net culture. Though immensely potential for providing various prominent positive impacts, the key findings of this work indicate that misuse of Internet can create tremendous harm to the members of the mainstream societies by generating a set of morally crippled people as well as a future generation completely void of principles and ethics. This structured diagnostic approach to the social problems caused by the manhandling of Internet leads to a concrete effort of providing the measures that can be taken to enhance or to overcome the supporting and limiting effects of the Net culture respectively with the intent to benefit our society and to protect the teratoidation of certain ethical values.",
    "lastUpdated": "1999-03-18T17:01:27Z",
    "categories": [
      "cs.CY",
      "K.4.0;K.4.1;K.4.2"
    ],
    "url": "http://arxiv.org/abs/cs/9903013v1"
  },
  {
    "title": "Statistics, ethics, and probiotica",
    "authors": [
      "Richard D. Gill"
    ],
    "abstract": "A randomized clinical trial comparing an experimental new treatment to a standard therapy for a life-threatening medical condition should be stopped early on ethical grounds, in either of the following scenarios: (1) it has become overwhelmingly clear that the new treatment is better than the standard; (2) it has become overwhelmingly clear that the trial is not going to show that the new treatment is any better than the standard. The trial is continued in the third scenario: (3) there is a reasonable chance that the new treatment will finally turn out to be better than the standard, but we aren't sure yet. However, the (blinded) data monitoring committee in the \"PROPATRIA\" trial of an experimental probiotica treatment for patients with acute pancreatitis allowed the trial to continue at the half way interim analysis, in effect because there was still a good chance of proving that the probiotica treatment was very harmful to their patients. The committee did not know whether treatment A was the probiotica treatment or the placebo. In itself this should not have caused a problem, since it could easily have determined the appropriate decision under both scenarios. Were the decisions in the two scenarios different, then the data would have to be de-blinded, in order to determine the appropriate decision. The committee mis-read the output of SPSS, which reports the smaller of two one-sided p-values, without informing the user what it is doing. It seems that about 5 lives were sacrificed to the chance of getting a significant result that the probiotica treatment was bad for the patients in the trial.",
    "lastUpdated": "2009-01-31T19:28:11Z",
    "categories": [
      "stat.AP"
    ],
    "url": "http://arxiv.org/abs/0804.2522v2"
  },
  {
    "title": "Science for Peace in the Benefit of Humankind. The Hippocratic Oath for Scientists concept",
    "authors": [
      "Guillermo A. Lemarchand"
    ],
    "abstract": "This article shows the importance that has had the scientific research, the technological development and the innovation processes in increasing the lethality of the available weapons during the last century. A set of initiatives promoted by the scientific community to stop the nuclear arms race that threatened the continuation of life on the planet is described. At this point, a thorough survey of the texts and proposals of Hippocratic Oaths for Scientists presented at different epochs is made. It is observed that the interest in linking ethical aspects with science and technology issues shows an exponential growth behavior since the Second World War. It is shown how the several proposals of oaths and ethical commitments for scientists, engineers and technologists are disseminated following a logistic growth behavior, in the same manner as a disembodied technology in a particular niche. The data analysis shows that there is a coincidence between the maximum rate of proposals and the historical moment at which the world had deployed the largest number of nuclear warheads (70,586) as well as the largest world military expenditures in history (USD 1,485,000,000,000). Subsequently, the origin of the Hippocratic Oath for Scientists used for more than two decades in graduation ceremonies at the Faculty of Exact and Natural Sciences of the University of Buenos Aires is analyzed and linked with the historical circumstances of its birth.",
    "lastUpdated": "2010-06-17T17:21:44Z",
    "categories": [
      "physics.hist-ph",
      "physics.soc-ph"
    ],
    "url": "http://arxiv.org/abs/1006.3527v1"
  },
  {
    "title": "Functional Magnetic Resonance Imaging and the Challenge of Balancing Human Security with State Security",
    "authors": [
      "Farhan Sahito",
      "Wolfgang Slany"
    ],
    "abstract": "Recent reports reveal that violent extremists are trying to obtain insider positions that may increase the impact of any attack on critical infrastructure and could potentially endanger state services, people's lives and even democracy. It is of utmost importance to be able to adopt extreme security measures in certain high-risk situations in order to secure critical infrastructure and thus lower the level of terrorist threats while preserving the rights of citizens. To counter these threats, our research is aiming for extreme measures to analyse and evaluate human threats related assessment methods for employee screening and evaluations using cognitive analysis technology, in particular functional Magnetic Resonance Imaging (fMRI). The development of fMRI has led some researchers to conclude that this technology has forensic potential and may be useful in investing personality traits, mental illness, psychopathology, racial prejudice and religious extremism. However, critics claim that this technology may present many new human rights and ethical dilemmas and could result in potentially disastrous outcomes. The main thrust of the research is to counter above concerns and harmful consequences by presenting a set of ethical and professional guidelines that will substantially reduce the risk of unethical use of this technology. The significance of this research is to ensure the limits of the state/organisation's right to peer into an individual's thought process with and without consent, to define the parameters of a person's right to ensure that fMRI scans do not pose more than an appropriate threat to cognitive liberty, and the proper use of such information in civil, forensic and security settings.",
    "lastUpdated": "2012-04-16T15:55:50Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1204.3543v1"
  },
  {
    "title": "Ethics of using language editing services in an era of digital communication and heavily multiauthored papers",
    "authors": [
      "George A. Lozano"
    ],
    "abstract": "Scientists of many countries in which English is not the primary language routinely use a variety of manuscript preparation, correction or editing services, a practice that is openly endorsed by many journals and scientific institutions. These services vary tremendously in their scope; at one end there is simple proof-reading, and at the other extreme there is in-depth and extensive peer-reviewing, proposal preparation, statistical analyses, re-writing and co-writing. In this paper, the various types of service are reviewed, along with authorship guidelines, and the question is raised of whether the high-end services surpass most guidelines' criteria for authorship. Three other factors are considered. First, the ease of collaboration possible in the internet era allows multiple iterations between authors and the editing service, so essentially, papers can be co-written. Second, 'editing services' often offer subject-specific experts who comment not only on the language, but interpret and improve scientific content. Third, the trend towards heavily multi-authored papers implies that the threshold necessary to earn authorship is declining. The inevitable conclusion is that at some point the contributions by 'editing services' should be deemed sufficient to warrant authorship. Trying to enforce any guidelines would likely be futile, but nevertheless, it might be time to revisit the ethics of using some of the high-end 'editing services'. In an increasingly international job market, recognizing this problem might prove progressively more important in authorship disputes, the allocation of research grants, and hiring decisions",
    "lastUpdated": "2013-05-10T18:16:15Z",
    "categories": [
      "physics.soc-ph",
      "cs.DL"
    ],
    "url": "http://arxiv.org/abs/1305.2401v1"
  },
  {
    "title": "Advanced Personnel Vetting Techniques in Critical Multi-Tennant Hosted Computing Environments",
    "authors": [
      "Farhan Hyder Sahito",
      "Wolfgang Slany"
    ],
    "abstract": "The emergence of cloud computing presents a strategic direction for critical infrastructures and promises to have far-reaching effects on their systems and networks to deliver better outcomes to the nations at a lower cost. However, when considering cloud computing, government entities must address a host of security issues (such as malicious insiders) beyond those of service cost and flexibility. The scope and objective of this paper is to analyze, evaluate and investigate the insider threat in cloud security in sensitive infrastructures as well as to propose two proactive socio-technical solutions for securing commercial and governmental cloud infrastructures. Firstly, it proposes actionable framework, techniques and practices in order to ensure that such disruptions through human threats are infrequent, of minimal duration, manageable, and cause the least damage possible. Secondly, it aims for extreme security measures to analyze and evaluate human threats related assessment methods for employee screening in certain high-risk situations using cognitive analysis technology, in particular functional magnetic Resonance Imaging (fMRI). The significance of this research is also to counter human rights and ethical dilemmas by presenting a set of ethical and professional guidelines. The main objective of this work is to analyze related risks, identify countermeasures and present recommendations to develop a security awareness culture that will allow cloud providers to utilize effectively the benefits of this advanced techniques without sacrificing system security.",
    "lastUpdated": "2013-05-31T16:59:06Z",
    "categories": [
      "cs.CR",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1305.7488v1"
  },
  {
    "title": "A Formal Sociologic Study of Free Will",
    "authors": [
      "Giovanni Giuffrida",
      "Calogero G. Zarba"
    ],
    "abstract": "We make a formal sociologic study of the concept of free will. By using the language of mathematics and logic, we define what we call everlasting societies. Everlasting societies never age: persons never age, and the goods of the society are indestructible. The infinite history of an everlasting society unfolds by following deterministic and probabilistic laws that do their best to satisfy the free will of all the persons of the society. We define three possible kinds of histories for everlasting societies: primitive histories, good histories, and golden histories. In primitive histories, persons are inherently selfish, and they use their free will to obtain the personal ownerships of all the goods of the society. In good histories, persons are inherently good, and they use their free will to distribute the goods of the society. In good histories, a person is not only able to desire the personal ownership of goods, but is also able to desire that a good be owned by another person. In golden histories, free will is bound by the ethic of reciprocity, which states that \"you should wish upon others as you would like others to wish upon yourself\". In golden societies, the ethic of reciprocity becomes a law that partially binds free will, and that must be abided at all times. In other words, the verb \"should\" becomes the verb \"must\".",
    "lastUpdated": "2013-06-05T10:27:08Z",
    "categories": [
      "cs.SI"
    ],
    "url": "http://arxiv.org/abs/1307.1170v1"
  },
  {
    "title": "Ethical Artificial Intelligence",
    "authors": [
      "Bill Hibbard"
    ],
    "abstract": "This book-length article combines several peer reviewed papers and new material to analyze the issues of ethical artificial intelligence (AI). The behavior of future AI systems can be described by mathematical equations, which are adapted to analyze possible unintended AI behaviors and ways that AI designs can avoid them. This article makes the case for utility-maximizing agents and for avoiding infinite sets in agent definitions. It shows how to avoid agent self-delusion using model-based utility functions and how to avoid agents that corrupt their reward generators (sometimes called \"perverse instantiation\") using utility functions that evaluate outcomes at one point in time from the perspective of humans at a different point in time. It argues that agents can avoid unintended instrumental actions (sometimes called \"basic AI drives\" or \"instrumental goals\") by accurately learning human values. This article defines a self-modeling agent framework and shows how it can avoid problems of resource limits, being predicted by other agents, and inconsistency between the agent's utility function and its definition (one version of this problem is sometimes called \"motivated value selection\"). This article also discusses how future AI will differ from current AI, the politics of AI, and the ultimate use of AI to help understand the nature of the universe and our place in it.",
    "lastUpdated": "2015-11-17T20:54:38Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1411.1373v9"
  },
  {
    "title": "What is Learning Analytics about? A Survey of Different Methods Used in 2013-2015",
    "authors": [
      "Mohammad Khalil",
      "Martin Ebner"
    ],
    "abstract": "The area of Learning Analytics has developed enormously since the first International Conference on Learning Analytics and Knowledge (LAK) in 2011. It is a field that combines different disciplines such as computer science, statistics, psychology and pedagogy to achieve its intended objectives. The main goals illustrate in creating convenient interventions on learning as well as its environment and the final optimization about learning domain stakeholders. Because the field matures and is now adapted in diverse educational settings, we believe there is a pressing need to list its own research methods and specify its objectives and dilemmas. This paper surveys publications from Learning Analytics and Knowledge conference from 2013 to 2015 and lists the significant research areas in this sphere. We consider the method profile and classify them into seven different categories with a brief description on each. Furthermore, we show the most cited method categories using Google scholar. Finally, the authors raise the challenges and constraints that affect its ethical approach through the meta-analysis study. It is believed that this paper will help researchers to identify the common methods used in Learning Analytics, and it will assist by establishing a future forecast towards new research work taking into account the privacy and ethical issues of this strongly emerged field.",
    "lastUpdated": "2016-06-09T09:16:39Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1606.02878v1"
  },
  {
    "title": "An Exploratory Ethnographic Study of Issues and Concerns with Whole Genome Sequencing",
    "authors": [
      "Emiliano De Cristofaro"
    ],
    "abstract": "Progress in Whole Genome Sequencing (WGS) will soon allow a large number of individuals to have their genome fully sequenced. This lays the foundations to improve modern healthcare, enabling a new era of personalized medicine where diagnosis and treatment is tailored to the patient's genetic makeup. It also allows individuals motivated by personal curiosity to have access to their genetic information, and use it, e.g., to trace their ancestry. However, the very same progress also amplifies a number of ethical and privacy concerns, that stem from the unprecedented sensitivity of genomic information and that are not well studied. This paper presents an exploratory ethnographic study of users' perception of privacy and ethical issues with WGS, as well as their attitude toward different WGS programs. We report on a series of semi-structured interviews, involving 16 participants, and analyze the results both quantitatively and qualitatively. Our analysis shows that users exhibit common trust concerns and fear of discrimination, and demand to retain strict control over their genetic information. Finally, we highlight the need for further research in the area and follow-up studies that build on our initial findings.",
    "lastUpdated": "2014-01-31T08:06:46Z",
    "categories": [
      "cs.CR",
      "cs.CY",
      "q-bio.GN"
    ],
    "url": "http://arxiv.org/abs/1306.4962v5"
  },
  {
    "title": "Introducing nanoengineering and nanotechnology to the first year students through an interactive seminar course",
    "authors": [
      "Hassan Raza",
      "Tehseen Z. Raza"
    ],
    "abstract": "We report a first year seminar course on nanoengineering, which provides a unique opportunity to get exposed to the bottom-up approach and novel nanotechnology applications in an informal small class setting early in the undergraduate engineering education. Our objective is not only to introduce the fundamentals and applications of nanoengineering but also the issues related to ethics, environmental and societal impact of nanotechnology used in engineering. To make the course more interactive, laboratory tours for microfabrication facility, microscopy facility, and nanoscale laboratory at the University of Iowa are included, which inculcate the practical feel of the technology. The course also involves active student participation through weekly student presentations, highlighting topics of interest to this field, with the incentive of \"nano is everywhere\" Final term papers submitted by the students involve a rigorous technology analysis through various perspectives. Furthermore, a student based peer review process is developed which helps them to improve technical writing skills, as well as address the ethical issues of academic honesty while reviewing and getting introduced to a new aspect of the area presented by their colleagues. Based on the chosen paper topics and student ratings, the student seemed motivated to learn about the novel area introduced to them through theoretical, computational and experimental aspects of the bottom-up approach.",
    "lastUpdated": "2013-03-26T02:23:47Z",
    "categories": [
      "physics.ed-ph",
      "cond-mat.mes-hall"
    ],
    "url": "http://arxiv.org/abs/1303.6910v1"
  },
  {
    "title": "Crowd Behaviour during High-Stress Evacuations in an Immersive Virtual Environment",
    "authors": [
      "Mehdi Moussaïd",
      "Mubbasir Kapadia",
      "Tyler Thrash",
      "Robert W. Sumner",
      "Markus Gross",
      "Dirk Helbing",
      "Christoph Hölscher"
    ],
    "abstract": "Understanding the collective dynamics of crowd movements during stressful emergency situations is central to reducing the risk of deadly crowd disasters. Yet, their systematic experimental study remains a challenging open problem due to ethical and methodological constraints. In this paper, we demonstrate the viability of shared 3D virtual environments as an experimental platform for conducting crowd experiments with real people. In particular, we show that crowds of real human subjects moving and interacting in an immersive 3D virtual environment exhibit typical patterns of real crowds as observed in real-life crowded situations. These include the manifestation of social conventions and the emergence of self-organized patterns during egress scenarios. High-stress evacuation experiments conducted in this virtual environment reveal movements characterized by mass herding and dangerous overcrowding as they occur in crowd disasters. We describe the behavioral mechanisms at play under such extreme conditions and identify critical zones where overcrowding may occur. Furthermore, we show that herding spontaneously emerges from a density effect without the need to assume an increase of the individual tendency to imitate peers. Our experiments reveal the promise of immersive virtual environments as an ethical, cost-efficient, yet accurate platform for exploring crowd behaviour in high-risk situations with real human subjects.",
    "lastUpdated": "2016-09-13T08:55:39Z",
    "categories": [
      "physics.soc-ph"
    ],
    "url": "http://arxiv.org/abs/1609.03731v1"
  },
  {
    "title": "Exploring the Pathways of Adaptation an Avatar 3D Animation Procedures and Virtual Reality Arenas in Research of Human Courtship Behaviour and Sexual Reactivity in Psychological Research",
    "authors": [
      "Jakub Binter",
      "Kateřina Klapilová",
      "Tereza Zikánová",
      "Tommy Nilsson",
      "Klára Bártová",
      "Lucie Krejcová",
      "Renata Androvicová",
      "Jitka Lindová",
      "Denisa Prušová",
      "Timothy Wells",
      "Daniel Riha"
    ],
    "abstract": "There are many reasons for utilising 3D animation and virtual reality in sexuality research. Apart from providing a mean with which to (re)experience certain situations there are four main advantages: a) bespoke animated stimuli can be created and customized, which is especially important when researching paraphilia and sexual preferences, b) stimulus production is less expensive and easier to produce compared to real world stimuli, c) virtual reality allows us to capture data such as physiological reasons to stimuli, that we would not be able to otherwise (without resorting to self-report measures which are especially problematic in this research domain), d) ethical, legal, and health and safety issues are less complex since neither physical nor psychological harm is caused to animated characters allowing for the safe presentation of stimuli involving vulnerable targets. The animation sub-group has been exploring so far several production quality levels and various animation procedures in a number of available software. The aim is to develop static as well as dynamic, interactive sexual stimuli for sexual diagnostic and therapeutic purposes. We are aware of number of ethical issues related to the use of virtual reality in proposed research are analysed in this chapter.",
    "lastUpdated": "2016-11-06T18:27:09Z",
    "categories": [
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/1611.01817v1"
  },
  {
    "title": "Always Lurking: Understanding and Mitigating Bias in Online Human Trafficking Detection",
    "authors": [
      "Kyle Hundman",
      "Thamme Gowda",
      "Mayank Kejriwal",
      "Benedikt Boecking"
    ],
    "abstract": "Web-based human trafficking activity has increased in recent years but it remains sparsely dispersed among escort advertisements and difficult to identify due to its often-latent nature. The use of intelligent systems to detect trafficking can thus have a direct impact on investigative resource allocation and decision-making, and, more broadly, help curb a widespread social problem. Trafficking detection involves assigning a normalized score to a set of escort advertisements crawled from the Web -- a higher score indicates a greater risk of trafficking-related (involuntary) activities. In this paper, we define and study the problem of trafficking detection and present a trafficking detection pipeline architecture developed over three years of research within the DARPA Memex program. Drawing on multi-institutional data, systems, and experiences collected during this time, we also conduct post hoc bias analyses and present a bias mitigation plan. Our findings show that, while automatic trafficking detection is an important application of AI for social good, it also provides cautionary lessons for deploying predictive machine learning algorithms without appropriate de-biasing. This ultimately led to integration of an interpretable solution into a search system that contains over 100 million advertisements and is used by over 200 law enforcement agencies to investigate leads.",
    "lastUpdated": "2017-12-03T22:34:43Z",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1712.00846v1"
  },
  {
    "title": "Interventions over Predictions: Reframing the Ethical Debate for Actuarial Risk Assessment",
    "authors": [
      "Chelsea Barabas",
      "Karthik Dinakar",
      "Joichi Ito",
      "Madars Virza",
      "Jonathan Zittrain"
    ],
    "abstract": "Actuarial risk assessments might be unduly perceived as a neutral way to counteract implicit bias and increase the fairness of decisions made at almost every juncture of the criminal justice system, from pretrial release to sentencing, parole and probation. In recent times these assessments have come under increased scrutiny, as critics claim that the statistical techniques underlying them might reproduce existing patterns of discrimination and historical biases that are reflected in the data. Much of this debate is centered around competing notions of fairness and predictive accuracy, resting on the contested use of variables that act as \"proxies\" for characteristics legally protected against discrimination, such as race and gender. We argue that a core ethical debate surrounding the use of regression in risk assessments is not simply one of bias or accuracy. Rather, it's one of purpose. If machine learning is operationalized merely in the service of predicting individual future crime, then it becomes difficult to break cycles of criminalization that are driven by the iatrogenic effects of the criminal justice system itself. We posit that machine learning should not be used for prediction, but rather to surface covariates that are fed into a causal model for understanding the social, structural and psychological drivers of crime. We propose an alternative application of machine learning and causal inference away from predicting risk scores to risk mitigation.",
    "lastUpdated": "2018-07-14T20:52:15Z",
    "categories": [
      "cs.LG",
      "cs.CY",
      "stat.AP"
    ],
    "url": "http://arxiv.org/abs/1712.08238v2"
  },
  {
    "title": "Improving Safety of the Continual Reassessment Method via a Modified Allocation Rule",
    "authors": [
      "Pavel Mozgunov",
      "Thomas Jaki"
    ],
    "abstract": "This paper proposes a novel criterion for the allocation of patients in Phase~I dose-escalation clinical trials aiming to find the maximum tolerated dose (MTD). Conventionally, using a model-based approach the next patient is allocated to the dose with the toxicity estimate closest (in terms of the absolute or squared distance) to the maximum acceptable toxicity. This approach, however, ignores the uncertainty in point estimates and ethical concerns of assigning a lot of patients to overly toxic doses. Motivated by recent discussions in the theory of estimation in restricted parameter spaces, we propose a criterion which accounts for both of these issues. The criterion requires a specification of one additional parameter only which has a simple and intuitive interpretation. We incorporate the proposed criterion into the one-parameter Bayesian continual reassessment method (CRM) and show, using simulations, that it results in the same proportion of correct selections on average as the original design, but in fewer mean number of toxic responses. A comparison to other model-based dose-escalation designs demonstrates that the proposed design can result in either the same mean accuracy as alternatives but fewer number of toxic responses, or in a higher mean accuracy but the same number of toxic responses. We conclude that the new criterion makes the existing model-based designs more ethical without losing efficiency in the context of Phase I clinical trials.",
    "lastUpdated": "2018-07-16T10:43:30Z",
    "categories": [
      "stat.ME"
    ],
    "url": "http://arxiv.org/abs/1807.05781v1"
  },
  {
    "title": "Extracting Keywords from Open-Ended Business Survey Questions",
    "authors": [
      "Barbara McGillivray",
      "Gard Jenset",
      "Dominik Heil"
    ],
    "abstract": "Open-ended survey data constitute an important basis in research as well as for making business decisions. Collecting and manually analysing free-text survey data is generally more costly than collecting and analysing survey data consisting of answers to multiple-choice questions. Yet free-text data allow for new content to be expressed beyond predefined categories and are a very valuable source of new insights into people's opinions. At the same time, surveys always make ontological assumptions about the nature of the entities that are researched, and this has vital ethical consequences. Human interpretations and opinions can only be properly ascertained in their richness using textual data sources; if these sources are analyzed appropriately, the essential linguistic nature of humans and social entities is safeguarded. Natural Language Processing (NLP) offers possibilities for meeting this ethical business challenge by automating the analysis of natural language and thus allowing for insightful investigations of human judgements. We present a computational pipeline for analysing large amounts of responses to open-ended questions in surveys and extract keywords that appropriately represent people's opinions. This pipeline addresses the need to perform such tasks outside the scope of both commercial software and bespoke analysis, exceeds the performance to state-of-the-art systems, and performs this task in a transparent way that allows for scrutinising and exposing potential biases in the analysis. Following the principle of Open Data Science, our code is open-source and generalizable to other datasets.",
    "lastUpdated": "2020-08-07T13:25:46Z",
    "categories": [
      "cs.CL"
    ],
    "url": "http://arxiv.org/abs/1808.10685v3"
  },
  {
    "title": "Representation, Justification and Explanation in a Value Driven Agent: An Argumentation-Based Approach",
    "authors": [
      "Beishui Liao",
      "Michael Anderson",
      "Susan Leigh Anderson"
    ],
    "abstract": "Ethical and explainable artificial intelligence is an interdisciplinary research area involving computer science, philosophy, logic, the social sciences, etc. For an ethical autonomous system, the ability to justify and explain its decision making is a crucial aspect of transparency and trustworthiness. This paper takes a Value Driven Agent (VDA) as an example, explicitly representing implicit knowledge of a machine learning-based autonomous agent and using this formalism to justify and explain the decisions of the agent. For this purpose, we introduce a novel formalism to describe the intrinsic knowledge and solutions of a VDA in each situation. Based on this formalism, we formulate an approach to justify and explain the decision-making process of a VDA, in terms of a typical argumentation formalism, Assumption-based Argumentation (ABA). As a result, a VDA in a given situation is mapped onto an argumentation framework in which arguments are defined by the notion of deduction. Justified actions with respect to semantics from argumentation correspond to solutions of the VDA. The acceptance (rejection) of arguments and their premises in the framework provides an explanation for why an action was selected (or not). Furthermore, we go beyond the existing version of VDA, considering not only practical reasoning, but also epistemic reasoning, such that the inconsistency of knowledge of the VDA can be identified, handled and explained.",
    "lastUpdated": "2019-10-20T09:11:34Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1812.05362v2"
  },
  {
    "title": "Mapping Informal Settlements in Developing Countries using Machine Learning and Low Resolution Multi-spectral Data",
    "authors": [
      "Bradley Gram-Hansen",
      "Patrick Helber",
      "Indhu Varatharajan",
      "Faiza Azam",
      "Alejandro Coca-Castro",
      "Veronika Kopackova",
      "Piotr Bilinski"
    ],
    "abstract": "Informal settlements are home to the most socially and economically vulnerable people on the planet. In order to deliver effective economic and social aid, non-government organizations (NGOs), such as the United Nations Children's Fund (UNICEF), require detailed maps of the locations of informal settlements. However, data regarding informal and formal settlements is primarily unavailable and if available is often incomplete. This is due, in part, to the cost and complexity of gathering data on a large scale. To address these challenges, we, in this work, provide three contributions. 1) A brand new machine learning data-set, purposely developed for informal settlement detection. 2) We show that it is possible to detect informal settlements using freely available low-resolution (LR) data, in contrast to previous studies that use very-high resolution (VHR) satellite and aerial imagery, something that is cost-prohibitive for NGOs. 3) We demonstrate two effective classification schemes on our curated data set, one that is cost-efficient for NGOs and another that is cost-prohibitive for NGOs, but has additional utility. We integrate these schemes into a semi-automated pipeline that converts either a LR or VHR satellite image into a binary map that encodes the locations of informal settlements.",
    "lastUpdated": "2019-05-30T11:11:39Z",
    "categories": [
      "cs.CY",
      "cs.CV",
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1901.00861v3"
  },
  {
    "title": "Understanding artificial intelligence ethics and safety",
    "authors": [
      "David Leslie"
    ],
    "abstract": "A remarkable time of human promise has been ushered in by the convergence of the ever-expanding availability of big data, the soaring speed and stretch of cloud computing platforms, and the advancement of increasingly sophisticated machine learning algorithms. Innovations in AI are already leaving a mark on government by improving the provision of essential social goods and services from healthcare, education, and transportation to food supply, energy, and environmental management. These bounties are likely just the start. The prospect that progress in AI will help government to confront some of its most urgent challenges is exciting, but legitimate worries abound. As with any new and rapidly evolving technology, a steep learning curve means that mistakes and miscalculations will be made and that both unanticipated and harmful impacts will occur. This guide, written for department and delivery leads in the UK public sector and adopted by the British Government in its publication, 'Using AI in the Public Sector,' identifies the potential harms caused by AI systems and proposes concrete, operationalisable measures to counteract them. It stresses that public sector organisations can anticipate and prevent these potential harms by stewarding a culture of responsible innovation and by putting in place governance processes that support the design and implementation of ethical, fair, and safe AI systems. It also highlights the need for algorithmically supported outcomes to be interpretable by their users and made understandable to decision subjects in clear, non-technical, and accessible ways. Finally, it builds out a vision of human-centred and context-sensitive implementation that gives a central role to communication, evidence-based reasoning, situational awareness, and moral justifiability.",
    "lastUpdated": "2019-06-11T22:14:07Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG",
      "stat.AP"
    ],
    "url": "http://arxiv.org/abs/1906.05684v1"
  },
  {
    "title": "Image Counterfactual Sensitivity Analysis for Detecting Unintended Bias",
    "authors": [
      "Emily Denton",
      "Ben Hutchinson",
      "Margaret Mitchell",
      "Timnit Gebru",
      "Andrew Zaldivar"
    ],
    "abstract": "Facial analysis models are increasingly used in applications that have serious impacts on people's lives, ranging from authentication to surveillance tracking. It is therefore critical to develop techniques that can reveal unintended biases in facial classifiers to help guide the ethical use of facial analysis technology. This work proposes a framework called \\textit{image counterfactual sensitivity analysis}, which we explore as a proof-of-concept in analyzing a smiling attribute classifier trained on faces of celebrities. The framework utilizes counterfactuals to examine how a classifier's prediction changes if a face characteristic slightly changes. We leverage recent advances in generative adversarial networks to build a realistic generative model of face images that affords controlled manipulation of specific image characteristics. We then introduce a set of metrics that measure the effect of manipulating a specific property on the output of the trained classifier. Empirically, we find several different factors of variation that affect the predictions of the smiling classifier. This proof-of-concept demonstrates potential ways generative models can be leveraged for fine-grained analysis of bias and fairness.",
    "lastUpdated": "2020-10-03T21:33:55Z",
    "categories": [
      "cs.CV",
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1906.06439v3"
  },
  {
    "title": "Towards Empathic Deep Q-Learning",
    "authors": [
      "Bart Bussmann",
      "Jacqueline Heinerman",
      "Joel Lehman"
    ],
    "abstract": "As reinforcement learning (RL) scales to solve increasingly complex tasks, interest continues to grow in the fields of AI safety and machine ethics. As a contribution to these fields, this paper introduces an extension to Deep Q-Networks (DQNs), called Empathic DQN, that is loosely inspired both by empathy and the golden rule (\"Do unto others as you would have them do unto you\"). Empathic DQN aims to help mitigate negative side effects to other agents resulting from myopic goal-directed behavior. We assume a setting where a learning agent coexists with other independent agents (who receive unknown rewards), where some types of reward (e.g. negative rewards from physical harm) may generalize across agents. Empathic DQN combines the typical (self-centered) value with the estimated value of other agents, by imagining (by its own standards) the value of it being in the other's situation (by considering constructed states where both agents are swapped). Proof-of-concept results in two gridworld environments highlight the approach's potential to decrease collateral harms. While extending Empathic DQN to complex environments is non-trivial, we believe that this first step highlights the potential of bridge-work between machine ethics and RL to contribute useful priors for norm-abiding RL agents.",
    "lastUpdated": "2019-06-26T08:59:02Z",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "url": "http://arxiv.org/abs/1906.10918v1"
  },
  {
    "title": "The Ethical Dilemma when (not) Setting up Cost-based Decision Rules in Semantic Segmentation",
    "authors": [
      "Robin Chan",
      "Matthias Rottmann",
      "Radin Dardashti",
      "Fabian Hüger",
      "Peter Schlicht",
      "Hanno Gottschalk"
    ],
    "abstract": "Neural networks for semantic segmentation can be seen as statistical models that provide for each pixel of one image a probability distribution on predefined classes. The predicted class is then usually obtained by the maximum a-posteriori probability (MAP) which is known as Bayes rule in decision theory. From decision theory we also know that the Bayes rule is optimal regarding the simple symmetric cost function. Therefore, it weights each type of confusion between two different classes equally, e.g., given images of urban street scenes there is no distinction in the cost function if the network confuses a person with a street or a building with a tree. Intuitively, there might be confusions of classes that are more important to avoid than others. In this work, we want to raise awareness of the possibility of explicitly defining confusion costs and the associated ethical difficulties if it comes down to providing numbers. We define two cost functions from different extreme perspectives, an egoistic and an altruistic one, and show how safety relevant quantities like precision / recall and (segment-wise) false positive / negative rate change when interpolating between MAP, egoistic and altruistic decision rules.",
    "lastUpdated": "2019-07-02T13:17:14Z",
    "categories": [
      "cs.CV",
      "68T45, 62-07, 62C05"
    ],
    "url": "http://arxiv.org/abs/1907.01342v1"
  },
  {
    "title": "Absolute Prioritization of Planetary Protection, Safety, and Avoiding Imperialism in All Future Science Missions: A Policy Perspective",
    "authors": [
      "Monica Vidaurri",
      "Alia Wofford",
      "Jonathan Brande",
      "Gabriel Black-Planas",
      "Shawn Domagal-Goldman",
      "Jacob Haqq-Misra"
    ],
    "abstract": "The prioritization and improvement of ethics, planetary protection, and safety standards in the astro-sciences is the most critical priority as our scientific and exploratory capabilities progress, both within government agencies and the private sector. These priorities lie in the belief that every single science mission - crewed or non-crewed, ground-based or not - should heed strict ethical and safety standards starting at the very beginning of a mission. Given the inevitability of the private sector in influencing future crewed missions both in and beyond low-Earth orbit, it is essential to the science community to agree on universal standards of safety, mission assurance, planetary protection, and especially anti-colonization. These issues will impact all areas of space science. Examples that are particularly relevant to the Astro2020 Decadal Survey include but are not limited to: light pollution from satellites, the voices and rights of Native people when constructing telescopes on their lands, and the need to be cognizant of contamination when searching for and exploring habitable environments beyond Earth. Ultimately, moving international space law and domestic space policy from a reactive nature to a proactive one will ensure the future of space exploration is one that is safe, transparent, and anti-imperialist.",
    "lastUpdated": "2019-07-12T16:50:50Z",
    "categories": [
      "astro-ph.IM"
    ],
    "url": "http://arxiv.org/abs/1907.05834v1"
  },
  {
    "title": "Oxford Handbook on AI Ethics Book Chapter on Race and Gender",
    "authors": [
      "Timnit Gebru"
    ],
    "abstract": "From massive face-recognition-based surveillance and machine-learning-based decision systems predicting crime recidivism rates, to the move towards automated health diagnostic systems, artificial intelligence (AI) is being used in scenarios that have serious consequences in people's lives. However, this rapid permeation of AI into society has not been accompanied by a thorough investigation of the sociopolitical issues that cause certain groups of people to be harmed rather than advantaged by it. For instance, recent studies have shown that commercial face recognition systems have much higher error rates for dark skinned women while having minimal errors on light skinned men. A 2016 ProPublica investigation uncovered that machine learning based tools that assess crime recidivism rates in the US are biased against African Americans. Other studies show that natural language processing tools trained on newspapers exhibit societal biases (e.g. finishing the analogy \"Man is to computer programmer as woman is to X\" by homemaker). At the same time, books such as Weapons of Math Destruction and Automated Inequality detail how people in lower socioeconomic classes in the US are subjected to more automated decision making tools than those who are in the upper class. Thus, these tools are most often used on people towards whom they exhibit the most bias. While many technical solutions have been proposed to alleviate bias in machine learning systems, we have to take a holistic and multifaceted approach. This includes standardization bodies determining what types of systems can be used in which scenarios, making sure that automated decision tools are created by people from diverse backgrounds, and understanding the historical and political factors that disadvantage certain groups who are subjected to these tools.",
    "lastUpdated": "2019-08-08T15:35:23Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1908.06165v1"
  },
  {
    "title": "Artificial Intelligence and the Future of Psychiatry: Qualitative Findings from a Global Physician Survey",
    "authors": [
      "Charlotte Blease",
      "Cosima Locher",
      "Marisa Leon-Carlyle",
      "P. Murali Doraiswamy"
    ],
    "abstract": "The potential for machine learning to disrupt the medical profession is the subject of ongoing debate within biomedical informatics. This study aimed to explore psychiatrists' opinions about the potential impact of innovations in artificial intelligence and machine learning on psychiatric practice. In Spring 2019, we conducted a web-based survey of 791 psychiatrists from 22 countries worldwide. The survey measured opinions about the likelihood future technology would fully replace physicians in performing ten key psychiatric tasks. This study involved qualitative descriptive analysis of written response to three open-ended questions in the survey. Comments were classified into four major categories in relation to the impact of future technology on patient-psychiatric interactions, the quality of patient medical care, the profession of psychiatry, and health systems. Overwhelmingly, psychiatrists were skeptical that technology could fully replace human empathy. Many predicted that 'man and machine' would increasingly collaborate in undertaking clinical decisions, with mixed opinions about the benefits and harms of such an arrangement. Participants were optimistic that technology might improve efficiencies and access to care, and reduce costs. Ethical and regulatory considerations received limited attention. This study presents timely information of psychiatrists' view about the scope of artificial intelligence and machine learning on psychiatric practice. Psychiatrists expressed divergent views about the value and impact of future technology with worrying omissions about practice guidelines, and ethical and regulatory issues.",
    "lastUpdated": "2019-10-22T13:25:18Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1910.09956v1"
  },
  {
    "title": "Teaching Responsible Data Science: Charting New Pedagogical Territory",
    "authors": [
      "Julia Stoyanovich",
      "Armanda Lewis"
    ],
    "abstract": "Although numerous ethics courses are available, with many focusing specifically on technology and computer ethics, pedagogical approaches employed in these courses rely exclusively on texts rather than on software development or data analysis. Technical students often consider these courses unimportant and a distraction from the \"real\" material. To develop instructional materials and methodologies that are thoughtful and engaging, we must strive for balance: between texts and coding, between critique and solution, and between cutting-edge research and practical applicability. Finding such balance is particularly difficult in the nascent field of responsible data science (RDS), where we are only starting to understand how to interface between the intrinsically different methodologies of engineering and social sciences. In this paper we recount a recent experience in developing and teaching an RDS course to graduate and advanced undergraduate students in data science. We then dive into an area that is critically important to RDS -- transparency and interpretability of machine-assisted decision-making, and tie this area to the needs of emerging RDS curricula. Recounting our own experience, and leveraging literature on pedagogical methods in data science and beyond, we propose the notion of an \"object-to-interpret-with\". We link this notion to \"nutritional labels\" -- a family of interpretability tools that are gaining popularity in RDS research and practice. With this work we aim to contribute to the nascent area of RDS education, and to inspire others in the community to come together to develop a deeper theoretical understanding of the pedagogical needs of RDS, and contribute concrete educational materials and methodologies that others can use. All course materials are publicly available at https://dataresponsibly.github.io/courses.",
    "lastUpdated": "2019-12-23T00:10:22Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1912.10564v1"
  },
  {
    "title": "IMLI: An Incremental Framework for MaxSAT-Based Learning of Interpretable Classification Rules",
    "authors": [
      "Bishwamittra Ghosh",
      "Kuldeep S. Meel"
    ],
    "abstract": "The wide adoption of machine learning in the critical domains such as medical diagnosis, law, education had propelled the need for interpretable techniques due to the need for end users to understand the reasoning behind decisions due to learning systems. The computational intractability of interpretable learning led practitioners to design heuristic techniques, which fail to provide sound handles to tradeoff accuracy and interpretability. Motivated by the success of MaxSAT solvers over the past decade, recently MaxSAT-based approach, called MLIC, was proposed that seeks to reduce the problem of learning interpretable rules expressed in Conjunctive Normal Form (CNF) to a MaxSAT query. While MLIC was shown to achieve accuracy similar to that of other state of the art black-box classifiers while generating small interpretable CNF formulas, the runtime performance of MLIC is significantly lagging and renders approach unusable in practice. In this context, authors raised the question: Is it possible to achieve the best of both worlds, i.e., a sound framework for interpretable learning that can take advantage of MaxSAT solvers while scaling to real-world instances? In this paper, we take a step towards answering the above question in affirmation. We propose IMLI: an incremental approach to MaxSAT based framework that achieves scalable runtime performance via partition-based training methodology. Extensive experiments on benchmarks arising from UCI repository demonstrate that IMLI achieves up to three orders of magnitude runtime improvement without loss of accuracy and interpretability.",
    "lastUpdated": "2020-01-07T05:03:53Z",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2001.01891v1"
  },
  {
    "title": "Artificial intelligence in medicine and healthcare: a review and classification of current and near-future applications and their ethical and social Impact",
    "authors": [
      "Emilio Gómez-González",
      "Emilia Gomez",
      "Javier Márquez-Rivas",
      "Manuel Guerrero-Claro",
      "Isabel Fernández-Lizaranzu",
      "María Isabel Relimpio-López",
      "Manuel E. Dorado",
      "María José Mayorga-Buiza",
      "Guillermo Izquierdo-Ayuso",
      "Luis Capitán-Morales"
    ],
    "abstract": "This paper provides an overview of the current and near-future applications of Artificial Intelligence (AI) in Medicine and Health Care and presents a classification according to their ethical and societal aspects, potential benefits and pitfalls, and issues that can be considered controversial and are not deeply discussed in the literature. This work is based on an analysis of the state of the art of research and technology, including existing software, personal monitoring devices, genetic tests and editing tools, personalized digital models, online platforms, augmented reality devices, and surgical and companion robotics. Motivated by our review, we present and describe the notion of 'extended personalized medicine', we then review existing applications of AI in medicine and healthcare and explore the public perception of medical AI systems, and how they show, simultaneously, extraordinary opportunities and drawbacks that even question fundamental medical concepts. Many of these topics coincide with urgent priorities recently defined by the World Health Organization for the coming decade. In addition, we study the transformations of the roles of doctors and patients in an age of ubiquitous information, identify the risk of a division of Medicine into 'fake-based', 'patient-generated', and 'scientifically tailored', and draw the attention of some aspects that need further thorough analysis and public debate.",
    "lastUpdated": "2020-02-06T14:46:51Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2001.09778v2"
  },
  {
    "title": "A Set of Distinct Facial Traits Learned by Machines Is Not Predictive of Appearance Bias in the Wild",
    "authors": [
      "Ryan Steed",
      "Aylin Caliskan"
    ],
    "abstract": "Research in social psychology has shown that people's biased, subjective judgments about another's personality based solely on their appearance are not predictive of their actual personality traits. But researchers and companies often utilize computer vision models to predict similarly subjective personality attributes such as \"employability.\" We seek to determine whether state-of-the-art, black box face processing technology can learn human-like appearance biases. With features extracted with FaceNet, a widely used face recognition framework, we train a transfer learning model on human subjects' first impressions of personality traits in other faces as measured by social psychologists. We find that features extracted with FaceNet can be used to predict human appearance bias scores for deliberately manipulated faces but not for randomly generated faces scored by humans. Additionally, in contrast to work with human biases in social psychology, the model does not find a significant signal correlating politicians' vote shares with perceived competence bias. With Local Interpretable Model-Agnostic Explanations (LIME), we provide several explanations for this discrepancy. Our results suggest that some signals of appearance bias documented in social psychology are not embedded by the machine learning techniques we investigate. We shed light on the ways in which appearance bias could be embedded in face processing technology and cast further doubt on the practice of predicting subjective traits based on appearances.",
    "lastUpdated": "2021-01-13T17:15:05Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2002.05636v3"
  },
  {
    "title": "Deepfakes for Medical Video De-Identification: Privacy Protection and Diagnostic Information Preservation",
    "authors": [
      "Bingquan Zhu",
      "Hao Fang",
      "Yanan Sui",
      "Luming Li"
    ],
    "abstract": "Data sharing for medical research has been difficult as open-sourcing clinical data may violate patient privacy. Traditional methods for face de-identification wipe out facial information entirely, making it impossible to analyze facial behavior. Recent advancements on whole-body keypoints detection also rely on facial input to estimate body keypoints. Both facial and body keypoints are critical in some medical diagnoses, and keypoints invariability after de-identification is of great importance. Here, we propose a solution using deepfake technology, the face swapping technique. While this swapping method has been criticized for invading privacy and portraiture right, it could conversely protect privacy in medical video: patients' faces could be swapped to a proper target face and become unrecognizable. However, it remained an open question that to what extent the swapping de-identification method could affect the automatic detection of body keypoints. In this study, we apply deepfake technology to Parkinson's disease examination videos to de-identify subjects, and quantitatively show that: face-swapping as a de-identification approach is reliable, and it keeps the keypoints almost invariant, significantly better than traditional methods. This study proposes a pipeline for video de-identification and keypoint preservation, clearing up some ethical restrictions for medical data sharing. This work could make open-source high quality medical video datasets more feasible and promote future medical research that benefits our society.",
    "lastUpdated": "2020-02-07T22:36:48Z",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2003.00813v1"
  },
  {
    "title": "Beyond privacy regulations: an ethical approach to data usage in transportation",
    "authors": [
      "Johannes M. van Hulst",
      "Mattia Zeni",
      "Alexander Kröller",
      "Cassandra Moons",
      "Pierluigi Casale"
    ],
    "abstract": "With the exponential advancement of business technology in recent years, data-driven decision making has become the core of most industries. With the rise of new privacy regulations such as the General Data Protection Regulation in the European Union and the California Consumer Privacy Act in the United States, companies dealing with personal data had to conform to these changes and adapt their processes accordingly. This obviously included the transportation industry with their use of location data. At the other side of the spectrum, users still expect a form of personalization, without having to compromise on their privacy. For this reason, companies across the industries started applying privacy-enhancing or preserving technologies at scale in their products as a competitive advantage. In this paper, we describe how Federated Machine Learning can be applied to the transportation sector. We present use-cases for which Federated Learning is beneficial in transportation and the new product lifecycle that is required for using such a technology. We see Federated Learning as a method that enables us to process privacy-sensitive data, while respecting customer's privacy and one that guides us beyond privacy-regulations and into the world of ethical data-usage.",
    "lastUpdated": "2020-04-01T15:10:12Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2004.00491v1"
  },
  {
    "title": "A Philosophy of Data",
    "authors": [
      "Alexander M. Mussgnug"
    ],
    "abstract": "We argue that while this discourse on data ethics is of critical importance, it is missing one fundamental point: If more and more efforts in business, government, science, and our daily lives are data-driven, we should pay more attention to what exactly we are driven by. Therefore, we need more debate on what fundamental properties constitute data. In the first section of the paper, we work from the fundamental properties necessary for statistical computation to a definition of statistical data. We define a statistical datum as the coming together of substantive and numerical properties and differentiate between qualitative and quantitative data. Subsequently, we qualify our definition by arguing that for data to be practically useful, it needs to be commensurable in a manner that reveals meaningful differences that allow for the generation of relevant insights through statistical methodologies. In the second section, we focus on what our conception of data can contribute to the discourse on data ethics and beyond. First, we hold that the need for useful data to be commensurable rules out an understanding of properties as fundamentally unique or equal. Second, we argue that practical concerns lead us to increasingly standardize how we operationalize a substantive property; in other words, how we formalize the relationship between the substantive and numerical properties of data. Thereby, we also standardize the interpretation of a property. With our increasing reliance on data and data technologies, these two characteristics of data affect our collective conception of reality. Statistical data's exclusion of the fundamentally unique and equal influences our perspective on the world, and the standardization of substantive properties can be viewed as profound ontological practice, entrenching ever more pervasive interpretations of phenomena in our everyday lives.",
    "lastUpdated": "2020-05-20T12:36:57Z",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2004.09990v2"
  },
  {
    "title": "Decolonial AI: Decolonial Theory as Sociotechnical Foresight in Artificial Intelligence",
    "authors": [
      "Shakir Mohamed",
      "Marie-Therese Png",
      "William Isaac"
    ],
    "abstract": "This paper explores the important role of critical science, and in particular of post-colonial and decolonial theories, in understanding and shaping the ongoing advances in artificial intelligence. Artificial Intelligence (AI) is viewed as amongst the technological advances that will reshape modern societies and their relations. Whilst the design and deployment of systems that continually adapt holds the promise of far-reaching positive change, they simultaneously pose significant risks, especially to already vulnerable peoples. Values and power are central to this discussion. Decolonial theories use historical hindsight to explain patterns of power that shape our intellectual, political, economic, and social world. By embedding a decolonial critical approach within its technical practice, AI communities can develop foresight and tactics that can better align research and technology development with established ethical principles, centring vulnerable peoples who continue to bear the brunt of negative impacts of innovation and scientific progress. We highlight problematic applications that are instances of coloniality, and using a decolonial lens, submit three tactics that can form a decolonial field of artificial intelligence: creating a critical technical practice of AI, seeking reverse tutelage and reverse pedagogies, and the renewal of affective and political communities. The years ahead will usher in a wave of new scientific breakthroughs and technologies driven by AI research, making it incumbent upon AI communities to strengthen the social contract through ethical foresight and the multiplicity of intellectual perspectives available to us; ultimately supporting future technologies that enable greater well-being, with the goal of beneficence and justice for all.",
    "lastUpdated": "2020-07-08T12:36:21Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2007.04068v1"
  },
  {
    "title": "Degrees of individual and groupwise backward and forward responsibility in extensive-form games with ambiguity, and their application to social choice problems",
    "authors": [
      "Jobst Heitzig",
      "Sarah Hiller"
    ],
    "abstract": "Many real-world situations of ethical relevance, in particular those of large-scale social choice such as mitigating climate change, involve not only many agents whose decisions interact in complicated ways, but also various forms of uncertainty, including quantifiable risk and unquantifiable ambiguity. In such problems, an assessment of individual and groupwise moral responsibility for ethically undesired outcomes or their responsibility to avoid such is challenging and prone to the risk of under- or overdetermination of responsibility. In contrast to existing approaches based on strict causation or certain deontic logics that focus on a binary classification of `responsible' vs `not responsible', we here present several different quantitative responsibility metrics that assess responsibility degrees in units of probability. For this, we use a framework based on an adapted version of extensive-form game trees and an axiomatic approach that specifies a number of potentially desirable properties of such metrics, and then test the developed candidate metrics by their application to a number of paradigmatic social choice situations. We find that while most properties one might desire of such responsibility metrics can be fulfilled by some variant, an optimal metric that clearly outperforms others has yet to be found.",
    "lastUpdated": "2020-07-09T13:19:13Z",
    "categories": [
      "econ.TH",
      "cs.AI",
      "91B06, 91A35, 90B50, 91A18",
      "F.4.3; G.3"
    ],
    "url": "http://arxiv.org/abs/2007.07352v1"
  },
  {
    "title": "Future Trends for Human-AI Collaboration: A Comprehensive Taxonomy of AI/AGI Using Multiple Intelligences and Learning Styles",
    "authors": [
      "Andrzej Cichocki",
      "Alexander P. Kuleshov"
    ],
    "abstract": "This article discusses some trends and concepts in developing new generation of future Artificial General Intelligence (AGI) systems which relate to complex facets and different types of human intelligence, especially social, emotional, attentional and ethical intelligence. We describe various aspects of multiple human intelligences and learning styles, which may impact on a variety of AI problem domains. Using the concept of 'multiple intelligences' rather than a single type of intelligence, we categorize and provide working definitions of various AGI depending on their cognitive skills or capacities. Future AI systems will be able not only to communicate with human users and each other, but also to efficiently exchange knowledge and wisdom with abilities of cooperation, collaboration and even co-creating something new and valuable and have meta-learning capacities. Multi-agent systems such as these can be used to solve problems that would be difficult to solve by any individual intelligent agent. Key words: Artificial General Intelligence (AGI), multiple intelligences, learning styles, physical intelligence, emotional intelligence, social intelligence, attentional intelligence, moral-ethical intelligence, responsible decision making, creative-innovative intelligence, cognitive functions, meta-learning of AI systems.",
    "lastUpdated": "2020-12-11T10:38:05Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2008.04793v4"
  },
  {
    "title": "Progressing Towards Responsible AI",
    "authors": [
      "Teresa Scantamburlo",
      "Atia Cortés",
      "Marie Schacht"
    ],
    "abstract": "The field of Artificial Intelligence (AI) and, in particular, the Machine Learning area, counts on a wide range of performance metrics and benchmark data sets to assess the problem-solving effectiveness of its solutions. However, the appearance of research centres, projects or institutions addressing AI solutions from a multidisciplinary and multi-stakeholder perspective suggests a new approach to assessment comprising ethical guidelines, reports or tools and frameworks to help both academia and business to move towards a responsible conceptualisation of AI. They all highlight the relevance of three key aspects: (i) enhancing cooperation among the different stakeholders involved in the design, deployment and use of AI; (ii) promoting multidisciplinary dialogue, including different domains of expertise in this process; and (iii) fostering public engagement to maximise a trusted relation with new technologies and practitioners. In this paper, we introduce the Observatory on Society and Artificial Intelligence (OSAI), an initiative grew out of the project AI4EU aimed at stimulating reflection on a broad spectrum of issues of AI (ethical, legal, social, economic and cultural). In particular, we describe our work in progress around OSAI and suggest how this and similar initiatives can promote a wider appraisal of progress in AI. This will give us the opportunity to present our vision and our modus operandi to enhance the implementation of these three fundamental dimensions.",
    "lastUpdated": "2020-08-11T09:46:00Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2008.07326v1"
  },
  {
    "title": "TRUSTD: Combat Fake Content using Blockchain and Collective Signature Technologies",
    "authors": [
      "Zakwan Jaroucheh",
      "Mohamad Alissa",
      "William J Buchanan"
    ],
    "abstract": "The growing trend of sharing news/contents, through social media platforms and the World Wide Web has been seen to impact our perception of the truth, altering our views about politics, economics, relationships, needs and wants. This is because of the growing spread of misinformation and disinformation intentionally or unintentionally by individuals and organizations. This trend has grave political, social, ethical, and privacy implications for society due to 1) the rapid developments in the field of Machine Learning (ML) and Deep Learning (DL) algorithms in creating realistic-looking yet fake digital content (such as text, images, and videos), 2) the ability to customize the content feeds and to create a polarized so-called \"filter-bubbles\" leveraging the availability of the big-data. Therefore, there is an ethical need to combat the flow of fake content. This paper attempts to resolve some of the aspects of this combat by presenting a high-level overview of TRUSTD, a blockchain and collective signature-based ecosystem to help content creators in getting their content backed by the community, and to help users judge on the credibility and correctness of these contents.",
    "lastUpdated": "2020-08-28T14:52:08Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/2008.13632v1"
  },
  {
    "title": "Biases in Data Science Lifecycle",
    "authors": [
      "Dinh-An Ho",
      "Oya Beyan"
    ],
    "abstract": "In recent years, data science has become an indispensable part of our society. Over time, we have become reliant on this technology because of its opportunity to gain value and new insights from data in any field - business, socializing, research and society. At the same time, it raises questions about how justified we are in placing our trust in these technologies. There is a risk that such powers may lead to biased, inappropriate or unintended actions. Therefore, ethical considerations which might occur as the result of data science practices should be carefully considered and these potential problems should be identified during the data science lifecycle and mitigated if possible. However, a typical data scientist has not enough knowledge for identifying these challenges and it is not always possible to include an ethics expert during data science production. The aim of this study is to provide a practical guideline to data scientists and increase their awareness. In this work, we reviewed different sources of biases and grouped them under different stages of the data science lifecycle. The work is still under progress. The aim of early publishing is to collect community feedback and improve the curated knowledge base for bias types and solutions.",
    "lastUpdated": "2020-10-27T12:31:24Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2009.09795v2"
  },
  {
    "title": "A Series of Unfortunate Counterfactual Events: the Role of Time in Counterfactual Explanations",
    "authors": [
      "Andrea Ferrario",
      "Michele Loi"
    ],
    "abstract": "Counterfactual explanations are a prominent example of post-hoc interpretability methods in the explainable Artificial Intelligence research domain. They provide individuals with alternative scenarios and a set of recommendations to achieve a sought-after machine learning model outcome. Recently, the literature has identified desiderata of counterfactual explanations, such as feasibility, actionability and sparsity that should support their applicability in real-world contexts. However, we show that the literature has neglected the problem of the time dependency of counterfactual explanations. We argue that, due to their time dependency and because of the provision of recommendations, even feasible, actionable and sparse counterfactual explanations may not be appropriate in real-world applications. This is due to the possible emergence of what we call \"unfortunate counterfactual events.\" These events may occur due to the retraining of machine learning models whose outcomes have to be explained via counterfactual explanation. Series of unfortunate counterfactual events frustrate the efforts of those individuals who successfully implemented the recommendations of counterfactual explanations. This negatively affects people's trust in the ability of institutions to provide machine learning-supported decisions consistently. We introduce an approach to address the problem of the emergence of unfortunate counterfactual events that makes use of histories of counterfactual explanations. In the final part of the paper we propose an ethical analysis of two distinct strategies to cope with the challenge of unfortunate counterfactual events. We show that they respond to an ethically responsible imperative to preserve the trustworthiness of credit lending organizations, the decision models they employ, and the social-economic function of credit lending.",
    "lastUpdated": "2020-10-09T17:16:29Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2010.04687v1"
  },
  {
    "title": "Ethical Decision Making During Automated Vehicle Crashes",
    "authors": [
      "Noah Goodall"
    ],
    "abstract": "Automated vehicles have received much attention recently, particularly the DARPA Urban Challenge vehicles, Google's self-driving cars, and various others from auto manufacturers. These vehicles have the potential to significantly reduce crashes and improve roadway efficiency by automating the responsibilities of the driver. Still, automated vehicles are expected to crash occasionally, even when all sensors, vehicle control components, and algorithms function perfectly. If a human driver is unable to take control in time, a computer will be responsible for pre-crash behavior. Unlike other automated vehicles--such as aircraft, where every collision is catastrophic, and guided track systems, which can only avoid collisions in one dimension--automated roadway vehicles can predict various crash trajectory alternatives and select a path with the lowest damage or likelihood of collision. In some situations, the preferred path may be ambiguous. This study investigates automated vehicle crashing and concludes the following: (1) automated vehicles will almost certainly crash, (2) an automated vehicle's decisions preceding certain crashes will have a moral component, and (3) there is no obvious way to effectively encode complex human morals in software. A three-phase approach to developing ethical crashing algorithms is presented, consisting of a rational approach, an artificial intelligence approach, and a natural language requirement. The phases are theoretical and should be implemented as the technology becomes available.",
    "lastUpdated": "2020-10-30T14:58:17Z",
    "categories": [
      "cs.CY",
      "K.4.1"
    ],
    "url": "http://arxiv.org/abs/2010.16309v1"
  },
  {
    "title": "Simulation as a sustainable trading zone: Aiming at intergenerational justice",
    "authors": [
      "Vitaly Pronskikh"
    ],
    "abstract": "The paper, drawing on the example of simulation codes used in nuclear physics and high-energy physics, seeks to highlight the ethical implications of discontinuing support for simulation codes and the loss of knowledge embodied in them. Predicated on the concept of trading zones and actor network models, the paper addresses the problem of extinction of simulation codes and attempts to understand their evolution and development within those frameworks. We show that simulation codes of closed type develop to the level of creoles, becoming local languages and standards of scientific centers and disappearing as their few main developers leave, whereas codes of open types become universal languages, imposing problem-solving patterns on the entire community and crowding out other codes. The paper suggests that because of simulations' reliance on tacit knowledge, practices entrenched in codes cannot be exhaustively explicated or transmitted through writing alone; on the contrary, the life cycle of a simulation code is determined by the life cycle of its trading zone. We examine the extent to which both of these phenomena pose a risk to the preservation of knowledge. Bearing upon intergenerational ethics, we draw analogies between the pure intergenerational problem (PIP) and the problem of preserving the knowledge implemented in simulation codes and transmitting it to future generations. We argue that for the complete transfer of knowledge, it is necessary to develop and maintain inhabitability and sustainability of simulation trading zones in a controllable way, at least until the demand for these codes is warranted to cease in the future.",
    "lastUpdated": "2020-11-25T03:29:29Z",
    "categories": [
      "physics.hist-ph"
    ],
    "url": "http://arxiv.org/abs/2011.12497v1"
  },
  {
    "title": "Biased Programmers? Or Biased Data? A Field Experiment in Operationalizing AI Ethics",
    "authors": [
      "Bo Cowgill",
      "Fabrizio Dell'Acqua",
      "Samuel Deng",
      "Daniel Hsu",
      "Nakul Verma",
      "Augustin Chaintreau"
    ],
    "abstract": "Why do biased predictions arise? What interventions can prevent them? We evaluate 8.2 million algorithmic predictions of math performance from $\\approx$400 AI engineers, each of whom developed an algorithm under a randomly assigned experimental condition. Our treatment arms modified programmers' incentives, training data, awareness, and/or technical knowledge of AI ethics. We then assess out-of-sample predictions from their algorithms using randomized audit manipulations of algorithm inputs and ground-truth math performance for 20K subjects. We find that biased predictions are mostly caused by biased training data. However, one-third of the benefit of better training data comes through a novel economic mechanism: Engineers exert greater effort and are more responsive to incentives when given better training data. We also assess how performance varies with programmers' demographic characteristics, and their performance on a psychological test of implicit bias (IAT) concerning gender and careers. We find no evidence that female, minority and low-IAT engineers exhibit lower bias or discrimination in their code. However, we do find that prediction errors are correlated within demographic groups, which creates performance improvements through cross-demographic averaging. Finally, we quantify the benefits and tradeoffs of practical managerial or policy interventions such as technical advice, simple reminders, and improved incentives for decreasing algorithmic bias.",
    "lastUpdated": "2020-12-04T04:12:33Z",
    "categories": [
      "econ.GN",
      "cs.CY",
      "q-fin.EC"
    ],
    "url": "http://arxiv.org/abs/2012.02394v1"
  },
  {
    "title": "The Local Luminosity Function at 25 Microns",
    "authors": [
      "David L. Shupe",
      "Fan Fang",
      "Perry B. Hacking",
      "John P. Huchra"
    ],
    "abstract": "The local luminosity function at 25 $\\mu$m provides the basis for interpreting the results of deep mid-infrared surveys planned or in progress with space astrophysics missions including ISO, WIRE and SIRTF. We have selected a sample of 1458 galaxies from the IRAS Faint Source Survey with a flux density limit of 250 mJy at 25 $\\mu$m. The local luminosity function is derived using both parametric and non-parametric maximum-likelihood techniques, and the classical $1/V_{max}$ estimator. Comparison of these results shows that the $1/V_{max}$ estimate of the luminosity function is significantly affected by the Local Supercluster. A maximum-likelihood fit to the radial density shows no systematic increase that would be caused by density evolution of the galaxy population. The density fit is used to correct the $1/V_{max}$ estimate. We also demonstrate the high quality and completeness of our sample by a variety of methods. The luminosity function derived from this sample is compared to previously published estimates, showing the prior estimates to have been strongly affected by the Local Supercluster. Our new luminosity function leads to lower estimates of mid-infrared backgrounds and number counts.",
    "lastUpdated": "1998-03-13T00:42:46Z",
    "categories": [
      "astro-ph"
    ],
    "url": "http://arxiv.org/abs/astro-ph/9803149v1"
  },
  {
    "title": "QSO 2359-1241: A Bright, Highly Polarized, Radio-Moderate, Reddened, Low-Ionization Broad Absorption Line Quasar",
    "authors": [
      "M. S. Brotherton",
      "Nahum Arav",
      "R. H. Becker",
      "Hien D. Tran",
      "Michael D. Gregg",
      "R. L. White",
      "S. A. Laurent-Muehleisen",
      "Warren Hack"
    ],
    "abstract": "We report the discovery of a bright quasar (E=15.8, z=0.868) associated with the flat spectrum radio source NVSS J235953-124148. This quasar we designate QSO 2359-1241 possesses a rare combination of extreme properties that make it of special interest. These properties include: intrinsic high-velocity outflow seen in absorption for both high and low-ionization species, high optical polarization (about 5%), significant radio emission, and dust reddening. The dereddened absolute magnitude of QSO 2359-1241 places it among the three most optically luminous quasars known at z<1. High-resolution spectroscopy and a detailed analysis of the optical/ultraviolet absorption features will be given in a companion paper (Arav et al 2000).",
    "lastUpdated": "2000-08-17T00:50:07Z",
    "categories": [
      "astro-ph"
    ],
    "url": "http://arxiv.org/abs/astro-ph/0008258v1"
  },
  {
    "title": "Detection of H2 Emission from Mira B in UV Spectra from the Hubble Space Telescope",
    "authors": [
      "Brian E. Wood",
      "Margarita Karovska",
      "Warren Hack"
    ],
    "abstract": "We present ultraviolet spectra of Mira's companion star from the Space Telescope Imaging Spectrograph (STIS) instrument on board the Hubble Space Telescope (HST). The companion is generally assumed to be a white dwarf surrounded by an accretion disk fed by Mira's wind, which dominates the UV emission from the system. The STIS UV spectrum is dominated by numerous, narrow H2 lines fluoresced by H I Ly-alpha, which were not detected in any of the numerous observations of Mira B by the International Ultraviolet Explorer (IUE). The high temperature lines detected by IUE (e.g., C IV 1550) still exist in the STIS spectrum but with dramatically lower fluxes. The continuum fluxes in the STIS spectra are also much lower, being more than an order of magnitude lower than ever observed by IUE, and also an order of magnitude lower than fluxes observed in more recent HST Faint Object Camera objective prism spectra from 1995. Thus, the accretion rate onto Mira B was apparently much lower when STIS observed the star, and this change altered the character of Mira B's UV spectrum.",
    "lastUpdated": "2001-07-02T20:57:52Z",
    "categories": [
      "astro-ph"
    ],
    "url": "http://arxiv.org/abs/astro-ph/0107032v1"
  },
  {
    "title": "X-ray Outburst in Mira A",
    "authors": [
      "M. Karovska",
      "E. Schlegel",
      "W. Hack",
      "B. Wood"
    ],
    "abstract": "We report here the Chandra ACIS-S detection of a bright soft X-ray transient in the Mira AB interacting symbiotic-like binary. We resolved the system for the first time in the X-rays. Using Chandra and HST images we determined that the unprecedented outburst is likely associated with the cool AGB star (Mira A), the prototype of Mira-type variables. X-rays have never before been detected from an AGB star, and the recent activity signals that the system is undergoing dramatic changes. The total X-ray luminosity of the system is several times higher than the luminosity estimated using previous XMM and ROSAT observations. The outburst may be caused by a giant flare in Mira A associated with a mass ejection or a jet, and may have long term consequences on the system.",
    "lastUpdated": "2005-03-02T20:08:04Z",
    "categories": [
      "astro-ph"
    ],
    "url": "http://arxiv.org/abs/astro-ph/0503050v1"
  },
  {
    "title": "Finiteness for Arithmetic Fewnomial Systems",
    "authors": [
      "J. Maurice Rojas"
    ],
    "abstract": "Suppose L is any finite algebraic extension of either the ordinary rational numbers or the p-adic rational numbers. Also let g_1,...,g_k be polynomials in n variables, with coefficients in L, such that the total number of monomial terms appearing in at least one g_i is exactly m. We prove that the maximum number of isolated roots of G:=(g_1,...,g_k) in L^n is finite and depends solely on (m,n,L), i.e., is independent of the degrees of the g_i. We thus obtain an arithmetic analogue of Khovanski's Theorem on Fewnomials, extending earlier work of Denef, Van den Dries, Lipshitz, and Lenstra.",
    "lastUpdated": "2001-03-30T00:56:11Z",
    "categories": [
      "math.NT",
      "math.AG",
      "Primary: 11G25; Secondary: 11G35, 14D10, 14G20"
    ],
    "url": "http://arxiv.org/abs/math/0010260v3"
  },
  {
    "title": "Quantum Hacking: Experimental demonstration of time-shift attack against practical quantum key distribution systems",
    "authors": [
      "Yi Zhao",
      "Chi-Hang Fred Fung",
      "Bing Qi",
      "Christine Chen",
      "Hoi-Kwong Lo"
    ],
    "abstract": "Quantum key distribution (QKD) systems can send signals over more than 100 km standard optical fiber and are widely believed to be secure. Here, we show experimentally for the first time a technologically feasible attack, namely the time-shift attack, against a commercial QKD system. Our result shows that, contrary to popular belief, an eavesdropper, Eve, has a non-negligible probability (~4%) to break the security of the system. Eve's success is due to the well-known detection efficiency loophole in the experimental testing of Bell inequalities. Therefore, the detection efficiency loophole plays a key role not only in fundamental physics, but also in technological applications such as QKD.",
    "lastUpdated": "2011-04-01T21:01:36Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/0704.3253v3"
  },
  {
    "title": "Newton's 2nd Law and the Physics of Dance",
    "authors": [
      "Richard P. Barber Jr.",
      "David J. Popalisky",
      "Rose Hacking",
      "Kristina Chiapella"
    ],
    "abstract": "In teaching the physical sciences, a significant challenge lies in the student's tendency to consider the scientific world and the \"real\" world as separate. For example, Newton's 1st Law of Motion states that an object in motion remains in motion in a straight line unless acted on by an external force. However, our experience tells us that most objects keep moving only as long as someone or something pushes on them. One key to understanding physics is the ability to abstract the \"law\" from a reality which also includes friction and other effects. In this article we describe a college course for non-science majors, The Physics of Dance. The central theme of this course is the personalization of the physics of motion by making each student the object. With this approach we give students not only scientific tools to measure and understand but personal involvement to experience forces and motion. This combination provides a bridge that connects the science to reality.",
    "lastUpdated": "2007-06-19T05:48:58Z",
    "categories": [
      "physics.ed-ph"
    ],
    "url": "http://arxiv.org/abs/0706.2717v1"
  },
  {
    "title": "Semantic Network Layering",
    "authors": [
      "Michael Neufeld",
      "Craig Partridge"
    ],
    "abstract": "The stack in various forms has been widely used as an architectural template for networking systems. Recently the stack has been subject to criticism for a lack of flexibility. However, when it comes right down to it nobody has offered a truly compelling alternative. Various cross-layer optimizations have been proposed, but these optimizations are frequently hacks to achieve a particular goal and offer no direct insight into why the existing network stack is inadequate. We propose that a fundamental problem with the existing network stack is that it attempts to layer functionality that is not well-suited to layering. In this work we use a \"bottom up\" model of information computation, storage, and transfer and the \"top down\" goals of networking systems to formulate a modular decomposition of networking systems. Based on this modular decomposition we propose a semantic layered structure for networking systems that eliminates many awkward cross-layer interactions that arise in the canonical layered stack.",
    "lastUpdated": "2009-02-24T20:31:34Z",
    "categories": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/0902.4221v1"
  },
  {
    "title": "Novel Intrusion Detection using Probabilistic Neural Network and Adaptive Boosting",
    "authors": [
      "Tich Phuoc Tran",
      "Longbing Cao",
      "Dat Tran",
      "Cuong Duc Nguyen"
    ],
    "abstract": "This article applies Machine Learning techniques to solve Intrusion Detection problems within computer networks. Due to complex and dynamic nature of computer networks and hacking techniques, detecting malicious activities remains a challenging task for security experts, that is, currently available defense systems suffer from low detection capability and high number of false alarms. To overcome such performance limitations, we propose a novel Machine Learning algorithm, namely Boosted Subspace Probabilistic Neural Network (BSPNN), which integrates an adaptive boosting technique and a semi parametric neural network to obtain good tradeoff between accuracy and generality. As the result, learning bias and generalization variance can be significantly minimized. Substantial experiments on KDD 99 intrusion benchmark indicate that our model outperforms other state of the art learning algorithms, with significantly improved detection accuracy, minimal false alarms and relatively small computational complexity.",
    "lastUpdated": "2009-11-03T04:07:19Z",
    "categories": [
      "cs.NE",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/0911.0485v1"
  },
  {
    "title": "Privacy Preserving k Secure Sum Protocol",
    "authors": [
      "Rashid Sheikh",
      "Beerendra Kumar",
      "Durgesh Kumar Mishra"
    ],
    "abstract": "Secure Multiparty Computation (SMC) allows parties to know the result of cooperative computation while preserving privacy of individual data. Secure sum computation is an important application of SMC. In our proposed protocols parties are allowed to compute the sum while keeping their individual data secret with increased computation complexity for hacking individual data. In this paper the data of individual party is broken into a fixed number of segments. For increasing the complexity we have used the randomization technique with segmentation",
    "lastUpdated": "2009-12-04T21:54:51Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/0912.0956v1"
  },
  {
    "title": "Tropical secant graphs of monomial curves",
    "authors": [
      "Maria Angelica Cueto",
      "Shaowei Lin"
    ],
    "abstract": "The first secant variety of a projective monomial curve is a threefold with an action by a one-dimensional torus. Its tropicalization is a three-dimensional fan with a one-dimensional lineality space, so the tropical threefold is represented by a balanced graph. Our main result is an explicit construction of that graph. As a consequence, we obtain algorithms to effectively compute the multidegree and Chow polytope of an arbitrary projective monomial curve. This generalizes an earlier degree formula due to Ranestad. The combinatorics underlying our construction is rather delicate, and it is based on a refinement of the theory of geometric tropicalization due to Hacking, Keel and Tevelev.",
    "lastUpdated": "2011-09-10T21:09:37Z",
    "categories": [
      "math.AG",
      "math.CO",
      "14Q05, 14T05 (Primary), 14M25 (Secondary)"
    ],
    "url": "http://arxiv.org/abs/1005.3364v2"
  },
  {
    "title": "Hacking commercial quantum cryptography systems by tailored bright illumination",
    "authors": [
      "Lars Lydersen",
      "Carlos Wiechers",
      "Christoffer Wittmann",
      "Dominique Elser",
      "Johannes Skaar",
      "Vadim Makarov"
    ],
    "abstract": "The peculiar properties of quantum mechanics allow two remote parties to communicate a private, secret key, which is protected from eavesdropping by the laws of physics. So-called quantum key distribution (QKD) implementations always rely on detectors to measure the relevant quantum property of single photons. Here we demonstrate experimentally that the detectors in two commercially available QKD systems can be fully remote-controlled using specially tailored bright illumination. This makes it possible to tracelessly acquire the full secret key; we propose an eavesdropping apparatus built of off-the-shelf components. The loophole is likely to be present in most QKD systems using avalanche photodiodes to detect single photons. We believe that our findings are crucial for strengthening the security of practical QKD, by identifying and patching technological deficiencies.",
    "lastUpdated": "2011-03-04T08:10:17Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/1008.4593v2"
  },
  {
    "title": "New Frontiers of Network Security: The Threat Within",
    "authors": [
      "Sugata Sanyal",
      "Ajit Shelat",
      "Amit Gupta"
    ],
    "abstract": "Nearly 70% of information security threats originate from inside an organization. Opportunities for insider threats have been increasing at an alarming rate with the latest trends of mobility (portable devices like Laptop, smart phones etc.), ubiquitous connectivity (wireless or through 3G connectivity) and this trend increases as more and more web-based applications are made available over the Internet. Insider threats are generally caused by current or ex-employees, contractors or partners, who have authorized access to the organization's network and servers. Theft of confidential information is often for either material gain or for willful damage. Easy availability of hacking tools on the Internet, USB devices and wireless connectivity provide for easy break-ins. The net result is losses worth millions of dollars in terms of IP theft, leakage of customer / individual information, etc. This paper presents an understanding of Insider threats, attackers and their motives and suggests mitigation techniques at the organization level",
    "lastUpdated": "2010-10-13T10:47:58Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1010.1938v2"
  },
  {
    "title": "Time Stamp Attack on Wide Area Monitoring System in Smart Grid",
    "authors": [
      "Zhenghao Zhang",
      "Shuping Gong",
      "Husheng Li",
      "Changxing Pei"
    ],
    "abstract": "Security becomes an extremely important issue in smart grid. To maintain the steady operation for smart power grid, massive measurement devices must be allocated widely among the power grid. Previous studies are focused on false data injection attack to the smart grid system. In practice, false data injection attack is not easy to implement, since it is not easy to hack the power grid data communication system. In this paper, we demonstrate that a novel time stamp attack is a practical and dangerous attack scheme for smart grid. Since most of measurement devices are equipped with global positioning system (GPS) to provide the time information of measurements, it is highly probable to attack the measurement system by spoofing the GPS. By employing the real measurement data in North American Power Grid, simulation results demonstrate the effectiveness of the time stamp attack on smart grid.",
    "lastUpdated": "2011-09-07T23:38:31Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1102.1408v2"
  },
  {
    "title": "Implicitization of surfaces via geometric tropicalization",
    "authors": [
      "Maria Angelica Cueto"
    ],
    "abstract": "In this paper we further develop the theory of geometric tropicalization due to Hacking, Keel and Tevelev and we describe tropical methods for implicitization of surfaces. More precisely, we enrich this theory with a combinatorial formula for tropical multiplicities of regular points in arbitrary dimension and we prove a conjecture of Sturmfels and Tevelev regarding sufficient combinatorial conditions to compute tropical varieties via geometric tropicalization. Using these two results, we extend previous work of Sturmfels, Tevelev and Yu for tropical implicitization of generic surfaces, and we provide methods for approaching the non-generic cases.",
    "lastUpdated": "2012-05-23T20:59:47Z",
    "categories": [
      "math.AG",
      "math.CO",
      "14T05, 14M25, 68W30"
    ],
    "url": "http://arxiv.org/abs/1105.0509v2"
  },
  {
    "title": "Early Phishing",
    "authors": [
      "Koceilah Rekouche"
    ],
    "abstract": "The history of phishing traces back in important ways to the mid-1990s when hacking software facilitated the mass targeting of people in password stealing scams on America Online (AOL). The first of these software programs was mine, called AOHell, and it was where the word phishing was coined. The software provided an automated password and credit card-stealing mechanism starting in January 1995. Though the practice of tricking users in order to steal passwords or information possibly goes back to the earliest days of computer networking, AOHell's phishing system was the first automated tool made publicly available for this purpose. The program influenced the creation of many other automated phishing systems that were made over a number of years. These tools were available to amateurs who used them to engage in a countless number of phishing attacks. By the later part of the decade, the activity moved from AOL to other networks and eventually grew to involve professional criminals on the internet. What began as a scheme by rebellious teenagers to steal passwords evolved into one of the top computer security threats affecting people, corporations, and governments.",
    "lastUpdated": "2011-06-23T12:17:39Z",
    "categories": [
      "cs.CR",
      "cs.CY",
      "cs.SI"
    ],
    "url": "http://arxiv.org/abs/1106.4692v1"
  },
  {
    "title": "Mirror symmetry for log Calabi-Yau surfaces I",
    "authors": [
      "Mark Gross",
      "Paul Hacking",
      "Sean Keel"
    ],
    "abstract": "We give a canonical synthetic construction of the mirror family to a pair (Y,D) of a smooth projective surface with an anti-canonical cycle of rational curves, as the spectrum of an explicit algebra defined in terms of counts of rational curves on Y meeting D in a single point. In the case D is contractible, the family gives a smoothing of the dual cusp, and thus a proof of Looijenga's 1981 cusp conjecture.",
    "lastUpdated": "2015-03-06T09:24:50Z",
    "categories": [
      "math.AG",
      "14J33, 58K60"
    ],
    "url": "http://arxiv.org/abs/1106.4977v3"
  },
  {
    "title": "Capturing an Evader in Polygonal Environments: A Complete Information Game",
    "authors": [
      "Kyle Klein",
      "Subhash Suri"
    ],
    "abstract": "Suppose an unpredictable evader is free to move around in a polygonal environment of arbitrary complexity that is under full camera surveillance. How many pursuers, each with the same maximum speed as the evader, are necessary and sufficient to guarantee a successful capture of the evader? The pursuers always know the evader's current position through the camera network, but need to physically reach the evader to capture it. We allow the evader the knowledge of the current positions of all the pursuers as well---this accords with the standard worst-case analysis model, but also models a practical situation where the evader has \"hacked\" into the surveillance system. Our main result is to prove that three pursuers are always sufficient and sometimes necessary to capture the evader. The bound is independent of the number of vertices or holes in the polygonal environment. The result should be contrasted with the incomplete information pursuit-evasion where at least {\\Omega}(\\surd h + log n) pursuers are required just for detecting the evader in an environment with n vertices and h holes.",
    "lastUpdated": "2011-10-21T16:41:47Z",
    "categories": [
      "cs.GT",
      "I.2.11; I.2.9"
    ],
    "url": "http://arxiv.org/abs/1110.4838v1"
  },
  {
    "title": "A Topological Phase Transition in the Scheidegger Model of River Networks",
    "authors": [
      "Jacob N. Oppenheim",
      "Marcelo O. Magnasco"
    ],
    "abstract": "We investigate the canonical Scheidegger Model of river network morphology for the case of convergent and divergent underlying topography, by embedding it on a cone. We find two distinct phases corresponding to few, long basins and many, short basins, respectively, separated by a singularity in number of basins, indicating a phase transition. Quantifying basin shape through Hack's Law $l\\sim a^h$ gives distinct values for the exponent $h$, providing a method of testing our hypotheses. The generality of our model suggests implications for vascular morphology, in particular differing number and shapes of arterial and venous trees.",
    "lastUpdated": "2012-08-22T14:02:22Z",
    "categories": [
      "q-bio.TO",
      "cond-mat.stat-mech"
    ],
    "url": "http://arxiv.org/abs/1205.5066v2"
  },
  {
    "title": "Information Security Awareness Within Business Environment: An IT Review",
    "authors": [
      "Heru Susanto",
      "Mohammad Nabil Almunawar"
    ],
    "abstract": "The beauty of Information Technology (IT) is with its multifunction nature; it is a support system, a networking system, a storage system, as well as an information facilitator. Aided with their broad line of services, an IT system aims to support or even drive organizations towards desired paths. Trends of IT and information security awareness (ISA) in society today, particularly within the business environment is quite interesting phenomenon. The overviews of the role of IT in the modern world as well as the perception towards ISA are initially introduced. A series of scope are outlined, and also further examination on matter of IT and ISA in the business environment-emphasis on revolution of business with ISA, security threats such as identity thefts, hacking and web harassment, and the different mode of protections that are applied in different business environments. Unfortunately, the advancement of IT is not followed by the awareness of its security issues properly, especially in the context of the business settings and functions. This research and review is expected to influence the awareness of information security issues in business processes.",
    "lastUpdated": "2012-06-12T17:16:42Z",
    "categories": [
      "cs.OH"
    ],
    "url": "http://arxiv.org/abs/1206.2597v1"
  },
  {
    "title": "On the ample cone of a rational surface with an anticanonical cycle",
    "authors": [
      "Robert Friedman"
    ],
    "abstract": "Let $Y$ be a smooth rational surface and let $D$ be a cycle of rational curves on $Y$ which is an anticanonical divisor, i.e. an element of $|-K_Y|$. Looijenga studied the geometry of such surfaces $Y$ in case $D$ has at most five components and identified a geometrically significant subset $R$ of the divisor classes of square -2 orthogonal to the components of $D$. Motivated by recent work of Gross, Hacking, and Keel on the global Torelli theorem for pairs $(Y,D)$, we attempt to generalize some of Looijenga's results in case $D$ has more than five components. In particular, given an integral isometry $f$ of $H^2(Y)$ which preserves the classes of the components of $D$, we investigate the relationship between the condition that $f$ preserves the \"generic\" ample cone of $Y$ and the condition that $f$ preserves the set $R$.",
    "lastUpdated": "2013-01-04T18:18:55Z",
    "categories": [
      "math.AG"
    ],
    "url": "http://arxiv.org/abs/1207.7012v2"
  },
  {
    "title": "Skewless Network Clock Synchronization",
    "authors": [
      "Enrique Mallada",
      "Xiaoqiao Meng",
      "Michel Hack",
      "Li Zhang",
      "Ao Tang"
    ],
    "abstract": "This paper examines synchronization of computer clocks connected via a data network and proposes a skewless algorithm to synchronize them. Unlike existing solutions, which either estimate and compensate the frequency difference (skew) among clocks or introduce offset corrections that can generate jitter and possibly even backward jumps, our algorithm achieves synchronization without these problems. We first analyze the convergence property of the algorithm and provide necessary and sufficient conditions on the parameters to guarantee synchronization. We then implement our solution on a cluster of IBM BladeCenter servers running Linux and study its performance. In particular, both analytically and experimentally, we show that our algorithm can converge in the presence of timing loops. This marks a clear contrast with current standards such as NTP and PTP, where timing loops are specifically avoided. Furthermore, timing loops can even be beneficial in our scheme. For example, it is demonstrated that highly connected subnetworks can collectively outperform individual clients when the time source has large jitter. It is also experimentally demonstrated that our algorithm outperforms other well-established software-based solutions such as the NTPv4 and IBM Coordinated Cluster Time (IBM CCT).",
    "lastUpdated": "2013-08-19T20:57:54Z",
    "categories": [
      "math.OC",
      "cs.SY"
    ],
    "url": "http://arxiv.org/abs/1208.5703v2"
  },
  {
    "title": "Off-Path Hacking: The Illusion of Challenge-Response Authentication",
    "authors": [
      "Yossi Gilad",
      "Amir Herzberg",
      "Haya Shulman"
    ],
    "abstract": "Everyone is concerned about the Internet security, yet most traffic is not cryptographically protected. The usual justification is that most attackers are only off-path and cannot intercept traffic; hence, challenge-response mechanisms suffice to ensure authenticity. Usually, the challenges re-use existing `unpredictable' header fields to protect widely-deployed protocols such as TCP and DNS. We argue that this practice may often only give an illusion of security. We present recent off-path TCP injection and DNS poisoning attacks, enabling attackers to circumvent existing challenge-response defenses. Both TCP and DNS attacks are non-trivial, yet very efficient and practical. The attacks foil widely deployed security mechanisms, such as the Same Origin Policy, and allow a wide range of exploits, e.g., long-term caching of malicious objects and scripts. We hope that this article will motivate adoption of cryptographic mechanisms such as SSL/TLS, IPsec and DNSSEC, and of correct, secure challenge-response mechanisms.",
    "lastUpdated": "2013-05-03T23:01:21Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1305.0854v1"
  },
  {
    "title": "A universal setup for active control of a single-photon detector",
    "authors": [
      "Qin Liu",
      "Antía Lamas-Linares",
      "Christian Kurtsiefer",
      "Johannes Skaar",
      "Vadim Makarov",
      "Ilja Gerhardt"
    ],
    "abstract": "The influence of bright light on a single-photon detector has been described in a number of recent publications. The impact on quantum key distribution (QKD) is important, and several hacking experiments have been tailored to fully control single-photon detectors. Special attention has been given to avoid introducing further errors into a QKD system. We describe the design and technical details of an apparatus which allows to attack a quantum-cryptographic connection. This device is capable of controlling free-space and fiber-based systems and of minimizing unwanted clicks in the system. With different control diagrams, we are able to achieve a different level of control. The control was initially targeted to the systems using BB84 protocol, with polarization encoding and basis switching using beamsplitters, but could be extended to other types of systems. We further outline how to characterize the quality of active control of single-photon detectors.",
    "lastUpdated": "2013-12-15T22:09:18Z",
    "categories": [
      "quant-ph",
      "physics.ins-det"
    ],
    "url": "http://arxiv.org/abs/1307.5951v2"
  },
  {
    "title": "Flipping surfaces",
    "authors": [
      "Paul Hacking",
      "Jenia Tevelev",
      "Giancarlo Urzúa"
    ],
    "abstract": "We study semistable extremal threefold neighborhoods following earlier work of Mori, Koll\\'ar, and Prokhorov. We classify possible flips and extend Mori's algorithm for computing flips of extremal neighborhoods of type k2A to more general neighborhoods of type k1A. In fact we show that they belong to the same deformation family as k2A, and we explicitly construct the universal family of extremal neighborhoods. This construction follows very closely Mori's division algorithm, which we interpret as a sequence of mutations in the cluster algebra of rank 2 with general coefficients. We identify, in the versal deformation space of a cyclic quotient singularity, the locus of deformations such that the total space admits a (terminal) antiflip. We show that these deformations come from at most two irreducible components of the versal deformation space. As an application, we give an algorithm for computing stable one-parameter degenerations of smooth projective surfaces (under some conditions) and describe several components of the Koll\\'ar-Shepherd-Barron boundary of the moduli space of smooth canonically polarized surfaces of geometric genus zero.",
    "lastUpdated": "2015-07-02T19:42:37Z",
    "categories": [
      "math.AG"
    ],
    "url": "http://arxiv.org/abs/1310.1580v2"
  },
  {
    "title": "Gauge Symmetry, Spontaneous Breaking of Gauge Symmetry: Philosophical Approach",
    "authors": [
      "Pascal Lederer"
    ],
    "abstract": "This paper deals with the Berry phase, and the ontology of the electromagnetic vector potential. When the state of the system is gauge symmetric, the vector potential may be interpreted as a convenient tool of a mathematical formulation, with no ontological meaning. I argue that this interpretation is in difficulty because the vector potential depends linearly on the supercurrent in the superfluid state, which is a spontaneously broken gauge symmetry state, where particle number is not conserved. I suggest that when gauge symmetry is spontaneously broken, the vector potential becomes an emergent material object of nature. The revised version includes sections on scientific realism, and emergence, and new references on Noether's theorem, among others.",
    "lastUpdated": "2014-11-07T22:14:11Z",
    "categories": [
      "physics.hist-ph",
      "cond-mat.other"
    ],
    "url": "http://arxiv.org/abs/1401.8146v2"
  },
  {
    "title": "Tropical Theta Functions and Log Calabi-Yau Surfaces",
    "authors": [
      "Travis Mandel"
    ],
    "abstract": "We generalize the standard combinatorial techniques of toric geometry to the study of log Calabi-Yau surfaces. The character and cocharacter lattices are replaced by certain integral linear manifolds described by Gross, Hacking, and Keel, and monomials on toric varieties are replaced with the canonical theta functions which GHK defined using ideas from mirror symmetry. We describe the tropicalizations of theta functions and use them to generalize the dual pairing between the character and cocharacter lattices. We use this to describe generalizations of dual cones, Newton and polar polytopes, Minkowski sums, and finite Fourier series expansions. We hope that these techniques will generalize to higher-rank cluster varieties.",
    "lastUpdated": "2016-01-15T21:50:13Z",
    "categories": [
      "math.AG",
      "14J33, 14M25, 13F60"
    ],
    "url": "http://arxiv.org/abs/1407.5901v2"
  },
  {
    "title": "Measurement-device-independent quantum key distribution based on Bell's inequality",
    "authors": [
      "Hua-Lei Yin",
      "Yao Fu",
      "Yan-Lin Tang",
      "Yuan Li",
      "Teng-Yun Chen",
      "Zeng-Bing Chen"
    ],
    "abstract": "We propose two quantum key distribution (QKD) protocols based on Bell's inequality, which can be considered as modified time-reversed E91 protocol. Similar to the measurement-device-independent quantum key distribution (MDI-QKD) protocol, the first scheme requires the assumption that Alice and Bob perfectly characterize the encoded quantum states. However, our second protocol does not require this assumption, which can defeat more known and unknown source-side attacks compared with the MDI-QKD. The two protocols are naturally immune to all hacking attacks with respect to detections. Therefore, the security of the two protocols can be proven based on the violation of Bell's inequality with measurement data under fair-sampling assumption. In our simulation, the results of both protocols show that long-distance quantum key distribution over 200 km remains secure with conventional lasers in the asymptotic-data case. We present a new technique to estimate the Bell's inequality violation, which can also be applied to other fields of quantum information processing.",
    "lastUpdated": "2014-07-28T10:25:43Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/1407.7375v1"
  },
  {
    "title": "Classical phase space and Hadamard states in the BRST formalism for gauge field theories on curved spacetime",
    "authors": [
      "Michał Wrochna",
      "Jochen Zahn"
    ],
    "abstract": "We investigate linearized gauge theories on globally hyperbolic spacetimes in the BRST formalism. A consistent definition of the classical phase space and of its Cauchy surface analogue is proposed. We prove that it is isomorphic to the phase space in the subsidiary condition approach of Hack and Schenkel in the case of Maxwell, Yang-Mills, and Rarita-Schwinger fields. Defining Hadamard states in the BRST formalism in a standard way, their existence in the Maxwell and Yang-Mills case is concluded from known results in the subsidiary condition (or Gupta-Bleuler) formalism. Within our framework, we also formulate criteria for non-degeneracy of the phase space in terms of BRST cohomology and discuss special cases. These include an example in the Yang-Mills case, where degeneracy is not related to a non-trivial topology of the Cauchy surface.",
    "lastUpdated": "2017-05-08T10:20:35Z",
    "categories": [
      "math-ph",
      "hep-th",
      "math.MP"
    ],
    "url": "http://arxiv.org/abs/1407.8079v4"
  },
  {
    "title": "Plug-and-Play Measurement-Device-Independent Quantum Key Distribution",
    "authors": [
      "Yong-Su Kim",
      "Yujun Choi",
      "Osung Kwon",
      "Sang-Wook Han",
      "Sung Moon"
    ],
    "abstract": "Quantum key distribution (QKD) gaurantees unconditional communication security based on the laws of quantum physics. However, practical QKD suffers from a number of quantum hackings due to the device imperfections. From the security standpoint, measurement-device-independent quantum key distribution (MDI-QKD) is in the limelight since it eliminates all the possible loopholes in detection. Due to active control units for mode matching between the photons from remote parties, however, the implementation of MDI-QKD is highly impractical. In this article, we propose a novel method in which the indistinguishability issue is resolved without any active control unit. By introducing Plug-and-Play (P&P) concept into MDI-QKD, the indistinguishability between photons can naturally be guaranteed. We show the feasibility of P&P MDI-QKD with a proof-of-principle experiment.",
    "lastUpdated": "2016-03-17T06:15:54Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/1501.03344v2"
  },
  {
    "title": "Scattering diagrams, theta functions, and refined tropical curve counts",
    "authors": [
      "Travis Mandel"
    ],
    "abstract": "Working over various graded Lie algebras and in arbitrary dimension, we express scattering diagrams and theta functions in terms of counts of tropical curves/disks, weighted by multiplicities given in terms of iterated Lie brackets. Over the tropical vertex group, our tropical curve counts are known to give certain descendant log Gromov-Witten invariants. Working over the quantum torus algebra yields theta functions for quantum cluster varieties, and our tropical description sets up for geometric interpretations of these. As an immediate application, we prove the quantum Frobenius conjecture of Fock and Goncharov. We also prove a refined version of the Carl-Pumperla-Siebert result on consistency of theta functions, and we prove the non-degeneracy of the trace-pairing for the Gross-Hacking-Keel Frobenius structure conjecture.",
    "lastUpdated": "2019-08-01T18:25:32Z",
    "categories": [
      "math.QA",
      "math.AG",
      "math.CO",
      "14T05 (Primary), 13F60, 14N10 (Secondary)"
    ],
    "url": "http://arxiv.org/abs/1503.06183v5"
  },
  {
    "title": "A Linear First-Order Functional Intermediate Language for Verified Compilers",
    "authors": [
      "Sigurd Schneider",
      "Gert Smolka",
      "Sebastian Hack"
    ],
    "abstract": "We present the linear first-order intermediate language IL for verified compilers. IL is a functional language with calls to a nondeterministic environment. We give IL terms a second, imperative semantic interpretation and obtain a register transfer language. For the imperative interpretation we establish a notion of live variables. Based on live variables, we formulate a decidable property called coherence ensuring that the functional and the imperative interpretation of a term coincide. We formulate a register assignment algorithm for IL and prove its correctness. The algorithm translates a functional IL program into an equivalent imperative IL program. Correctness follows from the fact that the algorithm reaches a coherent program after consistently renaming local variables. We prove that the maximal number of live variables in the initial program bounds the number of different variables in the final coherent program. The entire development is formalized in Coq.",
    "lastUpdated": "2015-06-04T10:45:52Z",
    "categories": [
      "cs.PL"
    ],
    "url": "http://arxiv.org/abs/1503.08665v2"
  },
  {
    "title": "Security proof of quantum key distribution with detection efficiency mismatch",
    "authors": [
      "Chi-Hang Fred Fung",
      "Kiyoshi Tamaki",
      "Bing Qi",
      "Hoi-Kwong Lo",
      "Xiongfeng Ma"
    ],
    "abstract": "In theory, quantum key distribution (QKD) offers unconditional security based on the laws of physics. However, as demonstrated in recent quantum hacking theory and experimental papers, detection efficiency loophole can be fatal to the security of practical QKD systems. Here, we describe the physical origin of detection efficiency mismatch in various domains including spatial, spectral, and time domains and in various experimental set-ups. More importantly, we prove the unconditional security of QKD even with detection efficiency mismatch. We explicitly show how the key generation rate is characterized by the maximal detection efficiency ratio between the two detectors. Furthermore, we prove that by randomly switching the bit assignments of the detectors, the effect of detection efficiency mismatch can be completely eliminated.",
    "lastUpdated": "2008-10-15T11:10:29Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/0802.3788v2"
  },
  {
    "title": "Image Steganography using Karhunen-Loeve Transform and Least Bit Substitution",
    "authors": [
      "Ankit Chadha",
      "Neha Satam",
      "Rakshak Sood",
      "Dattatray Bade"
    ],
    "abstract": "As communication channels are increasing in number, reliability of faithful communication is reducing. Hacking and tempering of data are two major issues for which security should be provided by channel. This raises the importance of steganography. In this paper, a novel method to encode the message information inside a carrier image has been described. It uses Karhunen-Lo\\`eve Transform for compression of data and Least Bit Substitution for data encryption. Compression removes redundancy and thus also provides encoding to a level. It is taken further by means of Least Bit Substitution. The algorithm used for this purpose uses pixel matrix which serves as a best tool to work on. Three different sets of images were used with three different numbers of bits to be substituted by message information. The experimental results show that algorithm is time efficient and provides high data capacity. Further, it can decrypt the original data effectively. Parameters such as carrier error and message error were calculated for each set and were compared for performance analysis.",
    "lastUpdated": "2013-11-07T14:45:30Z",
    "categories": [
      "cs.MM"
    ],
    "url": "http://arxiv.org/abs/1311.1700v1"
  },
  {
    "title": "DrizzlePac 2.0 - Introducing New Features",
    "authors": [
      "Roberto J. Avila",
      "Warren Hack",
      "Mihai Cara",
      "David Borncamp",
      "Jennifer Mack",
      "Linda Smith",
      "Leonardo Ubeda"
    ],
    "abstract": "The DrizzlePac package includes tasks for aligning and drizzling images taken with the Hubble Space Telescope. We present this release which includes new features that facilitate image alignment, sky matching, and adds support for new time dependent distortion solutions of the ACS instrument. The TweakReg task now includes capabilities for automatically aligning images which form part of a mosaic. In addition, new parameters make it easier to reject cosmic rays and other spurious detections from source catalogs used for alignment. The Astrodrizzle task has been improved with a new sky matching algorithm which makes producing mosaics easier than ever before. This new version supports an improved version of the ACS/WFC time-dependent distortion correction. There are also improvements to the GUI interfaces and some behind the scene bug fixes.",
    "lastUpdated": "2014-11-20T17:03:29Z",
    "categories": [
      "astro-ph.IM"
    ],
    "url": "http://arxiv.org/abs/1411.5605v1"
  },
  {
    "title": "Hacking energy-time entanglement-based systems with classical light",
    "authors": [
      "Jonathan Jogenfors",
      "Ashraf M. Elhassan",
      "Johan Ahrens",
      "Mohamed Bourennane",
      "Jan-Åke Larsson"
    ],
    "abstract": "Photonic systems based on energy-time entanglement have been proposed to test local realism using the Bell inequality. A violation of this inequality normally also certifies security of device-independent quantum key distribution, so that an attacker cannot eavesdrop or control the system. Here, we show how this security test can be circumvented in energy-time entangled systems when using standard avalanche photodetectors, allowing an attacker to compromise the system without leaving a trace. With tailored pulses of classical light we reach Bell values up to 3.63 at 97.6% detector efficiency which is an extreme violation. This is the first demonstration of a violation-faking source that both gives tunable violation and high detector efficiency. The implications are severe: the standard Clauser-Horne-Shimony-Holt inequality cannot be used to show device-independent security for standard postselecting energy-time entanglement setups. We conclude with suggestions of improved tests and experimental setups that can re-establish device-independent security.",
    "lastUpdated": "2014-11-26T13:40:07Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/1411.7222v1"
  },
  {
    "title": "Effect of source tampering in the security of quantum cryptography",
    "authors": [
      "Shi-Hai Sun",
      "Feihu Xu",
      "Mu-Sheng Jiang",
      "Xiang-Chun Ma",
      "Hoi-Kwong Lo",
      "Lin-Mei Liang"
    ],
    "abstract": "The security of source has become an increasingly important issue in quantum cryptography. Based on the framework of measurement-device-independent quantum-key-distribution (MDI-QKD), the source becomes the only region exploitable by a potential eavesdropper (Eve). Phase randomization is a cornerstone assumption in most discrete-variable (DV-) quantum communication protocols (e.g., QKD, quantum coin tossing, weak coherent state blind quantum computing, and so on), and the violation of such an assumption is thus fatal to the security of those protocols. In this paper, we show a simple quantum hacking strategy, with commercial and homemade pulsed lasers, by Eve that allows her to actively tamper with the source and violate such an assumption, without leaving a trace afterwards. Furthermore, our attack may also be valid for continuous-variable (CV-) QKD, which is another main class of QKD protocol, since, excepting the phase random assumption, other parameters (e.g., intensity) could also be changed, which directly determine the security of CV-QKD.",
    "lastUpdated": "2015-08-21T12:39:16Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/1508.05258v1"
  },
  {
    "title": "Randomness determines practical security of BB84 quantum key distribution",
    "authors": [
      "Hong-Wei Li",
      "Zhen-Qiang Yin",
      "Shuang Wang",
      "Yong-Jun Qian",
      "Wei Chen",
      "Guang-Can Guo",
      "Zheng-Fu Han"
    ],
    "abstract": "Unconditional security of the BB84 quantum key distribution protocol has been proved by exploiting the fundamental laws of quantum mechanics, but the practical quantum key distribution system maybe hacked by considering the imperfect state preparation and measurement respectively. Until now, different attacking schemes have been proposed by utilizing imperfect devices, but the general security analysis model against all of the practical attacking schemes has not been proposed. Here, we demonstrate that the general practical attacking schemes can be divided into the Trojan horse attack, strong randomness attack and weak randomness attack respectively. We prove security of BB84 protocol under randomness attacking models, and these results can be applied to guarantee the security of the practical quantum key distribution system.",
    "lastUpdated": "2015-09-20T04:41:46Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/1508.06396v2"
  },
  {
    "title": "Donaldson-Thomas Transformation of Double Bruhat Cells in General Linear Groups",
    "authors": [
      "Daping Weng"
    ],
    "abstract": "Kontsevich and Soibelman defined the Donaldson-Thomas invariants of a 3d Calabi-Yau category with a stability condition. Any cluster variety can produce an example of such a category, whose corresponding Donaldson-Thomas invariants are encoded by a special formal automorphism of the cluster variety, known as the Donaldson-Thomas transformation. In this paper we prove a conjecture of Goncharov and Shen in the case of $\\mathrm{GL}_n$, which describes the Donaldson-Thomas transformation of the double quotient of the double Bruhat cells $H \\backslash \\mathrm{GL}_n^{u,v}/H$ where $H$ is a maximal torus, as a certain explicit cluster transformation related to Fomin-Zelevinsky's twist map. Our result, combined with the work of Gross, Hacking, Keel, and Kontsevich, proves the duality conjecture of Fock and Goncharov in the case of $H\\backslash \\mathrm{GL}_n^{u,v}/H$.",
    "lastUpdated": "2016-09-29T14:58:43Z",
    "categories": [
      "math.AG",
      "math-ph",
      "math.MP",
      "math.RT"
    ],
    "url": "http://arxiv.org/abs/1606.01948v2"
  },
  {
    "title": "Concrete Problems in AI Safety",
    "authors": [
      "Dario Amodei",
      "Chris Olah",
      "Jacob Steinhardt",
      "Paul Christiano",
      "John Schulman",
      "Dan Mané"
    ],
    "abstract": "Rapid progress in machine learning and artificial intelligence (AI) has brought increasing attention to the potential impacts of AI technologies on society. In this paper we discuss one such potential impact: the problem of accidents in machine learning systems, defined as unintended and harmful behavior that may emerge from poor design of real-world AI systems. We present a list of five practical research problems related to accident risk, categorized according to whether the problem originates from having the wrong objective function (\"avoiding side effects\" and \"avoiding reward hacking\"), an objective function that is too expensive to evaluate frequently (\"scalable supervision\"), or undesirable behavior during the learning process (\"safe exploration\" and \"distributional shift\"). We review previous work in these areas as well as suggesting research directions with a focus on relevance to cutting-edge AI systems. Finally, we consider the high-level question of how to think most productively about the safety of forward-looking applications of AI.",
    "lastUpdated": "2016-07-25T17:23:29Z",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1606.06565v2"
  },
  {
    "title": "Markov numbers and Lagrangian cell complexes in the complex projective plane",
    "authors": [
      "Jonathan David Evans",
      "Ivan Smith"
    ],
    "abstract": "We study Lagrangian embeddings of a class of two-dimensional cell complexes $L_{p,q}$ into the complex projective plane. These cell complexes, which we call pinwheels, arise naturally in algebraic geometry as vanishing cycles for quotient singularities of type $\\frac{1}{p^2}(pq-1,1)$ (Wahl singularities). We show that if a pinwheel admits a Lagrangian embedding into $\\mathbf{CP}^2$ then $p$ is a Markov number and we completely characterise $q$. We also show that a collection of Lagrangian pinwheels $L_{p_i,q_i}$, $i=1,\\ldots,N$, cannot be made disjoint unless $N\\leq 3$ and the $p_i$ form part of a Markov triple. These results are the symplectic analogue of a theorem of Hacking and Prokhorov, which classifies complex surfaces with quotient singularities admitting a $\\mathbf{Q}$-Gorenstein smoothing whose general fibre is $\\mathbf{CP}^2$.",
    "lastUpdated": "2017-06-12T11:28:49Z",
    "categories": [
      "math.SG",
      "math.AG",
      "math.GT",
      "53D53, 53D12"
    ],
    "url": "http://arxiv.org/abs/1606.08656v3"
  },
  {
    "title": "A New Approach to SMS Steganography using Mathematical Equations",
    "authors": [
      "Min Yang Lee",
      "Vahab Iranmanesh",
      "Juan C. Quiroz"
    ],
    "abstract": "In the era of Information Technology, cyber-crime has always been a worrying issue for online users. Phishing, social engineering, and third party attacks have made people reluctant to share their personal information, even with trusted entities. Messages that are sent via Short Message Service (SMS) are easily copied and hacked by using special software. To enforce the security of sending messages through mobile phones, one solution is SMS steganography. SMS Steganography is a technique that hides a secret message in the SMS. We propose a new approach for SMS steganography that uses a mathematical equation as the stego media in order to transmit the data. With this approach, we can hide up to 35 characters (25%) of a secret message on a single SMS with maximum of 140 characters.",
    "lastUpdated": "2016-07-27T03:42:49Z",
    "categories": [
      "cs.CR",
      "cs.MM"
    ],
    "url": "http://arxiv.org/abs/1607.07947v1"
  },
  {
    "title": "Quantum Field Theory on Curved Backgrounds -- A Primer",
    "authors": [
      "Marco Benini",
      "Claudio Dappiaggi",
      "Thomas-Paul Hack"
    ],
    "abstract": "Goal of this review is to introduce the algebraic approach to quantum field theory on curved backgrounds. Based on a set of axioms, first written down by Haag and Kastler, this method consists of a two-step procedure. In the first one, a suitable algebra of observables is assigned to a physical system, which is meant to encode all algebraic relations among observables, such as commutation relations, while, in the second step, one must select an algebraic state in order to recover the standard Hilbert space interpretation of a quantum system. As quantum field theories possess infinitely many degrees of freedom, many unitarily inequivalent Hilbert space representations exist and the power of such approach is the ability to treat them all in a coherent manner. We will discuss in detail the algebraic approach for free fields in order to give to the reader all necessary information to deal with the recent literature, which focuses on the applications to specific problems, mostly in cosmology.",
    "lastUpdated": "2013-06-30T16:58:00Z",
    "categories": [
      "gr-qc",
      "hep-th",
      "math-ph",
      "math.MP"
    ],
    "url": "http://arxiv.org/abs/1306.0527v2"
  },
  {
    "title": "Penetration Testing == POMDP Solving?",
    "authors": [
      "Carlos Sarraute",
      "Olivier Buffet",
      "Joerg Hoffmann"
    ],
    "abstract": "Penetration Testing is a methodology for assessing network security, by generating and executing possible attacks. Doing so automatically allows for regular and systematic testing without a prohibitive amount of human labor. A key question then is how to generate the attacks. This is naturally formulated as a planning problem. Previous work (Lucangeli et al. 2010) used classical planning and hence ignores all the incomplete knowledge that characterizes hacking. More recent work (Sarraute et al. 2011) makes strong independence assumptions for the sake of scaling, and lacks a clear formal concept of what the attack planning problem actually is. Herein, we model that problem in terms of partially observable Markov decision processes (POMDP). This grounds penetration testing in a well-researched formalism, highlighting important aspects of this problem's nature. POMDPs allow to model information gathering as an integral part of the problem, thus providing for the first time a means to intelligently mix scanning actions with actual exploits.",
    "lastUpdated": "2013-06-19T22:39:20Z",
    "categories": [
      "cs.AI",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1306.4714v1"
  },
  {
    "title": "A Security Analysis of Browser Extensions",
    "authors": [
      "Abhay Rana",
      "Rushil Nagda"
    ],
    "abstract": "Browser Extensions (often called plugins or addons) are small pieces of code that let developers add additional functionality to the browser. However, with extensions comes a security price: the user must trust the developer. We look at ways in which this trust can be broken and malicious extensions installed. We also look at silent installations of plugins in various browsers and work on ways to make silent installations possible in browsers that work against it. We compare the browser extension mechanism among various browsers, and try to create a set of rules to maintain the principle of least privileges in the browser. We track various plugins and determine whether the least privileges required match with the privileges asked for. We also work on a survey of extensions (for various browsers) and determine the nature of attacks possible. For eg, if a developer account gets hacked, updating of a normal extension with a malicious one is possible. We look at privilege abuse and survey extensions that ask for more privileges than they use. We finally provide a solution and allow a person to check the authenticity of the extension even before they download it.",
    "lastUpdated": "2014-03-13T11:18:43Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1403.3235v1"
  },
  {
    "title": "Enumeration of holomorphic cylinders in log Calabi-Yau surfaces. I",
    "authors": [
      "Tony Yue Yu"
    ],
    "abstract": "We define the counting of holomorphic cylinders in log Calabi-Yau surfaces. Although we start with a complex log Calabi-Yau surface, the counting is achieved by applying methods from non-archimedean geometry. This gives rise to new geometric invariants. Moreover, we prove that the counting satisfies a property of symmetry. Explicit calculations are given for a del Pezzo surface in detail, which verify the conjectured wall-crossing formula for the focus-focus singularity. Our holomorphic cylinders are expected to give a geometric understanding of the combinatorial notion of broken line by Gross, Hacking, Keel and Siebert. Our tools include Berkovich spaces, tropical geometry, Gromov-Witten theory and the GAGA theorem for non-archimedean analytic stacks.",
    "lastUpdated": "2016-08-23T06:19:29Z",
    "categories": [
      "math.AG",
      "math.SG",
      "Primary 14N35, Secondary 14J32, 14J26, 14T05, 14G22"
    ],
    "url": "http://arxiv.org/abs/1504.01722v3"
  },
  {
    "title": "Theta functions on varieties with effective anti-canonical class",
    "authors": [
      "Mark Gross",
      "Paul Hacking",
      "Bernd Siebert"
    ],
    "abstract": "We show that a large class of maximally degenerating families of n-dimensional polarized varieties come with a canonical basis of sections of powers of the ample line bundle. The families considered are obtained by smoothing a reducible union of toric varieties governed by a wall structure on a real n-(pseudo-)manifold. Wall structures have previously been constructed inductively for cases with locally rigid singularities and by Gromov-Witten theory for mirrors of log Calabi-Yau surfaces and K3 surfaces by various combinations of the authors. For trivial wall structures on the n-torus we retrieve the classical theta functions. Possible applications include mirror symmetry, geometric compactifications of moduli of certain polarized varieties via stable pairs and geometric quantization.",
    "lastUpdated": "2019-04-05T14:40:09Z",
    "categories": [
      "math.AG",
      "14J33, 14J32, 14J45"
    ],
    "url": "http://arxiv.org/abs/1601.07081v4"
  },
  {
    "title": "A Generic Slice of the Moduli Space of Line Arrangements",
    "authors": [
      "Kenneth Ascher",
      "Patricio Gallardo"
    ],
    "abstract": "We study the compactification of the locus parametrizing lines with a fixed intersection to a given line, inside the moduli space of line arrangements in the projective plane constructed for weight one by Hacking-Keel-Tevelev and Alexeev for general weights. We show that this space is smooth, with normal crossing boundary, and that it has a morphism to the moduli space of marked rational curves which can be understood as a natural continuation of the blow up construction of Kapranov. In addition, we prove that it is isomorphic to a closed subvariety inside a non-reductive Chow quotient. The parametrized objects are surfaces with broken lines, whose dual graphs are rooted trees with possibly repeated markings.",
    "lastUpdated": "2017-08-19T20:24:14Z",
    "categories": [
      "math.AG"
    ],
    "url": "http://arxiv.org/abs/1602.08958v3"
  },
  {
    "title": "Quantum Hacking on Quantum Key Distribution using Homodyne Detection",
    "authors": [
      "Jing-Zheng Huang",
      "Sébastien Kunz-Jacques",
      "Paul Jouguet",
      "Christian Weedbrook",
      "Zhen-Qiang Yin",
      "Shuang Wang",
      "Wei Chen",
      "Guang-Can Guo",
      "Zheng-Fu Han"
    ],
    "abstract": "Imperfect devices in commercial quantum key distribution systems open security loopholes that an eavesdropper may exploit. An example of one such imperfection is the wavelength dependent coupling ratio of the fiber beam splitter. Utilizing this loophole, the eavesdropper can vary the transmittances of the fiber beam splitter at the receiver's side by inserting lights with wavelengths different from what is normally used. Here, we propose a wavelength attack on a practical continuous-variable quantum key distribution system using homodyne detection. By inserting light pulses at different wavelengths, this attack allows the eavesdropper to bias the shot noise estimation even if it is done in real time. Based on experimental data, we discuss the feasibility of this attack and suggest a prevention scheme by improving the previously proposed countermeasures.",
    "lastUpdated": "2014-02-27T14:30:09Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/1402.6921v1"
  },
  {
    "title": "The Quantum Hall Effects: Philosophical Approach",
    "authors": [
      "Pascal Lederer"
    ],
    "abstract": "The Quantum Hall Effects offer a rich variety of theoretical and experimental advances. They provide interesting insights on such topics as complementarity, gauge invariance, strong interactions, emergence of new theoretical concepts. This paper focuses on some related philosophical questions. Hacking's views on Scientific Realism, Chalmers' on Non Figurative Realism are discussed. It is argued that the difficulties with those versions of realism may be resolved within a dialectical materialist approach. The latter is shown to provide a rational approach to the phenomena, the theory and the ontology of the Quantum Hall Effects.",
    "lastUpdated": "2015-03-19T10:49:57Z",
    "categories": [
      "physics.hist-ph"
    ],
    "url": "http://arxiv.org/abs/1406.4427v3"
  },
  {
    "title": "Robust Shot Noise Measurement for Continuous Variable Quantum Key Distribution",
    "authors": [
      "Sébastien Kunz-Jacques",
      "Paul Jouguet"
    ],
    "abstract": "We study a practical method to measure the shot noise in real time in Continuous Variable Quantum Key Distribution (CVQKD) systems. The amount of secret key that can be extracted from the raw statistics depends strongly on this quantity since it affects in particular the computation of the excess noise (i.e. noise in excess of the shot noise) added by an eavesdropper on the quantum channel. Some powerful quantum hacking attacks relying on faking the estimated value of the shot noise to hide an intercept and resend strategy were proposed. Here, we provide experimental evidence that our method can defeat the saturation attack and the wavelength attack.",
    "lastUpdated": "2015-01-17T20:27:46Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/1406.7554v2"
  },
  {
    "title": "Exceptional collections on Dolgachev surfaces associated with degenerations",
    "authors": [
      "Yonghwa Cho",
      "Yongnam Lee"
    ],
    "abstract": "Dolgachev surfaces are simply connected minimal elliptic surfaces with $p_g=q=0$ and of Kodaira dimension 1. These surfaces were constructed by logarithmic transformations of rational elliptic surfaces. In this paper, we explain the construction of Dolgachev surfaces via $\\mathbb Q$-Gorenstein smoothing of singular rational surfaces with two cyclic quotient singularities. This construction is based on the paper by Lee-Park. Also, some exceptional bundles on Dolgachev surfaces associated with $\\mathbb Q$-Gorenstein smoothing are constructed based on the idea of Hacking. In the case if Dolgachev surfaces were of type $(2,3)$, we describe the Picard group and present an exceptional collection of maximal length. Finally, we prove that the presented exceptional collection is not full, hence there exist a nontrivial phantom category in the derived category.",
    "lastUpdated": "2017-11-25T13:21:03Z",
    "categories": [
      "math.AG"
    ],
    "url": "http://arxiv.org/abs/1506.05213v4"
  },
  {
    "title": "Attacks on practical quantum key distribution systems (and how to prevent them)",
    "authors": [
      "Nitin Jain",
      "Birgit Stiller",
      "Imran Khan",
      "Dominique Elser",
      "Christoph Marquardt",
      "Gerd Leuchs"
    ],
    "abstract": "With the emergence of an information society, the idea of protecting sensitive data is steadily gaining importance. Conventional encryption methods may not be sufficient to guarantee data protection in the future. Quantum key distribution (QKD) is an emerging technology that exploits fundamental physical properties to guarantee perfect security in theory. However, it is not easy to ensure in practice that the implementations of QKD systems are exactly in line with the theoretical specifications. Such theory-practice deviations can open loopholes and compromise the security. Several of such loopholes have been discovered and investigated in the last decade. These activities have motivated the proposal and implementation of appropriate countermeasures, thereby preventing future attacks and enhancing the practical security of QKD. This article introduces the so-called field of quantum hacking by summarizing a variety of attacks and their prevention mechanisms.",
    "lastUpdated": "2016-09-17T20:36:44Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/1512.07990v2"
  },
  {
    "title": "Curbing cyber-crime and Enhancing e-commerce security with Digital Forensics",
    "authors": [
      "Israel Fianyi"
    ],
    "abstract": "The explosion in the e-commerce industry which has been necessitated by the growth and advance expansion of Information technology and its related facilities in recent years have been met with adverse security issues consequently affecting the industry and the entire online activities. This paper exams the prevailing security threats e-commerce is facing which is predominantly known as cyber-crime and how computer related technology and facilities such as digital forensics tools can be adopted extensively to ensure security in online related business activities. This paper investigated the risk, damage and the cost cyber-crime poses to individuals and organizations when they become victims. As it is obvious transacting business online as well as all related online activities has become inherent in our everyday life. The paper also comprehensively elucidate on some of the cyber-crime activities that are posing serious threat to the security of E-commerce. Amazon and eBay were used as the case of study in relation to respondents who patronizes these renowned e-commerce sites for various transactions. Keywords: E-commerce Security,Cyber-Crime,digital forensics, Network forensics, Network security, Online transactions, Identity theft, hacking.",
    "lastUpdated": "2016-01-18T08:27:57Z",
    "categories": [
      "cs.CR",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1610.08369v1"
  },
  {
    "title": "Compactly supported linearised observables in single-field inflation",
    "authors": [
      "Markus B. Fröb",
      "Thomas-Paul Hack",
      "Atsushi Higuchi"
    ],
    "abstract": "We investigate the gauge-invariant observables constructed by smearing the graviton and inflaton fields by compactly supported tensors at linear order in general single-field inflation. These observables correspond to gauge-invariant quantities that can be measured locally. In particular, we show that these observables are equivalent to (smeared) local gauge-invariant observables such as the linearised Weyl tensor, which have better infrared properties than the graviton and inflaton fields. Special cases include the equivalence between the compactly supported gauge-invariant graviton observable and the smeared linearised Weyl tensor in Minkowski and de Sitter spaces. Our results indicate that the infrared divergences in the tensor and scalar perturbations in single-field inflation have the same status as in de Sitter space and are both a gauge artefact, in a certain technical sense, at tree level.",
    "lastUpdated": "2017-08-31T13:54:55Z",
    "categories": [
      "gr-qc",
      "hep-th",
      "math-ph",
      "math.MP"
    ],
    "url": "http://arxiv.org/abs/1703.01158v2"
  },
  {
    "title": "Hacker Combat: A Competitive Sport from Programmatic Dueling & Cyberwarfare",
    "authors": [
      "Jovonni L. Pharr"
    ],
    "abstract": "The history of humanhood has included competitive activities of many different forms. Sports have offered many benefits beyond that of entertainment. At the time of this article, there exists not a competitive ecosystem for cyber security beyond that of conventional capture the flag competitions, and the like. This paper introduces a competitive framework with a foundation on computer science, and hacking. This proposed competitive landscape encompasses the ideas underlying information security, software engineering, and cyber warfare. We also demonstrate the opportunity to rank, score, & categorize actionable skill levels into tiers of capability. Physiological metrics are analyzed from participants during gameplay. These analyses provide support regarding the intricacies required for competitive play, and analysis of play. We use these intricacies to build a case for an organized competitive ecosystem. Using previous player behavior from gameplay, we also demonstrate the generation of an artificial agent purposed with gameplay at a competitive level.",
    "lastUpdated": "2017-03-15T01:38:16Z",
    "categories": [
      "cs.CR",
      "cs.CY",
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/1703.04874v1"
  },
  {
    "title": "Satellite-to-ground quantum communication using a 50-kg-class micro-satellite",
    "authors": [
      "Hideki Takenaka",
      "Alberto Carrasco-Casado",
      "Mikio Fujiwara",
      "Mitsuo Kitamura",
      "Masahide Sasaki",
      "Morio Toyoshima"
    ],
    "abstract": "Recent rapid growth in the number of satellite-constellation programs for remote sensing and communications, thanks to the availability of small-size and low-cost satellites, provides impetus for high capacity laser communication (lasercom) in space. Quantum communication can enhance the overall performance of lasercom, and also enables intrinsically hack-proof secure communication known as Quantum Key Distribution (QKD). Here, we report a quantum communication experiment between a micro-satellite (48 kg and 50 cm cube) in a low earth orbit and a ground station with single-photon counters. Non-orthogonal polarization states were transmitted from the satellite at a 10-MHz repetition rate. On the ground, by post-processing the received quantum states at an average of 0.14 photons/pulse, clock data recovery and polarization reference-frame synchronization were successfully done even under remarkable Doppler shifts. A quantum bit error rate below 5% was measured, demonstrating the feasibility of quantum communication in a real scenario from space.",
    "lastUpdated": "2017-07-12T08:30:24Z",
    "categories": [
      "physics.optics",
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/1707.08154v1"
  },
  {
    "title": "Del Pezzo surfaces with a single 1/k(1,1) singularity",
    "authors": [
      "Daniel Cavey",
      "Thomas Prince"
    ],
    "abstract": "Inspired by the recent progress by Coates-Corti-Kasprzyk et al. on Mirror Symmetry for del Pezzo surfaces, we show that for any positive integer k the deformation families of del Pezzo surfaces with a single 1/k(1,1) singularity (and no other singular points) fit into a single cascade. Additionally we construct models and toric degenerations of these surfaces embedded in toric varieties in codimension less than or equal two. Several of these directly generalise constructions of Reid-Suzuki (in the case k=3). We identify a root system in the Picard lattice, and in light of the work of Gross-Hacking-Keel, comment on Mirror Symmetry for each of these surfaces. Finally we classify all del Pezzo surfaces with certain combinations of 1/k(1,1) singularities for k=3,5,6 which admit a toric degeneration.",
    "lastUpdated": "2017-07-28T12:59:56Z",
    "categories": [
      "math.AG",
      "14J45, 14J17"
    ],
    "url": "http://arxiv.org/abs/1707.09213v1"
  },
  {
    "title": "How Does Knowledge of the AUC Constrain the Set of Possible Ground-truth Labelings?",
    "authors": [
      "Jacob Whitehill"
    ],
    "abstract": "Recent work on privacy-preserving machine learning has considered how data-mining competitions such as Kaggle could potentially be \"hacked\", either intentionally or inadvertently, by using information from an oracle that reports a classifier's accuracy on the test set. For binary classification tasks in particular, one of the most common accuracy metrics is the Area Under the ROC Curve (AUC), and in this paper we explore the mathematical structure of how the AUC is computed from an n-vector of real-valued \"guesses\" with respect to the ground-truth labels. We show how knowledge of a classifier's AUC on the test set can constrain the set of possible ground-truth labelings, and we derive an algorithm both to compute the exact number of such labelings and to enumerate efficiently over them. Finally, we provide empirical evidence that, surprisingly, the number of compatible labelings can actually decrease as n grows, until a test set-dependent threshold is reached.",
    "lastUpdated": "2017-09-11T15:11:28Z",
    "categories": [
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1709.02418v2"
  },
  {
    "title": "A Block Cipher using Rotation and Logical XOR Operations",
    "authors": [
      "D. Sravana Kumar",
      "CH. Suneetha",
      "A. Chandrasekhar"
    ],
    "abstract": "Cryptography is the study of methods of sending messages in disguised form so that only the intended recipients can remove the disguise and read the messages. Information security has become a very critical aspect of modern communication systems. With the global acceptance of the Internet as a medium of communication, virtually every computer in the world is connected to every other. It has created a new risk for the users of the computers with a constant threat of being hacked and being victims of data theft. In this connection data encryption has become an essential part of secure communication of the messages. In the present paper we propose a new method of encryption of data in blocks using the operations Rotation and Logical XOR",
    "lastUpdated": "2012-02-09T07:06:26Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1202.1898v1"
  },
  {
    "title": "On the symplectic cohomology of log Calabi-Yau surfaces",
    "authors": [
      "James Pascaleff"
    ],
    "abstract": "This article studies the symplectic cohomology of affine algebraic surfaces that admit a compactification by a normal crossings anticanonical divisor. Using a toroidal structure near the compactification divisor, we describe the complex computing symplectic cohomology, and compute enough differentials to identify a basis for the degree-zero part of the symplectic cohomology. This basis is indexed by integral points in a certain integral affine manifold, providing a relationship to the theta functions of Gross--Hacking--Keel. Included is a discussion of wrapped Floer cohomology of Lagrangian submanifolds and a description of the product structure in a special case. We also show that, after enhancing the coefficient ring, the degree--zero symplectic cohomology defines a family degenerating to a singular surface obtained by gluing together several affine planes.",
    "lastUpdated": "2018-11-29T17:48:11Z",
    "categories": [
      "math.SG",
      "math.AG",
      "Primary 53D40, Secondary 53D37, 14J33"
    ],
    "url": "http://arxiv.org/abs/1304.5298v3"
  },
  {
    "title": "Ideas for Advancing Code Sharing (A Different Kind of Hack Day)",
    "authors": [
      "Peter Teuben",
      "Alice Allen",
      "Bruce Berriman",
      "Kimberly DuPrie",
      "Robert J. Hanisch",
      "Jessica Mink",
      "Robert Nemiroff",
      "Lior Shamir",
      "Keith Shortridge",
      "Mark Taylor",
      "John Wallin"
    ],
    "abstract": "How do we as a community encourage the reuse of software for telescope operations, data processing, and calibration? How can we support making codes used in research available for others to examine? Continuing the discussion from last year Bring out your codes! BoF session, participants separated into groups to brainstorm ideas to mitigate factors which inhibit code sharing and nurture those which encourage code sharing. The BoF concluded with the sharing of ideas that arose from the brainstorming sessions and a brief summary by the moderator.",
    "lastUpdated": "2013-12-27T21:02:04Z",
    "categories": [
      "astro-ph.IM",
      "cs.DL"
    ],
    "url": "http://arxiv.org/abs/1312.7352v1"
  },
  {
    "title": "Measurement-device-independent quantum cryptography",
    "authors": [
      "Feihu Xu",
      "Marcos Curty",
      "Bing Qi",
      "Hoi-Kwong Lo"
    ],
    "abstract": "In theory, quantum key distribution (QKD) provides information-theoretic security based on the laws of physics. Owing to the imperfections of real-life implementations, however, there is a big gap between the theory and practice of QKD, which has been recently exploited by several quantum hacking activities. To fill this gap, a novel approach, called measurement-device-independent QKD (mdiQKD), has been proposed. It can remove all side-channels from the measurement unit, arguably the most vulnerable part in QKD systems, thus offering a clear avenue towards secure QKD realisations. Here, we review the latest developments in the framework of mdiQKD, together with its assumptions, strengths and weaknesses.",
    "lastUpdated": "2015-01-07T21:49:28Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/1409.5157v2"
  },
  {
    "title": "Long distance measurement-device-independent quantum key distribution with coherent-state superpositions",
    "authors": [
      "Hua-Lei Yin",
      "Wen-Fei Cao",
      "Yao Fu",
      "Yan-Lin Tang",
      "Yang Liu",
      "Teng-Yun Chen",
      "Zeng-Bing Chen"
    ],
    "abstract": "Measurement-device-independent quantum key distribution (MDI-QKD) with decoy-state method is believed to be securely applied to defeat various hacking attacks in practical quantum key distribution systems. Recently, the coherent-state superpositions (CSS) have emerged as an alternative to single-photon qubits for quantum information processing and metrology. Here, in this Letter, CSS are exploited as the source in MDI-QKD. We present an analytical method which gives two tight formulas to estimate the lower bound of yield and the upper bound of bit error rate. We exploit the standard statistical analysis and Chernoff bound to perform the parameter estimation. Chernoff bound can provide good bounds in the long distance MDI-QKD. Our results show that with CSS, both the security transmission distance and secure key rate are significantly improved compared with those of the weak coherent states in the finite-data case.",
    "lastUpdated": "2014-09-19T17:04:04Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/1409.5728v1"
  },
  {
    "title": "Necessary detection efficiencies for secure quantum key distribution and bound randomness",
    "authors": [
      "Antonio Acín",
      "Daniel Cavalcanti",
      "Elsa Passaro",
      "Stefano Pironio",
      "Paul Skrzypczyk"
    ],
    "abstract": "In recent years, several hacking attacks have broken the security of quantum cryptography implementations by exploiting the presence of losses and the ability of the eavesdropper to tune detection efficiencies. We present a simple attack of this form that applies to any protocol in which the key is constructed from the results of untrusted measurements performed on particles coming from an insecure source or channel. Because of its generality, the attack applies to a large class of protocols, from standard prepare-and-measure to device-independent schemes. Our attack gives bounds on the critical detection efficiencies necessary for secure quantum distribution, which show that the implementation of most partly device independent solutions is, from the point of view of detection efficiency, almost as demanding as fully device-independent ones. We also show how our attack implies the existence of a form of bound randomness, namely non-local correlations in which a non-signalling eavesdropper can find out a posteriori the result of any implemented measurement.",
    "lastUpdated": "2016-01-27T17:36:05Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/1505.00053v2"
  },
  {
    "title": "Polly's Polyhedral Scheduling in the Presence of Reductions",
    "authors": [
      "Johannes Doerfert",
      "Kevin Streit",
      "Sebastian Hack",
      "Zino Benaissa"
    ],
    "abstract": "The polyhedral model provides a powerful mathematical abstraction to enable effective optimization of loop nests with respect to a given optimization goal, e.g., exploiting parallelism. Unexploited reduction properties are a frequent reason for polyhedral optimizers to assume parallelism prohibiting dependences. To our knowledge, no polyhedral loop optimizer available in any production compiler provides support for reductions. In this paper, we show that leveraging the parallelism of reductions can lead to a significant performance increase. We give a precise, dependence based, definition of reductions and discuss ways to extend polyhedral optimization to exploit the associativity and commutativity of reduction computations. We have implemented a reduction-enabled scheduling approach in the Polly polyhedral optimizer and evaluate it on the standard Polybench 3.2 benchmark suite. We were able to detect and model all 52 arithmetic reductions and achieve speedups up to 2.21$\\times$ on a quad core machine by exploiting the multidimensional reduction in the BiCG benchmark.",
    "lastUpdated": "2015-05-28T15:05:46Z",
    "categories": [
      "cs.PL",
      "cs.DC",
      "D.3.4"
    ],
    "url": "http://arxiv.org/abs/1505.07716v1"
  },
  {
    "title": "Astronomy and Astrophysics in the Philosophy of Science",
    "authors": [
      "Sibylle Anderl"
    ],
    "abstract": "This article looks at philosophical aspects and questions that modern astrophysical research gives rise to. Other than cosmology, astrophysics particularly deals with understanding phenomena and processes operating at \"intermediate\" cosmic scales, which has rarely aroused philosophical interest so far. Being confronted with the attribution of antirealism by Ian Hacking because of its observational nature, astrophysics is equipped with a characteristic methodology that can cope with the missing possibility of direct interaction with most objects of research. In its attempt to understand the causal history of singular phenomena it resembles the historical sciences, while the search for general causal relations with respect to classes of processes or objects can rely on the \"cosmic laboratory\": the multitude of different phenomena and environments, naturally provided by the universe. Furthermore, the epistemology of astrophysics is strongly based on the use of models and simulations and a complex treatment of large amounts of data.",
    "lastUpdated": "2015-10-12T13:58:11Z",
    "categories": [
      "physics.hist-ph",
      "astro-ph.GA",
      "astro-ph.IM"
    ],
    "url": "http://arxiv.org/abs/1510.03284v1"
  },
  {
    "title": "Homological mirror symmetry for hypersurface cusp singularities",
    "authors": [
      "Ailsa Keating"
    ],
    "abstract": "We study versions of homological mirror symmetry for hypersurface cusp singularities and the three hypersurface simple elliptic singularities. We show that the Milnor fibres of each of these carries a distinguished Lefschetz fibration; its derived directed Fukaya category is equivalent to the derived category of coherent sheaves on a smooth rational surface $Y_{p,q,r}$. By using localization techniques on both sides, we get an isomorphism between the derived wrapped Fukaya category of the Milnor fibre and the derived category of coherent sheaves on a quasi-projective surface given by deleting an anti-canonical divisor $D$ from $Y_{p,q,r}$. In the cusp case, the pair $(Y_{p,q,r}, D)$ is naturally associated to the dual cusp singularity, tying into Gross, Hacking and Keel's proof of Looijenga's conjecture.",
    "lastUpdated": "2017-05-26T14:02:15Z",
    "categories": [
      "math.SG",
      "math.AG"
    ],
    "url": "http://arxiv.org/abs/1510.08911v2"
  },
  {
    "title": "New Combinatorial Formulas for Cluster Monomials of Type A Quivers",
    "authors": [
      "Kyungyong Lee",
      "Li Li",
      "Ba Nguyen"
    ],
    "abstract": "Lots of research focuses on the combinatorics behind various bases of cluster algebras. This paper studies the natural basis of a type A cluster algebra, which consists of all cluster monomials. We introduce a new kind of combinatorial formulas for the cluster monomials in terms of the so-called globally compatible collections. We give bijective proofs of these formulas by comparing with the well-known combinatorial models of the T-paths and of the perfect matchings in a snake diagram. For cluster variables of a type A cluster algebra, we give a bijection that relates our new formula with the theta functions constructed by Gross, Hacking, Keel and Kontsevich.",
    "lastUpdated": "2017-06-05T23:29:08Z",
    "categories": [
      "math.CO",
      "13F60, 05A19, 05E40"
    ],
    "url": "http://arxiv.org/abs/1604.06728v3"
  },
  {
    "title": "Enumeration of holomorphic cylinders in log Calabi-Yau surfaces. II. Positivity, integrality and the gluing formula",
    "authors": [
      "Tony Yue Yu"
    ],
    "abstract": "We prove three fundamental properties of counting holomorphic cylinders in log Calabi-Yau surfaces: positivity, integrality and the gluing formula. Positivity and integrality assert that the numbers of cylinders, defined via virtual techniques, are in fact nonnegative integers. The gluing formula roughly says that cylinders can be glued together to form longer cylinders, and the number of longer cylinders equals the product of the numbers of shorter cylinders. Our approach uses Berkovich geometry, tropical geometry, deformation theory and the ideas in the proof of associativity relations of Gromov-Witten invariants by Maxim Kontsevich. These three properties provide an evidence for a conjectural relation between counting cylinders and the broken lines of Gross-Hacking-Keel.",
    "lastUpdated": "2020-02-25T10:32:54Z",
    "categories": [
      "math.AG",
      "math.SG",
      "Primary 14N35, Secondary 53D37 14T05 14G22 14J32"
    ],
    "url": "http://arxiv.org/abs/1608.07651v3"
  },
  {
    "title": "Intrinsic mirror symmetry and punctured Gromov-Witten invariants",
    "authors": [
      "Mark Gross",
      "Bernd Siebert"
    ],
    "abstract": "This contribution to the 2015 AMS Summer Institute in Algebraic Geometry (Salt Lake City) announces a general mirror construction. This construction applies to log Calabi-Yau pairs (X,D) with maximal boundary D or to maximally unipotent degenerations of Calabi-Yau manifolds. The new ingredient is a notion of \"punctured Gromov-Witten invariant\", currently in progress with Abramovich and Chen. The mirror to a pair (X,D) is constructed as the spectrum of a ring defined using the punctured invariants of (X,D). An analogous construction leads to mirrors of Calabi-Yau manifolds. This can be viewed as a generalization of constructions developed jointly with Hacking and Keel in the case of log CY surfaces and K3 surfaces.",
    "lastUpdated": "2016-11-02T10:26:20Z",
    "categories": [
      "math.AG",
      "14J32"
    ],
    "url": "http://arxiv.org/abs/1609.00624v3"
  },
  {
    "title": "CNSMO: A Network Services Manager/Orchestrator Tool for Cloud Federated Environments",
    "authors": [
      "J. Aznar",
      "E. Escalona",
      "I. Canyameres",
      "O. Moya",
      "A. Viñes"
    ],
    "abstract": "Application service providers (ASPs) now develop, deploy, and maintain complex computing platforms within multiple cloud infrastructures to improve resilience, responsiveness and elasticity of their applications. On the other hand, complex applications have little control and visibility over network resources, and need to use low-level hacks to extract network properties and prioritize traffic. This biased view, limits tenants flexibility while deploying their applications and prevents them from implementing part of the application logic in the network. In this paper, we propose the CNSMO (CYCLONE Network Services Manager/Orchestrator) tool to bring the innovation at federated cloud environments by bridging these network service capabilities to cloud based services as part of the overall CYCLONE solution. The integration of networking aspects with purely federated clouds, will allow users to request specific infrastructures and manage their dedicated set of coordinated network and IT resources in an easy and transparent way while operating dynamic deployments of distributed applications.",
    "lastUpdated": "2016-09-05T07:43:35Z",
    "categories": [
      "cs.NI",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1609.01043v1"
  },
  {
    "title": "Waterfiling: Balancing the Tor network with maximum diversity",
    "authors": [
      "Florentin Rochet",
      "Olivier Pereira"
    ],
    "abstract": "We present the Waterfilling circuit selection method, which we designed in order to mitigate the risks of a successful end-to-end traffic correlation attack. Waterfilling proceeds by balancing the Tor network load as evenly as possible on endpoints of user paths. We simulate the use of Waterfilling thanks to the TorPS and Shadow tools. Applying several security metrics, we show that the adoption of Waterfilling considerably increases the number of nodes that an adversary needs to control in order to be able to mount a successful attack, while somewhat decreasing the minimum amount of bandwidth required to do so. Moreover, we evaluate Waterfilling into Shadow and show that it does not impact significantly the performance of the network. Furthermore, Waterfilling reduces the benefits that an attacker could obtain by hacking into a top bandwidth Tor relay, hence limiting the risks raised by such relays.",
    "lastUpdated": "2016-11-30T16:18:57Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1609.04203v2"
  },
  {
    "title": "Combinatorics of canonical bases revisited: Type A",
    "authors": [
      "Volker Genz",
      "Gleb Koshevoy",
      "Bea Schumann"
    ],
    "abstract": "We initiate a new approach to the study of the combinatorics of several parametrizations of canonical bases. In this work we deal with Lie algebras of type $A$. Using geometric objects called Rhombic tilings we derive a \"crossing formula\" to compute the actions of the crystal operators on Lusztig data for an arbitrary reduced word of the longest Weyl group element. We provide the following three applications of this result. Using the tropical Chamber Ansatz of Berenstein-Fomin-Zelevinsky we prove an enhanced version of the Anderson-Mirkovi\\'c conjecture for the crystal structure on MV polytopes. We establish a duality between Kashiwara's string and Lusztig's parametrization, revealing that each of them is controlled by the crystal structure of the other. We identify the potential functions of the unipotent radical of $SL_n$ defined by Berenstein-Kazhdan and Gross-Hacking-Keel-Kontsevich, respectively, with a function arising from the crystal structure on Lusztig data.",
    "lastUpdated": "2017-09-27T23:28:49Z",
    "categories": [
      "math.RT",
      "math.CO",
      "math.QA"
    ],
    "url": "http://arxiv.org/abs/1611.03465v2"
  },
  {
    "title": "Donaldson-Thomas Transformation of Double Bruhat Cells in Semisimple Lie Groups",
    "authors": [
      "Daping Weng"
    ],
    "abstract": "Double Bruhat cells $G^{u,v}$ were studied by Fomin and Zelevinsky. They provide important examples of cluster algebras and cluster Poisson varieties. Cluster varieties produce examples of 3d Calabi-Yau categories with stability conditions, and their Donaldson-Thomas invariants, defined by Kontsevich and Soibelman, are encoded by a formal automorphism on the cluster variety known as the Donaldson-Thomas transformation. Goncharov and Shen conjectured in that for any semisimple Lie group $G$, the Donaldson-Thomas transformation of the cluster Poisson variety $H\\backslash G^{u,v}/H$ is a slight modification of Fomin and Zelevinsky's twist map. In this paper we prove this conjecture, using crucially Fock and Goncharov's cluster ensembles and the amalgamation construction. Our result, combined with the work of Gross, Hacking, Keel, and Kontsevich, proves the duality conjecture of Fock and Goncharov in the case of $H\\backslash G^{u,v}/H$.",
    "lastUpdated": "2019-04-16T21:18:50Z",
    "categories": [
      "math.AG",
      "math-ph",
      "math.MP",
      "math.RT"
    ],
    "url": "http://arxiv.org/abs/1611.04186v2"
  },
  {
    "title": "Countermeasure against blinding attacks on low-noise detectors with background noise cancellation scheme",
    "authors": [
      "Min Soo Lee",
      "Byung Kwon Park",
      "Min Ki Woo",
      "Chang Hoon Park",
      "Yong-Su Kim",
      "Sang-Wook Han",
      "Sung Moon"
    ],
    "abstract": "We developed a countermeasure against blinding attacks on low-noise detectors with a background noise cancellation scheme in quantum key distribution (QKD) systems. Background noise cancellation includes self-differencing and balanced avalanche photon diode (APD) schemes and is considered a promising solution for low-noise APDs, which are critical components in high-performance QKD systems. However, its vulnerability to blinding attacks has been recently reported. In this work, we propose a new countermeasure that prevents this potential security loophole from being used in detector blinding attacks. An experimental QKD setup is implemented and various tests are conducted to verify the feasibility and performance of the proposed method. The obtained measurement results show that the proposed scheme successfully detects occurring blinding-attack-based hacking attempts.",
    "lastUpdated": "2016-11-14T07:12:22Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/1611.04267v1"
  },
  {
    "title": "String cone and Superpotential combinatorics for flag and Schubert varieties in type A",
    "authors": [
      "Lara Bossinger",
      "Ghislain Fourier"
    ],
    "abstract": "We study the combinatorics of pseudoline arrangements and their relation to the geometry of flag and Schubert varieties. We associate to each pseudoline arrangement two polyhedral cones, defined in a dual manner. We prove that one of them is the weighted string cone by Littelmann and Berenstein-Zelevinsky. For the other we show how it arises in the framework of cluster varieties and mirror symmetry by Gross-Hacking-Keel-Kontsevich: for the flag variety the cone is the tropicalization of their superpotential while for Schubert varieties a restriction of the superpotential is necessary. We prove that the two cones are unimodularly equivalent. As a corollary of our combinatorial result we realize Caldero's toric degenerations of Schubert varieties as GHKK-degeneration using cluster theory.",
    "lastUpdated": "2019-04-29T21:06:26Z",
    "categories": [
      "math.RT",
      "math.AG",
      "math.CO",
      "14M15, 14M25, 14M99, 13F60, 17B10, 52B20"
    ],
    "url": "http://arxiv.org/abs/1611.06504v4"
  },
  {
    "title": "Multivariate Industrial Time Series with Cyber-Attack Simulation: Fault Detection Using an LSTM-based Predictive Data Model",
    "authors": [
      "Pavel Filonov",
      "Andrey Lavrentyev",
      "Artem Vorontsov"
    ],
    "abstract": "We adopted an approach based on an LSTM neural network to monitor and detect faults in industrial multivariate time series data. To validate the approach we created a Modelica model of part of a real gasoil plant. By introducing hacks into the logic of the Modelica model, we were able to generate both the roots and causes of fault behavior in the plant. Having a self-consistent data set with labeled faults, we used an LSTM architecture with a forecasting error threshold to obtain precision and recall quality metrics. The dependency of the quality metric on the threshold level is considered. An appropriate mechanism such as \"one handle\" was introduced for filtering faults that are outside of the plant operator field of interest.",
    "lastUpdated": "2016-12-26T11:26:03Z",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1612.06676v2"
  },
  {
    "title": "The Star Product in Interacting Quantum Field Theory",
    "authors": [
      "Eli Hawkins",
      "Kasia Rejzner"
    ],
    "abstract": "We propose a new formula for the star product in deformation quantization of Poisson structures related in a specific way to a variational problem for a function $S$, interpreted as the action functional. Our approach is motivated by perturbative Algebraic Quantum Field Theory (pAQFT). We provide a direct combinatorial formula for the star product and we show that it can be applied to a certain class of infinite dimensional manifolds (e.g., regular observables in pAQFT). This is the first step towards understanding how pAQFT can be formulated such that the only formal parameter is $\\hbar$, while the coupling constant can be treated as a number. In the introductory part of the paper, apart from reviewing the framework, we make precise several statements present in the pAQFT literature and recast these in the language of (formal) deformation quantization. Finally, we use our formalism to streamline the proof of perturbative agreement provided by Drago, Hack, and Pinamonti and to generalize some of the results obtained in that work to the case of a non-linear interaction.",
    "lastUpdated": "2019-07-01T13:29:26Z",
    "categories": [
      "math-ph",
      "math.MP",
      "math.SG"
    ],
    "url": "http://arxiv.org/abs/1612.09157v4"
  },
  {
    "title": "Quantum lock on dark states",
    "authors": [
      "Yuri I. Ozhigov"
    ],
    "abstract": "We propose quantum protection circuit (quantum lock), based on dark states of ensembles of two-level atoms in optical cavity. The secret key is the splitting of atoms into pairs, and publicly accessible part of the lock is the tensor product of EPR singlets, corresponding to the given splitting. To open the lock one must move synchronously pairs of atoms from the correct splitting to the other cavity; the lock will open if atoms do not emit photons. This scheme has perfect secrecy: it is impossible to hack it, even with effective solutions of any classical computational problems, in contrast to the RSA scheme. The method of obtaining dark states through Stark shift of atomic excitation energy is also proposed. This scheme makes possible to create secret keys of a few tens of atoms that is sufficient for the most practical applications.",
    "lastUpdated": "2017-10-09T11:35:35Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/1710.04065v1"
  },
  {
    "title": "Reconsidering Experiments",
    "authors": [
      "Lydia Patton"
    ],
    "abstract": "Experiments may not reveal their full import at the time that they are performed. The scientists who perform them usually are testing a specific hypothesis and quite often have specific expectations limiting the possible inferences that can be drawn from the experiment. Nonetheless, as Hacking has said, experiments have lives of their own. Those lives do not end with the initial report of the results and consequences of the experiment. Going back and rethinking the consequences of the experiment in a new context, theoretical or empirical, has great merit as a strategy for investigation and for scientific problem analysis. I apply this analysis to the interplay between Fizeau's classic optical experiments and the building of special relativity. Einstein's understanding of the problems facing classical electrodynamics and optics, in part, was informed by Fizeau's 1851 experiments. However, between 1851 and 1905, Fizeau's experiments were duplicated and reinterpreted by a succession of scientists, including Hertz, Lorentz, and Michelson. Einstein's analysis of the consequences of the experiments is tied closely to this theoretical and experimental tradition. However, Einstein's own inferences from the experiments differ greatly from the inferences drawn by others in that tradition.",
    "lastUpdated": "2017-10-16T15:44:49Z",
    "categories": [
      "physics.hist-ph",
      "01"
    ],
    "url": "http://arxiv.org/abs/1710.05786v1"
  },
  {
    "title": "Inverse Reward Design",
    "authors": [
      "Dylan Hadfield-Menell",
      "Smitha Milli",
      "Pieter Abbeel",
      "Stuart Russell",
      "Anca Dragan"
    ],
    "abstract": "Autonomous agents optimize the reward function we give them. What they don't know is how hard it is for us to design a reward function that actually captures what we want. When designing the reward, we might think of some specific training scenarios, and make sure that the reward will lead to the right behavior in those scenarios. Inevitably, agents encounter new scenarios (e.g., new types of terrain) where optimizing that same reward may lead to undesired behavior. Our insight is that reward functions are merely observations about what the designer actually wants, and that they should be interpreted in the context in which they were designed. We introduce inverse reward design (IRD) as the problem of inferring the true objective based on the designed reward and the training MDP. We introduce approximate methods for solving IRD problems, and use their solution to plan risk-averse behavior in test MDPs. Empirical results suggest that this approach can help alleviate negative side effects of misspecified reward functions and mitigate reward hacking.",
    "lastUpdated": "2020-10-07T15:41:58Z",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1711.02827v2"
  },
  {
    "title": "A Case Study of the 2016 Korean Cyber Command Compromise",
    "authors": [
      "Kyong Jae Park",
      "Sung Mi Park",
      "Joshua I. James"
    ],
    "abstract": "On October 2016 the South Korean cyber military unit was the victim of a successful cyber attack that allowed access to internal networks. Per usual with large scale attacks against South Korean entities, the hack was immediately attributed to North Korea. Also, per other large-scale cyber security incidents, the same types of 'evidence' were used for attribution purposes. Disclosed methods of attribution provide weak evidence, and the procedure Korean organizations tend to use for information disclosure lead many to question any conclusions. We will analyze and discuss a number of issues with the current way that South Korean organizations disclose cyber attack information to the public. A time line of events and disclosures will be constructed and analyzed in the context of appropriate measures for cyber warfare. Finally, we will examine the South Korean cyber military attack in terms previously proposed cyber warfare response guidelines. Specifically, whether any of the guidelines can be applied to this real-world case, and if so, is South Korea justified in declaring war based on the most recent cyber attack.",
    "lastUpdated": "2017-11-13T10:24:57Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1711.04500v1"
  },
  {
    "title": "Security Issues in Controller Area Networks in Automobiles",
    "authors": [
      "Robert Buttigieg",
      "Mario Farrugia",
      "Clyde Meli"
    ],
    "abstract": "Modern vehicles may contain a considerable number of ECUs (Electronic Control Units) which are connected through various means of communication, with the CAN (Controller Area Network) protocol being the most widely used. However, several vulnerabilities such as the lack of authentication and the lack of data encryption have been pointed out by several authors, which ultimately render vehicles unsafe to their users and surroundings. Moreover, the lack of security in modern automobiles has been studied and analyzed by other researchers as well as several reports about modern car hacking have (already) been published. The contribution of this work aimed to analyze and test the level of security and how resilient is the CAN protocol by taking a BMW E90 (3-series) instrument cluster as a sample for a proof of concept study. This investigation was carried out by building and developing a rogue device using cheap commercially available components while being connected to the same CAN-Bus as a man in the middle device in order to send spoofed messages to the instrument cluster.",
    "lastUpdated": "2017-11-17T09:27:02Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1711.05824v2"
  },
  {
    "title": "Liquid dewetting under a thin elastic film",
    "authors": [
      "Rafael D. Schulman",
      "John F. Niven",
      "Michiel A. Hack",
      "Christian DiMaria",
      "Kari Dalnoki-Veress"
    ],
    "abstract": "We study the dewetting of liquid films capped by a thin elastomeric layer. When the tension in the elastomer is isotropic, circular holes grow at a rate which decreases with increasing tension. The morphology of holes and rim stability can be controlled by changing the boundary conditions and tension in the capping film. When the capping film is prepared with a biaxial tension, holes form with a non-circular shape elongated along the high tension axis. With suitable choice of elastic boundary conditions, samples can even be designed such that square holes appear.",
    "lastUpdated": "2017-11-26T02:09:58Z",
    "categories": [
      "cond-mat.soft",
      "cond-mat.mes-hall",
      "cond-mat.mtrl-sci",
      "physics.flu-dyn"
    ],
    "url": "http://arxiv.org/abs/1711.09318v1"
  },
  {
    "title": "Modeling mode interactions in boundary layer flows via the Parabolized Floquet Equations",
    "authors": [
      "Wei Ran",
      "Armin Zare",
      "M. J. Philipp Hack",
      "Mihailo R. Jovanović"
    ],
    "abstract": "In this paper, we develop a model based on successive linearization to study interactions between different modes in boundary layer flows. Our method consists of two steps. First, we augment the Blasius boundary layer profile with a disturbance field resulting from the linear Parabolized Stability Equations (PSE) to obtain the modified base flow; and, second, we draw on Floquet decomposition to capture the effect of mode interactions on the spatial evolution of flow fluctuations via a sequence of linear progressions. The resulting Parabolized Floquet Equations (PFE) can be conveniently advanced downstream to examine the interaction between different modes in slowly varying shear flows. We apply our framework to two canonical settings of transition in boundary layers; the H-type transition scenario that is initiated by exponential instabilities, and streamwise elongated laminar streaks that are triggered by the lift-up mechanism. We demonstrate that the PFE capture the growth of various harmonics and provide excellent agreement with the results obtained in direct numerical simulations and in experiments.",
    "lastUpdated": "2019-01-04T07:28:15Z",
    "categories": [
      "physics.flu-dyn"
    ],
    "url": "http://arxiv.org/abs/1712.02024v3"
  },
  {
    "title": "Approaches to linear local gauge-invariant observables in inflationary cosmologies",
    "authors": [
      "Markus B. Fröb",
      "Thomas-Paul Hack",
      "Igor Khavkine"
    ],
    "abstract": "We review and relate two recent complementary constructions of linear local gauge-invariant observables for cosmological perturbations in generic spatially flat single-field inflationary cosmologies. After briefly discussing their physical significance, we give explicit, covariant and mutually invertible transformations between the two sets of observables, thus resolving any doubts about their equivalence. In this way, we get a geometric interpretation and show the completeness of both sets of observables, while previously each of these properties was available only for one of them.",
    "lastUpdated": "2019-09-19T08:57:57Z",
    "categories": [
      "gr-qc",
      "math-ph",
      "math.MP"
    ],
    "url": "http://arxiv.org/abs/1801.02632v2"
  },
  {
    "title": "Avoiding the Internet of Insecure Industrial Things",
    "authors": [
      "Lachlan Urquhart",
      "Derek McAuley"
    ],
    "abstract": "Security incidents such as targeted distributed denial of service (DDoS) attacks on power grids and hacking of factory industrial control systems (ICS) are on the increase. This paper unpacks where emerging security risks lie for the industrial internet of things, drawing on both technical and regulatory perspectives. Legal changes are being ushered by the European Union (EU) Network and Information Security (NIS) Directive 2016 and the General Data Protection Regulation 2016 (GDPR) (both to be enforced from May 2018). We use the case study of the emergent smart energy supply chain to frame, scope out and consolidate the breadth of security concerns at play, and the regulatory responses. We argue the industrial IoT brings four security concerns to the fore, namely: appreciating the shift from offline to online infrastructure; managing temporal dimensions of security; addressing the implementation gap for best practice; and engaging with infrastructural complexity. Our goal is to surface risks and foster dialogue to avoid the emergence of an Internet of Insecure Industrial Things",
    "lastUpdated": "2018-01-22T17:19:18Z",
    "categories": [
      "cs.HC",
      "cs.CY",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1801.07207v1"
  },
  {
    "title": "Sensing the Chinese Diaspora: How Mobile Apps Can Provide Insights into Global Migration Flows",
    "authors": [
      "Minhui Xue",
      "Xin Yuan",
      "Heather Lee",
      "Keith Ross"
    ],
    "abstract": "Many countries today have \"country-centric mobile apps\" which are mobile apps that are primarily used by residents of a specific country. Many of these country-centric apps also include a location-based service which takes advantage of the smartphone's API access to the smartphone's current GPS location. In this paper, we investigate how such country-centric apps with location-based services can be employed to study the diaspora associated with ethnic and cultural groups. Our methodology combines GPS hacking, automated task tools for mobile phones, and OCR to generate migration statistics for diaspora. As a case study, we apply our methodology to WeChat, an enormously popular app within China and among ethnic Chinese worldwide. Using WeChat, we collect data about the Chinese diaspora in 32 cities. The combined data provides interesting insights to the modern Chinese diaspora and how it has changed in recent years.",
    "lastUpdated": "2019-09-06T05:53:59Z",
    "categories": [
      "cs.SI"
    ],
    "url": "http://arxiv.org/abs/1803.08256v3"
  },
  {
    "title": "Applications of Artificial Intelligence to Network Security",
    "authors": [
      "Alberto Perez Veiga"
    ],
    "abstract": "Attacks to networks are becoming more complex and sophisticated every day. Beyond the so-called script-kiddies and hacking newbies, there is a myriad of professional attackers seeking to make serious profits infiltrating in corporate networks. Either hostile governments, big corporations or mafias are constantly increasing their resources and skills in cybercrime in order to spy, steal or cause damage more effectively. traditional approaches to Network Security seem to start hitting their limits and it is being recognized the need for a smarter approach to threat detections. This paper provides an introduction on the need for evolution of Cyber Security techniques and how Artificial Intelligence could be of application to help solving some of the problems. It provides also, a high-level overview of some state of the art AI Network Security techniques, to finish analysing what is the foreseeable future of the application of AI to Network Security.",
    "lastUpdated": "2018-03-27T09:54:30Z",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1803.09992v1"
  },
  {
    "title": "Polarization attack on continuous-variable quantum key distribution",
    "authors": [
      "Yijia Zhao",
      "Yi-Chen Zhang",
      "Yundi Huang",
      "Bingjie Xu",
      "Song Yu",
      "Hong Guo"
    ],
    "abstract": "The shot-noise unit (SNU) is a crucial factor for the practical security of a continuous-variable quantum key distribution system. In the most widely used experimental scheme, the SNU should be calibrated first and acts as a constant during the key distribution. However, the SNU of a practical system is dependent on the various parameters of the local oscillator, which can be controlled by the eavesdropper in the open channel. In this paper, we report a quantum hacking method to control the practical SNU by using the limited compensation rate of the polarization compensation. Since the compensation is only based on of the polarization measurement results of part of local oscillator pulses, the polarization of other unmeasured pulses may not be compensated correctly, which can be utilized by the eavesdropper to control the practical SNU. The simulation and experiment results indicate that the practical SNU can be controlled by the eavesdropper. Thus, the eavesdropper can use the fact that the practical SNU is no longer equals to the calibrated one to control the excess noise and final key rate.",
    "lastUpdated": "2019-03-28T07:17:14Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/1803.10496v2"
  },
  {
    "title": "Developing a K-ary malware using Blockchain",
    "authors": [
      "Joanna Moubarak",
      "Eric Filiol",
      "Maroun Chamoun"
    ],
    "abstract": "Cyberattacks are nowadays moving rapidly. They are customized, multi-vector, staged in multiple flows and targeted. Moreover, new hacking playgrounds appeared to reach mobile network, modern architectures and smart cities. For that purpose, malware use different entry points and plug-ins. In addition, they are now deploying several techniques for obfuscation, camouflage and analysis resistance. On the other hand, antiviral protections are positioning innovative approaches exposing malicious indicators and anomalies, revealing assumptions of the limitations of the anti-antiviral mechanisms. Primarily, this paper exposes a state of art in computer virology and then introduces a new concept to create undetectable malware based on the blockchain technology. It summarizes techniques adopted by malicious software to avoid functionalities implemented for viral detection and presents the implementation of new viral techniques that leverage the blockchain network.",
    "lastUpdated": "2018-04-04T16:06:25Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1804.01488v1"
  },
  {
    "title": "Security and Privacy Analyses of Internet of Things Children's Toys",
    "authors": [
      "Gordon Chu",
      "Noah Apthorpe",
      "Nick Feamster"
    ],
    "abstract": "This paper investigates the security and privacy of Internet-connected children's smart toys through case studies of three commercially-available products. We conduct network and application vulnerability analyses of each toy using static and dynamic analysis techniques, including application binary decompilation and network monitoring. We discover several publicly undisclosed vulnerabilities that violate the Children's Online Privacy Protection Rule (COPPA) as well as the toys' individual privacy policies. These vulnerabilities, especially security flaws in network communications with first-party servers, are indicative of a disconnect between many IoT toy developers and security and privacy best practices despite increased attention to Internet-connected toy hacking risks.",
    "lastUpdated": "2018-08-29T00:35:58Z",
    "categories": [
      "cs.CR",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1805.02751v2"
  },
  {
    "title": "Adding Salt to Pepper: A Structured Security Assessment over a Humanoid Robot",
    "authors": [
      "Alberto Giaretta",
      "Michele De Donno",
      "Nicola Dragoni"
    ],
    "abstract": "The rise of connectivity, digitalization, robotics, and artificial intelligence (AI) is rapidly changing our society and shaping its future development. During this technological and societal revolution, security has been persistently neglected, yet a hacked robot can act as an insider threat in organizations, industries, public spaces, and private homes. In this paper, we perform a structured security assessment of Pepper, a commercial humanoid robot. Our analysis, composed by an automated and a manual part, points out a relevant number of security flaws that can be used to take over and command the robot. Furthermore, we suggest how these issues could be fixed, thus, avoided in the future. The very final aim of this work is to push the rise of the security level of IoT products before they are sold on the public market.",
    "lastUpdated": "2018-07-04T23:21:54Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1805.04101v2"
  },
  {
    "title": "Practical Decentralized Attribute-Based Delegation using Secure Name Systems",
    "authors": [
      "Martin Schanzenbach",
      "Christian Banse",
      "Julian Schütte"
    ],
    "abstract": "Identity and trust in the modern Internet are centralized around an oligopoly of identity service providers consisting solely of major tech companies. The problem with centralizing trust has become evident in recent discoveries of mass surveillance and censorship programs as well as information leakage through hacking incidents. One approach to decentralizing trust is distributed, attribute-based access control via attribute-based delegation (ABD). Attribute-based delegation allows a large number of cross-domain attribute issuers to be used in making authorization decisions. Attributes are not only issued to identities, but can also be delegated to other attributes issued by different entities in the system. The resulting trust chains can then be resolved by any entity given an appropriate attribute storage and resolution system. While current proposals often fail at the practicability, we show how attribute-based delegation can be realized on top of the secure GNU Name System (GNS) to solve an authorization problem in a real-world scenario.",
    "lastUpdated": "2018-05-16T16:10:00Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1805.06398v1"
  },
  {
    "title": "Motivic Volumes of Fibers of Tropicalization",
    "authors": [
      "Jeremy Usatine"
    ],
    "abstract": "Let $T$ be an algebraic torus over an algebraically closed field, let $X$ be a smooth closed subvariety of a $T$-toric variety such that $U = X \\cap T$ is not empty, and let $\\mathscr{L}(X)$ be the arc scheme of $X$. We define a tropicalization map on $\\mathscr{L}(X) \\setminus \\mathscr{L}(X \\setminus U)$, the set of arcs of $X$ that do not factor through $X \\setminus U$. We show that each fiber of this tropicalization map is a constructible subset of $\\mathscr{L}(X)$ and therefore has a motivic volume. We prove that if $U$ has a compactification with simple normal crossing boundary, then the generating function for these motivic volumes is rational, and we express this rational function in terms of certain lattice maps constructed in Hacking, Keel, and Tevelev's theory of geometric tropicalization. We explain how this result, in particular, gives a formula for Denef and Loeser's motivic zeta function of a polynomial. To further understand this formula, we also determine precisely which lattice maps arise in the construction of geometric tropicalization.",
    "lastUpdated": "2018-05-22T03:09:19Z",
    "categories": [
      "math.AG"
    ],
    "url": "http://arxiv.org/abs/1805.08372v1"
  },
  {
    "title": "Enabling Cooperative IoT Security via Software Defined Networks (SDN)",
    "authors": [
      "Garegin Grigoryan",
      "Yaoqing Liu",
      "Laurent Njilla",
      "Charles Kamhoua",
      "Kevin Kwiat"
    ],
    "abstract": "Internet of Things (IoT) is becoming an increasingly attractive target for cybercriminals. We observe that many attacks to IoTs are launched in a collusive way, such as brute-force hacking usernames and passwords, to target at a particular victim. However, most of the time our defending mechanisms to such kind of attacks are carried out individually and independently, which leads to ineffective and weak defense. To this end, we propose to leverage Software Defined Networks (SDN) to enable cooperative security for legacy IP-based IoT devices. SDN decouples control plane and data plane, and can help bridge the knowledge divided between the application and network layers. In this paper, we discuss the IoT security problems and challenges, and present an SDN-based architecture to enable IoT security in a cooperative manner. Furthermore, we implemented a platform that can quickly share the attacking information with peer controllers and block the attacks. We carried out our experiments in both virtual and physical SDN environments with OpenFlow switches. Our evaluation results show that both environments can scale well to handle attacks, but hardware implementation is much more efficient than a virtual one.",
    "lastUpdated": "2018-06-05T18:42:29Z",
    "categories": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1806.01885v1"
  },
  {
    "title": "Design of Voltage Pulse Control Module for Free Space Measurement-Device-Independent Quantum Key Distribution",
    "authors": [
      "Sijie Zhang",
      "Nan Zhou",
      "Fanshui Deng",
      "Hao Liang"
    ],
    "abstract": "Measurement-Device-Independent Quantum Key Distribution (MDIQKD) protocol has been proved that it is unaffected by all hacking attacks, and ensures the security of information theory even when the performance of single-photon detectors is not ideal. Fiber channel has been used by the previous MDIQKD experimental device. However, the signal attenuation increases exponentially as the transmission distance increases. In order to overcome this, we regard free space as the channel of signal transmission, and the signal attenuation increases square as the transmission distance increases (regardless of the atmospheric scattering), which can effectively reduce the signal attenuation trend. In order to implement the free space MDIQKD experiments, a modulation module is needed to modulate the wide pulse chopping, decoy-state, normalization, phase encoding and time encoding. In this paper, we present the design of the Voltage Pulse Control Module for the free space MDIQKD.",
    "lastUpdated": "2018-06-20T21:54:52Z",
    "categories": [
      "eess.SP",
      "cs.ET",
      "physics.app-ph"
    ],
    "url": "http://arxiv.org/abs/1806.01989v2"
  },
  {
    "title": "Quantifying memories: mapping urban perception",
    "authors": [
      "Shan He",
      "Yuji Yoshimura",
      "Jonas Helfer",
      "Gary Hack",
      "Carlo Ratti",
      "Takehiko Nagakura"
    ],
    "abstract": "What people choose to see, like, or remember is of profound interest to city planners and architects. Previous research suggests what people are more likely to store in their memory - buildings with dominant shapes and bright colors, historical sites, and intruding signs - yet little has been done by the systematic survey. This paper attempts to understand the relationships between the spatial structure of the built environment and inhabitants' memory of the city derived from their perceptual knowledge. For this purpose, we employed the web-based visual survey in the form of a geo-guessing game. This enables us to externalize people's spatial knowledge as a large-scale dataset. The result sheds light on unknown aspects of the cognitive role in exploring the built environment, and hidden patterns embedded in the relationship between the spatial elements and the mental map.",
    "lastUpdated": "2018-06-11T15:23:21Z",
    "categories": [
      "physics.soc-ph"
    ],
    "url": "http://arxiv.org/abs/1806.04054v1"
  },
  {
    "title": "Antiflips, mutations, and unbounded symplectic embeddings of rational homology balls",
    "authors": [
      "Jonathan David Evans",
      "Giancarlo Urzúa"
    ],
    "abstract": "The Milnor fibre of a $\\mathbb{Q}$-Gorenstein smoothing of a Wahl singularity is a rational homology ball $B_{p,q}$. For a canonically polarised surface of general type $X$, it is known that there are bounds on the number $p$ for which $B_{p,q}$ admits a symplectic embedding into $X$. In this paper, we give a recipe to construct unbounded sequences of symplectically embedded $B_{p,q}$ into surfaces of general type equipped with non-canonical symplectic forms. Ultimately, these symplectic embeddings come from Mori's theory of flips, but we give an interpretation in terms of almost toric structures and mutations of polygons. The key point is that a flip of surfaces, as studied by Hacking, Tevelev and Urz\\'ua, can be formulated as a combination of mutations of an almost toric structure and deformation of the symplectic form.",
    "lastUpdated": "2020-04-03T09:40:11Z",
    "categories": [
      "math.SG",
      "math.AG",
      "math.GT",
      "14J29, 14J17, 53D35"
    ],
    "url": "http://arxiv.org/abs/1807.06073v2"
  },
  {
    "title": "Stable log surfaces, admissible covers, and canonical curves of genus 4",
    "authors": [
      "Anand Deopurkar",
      "Changho Han"
    ],
    "abstract": "We explicitly describe the KSBA/Hacking compactification of a moduli space of log surfaces of Picard rank 2. The space parametrizes log pairs $(S, D)$ where $S$ is a degeneration of $\\mathbb{P}^1 \\times \\mathbb{P}^1$ and $D \\subset S$ is a degeneration of a curve of class $(3,3)$. We prove that the compactified moduli space is a smooth Deligne--Mumford stack with 4 boundary components. We relate it to the moduli space of genus 4 curves; we show that it compactifies the blow-up of the hyperelliptic locus. We also relate it to a compactification of the Hurwitz space of triple coverings of $\\mathbb{P}^1$ by genus 4 curves.",
    "lastUpdated": "2020-06-21T00:41:41Z",
    "categories": [
      "math.AG",
      "14D06 (Primary) 14D23, 14H10, 14J10 (Secondary)"
    ],
    "url": "http://arxiv.org/abs/1807.08413v2"
  },
  {
    "title": "SIC-MMAB: Synchronisation Involves Communication in Multiplayer Multi-Armed Bandits",
    "authors": [
      "Etienne Boursier",
      "Vianney Perchet"
    ],
    "abstract": "Motivated by cognitive radio networks, we consider the stochastic multiplayer multi-armed bandit problem, where several players pull arms simultaneously and collisions occur if one of them is pulled by several players at the same stage. We present a decentralized algorithm that achieves the same performance as a centralized one, contradicting the existing lower bounds for that problem. This is possible by \"hacking\" the standard model by constructing a communication protocol between players that deliberately enforces collisions, allowing them to share their information at a negligible cost. This motivates the introduction of a more appropriate dynamic setting without sensing, where similar communication protocols are no longer possible. However, we show that the logarithmic growth of the regret is still achievable for this model with a new algorithm.",
    "lastUpdated": "2019-11-19T09:51:23Z",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1809.08151v4"
  },
  {
    "title": "Community-Based Security for the Internet of Things",
    "authors": [
      "Quanyan Zhu",
      "Stefan Rass",
      "Peter Schartner"
    ],
    "abstract": "With more and more devices becoming connectable to the internet, the number of services but also a lot of threats increases dramatically. Security is often a secondary matter behind functionality and comfort, but the problem has already been recognized. Still, with many IoT devices being deployed already, security will come step-by-step and through updates, patches and new versions of apps and IoT software. While these updates can be safely retrieved from app stores, the problems kick in via jailbroken devices and with the variety of untrusted sources arising on the internet. Since hacking is typically a community effort? these days, security could be a community goal too. The challenges are manifold, and one reason for weak or absent security on IoT devices is their weak computational power. In this chapter, we discuss a community based security mechanism in which devices mutually aid each other in secure software management. We discuss game-theoretic methods of community formation and light-weight cryptographic means to accomplish authentic software deployment inside the IoT device community.",
    "lastUpdated": "2018-09-30T00:24:22Z",
    "categories": [
      "cs.CY",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1810.00281v1"
  },
  {
    "title": "Explicit equations for mirror families to log Calabi-Yau surfaces",
    "authors": [
      "Lawrence Jack Barrott"
    ],
    "abstract": "Mirror symmetry for del Pezzo surfaces was studied by Auroux, Katzarkov and Orlov who suggested that the mirror should take the form of a Landau-Ginzburg model with a particular type of elliptic fibration. This problem was then considered again but from an algebro-geometric perspective by Gross, Hacking and Keel. Their construction allows one to construct a formal mirror family to a pair $(S,D)$ where $S$ is a smooth rational projective surface and $D$ a certain type of Weil divisor supporting an ample or anti-ample class. In the case of $S$ a Fano surface they proved that this family may be lifted to an algebraic family over an affine base. In this paper we perform this construction for all smooth del Pezzo surfaces of degree at least two and obtain explicit equations for the mirror families and explain some of the motivation for their construction. We also provide an implementation of the Kontsevich Soibelman lemma in Sage.",
    "lastUpdated": "2018-10-19T05:27:03Z",
    "categories": [
      "math.AG"
    ],
    "url": "http://arxiv.org/abs/1810.08356v1"
  },
  {
    "title": "Reward learning from human preferences and demonstrations in Atari",
    "authors": [
      "Borja Ibarz",
      "Jan Leike",
      "Tobias Pohlen",
      "Geoffrey Irving",
      "Shane Legg",
      "Dario Amodei"
    ],
    "abstract": "To solve complex real-world problems with reinforcement learning, we cannot rely on manually specified reward functions. Instead, we can have humans communicate an objective to the agent directly. In this work, we combine two approaches to learning from human feedback: expert demonstrations and trajectory preferences. We train a deep neural network to model the reward function and use its predicted reward to train an DQN-based deep reinforcement learning agent on 9 Atari games. Our approach beats the imitation learning baseline in 7 games and achieves strictly superhuman performance on 2 games without using game rewards. Additionally, we investigate the goodness of fit of the reward model, present some reward hacking problems, and study the effects of noise in the human labels.",
    "lastUpdated": "2018-11-15T18:33:43Z",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1811.06521v1"
  },
  {
    "title": "Convergence of the mirror to a rational elliptic surface",
    "authors": [
      "Lawrence Jack Barrott"
    ],
    "abstract": "The construction introduced by Gross, Hacking and Keel allows one to construct a formal mirror family to a pair $(S,D)$ where $S$ is a smooth rational projective surface and $D$ a certain type of Weil divisor supporting an ample or anti-ample class. In that paper they proved two convergence results. Firstly that if the intersection matrix of $D$ is not negative semi-definite then the family they construct lifts to an algebraic family. Secondly they prove that if the intersection matrix is negative definite then their construction lifts along certain analytic strata on the base, and then over a formal neighbourhood of this. In the original version of that paper they claimed that if the intersection matrix were negative semi-definite then family in fact extends over an analytic neighbourhood of the origin but gave an incorrect proof. In this paper we correct this error. We explain how the general Gross-Siebert program can be used to reduce construction of the mirror to such a surface to calculating certain relative Gromov-Witten invariants. We then relate these invariants to the invariants of a new space where we can find explicit formulae for the invariants. From this we deduce analytic convergence of the mirror family, at least when the original surface has an $I_4$ fibre.",
    "lastUpdated": "2018-11-20T03:09:39Z",
    "categories": [
      "math.AG"
    ],
    "url": "http://arxiv.org/abs/1811.08050v1"
  },
  {
    "title": "Towards Automatic Discovery of Cybercrime Supply Chains",
    "authors": [
      "Rasika Bhalerao",
      "Maxwell Aliapoulios",
      "Ilia Shumailov",
      "Sadia Afroz",
      "Damon McCoy"
    ],
    "abstract": "Cybercrime forums enable modern criminal entrepreneurs to collaborate with other criminals into increasingly efficient and sophisticated criminal endeavors. Understanding the connections between different products and services can often illuminate effective interventions. However, generating this understanding of supply chains currently requires time-consuming manual effort. In this paper, we propose a language-agnostic method to automatically extract supply chains from cybercrime forum posts and replies. Our supply chain detection algorithm can identify 36% and 58% relevant chains within major English and Russian forums, respectively, showing improvements over the baselines of 13% and 36%, respectively. Our analysis of the automatically generated supply chains demonstrates underlying connections between products and services within these forums. For example, the extracted supply chain illuminated the connection between hack-for-hire services and the selling of rare and valuable `OG' accounts, which has only recently been reported. The understanding of connections between products and services exposes potentially effective intervention points.",
    "lastUpdated": "2018-12-04T23:48:55Z",
    "categories": [
      "cs.CR",
      "cs.CL",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1812.00381v2"
  },
  {
    "title": "A Longitudinal Analysis of the Public Perception of the Opportunities and Challenges of the Internet of Things",
    "authors": [
      "Arkaitz Zubiaga",
      "Rob Procter",
      "Carsten Maple"
    ],
    "abstract": "The Internet of Things (or IoT), which enables the networked interconnection of everyday objects, is becoming increasingly popular in many aspects of our lives ranging from entertainment to health care. While the IoT brings a set of invaluable advantages and opportunities with it, there is also evidence of numerous challenges that are yet to be resolved. This is certainly the case with regard to ensuring the cyber security of the IoT, and there are various examples of devices being hacked. Despite this evidence, little is known about the public perceptions of the opportunities and challenges presented by the IoT. To advance research in this direction, we mined the social media platform Twitter to learn about public opinion about the IoT. Analysing a longitudinal dataset of more than 6.7 million tweets, we reveal insights into public perceptions of the IoT, identifying big data analytics as the most positive aspect, whereas security issues are the main public concern on the negative side. Our study serves to highlight the importance of keeping IoT devices secure, and remind manufacturers that it is a concern that remains unresolved, at least insofar as the public believes.",
    "lastUpdated": "2018-12-03T18:32:07Z",
    "categories": [
      "cs.SI",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1812.00959v1"
  },
  {
    "title": "A low-order nonconforming method for linear elasticity on general meshes",
    "authors": [
      "Michele Botti",
      "Daniele A. Di Pietro",
      "Alessandra Guglielmana"
    ],
    "abstract": "In this work we construct a low-order nonconforming approximation method for linear elasticity problems supporting general meshes and valid in two and three space dimensions. The method is obtained by hacking the Hybrid High-Order method, that requires the use of polynomials of degree $k\\ge1$ for stability. Specifically, we show that coercivity can be recovered for $k=0$ by introducing a novel term that penalises the jumps of the displacement reconstruction across mesh faces. This term plays a key role in the fulfillment of a discrete Korn inequality on broken polynomial spaces, for which a novel proof valid for general polyhedral meshes is provided. Locking-free error estimates are derived for both the energy- and the $L^2$-norms of the error, that are shown to convergence, for smooth solutions, as $h$ and $h^2$, respectively (here, $h$ denotes the meshsize). A thorough numerical validation on a complete panel of two- and three-dimensional test cases is provided.",
    "lastUpdated": "2019-02-06T18:20:43Z",
    "categories": [
      "math.NA",
      "65N08, 65N30, 74B05, 74G15"
    ],
    "url": "http://arxiv.org/abs/1902.02316v1"
  },
  {
    "title": "Parenting: Safe Reinforcement Learning from Human Input",
    "authors": [
      "Christopher Frye",
      "Ilya Feige"
    ],
    "abstract": "Autonomous agents trained via reinforcement learning present numerous safety concerns: reward hacking, negative side effects, and unsafe exploration, among others. In the context of near-future autonomous agents, operating in environments where humans understand the existing dangers, human involvement in the learning process has proved a promising approach to AI Safety. Here we demonstrate that a precise framework for learning from human input, loosely inspired by the way humans parent children, solves a broad class of safety problems in this context. We show that our Parenting algorithm solves these problems in the relevant AI Safety gridworlds of Leike et al. (2017), that an agent can learn to outperform its parent as it \"matures\", and that policies learnt through Parenting are generalisable to new environments.",
    "lastUpdated": "2019-02-18T19:10:18Z",
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1902.06766v1"
  },
  {
    "title": "Characterizing Activity on the Deep and Dark Web",
    "authors": [
      "Nazgol Tavabi",
      "Nathan Bartley",
      "Andrés Abeliuk",
      "Sandeep Soni",
      "Emilio Ferrara",
      "Kristina Lerman"
    ],
    "abstract": "The deep and darkweb (d2web) refers to limited access web sites that require registration, authentication, or more complex encryption protocols to access them. These web sites serve as hubs for a variety of illicit activities: to trade drugs, stolen user credentials, hacking tools, and to coordinate attacks and manipulation campaigns. Despite its importance to cyber crime, the d2web has not been systematically investigated. In this paper, we study a large corpus of messages posted to 80 d2web forums over a period of more than a year. We identify topics of discussion using LDA and use a non-parametric HMM to model the evolution of topics across forums. Then, we examine the dynamic patterns of discussion and identify forums with similar patterns. We show that our approach surfaces hidden similarities across different forums and can help identify anomalous events in this rich, heterogeneous data.",
    "lastUpdated": "2019-03-01T05:01:04Z",
    "categories": [
      "cs.CY",
      "cs.CR",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1903.00156v1"
  },
  {
    "title": "Hacking Google reCAPTCHA v3 using Reinforcement Learning",
    "authors": [
      "Ismail Akrout",
      "Amal Feriani",
      "Mohamed Akrout"
    ],
    "abstract": "We present a Reinforcement Learning (RL) methodology to bypass Google reCAPTCHA v3. We formulate the problem as a grid world where the agent learns how to move the mouse and click on the reCAPTCHA button to receive a high score. We study the performance of the agent when we vary the cell size of the grid world and show that the performance drops when the agent takes big steps toward the goal. Finally, we used a divide and conquer strategy to defeat the reCAPTCHA system for any grid resolution. Our proposed method achieves a success rate of 97.4% on a 100x100 grid and 96.7% on a 1000x1000 screen resolution.",
    "lastUpdated": "2019-04-18T16:22:33Z",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1903.01003v3"
  },
  {
    "title": "Preventing the attempts of abusing cheap-hosting Web-servers for monetization attacks",
    "authors": [
      "Van-Linh Nguyen",
      "Po-Ching Lin",
      "Ren-Hung Hwang"
    ],
    "abstract": "Over the past decades, the web is always one of the most popular targets of hackers. Today, along with the popular usage of open sources such as Wordpress and Joomla, the explosion of the vulnerabilities in such frameworks causes the websites using them to face numerous security threats. Unfortunately, many clients and small companies may not be aware of these serious security threats and call a rescuer only when the website is hacked, compromised, or blocked by the search engines. In this paper, we present an effective counter against such threats, including monetization attempts in the less valuable targets such as small websites.",
    "lastUpdated": "2019-03-14T02:33:23Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1903.05470v2"
  },
  {
    "title": "Secure quantum key distribution with realistic devices",
    "authors": [
      "Feihu Xu",
      "Xiongfeng Ma",
      "Qiang Zhang",
      "Hoi-Kwong Lo",
      "Jian-Wei Pan"
    ],
    "abstract": "In principle, quantum key distribution (QKD) offers information-theoretic security based on the laws of physics. In practice, however, the imperfections of realistic devices might introduce deviations from the idealized models used in security analyses. Can quantum code-breakers successfully hack real systems by exploiting the side channels? Can quantum code-makers design innovative counter-measures to foil quantum code-breakers? This article reviews theoretical and experimental progress in the practical security aspects of quantum code-making and quantum code-breaking. After numerous attempts, researchers now thoroughly understand and are able to manage the practical imperfections. Recent advances, such as the measurement-device-independent protocol, have closed the critical side channels in the physical implementations, paving the way for secure QKD with realistic devices.",
    "lastUpdated": "2020-02-19T06:01:00Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/1903.09051v3"
  },
  {
    "title": "Helping IT and OT Defenders Collaborate",
    "authors": [
      "Glenn A. Fink",
      "Penny McKenzie"
    ],
    "abstract": "Cyber-physical systems, especially in critical infrastructures, have become primary hacking targets in international conflicts and diplomacy. However, cyber-physical systems present unique challenges to defenders, starting with an inability to communicate. This paper outlines the results of our interviews with information technology (IT) defenders and operational technology (OT) operators and seeks to address lessons learned from them in the structure of our notional solutions. We present two problems in this paper: (1) the difficulty of coordinating detection and response between defenders who work on the cyber/IT and physical/OT sides of cyber-physical infrastructures, and (2) the difficulty of estimating the safety state of a cyber-physical system while an intrusion is underway but before damage can be effected by the attacker. To meet these challenges, we propose two solutions: (1) a visualization that will enable communication between IT defenders and OT operators, and (2) a machine-learning approach that will estimate the distance from normal the physical system is operating and send information to the visualization.",
    "lastUpdated": "2019-04-16T00:05:35Z",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1904.07374v1"
  },
  {
    "title": "Measurement-device-independent quantum key distribution coexisting with classical communication",
    "authors": [
      "Raju Valivarthi",
      "Prathwiraj Umesh",
      "Caleb John",
      "Kimberley A. Owen",
      "Varun B. Verma",
      "Sae Woo Nam",
      "Daniel Oblak",
      "Qiang Zhou",
      "Wolfgang Tittel"
    ],
    "abstract": "The possibility for quantum and classical communication to coexist on the same fibre is important for deployment and widespread adoption of quantum key distribution (QKD) and, more generally, a future quantum internet. While coexistence has been demonstrated for different QKD implementations, a comprehensive investigation for measurement-device independent (MDI) QKD -- a recently proposed QKD protocol that cannot be broken by quantum hacking that targets vulnerabilities of single-photon detectors -- is still missing. Here we experimentally demonstrate that MDI-QKD can operate simultaneously with at least five 10 Gbps bidirectional classical communication channels operating at around 1550 nm wavelength and over 40 km of spooled fibre, and we project communication rates in excess of 10 THz when moving the quantum channel from the third to the second telecommunication window. The similarity of MDI-QKD with quantum repeaters suggests that classical and generalised quantum networks can co-exist on the same fibre infrastructure.",
    "lastUpdated": "2019-05-01T19:37:35Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/1905.00465v1"
  },
  {
    "title": "Long-distance device-independent quantum key distribution",
    "authors": [
      "Víctor Zapatero",
      "Marcos Curty"
    ],
    "abstract": "Besides being a beautiful idea, device-independent quantum key distribution (DIQKD) is probably the ultimate solution to defeat quantum hacking. To guarantee security, it requires, however, that the fair-sampling loophole is closed, which results in a very limited maximum achievable distance. To overcome this limitation, DIQKD must be furnished with fair-sampling devices like, for instance, qubit amplifiers. These devices can herald the arrival of a photon to the receiver and thus decouple channel loss from the selection of the measurement settings. Consequently, one can safely postselect the heralded events and discard the rest, which results in a significant enhancement of the achievable distance. In this work, we investigate photonic-based DIQKD assisted by two main types of qubit amplifiers in the finite data block size scenario, and study the resources -- particularly, the detection efficiency of the photodetectors and the quality of the entanglement sources -- that would be necessary to achieve long-distance DIQKD within a reasonable time frame of signal transmission.",
    "lastUpdated": "2019-05-09T13:11:57Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/1905.03591v1"
  },
  {
    "title": "The Mathematical Specification of the Statebox Language",
    "authors": [
      "Statebox Team",
      "Fabrizio Genovese",
      "Jelle Herold"
    ],
    "abstract": "This document defines the mathematical backbone of the Statebox programming language. In the simplest way possible, Statebox can be seen as a clever way to tie together different theoretical structures to maximize their benefits and limit their downsides. Since consistency and correctness are central requisites for our language, it became clear from the beginning that such tying could not be achieved by just hacking together different pieces of code representing implementations of the structures we wanted to leverage: Rigorous mathematics is employed to ensure both conceptual consistency of the language and reliability of the code itself. The mathematics presented here is what guided the implementation process, and we deemed very useful to release it to the public to help people wanting to audit our work to better understand the code itself.",
    "lastUpdated": "2019-06-26T14:26:53Z",
    "categories": [
      "cs.PL",
      "cs.DC",
      "math.CT",
      "5Uxx"
    ],
    "url": "http://arxiv.org/abs/1906.07629v2"
  },
  {
    "title": "Toric bundles, valuations, and tropical geometry over semifield of piecewise linear functions",
    "authors": [
      "Kiumars Kaveh",
      "Christopher Manon"
    ],
    "abstract": "We initiate the algebro-geometric study of tropical geometry over the idemopotent semifield of piecewise linear functions. One of our main results shows that points on the tropical variety of a linear ideal over this semifield correspond to toric vector bundles. We introduce the notion of a valuation with values in the semifield of piecewise linear functions and we describe Khovanskii bases in this context. Far extending the Klyachko classification of toric vector bundles, we show that torus equivariant families over toric varieties are classified by such valuations. Finally, we see that the Gross-Hacking-Keel-Kontsevich toric degenerations of cluster varieties fit into our picture as a family over the toric scheme of the Fock-Goncharov fan.",
    "lastUpdated": "2019-07-01T04:46:00Z",
    "categories": [
      "math.AG",
      "14M25, 14T05"
    ],
    "url": "http://arxiv.org/abs/1907.00543v1"
  },
  {
    "title": "Lattice Structural Analysis on Sniffing to Denial of Service Attacks",
    "authors": [
      "B. Prabadevi",
      "N. Jeyanthi",
      "Nur Izura Udzir",
      "Dhinaharan Nagamalai"
    ],
    "abstract": "Sniffing is one of the most prominent causes for most of the attacks in the digitized computing environment. Through various packet analyzers or sniffers available free of cost, the network packets can be captured and analyzed. The sensitive information of the victim like user credentials, passwords, a PIN which is of more considerable interest to the assailants can be stolen through sniffers. This is the primary reason for most of the variations of DDoS attacks in the network from a variety of its catalog of attacks. An effective and trusted framework for detecting and preventing these sniffing has greater significance in today's computing. A counter hack method to avoid data theft is to encrypt sensitive information. This paper provides an analysis of the most prominent sniffing attacks. Moreover, this is one of the most important strides to guarantee system security. Also, a Lattice structure has been derived to prove that sniffing is the prominent activity for DoS or DDoS attacks.",
    "lastUpdated": "2019-07-29T13:24:13Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1907.12735v1"
  },
  {
    "title": "Wall crossing for K-moduli spaces of plane curves",
    "authors": [
      "Kenneth Ascher",
      "Kristin DeVleming",
      "Yuchen Liu"
    ],
    "abstract": "We construct proper good moduli spaces parametrizing K-polystable $\\mathbb{Q}$-Gorenstein smoothable log Fano pairs $(X, cD)$, where $X$ is a Fano variety and $D$ is a rational multiple of the anti-canonical divisor. We then establish a wall-crossing framework of these K-moduli spaces as $c$ varies. The main application in this paper is the case of plane curves of degree $d \\geq 4$ as boundary divisors of $\\mathbb{P}^2$. In this case, we show that when the coefficient $c$ is small, the K-moduli space of these pairs is isomorphic to the GIT moduli space. We then show that the first wall crossing of these K-moduli spaces are weighted blow-ups of Kirwan type. We also describe all wall crossings for degree 4,5,6, and relate the final K-moduli spaces to Hacking's compactification and the moduli of K3 surfaces.",
    "lastUpdated": "2019-09-10T15:37:58Z",
    "categories": [
      "math.AG",
      "math.DG"
    ],
    "url": "http://arxiv.org/abs/1909.04576v1"
  },
  {
    "title": "LICSTER -- A Low-cost ICS Security Testbed for Education and Research",
    "authors": [
      "Felix Sauer",
      "Matthias Niedermaier",
      "Susanne Kießling",
      "Dominik Merli"
    ],
    "abstract": "Unnoticed by most people, Industrial Control Systems (ICSs) control entire productions and critical infrastructures such as water distribution, smart grid and automotive manufacturing. Due to the ongoing digitalization, these systems are becoming more and more connected in order to enable remote control and monitoring. However, this shift bears significant risks, namely a larger attack surface, which can be exploited by attackers. In order to make these systems more secure, it takes research, which is, however, difficult to conduct on productive systems, since these often have to operate twenty-four-seven. Testbeds are mostly very expensive or based on simulation with no real-world physical process. In this paper, we introduce LICSTER, an open-source low-cost ICS testbed, which enables researchers and students to get hands-on experience with industrial security for about 500 Euro. We provide all necessary material to quickly start ICS hacking, with the focus on low-cost and open-source for education and research.",
    "lastUpdated": "2019-10-01T11:05:36Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1910.00303v1"
  },
  {
    "title": "Techniques for Adversarial Examples Threatening the Safety of Artificial Intelligence Based Systems",
    "authors": [
      "Utku Kose"
    ],
    "abstract": "Artificial intelligence is known as the most effective technological field for rapid developments shaping the future of the world. Even today, it is possible to see intense use of intelligence systems in all fields of the life. Although advantages of the Artificial Intelligence are widely observed, there is also a dark side employing efforts to design hacking oriented techniques against Artificial Intelligence. Thanks to such techniques, it is possible to trick intelligent systems causing directed results for unsuccessful outputs. That is critical for also cyber wars of the future as it is predicted that the wars will be done unmanned, autonomous intelligent systems. Moving from the explanations, objective of this study is to provide information regarding adversarial examples threatening the Artificial Intelligence and focus on details of some techniques, which are used for creating adversarial examples. Adversarial examples are known as training data, which can trick a Machine Learning technique to learn incorrectly about the target problem and cause an unsuccessful or maliciously directed intelligent system at the end. The study enables the readers to learn enough about details of recent techniques for creating adversarial examples.",
    "lastUpdated": "2019-09-29T21:56:59Z",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "url": "http://arxiv.org/abs/1910.06907v1"
  },
  {
    "title": "The mirror of the cubic surface",
    "authors": [
      "Mark Gross",
      "Paul Hacking",
      "Sean Keel",
      "Bernd Siebert"
    ],
    "abstract": "This paper expands on a remark in the paper \"Mirror Symmetry for Log Calabi-Yau Surfaces I\" of the first three authors of this paper, explaining fully how various constructions of the authors apply to give the mirror to the cubic surface. We give a full description of the scattering diagram associated to the cubic surface: this is a particularly nice diagram in which rays of every rational slope occur, but they may all be described. The equation of the mirror cubic family is then derived in two ways, first by using broken lines and then by using more recent constructions involving a direct calculation of Gromov-Witten invariants.",
    "lastUpdated": "2019-10-18T14:02:30Z",
    "categories": [
      "math.AG",
      "math.SG",
      "14J33"
    ],
    "url": "http://arxiv.org/abs/1910.08427v1"
  },
  {
    "title": "Advanced attribute-based protocol based on the modified secret sharing scheme",
    "authors": [
      "M. A. Kudinov",
      "A. A. Chilikov",
      "E. O. Kiktenko",
      "A. K. Fedorov"
    ],
    "abstract": "We construct a new protocol for attribute-based encryption with the use of the modification of the standard secret sharing scheme. In the suggested modification of the secret sharing scheme, only one master key for each user is required that is achieved by linearly enlarging public parameters in the access formula. We then use this scheme for designing an attribute-based encryption protocol related to some access structure in terms of attributes. We demonstrate that the universe of possible attributes does not affect the resulting efficiency of the scheme. The security proofs for both constructions are provided.",
    "lastUpdated": "2020-11-23T13:18:02Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1912.03009v3"
  },
  {
    "title": "Compactifications of cluster varieties and convexity",
    "authors": [
      "Man-Wai Cheung",
      "Timothy Magee",
      "Alfredo Nájera Chávez"
    ],
    "abstract": "In [GHKK18], Gross-Hacking-Keel-Kontsevich discuss compactifications of cluster varieties from \"positive subsets\" in the real tropicalization of the mirror. To be more precise, let $\\mathfrak{D}$ be the scattering diagram of a cluster variety $V$ (of either type-- $\\mathcal{A}$ or $\\mathcal{X}$), and let $S$ be a closed subset of $\\left(V^\\vee\\right)^{\\text{trop}}(\\mathbb{R})$-- the ambient space of $\\mathfrak{D}$. The set $S$ is positive if the theta functions corresponding to the integral points of $S$ and its $\\mathbb{N}$-dilations define an $\\mathbb{N}$-graded subalgebra of $\\Gamma(V, \\mathcal{O}_V)$. In particular, a positive set $S$ defines a compactification of $V$ through a Proj construction applied to the corresponding $\\mathbb{N}$-graded algebra. In this paper we give a natural convexity notion for subsets of $\\mathfrak{D}$, called \"broken line convexity\", and show that a set is positive if and only if it is broken line convex. The combinatorial criterion of broken line convexity provides a tractable way to construct positive subsets of $\\mathfrak{D}$, or to check positivity of a given subset.",
    "lastUpdated": "2019-12-30T18:52:47Z",
    "categories": [
      "math.AG",
      "math.CO",
      "math.RT"
    ],
    "url": "http://arxiv.org/abs/1912.13052v1"
  },
  {
    "title": "Genuine Network Multipartite Entanglement",
    "authors": [
      "Miguel Navascues",
      "Elie Wolfe",
      "Denis Rosset",
      "Alejandro Pozas-Kerstjens"
    ],
    "abstract": "The standard definition of genuine multipartite entanglement stems from the need to assess the quantum control over an ever-growing number of quantum systems. We argue that this notion is easy to hack: in fact, a source capable of distributing bipartite entanglement can, by itself, generate genuine $k$-partite entangled states for any $k$. We propose an alternative definition for genuine multipartite entanglement, whereby a quantum state is genuinely network $k$-entangled if it cannot be produced by applying local trace-preserving maps over several $k$-partite states distributed among the parties, even with the aid of global shared randomness. We provide analytic and numerical witnesses of genuine network entanglement, and we reinterpret many past quantum experiments as demonstrations of this feature.",
    "lastUpdated": "2020-12-18T11:22:41Z",
    "categories": [
      "quant-ph",
      "math-ph",
      "math.MP"
    ],
    "url": "http://arxiv.org/abs/2002.02773v3"
  },
  {
    "title": "Hacking single-photon avalanche detector in quantum key distribution via pulse illumination",
    "authors": [
      "Zhihao Wu",
      "Anqi Huang",
      "Huan Chen",
      "Shi-Hai Sun",
      "Jiangfang Ding",
      "Xiaogang Qiang",
      "Xiang Fu",
      "Ping Xu",
      "Junjie Wu"
    ],
    "abstract": "Quantum key distribution (QKD) has been proved to be information-theoretically secure in theory. Unfortunately, the imperfect devices in practice compromise its security. Thus, to improve the security property of practical QKD systems, a commonly used method is to patch the loopholes in the existing QKD systems. However, in this work, we show an adversary's capability of exploiting the imperfection of the patch itself to bypass the patch. Specifically, we experimentally demonstrate that, in the detector under test, the patch of photocurrent monitor against the detector blinding attack can be defeated by the pulse illumination attack proposed in this paper. We also analyze the secret key rate under the pulse illumination attack, which theoretically confirmed that Eve can conduct the attack to learn the secret key. This work indicates the importance of inspecting the security loopholes in a detection unit to further understand their impacts on a QKD system. The method of pulse illumination attack can be a general testing item in the security evaluation standard of QKD.",
    "lastUpdated": "2020-08-03T13:48:19Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/2002.09146v2"
  },
  {
    "title": "Experimental Test of Tight State-Independent Preparation Uncertainty Relations for Qubits",
    "authors": [
      "Stephan Sponar",
      "Armin Danner",
      "Kazuma Obigane",
      "Simon Hack",
      "Yuji Hasegawa"
    ],
    "abstract": "The well-known Robertson-Schroedinger uncertainty relations miss an irreducible lower bound. This is widely attributed to the lower bound's state-dependence. Therefore, Abbott \\emph{et al.} introduced a general approach to derive tight state-independent uncertainty relations for qubit measurements [Mathematics 4, 8 (2016)]. The relations are expressed in two measures of uncertainty, which are standard deviation and entropy, both functions of the expectation value. Here, we present a neutron optical test of the tight state-independent preparation uncertainty relations for non-commuting Pauli spin observables with mixed spin states. The final results, obtained in a polarimetric experiment, reproduce the theoretical predictions evidently for arbitrary initial states of variable degree of polarization.",
    "lastUpdated": "2020-08-05T14:35:39Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/2002.10725v2"
  },
  {
    "title": "Anti-Forging Quantum Data: Cryptographic Verification of Quantum Cloud Computing",
    "authors": [
      "Man-Hong Yung",
      "Bin Cheng"
    ],
    "abstract": "Quantum cloud computing is emerging as a popular model for users to experience the power of quantum computing through the internet, enabling quantum computing as a service (QCaaS). The question is, when the scale of the computational problems becomes out of reach of classical computers, how can users be sure that the output strings sent by the server are really from a quantum hardware? In 2008, Shepherd and Bremner proposed a cryptographic verification protocol based on a simplified circuit model called IQP (instantaneous quantum polynomial-time), which can potentially be applied to most existing quantum cloud platforms. However, the Shepherd-Bremner protocol has recently been shown to be insecure by Kahanamoku-Meyer. Here we present a generalized model of cryptographic verification protocol, where the Shepherd-Bremner model can be regarded as a special case. This protocol not only can avoid the attack by Kahanamoku-Meyer but also provide several additional security measures for anti-forging quantum data. In particular, our protocol admits a simultaneous encoding of multiple secret strings, strengthening significantly the hardness for classical hacking. Furthermore, we provide methods for estimating the correlation functions associated with the secret strings, which are the key elements in our verification protocol.",
    "lastUpdated": "2020-05-04T14:28:14Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/2005.01510v1"
  },
  {
    "title": "A Human Dimension of Hacking: Social Engineering through Social Media",
    "authors": [
      "Heidi Wilcox",
      "Maumita Bhattacharya"
    ],
    "abstract": "Social engineering through social media channels targeting organizational employees is emerging as one of the most challenging information security threats. Social engineering defies traditional security efforts due to the method of attack relying on human naivet\\'e or error. The vast amount of information now made available to social engineers through online social networks is facilitating methods of attack which rely on some form of human error to enable infiltration into company networks. While, paramount to organisational information security objectives is the introduction of relevant comprehensive policy and guideline, perspectives and practices vary from global region to region. This paper identifies such regional variations and then presents a detailed investigation on information security outlooks and practices, surrounding social media, in Australian organisations (both public and private). Results detected disparate views and practices, suggesting further work is needed to achieve effective protection against security threats arsing due to social media adoption.",
    "lastUpdated": "2020-05-08T13:55:55Z",
    "categories": [
      "cs.CR",
      "K.6.5; D.4.6"
    ],
    "url": "http://arxiv.org/abs/2005.04049v1"
  },
  {
    "title": "Modeling Penetration Testing with Reinforcement Learning Using Capture-the-Flag Challenges and Tabular Q-Learning",
    "authors": [
      "Fabio Massimo Zennaro",
      "Laszlo Erdodi"
    ],
    "abstract": "Penetration testing is a security exercise aimed at assessing the security of a system by simulating attacks against it. So far, penetration testing has been carried out mainly by trained human attackers and its success critically depended on the available expertise. Automating this practice constitutes a non-trivial problem, as the range of actions that a human expert may attempts against a system and the range of knowledge she relies on to take her decisions are hard to capture. In this paper, we focus our attention on simplified penetration testing problems expressed in the form of capture the flag hacking challenges, and we apply reinforcement learning algorithms to try to solve them. In modelling these capture the flag competitions as reinforcement learning problems we highlight the specific challenges that characterize penetration testing. We observe these challenges experimentally across a set of varied simulations, and we study how different reinforcement learning techniques may help us addressing these challenges. In this way we show the feasibility of tackling penetration testing using reinforcement learning, and we highlight the challenges that must be taken into consideration, and possible directions to solve them.",
    "lastUpdated": "2020-05-26T11:23:10Z",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2005.12632v1"
  },
  {
    "title": "Benefits and Cyber-Vulnerability of Demand Response System in Real-Time Grid Operations",
    "authors": [
      "Mingjian Tuo",
      "Arun Venkatesh Ramesh",
      "Xingpeng Li"
    ],
    "abstract": "With improvement in smart grids through two-way communication, demand response (DR) has gained significant attention due to the inherent flexibility provided by shifting non-critical loads from peak periods to off-peak periods, which can greatly improve grid reliability and reduce cost of energy. Operators utilize DR to enhance operational flexibility and alleviate network congestion. However, the intelligent two-way communication is susceptible to cyber-attacks. This paper studies the benefits of DR in security-constrained economic dispatch (SCED) and then the vulnerability of the system to line overloads when cyber-attack targets DR signals. This paper proposes a false demand response signal and load measurement injection (FSMI) cyber-attack model that sends erroneous DR signals while hacking measurements to make the attack undetectable. Simulation results on the IEEE 24-bus system (i) demonstrate the cost-saving benefits of demand response, and (ii) show significant line overloads when the demand response signals are altered under an FSMI attack.",
    "lastUpdated": "2020-05-27T07:13:18Z",
    "categories": [
      "eess.SY",
      "cs.SY",
      "math.OC"
    ],
    "url": "http://arxiv.org/abs/2005.13207v1"
  },
  {
    "title": "Implementation of password manager with sram-based physical unclonable function",
    "authors": [
      "Mohammad Mohammadinodoushan"
    ],
    "abstract": "Hacking password databases is one of the most frequently reported cyber-attacks. Current password management systems are based on known and public algorithms. Also, many studies have shown that users select weak passwords. Thus, with the emergence of new powerful computing devices, the passwords based on known algorithms can be disclosed. Using physical unclonable functions (PUFs) for increasing the security level of password management systems is a quite recent method that is proposed to solve this problem. In this method, Addressable PUF Generator (APG) is added to the conventional password management systems. This report is aimed at implementing the password generation scheme using SRAM-based PUF. The bit error is indeed the main issue with using PUFs is addresses in this paper. To solve this issue, Ternary Addresseble PUF Generator is used.",
    "lastUpdated": "2020-12-06T22:33:38Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/2006.02562v2"
  },
  {
    "title": "Experimental quantum key distribution secure against malicious devices",
    "authors": [
      "Wei Li",
      "Victor Zapatero",
      "Hao Tan",
      "Kejin Wei",
      "Hao Min",
      "Wei-Yue Liu",
      "Xiao Jiang",
      "Sheng-Kai Liao",
      "Cheng-Zhi Peng",
      "Marcos Curty",
      "Feihu Xu",
      "Jian-Wei Pan"
    ],
    "abstract": "The fabrication of quantum key distribution (QKD) systems typically involves several parties, thus providing Eve with multiple opportunities to meddle with the devices. As a consequence, conventional hardware and/or software hacking attacks pose natural threats to the security of practical QKD. Fortunately, if the number of corrupted devices is limited, the security can be restored by using redundant apparatuses. Here, we report on the demonstration of a secure QKD setup with optical devices and classical post-processing units possibly controlled by an eavesdropper. We implement a 1.25 GHz chip-based measurement-device-independent QKD system secure against malicious devices on \\emph{both} the measurement and the users' sides. The secret key rate reaches 137 bps over a 24 dB channel loss. Our setup, benefiting from high clock rate, miniaturized transmitters and a cost-effective structure, provides a promising solution for widespread applications requiring uncompromising communication security.",
    "lastUpdated": "2020-06-23T09:54:02Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/2006.12863v1"
  },
  {
    "title": "Data-driven Analytical Models of COVID-2019 for Epidemic Prediction, Clinical Diagnosis, Policy Effectiveness and Contact Tracing: A Survey",
    "authors": [
      "Ying Mao",
      "Susiyan Jiang",
      "Daniel Nametz",
      "Yuxin Lin",
      "Jake Hack",
      "John Hensley",
      "Ryan Monaghan",
      "Tess Gutenbrunner"
    ],
    "abstract": "The widely spread CoronaVirus Disease (COVID)-19 is one of the worst infectious disease outbreaks in history and has become an emergency of primary international concern. As the pandemic evolves, academic communities have been actively involved in various capacities, including accurate epidemic estimation, fast clinical diagnosis, policy effectiveness evaluation and development of contract tracing technologies. There are more than 23,000 academic papers on the COVID-19 outbreak, and this number is doubling every 20 days while the pandemic is still on-going [1]. The literature, however, at its early stage, lacks a comprehensive survey from a data analytics perspective. In this paper, we review the latest models for analyzing COVID19 related data, conduct post-publication model evaluations and cross-model comparisons, and collect data sources from different projects.",
    "lastUpdated": "2020-06-26T14:08:44Z",
    "categories": [
      "stat.AP"
    ],
    "url": "http://arxiv.org/abs/2006.13994v2"
  },
  {
    "title": "AI Failures: A Review of Underlying Issues",
    "authors": [
      "Debarag Narayan Banerjee",
      "Sasanka Sekhar Chanda"
    ],
    "abstract": "Instances of Artificial Intelligence (AI) systems failing to deliver consistent, satisfactory performance are legion. We investigate why AI failures occur. We address only a narrow subset of the broader field of AI Safety. We focus on AI failures on account of flaws in conceptualization, design and deployment. Other AI Safety issues like trade-offs between privacy and security or convenience, bad actors hacking into AI systems to create mayhem or bad actors deploying AI for purposes harmful to humanity and are out of scope of our discussion. We find that AI systems fail on account of omission and commission errors in the design of the AI system, as well as upon failure to develop an appropriate interpretation of input information. Moreover, even when there is no significant flaw in the AI software, an AI system may fail because the hardware is incapable of robust performance across environments. Finally an AI system is quite likely to fail in situations where, in effect, it is called upon to deliver moral judgments -- a capability AI does not possess. We observe certain trade-offs in measures to mitigate a subset of AI failures and provide some recommendations.",
    "lastUpdated": "2020-07-18T15:31:29Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2008.04073v1"
  },
  {
    "title": "Mind The Gap: Real-time Decentralized Distance Estimation using Ultrasound and Bluetooth across Multiple Smartphones",
    "authors": [
      "Devansh R. Agrawal",
      "Peter Lyon",
      "Martin Frobisher",
      "Andy Doherty",
      "Ben Allen",
      "Freddie Rawlins"
    ],
    "abstract": "Robust, low-cost solutions are needed to maintain social distancing guidelines during the COVID-19 pandemic. We establish a method to measure the distance between multiple phones across a large number of closely spaced smartphones with a median absolute error of 8.5~cm. The application works in real-time, using Time of Flight of near-ultrasound signals, providing alerts with sufficient responsiveness to be useful for distancing while devices are in users pockets and they are moving at walking speed. The approach is decentralized, requires no additional hardware, and can operate in the background without an internet connection. We have no device-specific requirements nor need any manual calibration or device synchronization. It has been tested with over 20 different phones models, from both the Android and iOS systems in the past 5 years. To the best of our knowledge, this is the first successful such implementation, and has 25000 users at time of publishing.",
    "lastUpdated": "2020-08-28T15:12:29Z",
    "categories": [
      "eess.SP"
    ],
    "url": "http://arxiv.org/abs/2008.13564v1"
  },
  {
    "title": "Bounds on amplitude damping channel discrimination",
    "authors": [
      "Jason L. Pereira",
      "Stefano Pirandola"
    ],
    "abstract": "Amplitude damping (AD) channels are good models for many physical scenarios, and so the development of protocols to discriminate between them is a crucial task in quantum information science. It is therefore important to bound the performance of such protocols. Since adaptivity has been shown to improve the performance of discrimination protocols, bounds on the distinguishability of AD channels must take this into account. In this paper, we use both channel simulation and a bound based on the diamond norm to significantly tighten the upper bound on the trace norm between the possible outputs of binary channel discrimination protocols acting on AD channels (and hence the lower bound on the error probability of such protocols). The diamond norm between any two AD channels is found analytically, giving the optimal error probability for a one-shot discrimination protocol. We also present a tighter lower bound on the achievable trace norm between protocol outputs (and a corresponding upper bound on the achievable error probability). The upper and lower bounds are compared with existing bounds and then applied to quantum hacking and biological quantum sensing scenarios.",
    "lastUpdated": "2020-12-02T19:00:03Z",
    "categories": [
      "quant-ph",
      "math-ph",
      "math.MP"
    ],
    "url": "http://arxiv.org/abs/2009.04783v2"
  },
  {
    "title": "tinyMD: A Portable and Scalable Implementation for Pairwise Interactions Simulations",
    "authors": [
      "Rafael Ravedutti L. Machado",
      "Jonas Schmitt",
      "Sebastian Eibl",
      "Jan Eitzinger",
      "Roland Leißa",
      "Sebastian Hack",
      "Arsène Pérard-Gayot",
      "Richard Membarth",
      "Harald Köstler"
    ],
    "abstract": "This paper investigates the suitability of the AnyDSL partial evaluation framework to implement tinyMD: an efficient, scalable, and portable simulation of pairwise interactions among particles. We compare tinyMD with the miniMD proxy application that scales very well on parallel supercomputers. We discuss the differences between both implementations and contrast miniMD's performance for single-node CPU and GPU targets, as well as its scalability on SuperMUC-NG and Piz Daint supercomputers. Additionaly, we demonstrate tinyMD's flexibility by coupling it with the waLBerla multi-physics framework. This allow us to execute tinyMD simulations using the load-balancing mechanism implemented in waLBerla.",
    "lastUpdated": "2020-09-16T00:29:13Z",
    "categories": [
      "cs.PF",
      "cs.DC",
      "cs.PL",
      "physics.comp-ph",
      "B.8.2, D.1.3, D.3.3, J.2"
    ],
    "url": "http://arxiv.org/abs/2009.07400v1"
  },
  {
    "title": "Exempla Gratis (E.G.): Code Examples for Free",
    "authors": [
      "Celeste Barnaby",
      "Koushik Sen",
      "Tianyi Zhang",
      "Elena Glassman",
      "Satish Chandra"
    ],
    "abstract": "Modern software engineering often involves using many existing APIs, both open source and, in industrial coding environments, proprietary. Programmers reference documentation and code search tools to remind themselves of proper common usage patterns of APIs. However, high-quality API usage examples are computationally expensive to curate and maintain, and API usage examples retrieved from company-wide code search can be tedious to review. We present a tool, EG, that mines codebases and shows the common, idiomatic usage examples for API methods. EG was integrated into Facebook's internal code search tool for the Hack language and evaluated on open-source GitHub projects written in Python. EG was also compared against code search results and hand-written examples from a popular programming website called ProgramCreek. Compared with these two baselines, examples generated by EG are more succinct and representative with less extraneous statements. In addition, a survey with Facebook developers shows that EG examples are preferred in 97 percent of cases.",
    "lastUpdated": "2020-11-03T01:20:42Z",
    "categories": [
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/2011.01407v1"
  },
  {
    "title": "Speaker De-identification System using Autoencodersand Adversarial Training",
    "authors": [
      "Fernando M. Espinoza-Cuadros",
      "Juan M. Perero-Codosero",
      "Javier Antón-Martín",
      "Luis A. Hernández-Gómez"
    ],
    "abstract": "The fast increase of web services and mobile apps, which collect personal data from users, increases the risk that their privacy may be severely compromised. In particular, the increasing variety of spoken language interfaces and voice assistants empowered by the vertiginous breakthroughs in Deep Learning are prompting important concerns in the European Union to preserve speech data privacy. For instance, an attacker can record speech from users and impersonate them to get access to systems requiring voice identification. Hacking speaker profiles from users is also possible by means of existing technology to extract speaker, linguistic (e.g., dialect) and paralinguistic features (e.g., age) from the speech signal. In order to mitigate these weaknesses, in this paper, we propose a speaker de-identification system based on adversarial training and autoencoders in order to suppress speaker, gender, and accent information from speech. Experimental results show that combining adversarial learning and autoencoders increase the equal error rate of a speaker verification system while preserving the intelligibility of the anonymized spoken content.",
    "lastUpdated": "2020-11-09T19:22:05Z",
    "categories": [
      "cs.SD",
      "cs.CL",
      "eess.AS"
    ],
    "url": "http://arxiv.org/abs/2011.04696v1"
  },
  {
    "title": "Reinforcement Learning based Multi-Robot Classification via Scalable Communication Structure",
    "authors": [
      "Guangyi Liu",
      "Arash Amini",
      "Martin Takáč",
      "Héctor Muñoz-Avila",
      "Nader Motee"
    ],
    "abstract": "In the multi-robot collaboration domain, training with Reinforcement Learning (RL) can become intractable, and performance starts to deteriorate drastically as the number of robots increases. In this work, we proposed a distributed multi-robot learning architecture with a scalable communication structure capable of learning a robust communication policy for time-varying communication topology. We construct the communication structure with Long-Short Term Memory (LSTM) cells and star graphs, in which the computational complexity of the proposed learning algorithm scales linearly with the number of robots and suitable for application with a large number of robots. The proposed methodology is validated with a map classification problem in the simulated environment. It is shown that the proposed architecture achieves a comparable classification accuracy with the centralized methods, maintains high performance with various numbers of robots without additional training cost, and robust to hacking and loss of the robots in the network.",
    "lastUpdated": "2020-12-18T19:35:10Z",
    "categories": [
      "cs.RO",
      "cs.LG",
      "cs.MA",
      "cs.SY",
      "eess.SY"
    ],
    "url": "http://arxiv.org/abs/2012.10480v1"
  },
  {
    "title": "When Interactive Graphic Storytelling Fails",
    "authors": [
      "James Barela",
      "Tiago Espinha Gasiba",
      "Santiago Reinhard Suppan",
      "Marc Berges",
      "Kristian Beckers"
    ],
    "abstract": "Many people are unaware of the digital dangers that lie around each cyber-corner. Teaching people how to recognize dangerous situations is crucial, especially for those who work on or with computers. We postulated that interactive graphic vignettes could be a great way to expose professionals to dangerous situations and demonstrate the effects of their choices in these situations. In that way, we aimed to inoculate employees against cybersecurity threats. We used the Comic-BEE platform to create interactive security awareness vignettes and evaluated for how employees of a major industrial company perceived them. For analysing the potential of these comics, we ran an evaluation study as part of a capture-the-flag (CTF) event, an interactive exercise for hacking vulnerable software. We evaluated whether the comics fulfilled our requirements based on the responses of the participants. We showed the comics, on various cybersecurity concepts, to 20 volunteers. In the context of a CTF event, our requirements were not fulfilled. Most participants considered the images distracting, stating a preference for text-only material.",
    "lastUpdated": "2021-01-06T15:57:00Z",
    "categories": [
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/2101.02106v1"
  },
  {
    "title": "Simulating SQL Injection Vulnerability Exploitation Using Q-Learning Reinforcement Learning Agents",
    "authors": [
      "Laszlo Erdodi",
      "Åvald Åslaugson Sommervoll",
      "Fabio Massimo Zennaro"
    ],
    "abstract": "In this paper, we propose a first formalization of the process of exploitation of SQL injection vulnerabilities. We consider a simplification of the dynamics of SQL injection attacks by casting this problem as a security capture-the-flag challenge. We model it as a Markov decision process, and we implement it as a reinforcement learning problem. We then deploy different reinforcement learning agents tasked with learning an effective policy to perform SQL injection; we design our training in such a way that the agent learns not just a specific strategy to solve an individual challenge but a more generic policy that may be applied to perform SQL injection attacks against any system instantiated randomly by our problem generator. We analyze the results in terms of the quality of the learned policy and in terms of convergence time as a function of the complexity of the challenge and the learning agent's complexity. Our work fits in the wider research on the development of intelligent agents for autonomous penetration testing and white-hat hacking, and our results aim to contribute to understanding the potential and the limits of reinforcement learning in a security environment.",
    "lastUpdated": "2021-01-08T17:19:21Z",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2101.03118v1"
  },
  {
    "title": "Robustness of on-device Models: Adversarial Attack to Deep Learning Models on Android Apps",
    "authors": [
      "Yujin Huang",
      "Han Hu",
      "Chunyang Chen"
    ],
    "abstract": "Deep learning has shown its power in many applications, including object detection in images, natural-language understanding, and speech recognition. To make it more accessible to end users, many deep learning models are now embedded in mobile apps. Compared to offloading deep learning from smartphones to the cloud, performing machine learning on-device can help improve latency, connectivity, and power consumption. However, most deep learning models within Android apps can easily be obtained via mature reverse engineering, while the models' exposure may invite adversarial attacks. In this study, we propose a simple but effective approach to hacking deep learning models using adversarial attacks by identifying highly similar pre-trained models from TensorFlow Hub. All 10 real-world Android apps in the experiment are successfully attacked by our approach. Apart from the feasibility of the model attack, we also carry out an empirical study that investigates the characteristics of deep learning models used by hundreds of Android apps on Google Play. The results show that many of them are similar to each other and widely use fine-tuning techniques to pre-trained models on the Internet.",
    "lastUpdated": "2021-01-12T10:49:30Z",
    "categories": [
      "cs.LG",
      "cs.CR",
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/2101.04401v1"
  },
  {
    "title": "Bitcoin and Beyond: Exclusively Informational Monies",
    "authors": [
      "Jan A. Bergstra",
      "Karl de Leeuw"
    ],
    "abstract": "The famous new money Bitcoin is classified as a technical informational money (TIM). Besides introducing the idea of a TIM, a more extreme notion of informational money will be developed: exclusively informational money (EXIM). The informational coins (INCOs) of an EXIM can be in control of an agent but are not owned by any agent. INCOs of an EXIM cannot be stolen, but they can be lost, or thrown away. The difference between an EXIM and a TIM shows up when considering a user perspective on security matters. Security for an EXIM user is discussed in substantial detail, with the remarkable conclusion that computer security (security models, access control, user names, passwords, firewalls etc.) is not always essential for an EXIM, while the application of cryptography based information security is unavoidable for the use of an EXIM. Bitcoin seems to meet the criteria of an EXIM, but the assertion that \"Bitcoin is an EXIM\", might also be considered problematic. As a thought experiment we will contemplate Bitguilder, a hypothetical copy of Bitcoin that qualifies as an EXIM. A business ethics assessment of Bitcoin is made which reveals a number of worries. By combining Bitguilder with a so-called technical informational near-money (TINM) a dual money system, having two units with a fluctuating rate, may be obtained. It seems that a dual money can remedy some, but not all, of the ethical worries that arise when contemplating Bitcoin after hypothetically having become a dominant form of money. The contributions that Bitcoin's designers can potentially make to the evolution of EXIMs and TIMs is analyzed in terms of the update of the portfolio of money related natural kinds that comes with Bitcoin.",
    "lastUpdated": "2013-12-30T16:39:27Z",
    "categories": [
      "cs.CY",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1304.4758v3"
  },
  {
    "title": "Effects of online group exercises for older adults on physical, psychological and social wellbeing: a pilot trial",
    "authors": [
      "Marcos Baez",
      "Iman Khaghani Far",
      "Francisco Ibarra",
      "Michela Ferron",
      "Daniele Didino",
      "Fabio Casati"
    ],
    "abstract": "Background. There are many factors that can make of group exercises a challenging setting for older adults. A major one in the elderly population is the difference in the level of skills. In this paper we report on the physical, psychological and social wellbeing outcomes of a novel virtual gym that enables online group-exercises in older adults with different levels of skills. Methods. A total of 37 older adults (65-87 years old) followed a personalized exercise program based on the OTAGO program for fall prevention, for a period of eight weeks. Participants could join online group exercises using a tablet-based application. Participants were assigned either to a Control group (individual training) or Social group (online group-exercising). Pre- and post- measurements were taken to analyze the physical, psychological and social wellbeing outcomes. The study received ethical approval from the CREATE-NET Ethics Committee on ICT Research Involving Human Beings (Application N. 2014-001). Results. There were improvements in both the Social and Control groups in terms of physical outcomes. Interestingly though, while in the Control group fitter individuals tended to adhere more to the training, this was not the case for the Social group, where the initial level had no effect on adherence. For psychological and social wellbeing outcomes there were improvements on both groups, regardless of the application used. Conclusion. Group exercising in a virtual gym can be effective in motivating and enabling individuals who are less fit to train as much as fitter individuals. This not only indicates the feasibility of training together despite differences in physical skills but also suggests that online exercise can reduce the effect of skills on adherence in a social context. Longer term interventions with more participants are instead recommended to assess impacts on wellbeing.",
    "lastUpdated": "2016-12-08T15:11:45Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1612.02686v1"
  },
  {
    "title": "Data Science as Political Action: Grounding Data Science in a Politics of Justice",
    "authors": [
      "Ben Green"
    ],
    "abstract": "In response to recent controversies, the field of data science has rushed to adopt codes of ethics. Such professional codes, however, are ill-equipped to address broad matters of social justice. Instead of ethics codes, I argue, the field must embrace politics. Data scientists must recognize themselves as political actors engaged in normative constructions of society and, as befits political work, evaluate their work according to its downstream material impacts on people's lives. I justify this notion in two parts: first, by articulating why data scientists must recognize themselves as political actors, and second, by describing how the field can evolve toward a deliberative and rigorous grounding in a politics of social justice. Part 1 responds to three arguments that are commonly invoked by data scientists when they are challenged to take political positions regarding their work. In confronting these arguments, I will demonstrate why attempting to remain apolitical is itself a political stance--a fundamentally conservative one--and why the field's current attempts to promote \"social good\" dangerously rely on vague and unarticulated political assumptions. Part 2 proposes a framework for what a politically-engaged data science could look like and how to achieve it, recognizing the challenge of reforming the field in this manner. I conceptualize the process of incorporating politics into data science in four stages: becoming interested in directly addressing social issues, recognizing the politics underlying these issues, redirecting existing methods toward new applications, and, finally, developing new practices and methods that orient data science around a mission of social justice. The path ahead does not require data scientists to abandon their technical expertise, but it does entail expanding their notions of what problems to work on and how to engage with society.",
    "lastUpdated": "2020-07-21T22:48:01Z",
    "categories": [
      "cs.CY",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1811.03435v3"
  },
  {
    "title": "Methodological provisions for conducting empirical research of the availability and implementation of the consumers socially responsible intentions",
    "authors": [
      "Lyudmyla Potrashkova",
      "Diana Raiko",
      "Leonid Tseitlin",
      "Olga Savchenko",
      "Szabolcs Nagy"
    ],
    "abstract": "Social responsibility of consumers is one of the main conditions for the recoupment of enterprises expenses associated with the implementation of social and ethical marketing tasks. Therefore, the enterprises, which plan to act on terms of social and ethical marketing, should monitor the social responsibility of consumers in the relevant markets. At the same time, special attention should be paid to the analysis of factors that prevent consumers from implementing their socially responsible intentions in the regions with a low level of social activity of consumers. The purpose of the article is to develop methodological guidelines that determine the tasks and directions of conducting empirical studies aimed at assessing the gap between the socially responsible intentions of consumers and the actual implementation of these intentions, as well as to identify the causes of this gap. An empirical survey of the sampled consumers in Kharkiv was carried out in terms of the proposed methodological provisions. It revealed a rather high level of respondents' willingness to support socially responsible enterprises and a rather low level of implementation of these intentions due to the lack of consumers awareness. To test the proposed methodological guidelines, an empirical study of the consumers social responsibility was conducted in 2017 on a sample of students and professors of the Semen Kuznets Kharkiv National University of Economics (120 people). Questioning of the respondents was carried out using the Google Forms. The finding allowed to make conclusion for existence of a high level of respondents' willingness to support socially responsible and socially active enterprises. However, the study also revealed the existence of a significant gap between the intentions and actions of consumers, caused by the lack of awareness.",
    "lastUpdated": "2019-01-01T18:22:08Z",
    "categories": [
      "econ.GN",
      "q-fin.EC"
    ],
    "url": "http://arxiv.org/abs/1901.00191v1"
  },
  {
    "title": "Fairway: A Way to Build Fair ML Software",
    "authors": [
      "Joymallya Chakraborty",
      "Suvodeep Majumder",
      "Zhe Yu",
      "Tim Menzies"
    ],
    "abstract": "Machine learning software is increasingly being used to make decisions that affect people's lives. But sometimes, the core part of this software (the learned model), behaves in a biased manner that gives undue advantages to a specific group of people (where those groups are determined by sex, race, etc.). This \"algorithmic discrimination\" in the AI software systems has become a matter of serious concern in the machine learning and software engineering community. There have been works done to find \"algorithmic bias\" or \"ethical bias\" in the software system. Once the bias is detected in the AI software system, the mitigation of bias is extremely important. In this work, we a)explain how ground-truth bias in training data affects machine learning model fairness and how to find that bias in AI software,b)propose a methodFairwaywhich combines pre-processing and in-processing approach to remove ethical bias from training data and trained model. Our results show that we can find bias and mitigate bias in a learned model, without much damaging the predictive performance of that model. We propose that (1) test-ing for bias and (2) bias mitigation should be a routine part of the machine learning software development life cycle. Fairway offers much support for these two purposes.",
    "lastUpdated": "2020-10-06T08:03:36Z",
    "categories": [
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/2003.10354v6"
  },
  {
    "title": "AI loyalty: A New Paradigm for Aligning Stakeholder Interests",
    "authors": [
      "Anthony Aguirre",
      "Gaia Dempsey",
      "Harry Surden",
      "Peter B. Reiner"
    ],
    "abstract": "When we consult with a doctor, lawyer, or financial advisor, we generally assume that they are acting in our best interests. But what should we assume when it is an artificial intelligence (AI) system that is acting on our behalf? Early examples of AI assistants like Alexa, Siri, Google, and Cortana already serve as a key interface between consumers and information on the web, and users routinely rely upon AI-driven systems like these to take automated actions or provide information. Superficially, such systems may appear to be acting according to user interests. However, many AI systems are designed with embedded conflicts of interests, acting in ways that subtly benefit their creators (or funders) at the expense of users. To address this problem, in this paper we introduce the concept of AI loyalty. AI systems are loyal to the degree that they are designed to minimize, and make transparent, conflicts of interest, and to act in ways that prioritize the interests of users. Properly designed, such systems could have considerable functional and competitive - not to mention ethical - advantages relative to those that do not. Loyal AI products hold an obvious appeal for the end-user and could serve to promote the alignment of the long-term interests of AI developers and customers. To this end, we suggest criteria for assessing whether an AI system is sufficiently transparent about conflicts of interest, and acting in a manner that is loyal to the user, and argue that AI loyalty should be considered during the technological design process alongside other important values in AI ethics such as fairness, accountability privacy, and equity. We discuss a range of mechanisms, from pure market forces to strong regulatory frameworks, that could support incorporation of AI loyalty into a variety of future AI systems.",
    "lastUpdated": "2020-03-24T23:55:59Z",
    "categories": [
      "cs.CY",
      "K.4"
    ],
    "url": "http://arxiv.org/abs/2003.11157v1"
  },
  {
    "title": "COVI White Paper",
    "authors": [
      "Hannah Alsdurf",
      "Edmond Belliveau",
      "Yoshua Bengio",
      "Tristan Deleu",
      "Prateek Gupta",
      "Daphne Ippolito",
      "Richard Janda",
      "Max Jarvie",
      "Tyler Kolody",
      "Sekoul Krastev",
      "Tegan Maharaj",
      "Robert Obryk",
      "Dan Pilat",
      "Valerie Pisano",
      "Benjamin Prud'homme",
      "Meng Qu",
      "Nasim Rahaman",
      "Irina Rish",
      "Jean-Francois Rousseau",
      "Abhinav Sharma",
      "Brooke Struck",
      "Jian Tang",
      "Martin Weiss",
      "Yun William Yu"
    ],
    "abstract": "The SARS-CoV-2 (Covid-19) pandemic has caused significant strain on public health institutions around the world. Contact tracing is an essential tool to change the course of the Covid-19 pandemic. Manual contact tracing of Covid-19 cases has significant challenges that limit the ability of public health authorities to minimize community infections. Personalized peer-to-peer contact tracing through the use of mobile apps has the potential to shift the paradigm. Some countries have deployed centralized tracking systems, but more privacy-protecting decentralized systems offer much of the same benefit without concentrating data in the hands of a state authority or for-profit corporations. Machine learning methods can circumvent some of the limitations of standard digital tracing by incorporating many clues and their uncertainty into a more graded and precise estimation of infection risk. The estimated risk can provide early risk awareness, personalized recommendations and relevant information to the user. Finally, non-identifying risk data can inform epidemiological models trained jointly with the machine learning predictor. These models can provide statistical evidence for the importance of factors involved in disease transmission. They can also be used to monitor, evaluate and optimize health policy and (de)confinement scenarios according to medical and economic productivity indicators. However, such a strategy based on mobile apps and machine learning should proactively mitigate potential ethical and privacy risks, which could have substantial impacts on society (not only impacts on health but also impacts such as stigmatization and abuse of personal data). Here, we present an overview of the rationale, design, ethical considerations and privacy strategy of `COVI,' a Covid-19 public peer-to-peer contact tracing and risk awareness mobile application developed in Canada.",
    "lastUpdated": "2020-07-27T15:41:17Z",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2005.08502v2"
  },
  {
    "title": "Report prepared by the Montreal AI Ethics Institute In Response to Mila's Proposal for a Contact Tracing App",
    "authors": [
      "Allison Cohen",
      "Abhishek Gupta"
    ],
    "abstract": "Contact tracing has grown in popularity as a promising solution to the COVID-19 pandemic. The benefits of automated contact tracing are two-fold. Contact tracing promises to reduce the number of infections by being able to: 1) systematically identify all of those that have been in contact with someone who has had COVID; and, 2) ensure those that have been exposed to the virus do not unknowingly infect others. \"COVI\" is the name of a recent contact tracing app developed by Mila and was proposed to help combat COVID-19 in Canada. The app was designed to inform each individual of their relative risk of being infected with the virus, which Mila claimed would empower citizens to make informed decisions about their movement and allow for a data-driven approach to public health policy; all the while ensuring data is safeguarded from governments, companies, and individuals. This article will provide a critical response to Mila's COVI White Paper. Specifically, this article will discuss: the extent to which diversity has been considered in the design of the app, assumptions surrounding users' interaction with the app and the app's utility, as well as unanswered questions surrounding transparency, accountability, and security. We see this as an opportunity to supplement the excellent risk analysis done by the COVI team to surface insights that can be applied to other contact- and proximity-tracing apps that are being developed and deployed across the world. Our hope is that, through a meaningful dialogue, we can ultimately help organizations develop better solutions that respect the fundamental rights and values of the communities these solutions are meant to serve.",
    "lastUpdated": "2020-08-11T06:05:13Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2008.04530v1"
  },
  {
    "title": "Not My Deepfake: Towards Plausible Deniability for Machine-Generated Media",
    "authors": [
      "Baiwu Zhang",
      "Jin Peng Zhou",
      "Ilia Shumailov",
      "Nicolas Papernot"
    ],
    "abstract": "Progress in generative modelling, especially generative adversarial networks, have made it possible to efficiently synthesize and alter media at scale. Malicious individuals now rely on these machine-generated media, or deepfakes, to manipulate social discourse. In order to ensure media authenticity, existing research is focused on deepfake detection. Yet, the very nature of frameworks used for generative modeling suggests that progress towards detecting deepfakes will enable more realistic deepfake generation. Therefore, it comes at no surprise that developers of generative models are under the scrutiny of stakeholders dealing with misinformation campaigns. As such, there is a clear need to develop tools that ensure the transparent use of generative modeling, while minimizing the harm caused by malicious applications. We propose a framework to provide developers of generative models with plausible deniability. We introduce two techniques to provide evidence that a model developer did not produce media that they are being accused of. The first optimizes over the source of entropy of each generative model to probabilistically attribute a deepfake to one of the models. The second involves cryptography to maintain a tamper-proof and publicly-broadcasted record of all legitimate uses of the model. We evaluate our approaches on the seminal example of face synthesis, demonstrating that our first approach achieves 97.62% attribution accuracy, and is less sensitive to perturbations and adversarial examples. In cases where a machine learning approach is unable to provide plausible deniability, we find that involving cryptography as done in our second approach is required. We also discuss the ethical implications of our work, and highlight that a more meaningful legislative framework is required for a more transparent and ethical use of generative modeling.",
    "lastUpdated": "2020-08-20T20:25:18Z",
    "categories": [
      "cs.LG",
      "cs.CR",
      "cs.CV",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2008.09194v1"
  },
  {
    "title": "Signs for Ethical AI: A Route Towards Transparency",
    "authors": [
      "Dario Garcia-Gasulla",
      "Atia Cortés",
      "Sergio Alvarez-Napagao",
      "Ulises Cortés"
    ],
    "abstract": "Artificial Intelligence (AI) has recently raised to the point where it has a direct impact on the daily life of billions of people. This is the result of its application to sectors like finance, health, digital entertainment, transportation, security and advertisement. Today, AI fuels some of the most significant economic and research institutions in the world, and the impact of AI in the near future seems difficult to predict or even bound. In contrast to all this power, society remains mostly ignorant of the capabilities, requirements and standard practices of AI today. Society is becoming aware of the dangers that come with that ignorance, and is rightfully asking for solutions. To address this need, improving on current practices of interaction between people and AI systems, we propose a transparency scheme to be implemented on any AI system open to the public. The scheme is based on two main pillars: Data Privacy and AI Transparency. The first recognizes the relevance of data for AI and is supported by GDPR, the most important legislation on the topic. The second considers aspects of AI transparency yet to be regulated: AI capacity, purpose and source. Lacking legislation to build upon, we design this pillar based on fundamental ethical principles. For each of the two pillars, we define a three-level display. The first level is based on visual signs, inspired by traffic signs managing the interaction between people and cars, and designed for quick and universal interpretability. The second level uses a factsheet system, providing further detail while still abstracting the subject. The last level provides access to all available details. After detailing and exemplifying the proposed transparency scheme, we define a set of principles for creating transparent by design software, to be used during the integration of AI components on user-oriented services.",
    "lastUpdated": "2020-09-29T08:49:44Z",
    "categories": [
      "cs.CY",
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/2009.13871v1"
  },
  {
    "title": "Synthesising clinically realistic Chest X-rays using Generative Adversarial Networks",
    "authors": [
      "Bradley Segal",
      "David M. Rubin",
      "Grace Rubin",
      "Adam Pantanowitz"
    ],
    "abstract": "Chest x-rays are one of the most commonly performed medical investigations globally and are vital to identifying a number of conditions. These images are however protected under patient confidentiality and as such require the removal of identifying information as well as ethical clearance to be released. Generative adversarial networks (GANs) are a branch of deep learning which are capable of producing synthetic samples of a desired distribution. Image generation is one such application with recent advances enabling the production of high-resolution images, a feature vital to the utility of x-rays given the scale of various pathologies. We apply the Progressive Growing GAN (PGGAN) to the task of chest x-ray generation with the goal of being able to produce images without any ethical concerns that may be used for medical education or in other machine learning work. We evaluate the properties of the generated x-rays with a practicing radiologist and demonstrate that high-quality, realistic images can be produced with global features consistent with pathologies seen in the NIH dataset. Improvements in the reproduction of small-scale details remains for future work. We train a classification model on the NIH images and evaluate the distribution of disease labels across the generated samples. We find that the model is capable of reproducing all the abnormalities in a similar proportion to the source image distribution as labelled by the classifier. We additionally demonstrate that the latent space can be optimised to produce images of a particular class despite unconditional training, with the model producing related features and complications for the class of interest. We also validate the application of the Fr'echet Inception Distance (FID) to x-ray images and determine that the PGGAN reproduces x-ray images with an FID of 8.02, which is similar to other high resolution tasks.",
    "lastUpdated": "2020-10-07T11:47:22Z",
    "categories": [
      "eess.IV",
      "cs.CV",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2010.03975v1"
  },
  {
    "title": "The Intrinsic Absorber in QSO 2359-1241: Keck and HST Observations",
    "authors": [
      "Nahum Arav",
      "Michael S. Brotherton",
      "Robert H. Becker",
      "Michael D. Gregg",
      "Richard L. White",
      "Trevor Price",
      "Warren Hack"
    ],
    "abstract": "We present detailed analyses of the absorption spectrum seen in QSO 2359-1241 (NVSS J235953-124148). Keck HIRES data reveal absorption from twenty transitions arising from: He I, Mg I, Mg II, Ca II, and Fe II. HST data show broad absorption lines (BALs) from Al III 1857, C IV 1549, Si IV 1397, and N V 1240. Absorption from excited Fe II states constrains the temperature of the absorber to 2000K < T < 10,000K and puts a lower limit of 10^5 cm^{-3} on the electron number density. Saturation diagnostics show that the real column densities of He I and Fe II can be determined, allowing to derive meaningful constraints on the ionization equilibrium and abundances in the flow. The ionization parameter is constrained by the iron, helium and magnesium data to -3.0 < log(U) < -2.5 and the observed column densities can be reproduced without assuming departure from solar abundances. From comparison of the He I and Fe II absorption features we infer that the outflow seen in QSO 2359-1241 is not shielded by a hydrogen ionization front and therefore that the existence of low-ionization species in the outflow (e.g., Mg II, Al III, Fe II) does not necessitate the existence of such a front. We find that the velocity width of the absorption systematically increases as a function of ionization and to a lesser extent with abundance. Complementary analyses of the radio and polarization properties of the object are discussed in a companion paper (Brotherton et al. 2000).",
    "lastUpdated": "2000-08-17T00:50:47Z",
    "categories": [
      "astro-ph"
    ],
    "url": "http://arxiv.org/abs/astro-ph/0008259v1"
  },
  {
    "title": "The Enigma of Lithium: from CP Stars to K Giants. First Results of CP Star Observations Obtained at Mount Stromlo Observatory",
    "authors": [
      "N. S. Polosukhina",
      "N. A. Drake",
      "M. Hack",
      "R. de la Reza",
      "P. R. Wood",
      "A. V. Shavrina"
    ],
    "abstract": "We present the results of the observations of some roAp stars made at Mount Stromlo Observatory during 17 nights in 2001 September-October. This long observing run permitted us to obtain a good phase-rotation coverage. In chemically peculiar magnetic stars, the Li I 6708 A spectral line presents very anomalous behaviour: in some stars it is a strong feature, in others, with similar atmospheric parameters, it is invisible. Interesting results were obtained for the roAp star HD 3980 which presents variations of the profile and position of the Li I line with the rotation period. These new observational results should serve as a base for the development of atmospheric models of ``Li-spotted'' roAp stars.",
    "lastUpdated": "2003-01-09T12:57:40Z",
    "categories": [
      "astro-ph"
    ],
    "url": "http://arxiv.org/abs/astro-ph/0301150v1"
  },
  {
    "title": "The spectrum of the roAp star HD 101065(Przybylski's star) in the Li I 6708 A spectral region",
    "authors": [
      "A. V. Shavrina",
      "N. S. Polosukhina",
      "Ya. V. Pavlenko",
      "A. V. Yushchenko",
      "P. Quinet",
      "M. Hack",
      "P. North",
      "V. F. Gopka",
      "J. Zverko",
      "J. Zhiznovsky",
      "A. Veles"
    ],
    "abstract": "We carried out a detailed analysis of spectra of the unique roAp star HD 101065 (Przybylski's star) near the resonance doublet Li I 6708 A, using a most complete line list including all possible transitions between REE levels of NIST database. Our model calculations were performed under two assumptions: blend of Li and REE lines, and blend of REE lines only. They prove that Li lines are present in the range 6707.72-6708.02 AA, and that the resulting Li abundance is 3.1 dex (in the scale log N(H) = 12.0, while the isotopic ratio 6Li/7Li is near to 0.3.",
    "lastUpdated": "2003-07-26T17:51:10Z",
    "categories": [
      "astro-ph"
    ],
    "url": "http://arxiv.org/abs/astro-ph/0307464v1"
  },
  {
    "title": "A multi--wavelength study of the IRAS Deep Survey galaxy sample II. The far-IR properties",
    "authors": [
      "P. Mazzei",
      "A. della Valle",
      "D. Bettoni"
    ],
    "abstract": "We derive the 60\\mu local LF to sensitivity levels 10 times deeper than before, to investigate evolutionary effects up to a redshift of 0.37, and, using the 60/15\\mu bi-variate method, the poorly known 15\\mu local LF of galaxies. We exploited our ISOCAM observations of the IRAS Deep Survey (IDS) fields (Hacking and Houck 1987), to correct the $60mu fluxes for confusion effects and observational biases. We find indications of a significant incompleteness of the IDS sample, still one of the deepest far-IR selected galaxy samples, below \\simeq 80mJy (Mazzei et al. 2001). We have reliable identifications and spectroscopic redshifts for 100% of a complete subsample comprising 56 sources with S(60mu(m))> 80mJy. With our spectroscopic coverage we construct the 60mu LF for a sample complete down to 80 mJy. This LF extends over three orders of magnitude in luminosity, from 9 up to more than 12 in log(L_(60)/L_(\\odot)). Despite the fact that the redshift range of our sample exceeds z=0.3, the V/V_{max} test gives <V/V_{max}>=0.51\\pm 0.06, consistent with a uniform distribution of sources. A more direct test, whereby the LF was measured in each of four different redshift intervals, does not point out any signature of evolution. On the other hand, the rest--frame 15\\mu local LF we derive, extends up to log(L_{15}/L_{\\odot})=12 and predicts 10 times more sources at log(L_{15}/L_{\\odot})=11 than are seen by Pozzi et al. (2004).",
    "lastUpdated": "2006-09-20T11:12:39Z",
    "categories": [
      "astro-ph"
    ],
    "url": "http://arxiv.org/abs/astro-ph/0609569v1"
  },
  {
    "title": "A matroid invariant via the K-theory of the Grassmannian",
    "authors": [
      "David E Speyer"
    ],
    "abstract": "Let G(d,n) denote the Grassmannian of d-planes in C^n and let T be the torus (C^*)^n/diag(C^*) which acts on G(d,n). Let x be a point of G(d,n) and let \\bar{Tx} be the closure of the T-orbit through x. Then the class of the structure sheaf of \\bar{Tx} in the K-theory of G(d,n) depends only on which Pl\\\"ucker coordinates of x are nonzero -- combinatorial data known as the matroid of x. In this paper, we will define a certain map of additive groups from the K-theory of G(d,n) to Z[t]. Letting g_x(t) denote the image of (-1)^{n-dim Tx} [ O_{\\bar{Tx}}], g_x behaves nicely under the standard constructions of matroid theory. Specifically, g_{x_1 \\oplus x_2}(t)=g_{x_1}(t) g_{x_2}(t), g_{x_1 +_2 x_2}(t)=g_{x_1}(t) g_{x_2}(t)/t, g_x(t) = g_{x^{\\perp}}(t) and g_x is unaltered by series and parallel extensions. Furthermore, the coefficients of g_x are nonnegative. The existence of this map implies bounds on (essentially equivalently) the complexity of Kapranov's Lie complexes, Hacking, Keel and Tevelev's very stable pairs and the author's tropical linear spaces when they are realizable in characteristic zero. Namely, in characteristic zero, a Lie complex or the underlying d-1 dimensional scheme of a very stable pair can have at most (n-i-1)! / (d-i)!(n-d-i)!(i-1)! strata of dimensions n-i and d-i respectively and a tropical linear space realizable in characteristic zero can have at most this many i-dimensional bounded faces.",
    "lastUpdated": "2006-03-23T15:42:15Z",
    "categories": [
      "math.AG",
      "math.CO"
    ],
    "url": "http://arxiv.org/abs/math/0603551v1"
  },
  {
    "title": "Geometry of River Networks I: Scaling, Fluctuations, and Deviations",
    "authors": [
      "Peter Sheridan Dodds",
      "Daniel H. Rothman"
    ],
    "abstract": "This article is the first in a series of three papers investigating the detailed geometry of river networks. Large-scale river networks mark an important class of two-dimensional branching networks, being not only of intrinsic interest but also a pervasive natural phenomenon. In the description of river network structure, scaling laws are uniformly observed. Reported values of scaling exponents vary suggesting that no unique set of scaling exponents exists. To improve this current understanding of scaling in river networks and to provide a fuller description of branching network structure, we report here a theoretical and empirical study of fluctuations about and deviations from scaling. We examine data for continent-scale river networks such as the Mississippi and the Amazon and draw inspiration from a simple model of directed, random networks. We center our investigations on the scaling of the length of sub-basin's dominant stream with its area, a characterization of basin shape known as Hack's law. We generalize this relationship to a joint probability density and show that fluctuations about scaling are substantial. We find strong deviations from scaling at small scales which can be explained by the existence of linear network structure. At intermediate scales, we find slow drifts in exponent values indicating that scaling is only approximately obeyed and that universality remains indeterminate. At large scales, we observe a breakdown in scaling due to decreasing sample space and correlations with overall basin shape. The extent of approximate scaling is significantly restricted by these deviations and will not be improved by increases in network resolution.",
    "lastUpdated": "2000-05-18T19:24:05Z",
    "categories": [
      "physics.geo-ph"
    ],
    "url": "http://arxiv.org/abs/physics/0005047v1"
  },
  {
    "title": "Controlling an actively-quenched single photon detector with bright light",
    "authors": [
      "Sebastien Sauge",
      "Lars Lydersen",
      "Andrey Anisimov",
      "Johannes Skaar",
      "Vadim Makarov"
    ],
    "abstract": "We control using bright light an actively-quenched avalanche single-photon detector. Actively-quenched detectors are commonly used for quantum key distribution (QKD) in the visible and near-infrared range. This study shows that these detectors are controllable by the same attack used to hack passively-quenched and gated detectors. This demonstrates the generality of our attack and its possible applicability to eavsdropping the full secret key of all QKD systems using avalanche photodiodes (APDs). Moreover, the commercial detector model we tested (PerkinElmer SPCM-AQR) exhibits two new blinding mechanisms in addition to the previously observed thermal blinding of the APD, namely: malfunctioning of the bias voltage control circuit, and overload of the DC/DC converter biasing the APD. These two new technical loopholes found just in one detector model suggest that this problem must be solved in general, by incorporating generally imperfect detectors into the security proof for QKD.",
    "lastUpdated": "2011-10-23T23:32:02Z",
    "categories": [
      "quant-ph",
      "physics.ins-det"
    ],
    "url": "http://arxiv.org/abs/0809.3408v4"
  },
  {
    "title": "A Precessing Jet in the CH Cyg Symbiotic System",
    "authors": [
      "M. Karovska",
      "T. J. Gaetz",
      "C. L. Carilli",
      "W. Hack",
      "J. C. Raymond",
      "N. P. Lee"
    ],
    "abstract": "Jets have been detected in only a few symbiotic binaries to date, and CH Cyg is one of them. In 2001, a non-relativistic jet was detected in CH Cyg for the first time in X-rays. We carried out coordinated Chandra, HST, and VLA observations in 2008 to study the propagation of this jet and its interaction with the circumbinary medium. We detected the jet with Chandra and HST and determined that the apex has expanded to the South from about 300 AU to about 1400 AU, with the shock front propagating with velocity < 100 km/s. The shock front has significantly slowed down since 2001. Unexpectedly, we also discovered a powerful jet in the NE-SW direction, in the X-ray, optical and radio. This jet has a multi-component structure, including an inner jet and a counter-jet at about 170 AU, and a SW component ending in several clumps extending out to approximately 750 AU. The structure of the jet and the curvature of the outer portion of the SW jet suggest an episodically powered precessing jet, or a continuous precessing jet with occasional mass ejections or pulses. We carried out detailed spatial mapping of the X-ray emission and correlation with the optical and radio emission. X-ray spectra were extracted of the central source, inner NE counter jet, and the brightest clump at a distance of approximately 500 AU from the central source. We discuss the initial results of our analyses, including the multi-component spectral fitting of the jet-components and of the central source.",
    "lastUpdated": "2010-01-19T20:18:38Z",
    "categories": [
      "astro-ph.HE",
      "astro-ph.SR"
    ],
    "url": "http://arxiv.org/abs/1001.3399v1"
  },
  {
    "title": "Implementation of a Cloud Data Server (CDS) for Providing Secure Service in E-Business",
    "authors": [
      "D. Kesavaraja",
      "R. Balasubramanian",
      "D. Sasireka"
    ],
    "abstract": "Cloud Data Servers is the novel approach for providing secure service to e-business .Millions of users are surfing the Cloud for various purposes, therefore they need highly safe and persistent services. Usually hackers target particular Operating Systems or a Particular Controller. Inspiteof several ongoing researches Conventional Web Servers and its Intrusion Detection System might not be able to detect such attacks. So we implement a Cloud Data Server with Session Controller Architecture using Redundancy and Disconnected Data Access Mechanism. In this paper, we generate the hash code using MD5 algorithm. With the help of which we can circumvent even the attacks, which are undefined by traditional Systems .we implement Cloud Data Sever using Java and Hash Code backup Management using My SQL. Here we Implement AES Algorithm for providing more Security for the hash Code. The CDS using the Virtual Controller controls and monitors the Connections and modifications of the page so as to prevent malicious users from hacking the website. In the proposed approach an activity analyzer takes care of intimating the administrator about possible intrusions and the counter measures required to tackle them. The efficiency ratio of our approach is 98.21% compared with similar approaches.",
    "lastUpdated": "2010-05-31T07:08:34Z",
    "categories": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1005.5606v1"
  },
  {
    "title": "Toward a \"fundamental theorem of quantal measure theory\"",
    "authors": [
      "Rafael D. Sorkin"
    ],
    "abstract": "We address the extension problem for quantal measures of path-integral type, concentrating on two cases: sequential growth of causal sets, and a particle moving on the finite lattice Z_n. In both cases the dynamics can be coded into a vector-valued measure mu on Omega, the space of all histories. Initially mu is defined only on special subsets of Omega called cylinder-events, and one would like to extend it to a larger family of subsets (events) in analogy to the way this is done in the classical theory of stochastic processes. Since quantally mu is generally not of bounded variation, a new method is required. We propose a method that defines the measure of an event by means of a sequence of simpler events which in a suitable sense converges to the event whose measure one is seeking to define. To this end, we introduce canonical sequences approximating certain events, and we propose a measure-based criterion for the convergence of such sequences. Applying the method, we encounter a simple event whose measure is zero classically but non-zero quantally.",
    "lastUpdated": "2011-04-08T00:37:40Z",
    "categories": [
      "hep-th",
      "gr-qc",
      "math-ph",
      "math.MP",
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/1104.0997v2"
  },
  {
    "title": "Linear bosonic and fermionic quantum gauge theories on curved spacetimes",
    "authors": [
      "Thomas-Paul Hack",
      "Alexander Schenkel"
    ],
    "abstract": "We develop a general setting for the quantization of linear bosonic and fermionic field theories subject to local gauge invariance and show how standard examples such as linearized Yang-Mills theory and linearized general relativity fit into this framework. Our construction always leads to a well-defined and gauge-invariant quantum field algebra, the centre and representations of this algebra, however, have to be analysed on a case-by-case basis. We discuss an example of a fermionic gauge field theory where the necessary conditions for the existence of Hilbert space representations are not met on any spacetime. On the other hand, we prove that these conditions are met for the Rarita-Schwinger gauge field in linearized pure N=1 supergravity on certain spacetimes, including asymptotically flat spacetimes and classes of spacetimes with compact Cauchy surfaces. We also present an explicit example of a supergravity background on which the Rarita-Schwinger gauge field can not be consistently quantized.",
    "lastUpdated": "2013-03-19T16:06:04Z",
    "categories": [
      "math-ph",
      "gr-qc",
      "hep-th",
      "math.MP",
      "81T20"
    ],
    "url": "http://arxiv.org/abs/1205.3484v2"
  },
  {
    "title": "Quantum Hacking on Continuous-Variable Quantum Key Distribution System using a Wavelength Attack",
    "authors": [
      "Jing-Zheng Huang",
      "Christian Weedbrook",
      "Zhen-Qiang Yin",
      "Shuang Wang",
      "Hong-Wei Li",
      "Wei Chen",
      "Guang-Can Guo",
      "Zheng-Fu Han"
    ],
    "abstract": "The security proofs of continuous-variable quantum key distribution are based on the assumptions that the eavesdropper can neither act on the local oscillator nor control Bob's beam splitter. These assumptions may be invalid in practice due to potential imperfections in the implementations of such protocols. In this paper, we consider the problem of transmitting the local oscillator in a public channel and propose a wavelength attack which can allow the eavesdropper to control the intensity transmission of Bob's beam splitter by switching the wavelength of the input light. Specifically we target continuous-variable quantum key distribution systems that use the heterodyne detection protocol using either direct or reverse reconciliation. Our attack is proved to be feasible and renders all of the final key shared between the legitimate parties insecure, even if they have monitored the intensity of the local oscillator. To prevent our attack on commercial systems, a simple wavelength filter should be added before performing the monitoring detection.",
    "lastUpdated": "2013-07-24T07:38:36Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/1302.0090v2"
  },
  {
    "title": "A C*-algebra for quantized principal U(1)-connections on globally hyperbolic Lorentzian manifolds",
    "authors": [
      "Marco Benini",
      "Claudio Dappiaggi",
      "Thomas-Paul Hack",
      "Alexander Schenkel"
    ],
    "abstract": "The aim of this work is to complete our program on the quantization of connections on arbitrary principal U(1)-bundles over globally hyperbolic Lorentzian manifolds. In particular, we show that one can assign via a covariant functor to any such bundle an algebra of observables which separates gauge equivalence classes of connections. The C*-algebra we construct generalizes the usual CCR-algebras since, contrary to the standard field-theoretic models, it is based on a presymplectic Abelian group instead of a symplectic vector space. We prove a no-go theorem according to which neither this functor, nor any of its quotients, satisfies the strict axioms of general local covariance. As a byproduct, we prove that a morphism violates the locality axiom if and only if a certain induced morphism of cohomology groups is non-injective. We then show that fixing any principal U(1)-bundle, there exists a suitable category of sub-bundles for which a quotient of our functor yields a quantum field theory in the sense of Haag and Kastler. We shall provide a physical interpretation of this feature and we obtain some new insights concerning electric charges in locally covariant quantum field theory.",
    "lastUpdated": "2014-03-20T09:49:24Z",
    "categories": [
      "math-ph",
      "hep-th",
      "math.DG",
      "math.MP",
      "81T20, 81T05, 81T13, 53Cxx"
    ],
    "url": "http://arxiv.org/abs/1307.3052v2"
  },
  {
    "title": "Les POMDP font de meilleurs hackers: Tenir compte de l'incertitude dans les tests de penetration",
    "authors": [
      "Carlos Sarraute",
      "Olivier Buffet",
      "Joerg Hoffmann"
    ],
    "abstract": "Penetration Testing is a methodology for assessing network security, by generating and executing possible hacking attacks. Doing so automatically allows for regular and systematic testing. A key question is how to generate the attacks. This is naturally formulated as planning under uncertainty, i.e., under incomplete knowledge about the network configuration. Previous work uses classical planning, and requires costly pre-processes reducing this uncertainty by extensive application of scanning methods. By contrast, we herein model the attack planning problem in terms of partially observable Markov decision processes (POMDP). This allows to reason about the knowledge available, and to intelligently employ scanning actions as part of the attack. As one would expect, this accurate solution does not scale. We devise a method that relies on POMDPs to find good attacks on individual machines, which are then composed into an attack on the network as a whole. This decomposition exploits network structure to the extent possible, making targeted approximations (only) where needed. Evaluating this method on a suitably adapted industrial test suite, we demonstrate its effectiveness in both runtime and solution quality.",
    "lastUpdated": "2013-07-30T04:21:54Z",
    "categories": [
      "cs.AI",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1307.7809v1"
  },
  {
    "title": "POMDPs Make Better Hackers: Accounting for Uncertainty in Penetration Testing",
    "authors": [
      "Carlos Sarraute",
      "Olivier Buffet",
      "Joerg Hoffmann"
    ],
    "abstract": "Penetration Testing is a methodology for assessing network security, by generating and executing possible hacking attacks. Doing so automatically allows for regular and systematic testing. A key question is how to generate the attacks. This is naturally formulated as planning under uncertainty, i.e., under incomplete knowledge about the network configuration. Previous work uses classical planning, and requires costly pre-processes reducing this uncertainty by extensive application of scanning methods. By contrast, we herein model the attack planning problem in terms of partially observable Markov decision processes (POMDP). This allows to reason about the knowledge available, and to intelligently employ scanning actions as part of the attack. As one would expect, this accurate solution does not scale. We devise a method that relies on POMDPs to find good attacks on individual machines, which are then composed into an attack on the network as a whole. This decomposition exploits network structure to the extent possible, making targeted approximations (only) where needed. Evaluating this method on a suitably adapted industrial test suite, we demonstrate its effectiveness in both runtime and solution quality.",
    "lastUpdated": "2013-07-31T01:03:00Z",
    "categories": [
      "cs.AI",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1307.8182v1"
  },
  {
    "title": "Is Somebody Watching Your Facebook Newsfeed?",
    "authors": [
      "Shan-Hung Wu",
      "Man-Ju Chou",
      "Ming-Hung Wang",
      "Chun-Hsiung Tseng",
      "Yuh-Jye Lee",
      "Kuan-Ta Chen"
    ],
    "abstract": "With the popularity of Social Networking Services (SNS), more and more sensitive information are stored online and associated with SNS accounts. The obvious value of SNS accounts motivates the usage stealing problem -- unauthorized, stealthy use of SNS accounts on the devices owned/used by account owners without any technology hacks. For example, anxious parents may use their kids' SNS accounts to inspect the kids' social status; husbands/wives may use their spouses' SNS accounts to spot possible affairs. Usage stealing could happen anywhere in any form, and seriously invades the privacy of account owners. However, there is no any currently known defense against such usage stealing. To an SNS operator (e.g., Facebook Inc.), usage stealing is hard to detect using traditional methods because such attackers come from the same IP addresses/devices, use the same credentials, and share the same accounts as the owners do. In this paper, we propose a novel continuous authentication approach that analyzes user browsing behavior to detect SNS usage stealing incidents. We use Facebook as a case study and show that it is possible to detect such incidents by analyzing SNS browsing behavior. Our experiment results show that our proposal can achieve higher than 80% detection accuracy within 2 minutes, and higher than 90% detection accuracy after 7 minutes of observation time.",
    "lastUpdated": "2013-08-23T16:14:15Z",
    "categories": [
      "cs.SI"
    ],
    "url": "http://arxiv.org/abs/1308.5168v1"
  },
  {
    "title": "Design of Generic Framework for Botnet Detection in Network Forensics",
    "authors": [
      "Sukhdilpreet Kaur",
      "Amandeep Verma"
    ],
    "abstract": "With the raise in practice of Internet, in social, personal, commercial and other aspects of life, the cybercrime is as well escalating at an alarming rate. Such usage of Internet in diversified areas also augmented the illegal activities, which in turn, bids many network attacks and threats. Network forensics is used to detect the network attacks. This can be viewed as the extension of network security. It is the technology, which detects and also suggests prevention of the various network attacks. Botnet is one of the most common attacks and is regarded as a network of hacked computers. It captures the network packet, store it and then analyze and correlate to find the source of attack. Various methods based on this approach for botnet detection are in literature, but a generalized method is lacking. So, there is a requirement to design a generic framework that can be used by any botnet detection. This framework is of use for researchers, in the development of their own method of botnet detection, by means of providing methodology and guidelines. In this paper, various prevalent methods of botnet detection are studied, commonalities among them are established and then a generalized model for the detection of botnet is proposed. The proposed framework is described as UML diagrams.",
    "lastUpdated": "2013-10-02T05:18:03Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1310.0569v1"
  },
  {
    "title": "Brachiaria species identification using imaging techniques based on fractal descriptors",
    "authors": [
      "João Batista Florindo",
      "Núbia Rosa da Silva",
      "Liliane Maria Romualdo",
      "Fernanda de Fátima da Silva",
      "Pedro Henrique de Cerqueira Luz",
      "Valdo Rodrigues Herling",
      "Odemir Martinez Bruno"
    ],
    "abstract": "The use of a rapid and accurate method in diagnosis and classification of species and/or cultivars of forage has practical relevance, scientific and trade in various areas of study. Thus, leaf samples of fodder plant species \\textit{Brachiaria} were previously identified, collected and scanned to be treated by means of artificial vision to make the database and be used in subsequent classifications. Forage crops used were: \\textit{Brachiaria decumbens} cv. IPEAN; \\textit{Brachiaria ruziziensis} Germain \\& Evrard; \\textit{Brachiaria Brizantha} (Hochst. ex. A. Rich.) Stapf; \\textit{Brachiaria arrecta} (Hack.) Stent. and \\textit{Brachiaria spp}. The images were analyzed by the fractal descriptors method, where a set of measures are obtained from the values of the fractal dimension at different scales. Therefore such values are used as inputs for a state-of-the-art classifier, the Support Vector Machine, which finally discriminates the images according to the respective species.",
    "lastUpdated": "2014-12-25T18:23:10Z",
    "categories": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1412.7849v1"
  },
  {
    "title": "Attacks exploiting deviation of mean photon number in quantum key distribution and coin tossing",
    "authors": [
      "Shihan Sajeed",
      "Igor Radchenko",
      "Sarah Kaiser",
      "Jean-Philippe Bourgoin",
      "Anna Pappa",
      "Laurent Monat",
      "Matthieu Legre",
      "Vadim Makarov"
    ],
    "abstract": "The security of quantum communication using a weak coherent source requires an accurate knowledge of the source's mean photon number. Finite calibration precision or an active manipulation by an attacker may cause the actual emitted photon number to deviate from the known value. We model effects of this deviation on the security of three quantum communication protocols: the Bennett-Brassard 1984 (BB84) quantum key distribution (QKD) protocol without decoy states, Scarani-Acin-Ribordy-Gisin 2004 (SARG04) QKD protocol, and a coin-tossing protocol. For QKD, we model both a strong attack using technology possible in principle, and a realistic attack bounded by today's technology. To maintain the mean photon number in two-way systems, such as plug-and-play and relativistic quantum cryptography schemes, bright pulse energy incoming from the communication channel must be monitored. Implementation of a monitoring detector has largely been ignored so far, except for ID Quantique's commercial QKD system Clavis2. We scrutinize this implementation for security problems, and show that designing a hack-proof pulse-energy-measuring detector is far from trivial. Indeed the first implementation has three serious flaws confirmed experimentally, each of which may be exploited in a cleverly constructed Trojan-horse attack. We discuss requirements for a loophole-free implementation of the monitoring detector.",
    "lastUpdated": "2015-03-30T19:09:14Z",
    "categories": [
      "quant-ph",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1412.8032v2"
  },
  {
    "title": "Supergeometry in locally covariant quantum field theory",
    "authors": [
      "Thomas-Paul Hack",
      "Florian Hanisch",
      "Alexander Schenkel"
    ],
    "abstract": "In this paper we analyze supergeometric locally covariant quantum field theories. We develop suitable categories SLoc of super-Cartan supermanifolds, which generalize Lorentz manifolds in ordinary quantum field theory, and show that, starting from a few representation theoretic and geometric data, one can construct a functor A : SLoc --> S*Alg to the category of super-*-algebras which can be interpreted as a non-interacting super-quantum field theory. This construction turns out to disregard supersymmetry transformations as the morphism sets in the above categories are too small. We then solve this problem by using techniques from enriched category theory, which allows us to replace the morphism sets by suitable morphism supersets that contain supersymmetry transformations as their higher superpoints. We construct super-quantum field theories in terms of enriched functors eA : eSLoc --> eS*Alg between the enriched categories and show that supersymmetry transformations are appropriately described within the enriched framework. As examples we analyze the superparticle in 1|1-dimensions and the free Wess-Zumino model in 3|2-dimensions.",
    "lastUpdated": "2015-09-16T12:40:22Z",
    "categories": [
      "math-ph",
      "hep-th",
      "math.DG",
      "math.MP",
      "81T05, 58A50, 81T60, 83E50"
    ],
    "url": "http://arxiv.org/abs/1501.01520v2"
  },
  {
    "title": "Canonical bases for cluster algebras",
    "authors": [
      "Mark Gross",
      "Paul Hacking",
      "Sean Keel",
      "Maxim Kontsevich"
    ],
    "abstract": "In previous work, the first three authors conjectured that the ring of regular functions on a natural class of affine log Calabi-Yau varieties (those with maximal boundary) has a canonical vector space basis parameterized by the integral tropical points of the mirror. Further, the structure constants for the multiplication rule in this basis should be given by counting broken lines (certain combinatorial objects, morally the tropicalisations of holomorphic discs). Here we prove the conjecture in the case of cluster varieties, where the statement is a more precise form of the Fock-Goncharov dual basis conjecture. In particular, under suitable hypotheses, for each Y the partial compactification of an affine cluster variety U given by allowing some frozen variables to vanish, we obtain canonical bases for the ring of functions on Y extending to a basis for functions on U. Each choice of seed canonically identifies the parameterizing sets of these bases with integral points in a polyhedral cone. These results specialize to basis results of combinatorial representation theory. For example, by considering the open double Bruhat cell U in the basic affine space Y we obtain a canonical basis of each irreducible representation of SL_r, parameterized by a set which each choice of seed identifies with integral points of a lattice polytope. These bases and polytopes are all constructed essentially without representation theoretic considerations. Along the way, our methods prove a number of conjectures in cluster theory, including positivity of the Laurent phenomenon for cluster algebras of geometric type.",
    "lastUpdated": "2016-10-28T14:45:24Z",
    "categories": [
      "math.AG",
      "math.CO",
      "math.RT"
    ],
    "url": "http://arxiv.org/abs/1411.1394v2"
  },
  {
    "title": "Network Analysis of Urban Traffic with Big Bus Data",
    "authors": [
      "Kai Zhao"
    ],
    "abstract": "Urban traffic analysis is crucial for traffic forecasting systems, urban planning and, more recently, various mobile and network applications. In this paper, we analyse urban traffic with network and statistical methods. Our analysis is based on one big bus dataset containing 45 million bus arrival samples in Helsinki. We mainly address following questions: 1. How can we identify the areas that cause most of the traffic in the city? 2. Why there is a urban traffic? Is bus traffic a key cause of the urban traffic? 3. How can we improve the urban traffic systems? To answer these questions, first, the betweenness is used to identify the most import areas that cause most traffics. Second, we find that bus traffic is not an important cause of urban traffic using statistical methods. We differentiate the urban traffic and the bus traffic in a city. We use bus delay as an identification of the urban traffic, and the number of bus as an identification of the bus traffic. Third, we give our solutions on how to improve urban traffic by the traffic simulation on road networks. We show that adding more buses during the peak time and providing better bus schedule plan in the hot areas like railway station, metro station, shopping malls etc. will reduce the urban traffic.",
    "lastUpdated": "2016-06-21T21:04:06Z",
    "categories": [
      "physics.soc-ph",
      "cs.SI"
    ],
    "url": "http://arxiv.org/abs/1606.06769v1"
  },
  {
    "title": "Approximate KMS states for scalar and spinor fields in Friedmann-Robertson-Walker spacetimes",
    "authors": [
      "Claudio Dappiaggi",
      "Thomas-Paul Hack",
      "Nicola Pinamonti"
    ],
    "abstract": "We construct and discuss Hadamard states for both scalar and Dirac spinor fields in a large class of spatially flat Friedmann-Robertson-Walker spacetimes characterised by an initial phase either of exponential or of power-law expansion. The states we obtain can be interpreted as being in thermal equilibrium at the time when the scale factor a has a specific value a=a_0. In the case a_0=0, these states fulfil a strict KMS condition on the boundary of the spacetime, which is either a cosmological horizon, or a Big Bang hypersurface. Furthermore, in the conformally invariant case, they are conformal KMS states on the full spacetime. However, they provide a natural notion of an approximate KMS state also in the remaining cases, especially for massive fields. On the technical side, our results are based on a bulk-to-boundary reconstruction technique already successfully applied in the scalar case and here proven to be suitable also for spinor fields. The potential applications of the states we find range over a broad spectrum, but they appear to be suited to discuss in particular thermal phenomena such as the cosmic neutrino background or the quantum state of dark matter.",
    "lastUpdated": "2010-09-27T07:56:41Z",
    "categories": [
      "gr-qc",
      "hep-th",
      "math-ph",
      "math.MP"
    ],
    "url": "http://arxiv.org/abs/1009.5179v1"
  },
  {
    "title": "On Perception and Reality in Wireless Air Traffic Communications Security",
    "authors": [
      "Martin Strohmeier",
      "Matthias Schäfer",
      "Rui Pinheiro",
      "Vincent Lenders",
      "Ivan Martinovic"
    ],
    "abstract": "More than a dozen wireless technologies are used by air traffic communication systems during different flight phases. From a conceptual perspective, all of them are insecure as security was never part of their design. Recent contributions from academic and hacking communities have exploited this inherent vulnerability to demonstrate attacks on some of these technologies. However, not all of these contributions have resonated widely within aviation circles. At the same time, the security community lacks certain aviation domain knowledge, preventing aviation authorities from giving credence to their findings. In this paper, we aim to reconcile the view of the security community and the perspective of aviation professionals concerning the safety of air traffic communication technologies. To achieve this, we first provide a systematization of the applications of wireless technologies upon which civil aviation relies. Based on these applications, we comprehensively analyze vulnerabilities, attacks, and countermeasures. We categorize the existing research on countermeasures into approaches that are applicable in the short term and research of secure new technologies deployable in the long term. Since not all of the required aviation knowledge is codified in academic publications, we additionally examine existing aviation standards and survey 242 international aviation experts. Besides their domain knowledge, we also analyze the awareness of members of the aviation community concerning the security of wireless systems and collect their expert opinions on the potential impact of concrete attack scenarios using these technologies.",
    "lastUpdated": "2016-10-24T17:00:40Z",
    "categories": [
      "cs.CR",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1602.08777v3"
  },
  {
    "title": "Power-law of Aggregate-size Spectra in Natural Systems",
    "authors": [
      "Matteo Convertino",
      "Filippo Simini",
      "Filippo Catani",
      "Igor Linkov",
      "Gregory A. Kiker"
    ],
    "abstract": "Patterns of animate and inanimate systems show remarkable similarities in their aggregation. One similarity is the double-Pareto distribution of the aggregate-size of system components. Different models have been developed to predict aggregates of system components. However, not many models have been developed to describe probabilistically the aggregate-size distribution of any system regardless of the intrinsic and extrinsic drivers of the aggregation process. Here we consider natural animate systems, from one of the greatest mammals - the African elephant (\\textit{Loxodonta africana}) - to the \\textit{Escherichia coli} bacteria, and natural inanimate systems in river basins. Considering aggregates as islands and their perimeter as a curve mirroring the sculpting network of the system, the probability of exceedence of the drainage area, and the Hack's law are shown to be the the Kor\\v{c}ak's law and the perimeter-area relationship for river basins. The perimeter-area relationship, and the probability of exceedence of the aggregate-size provide a meaningful estimate of the same fractal dimension. Systems aggregate because of the influence exerted by a physical or processes network within the system domain. The aggregate-size distribution is accurately derived using the null-method of box-counting on the occurrences of system components. The importance of the aggregate-size spectrum relies on its ability to reveal system form, function, and dynamics also as a function of other coupled systems. Variations of the fractal dimension and of the aggregate-size distribution are related to changes of systems that are meaningful to monitor because potentially critical for these systems.",
    "lastUpdated": "2013-03-07T06:19:06Z",
    "categories": [
      "q-bio.QM",
      "math-ph",
      "math.MP",
      "stat.AP"
    ],
    "url": "http://arxiv.org/abs/1303.1610v1"
  },
  {
    "title": "Modification of Symmetric Cryptography with Combining Affine Chiper and Caesar Chiper which Dynamic Nature in Matrix of Chiper Transposition by Applying Flow Pattern in the Planting Rice",
    "authors": [
      "Dewi Sartika Ginting",
      "Kristin Sitompul",
      "Jasael Simanulang",
      "Rahmat Widia Sembiring",
      "Muhammad Zarlis"
    ],
    "abstract": "Classical cryptography is a way of disguising the news done by the people when there was no computer. The goal is to protect information by way of encoding. This paper describesa modification of classical algorithms to make cryptanalis difficult to steal undisclosed messages. There are three types of classical algorithms that are combined affine chiper, Caesar chiper and chiper transposition. Where for chiperteks affine chiper and Caesar chiper can be looped as much as the initial key, because the result can be varied as much as key value, then affine chiper and Caesar chiper in this case is dynamic. Then the results of the affine and Caesar will be combined in the transposition chiper matrix by applying the pattern of rice cultivation path and for chipertext retrieval by finally applying the pattern of rice planting path. And the final digit of the digit shown in the form of binary digits so that 5 characters can be changed to 80 digit bits are scrambled. Thus the cryptanalyst will be more difficult and takes a very long time to hack information that has been kept secret.",
    "lastUpdated": "2017-07-11T15:19:33Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1707.03319v1"
  },
  {
    "title": "Comparing Topology of Engineered and Natural Drainage Networks",
    "authors": [
      "Soohyun Yang",
      "Kyungrock Paik",
      "Gavan McGrath",
      "Christian Urich",
      "Elisabeth Kruger",
      "Praveen Kumar",
      "P. Suresh C. Rao"
    ],
    "abstract": "We investigated the scaling and topology of engineered urban drainage networks (UDNs) in two cities, and further examined UDN evolution over decades. UDN scaling was analyzed using two power-law characteristics widely employed for river networks: (1) Hack's law of length ($L$)-area ($A$) scaling [$L \\propto A^{h}$], and (2) exceedance probability distribution of upstream contributing area $(\\delta)$ [$P(A\\geq \\delta) \\sim a \\delta^{-\\epsilon}$]. For the smallest UDNs ($<2 \\>\\text{km}^2$), length-area scales linearly ($h\\sim 1$), but power-law scaling emerges as the UDNs grow. While $P(A\\geq \\delta)$ plots for river networks are abruptly truncated, those for UDNs display exponential tempering [$P(A\\geq \\delta) \\>\\text{=}\\> a \\delta^{-\\epsilon}\\exp(-c\\delta)$]. The tempering parameter $c$ decreases as the UDNs grow, implying that the distribution evolves in time to resemble those for river networks. However, the power-law exponent $\\epsilon$ for large UDNs tends to be slightly larger than the range reported for river networks. Differences in generative processes and engineering design constraints contribute to observed differences in the evolution of UDNs and river networks, including subnet heterogeneity and non-random branching.",
    "lastUpdated": "2017-07-16T16:56:44Z",
    "categories": [
      "physics.geo-ph"
    ],
    "url": "http://arxiv.org/abs/1707.04911v1"
  },
  {
    "title": "Skewless Network Clock Synchronization Without Discontinuity: Convergence and Performance",
    "authors": [
      "Enrique Mallada",
      "Xiaoqiao Meng",
      "Michel Hack",
      "Li Zhang",
      "Ao Tang"
    ],
    "abstract": "This paper examines synchronization of computer clocks connected via a data network and proposes a skewless algorithm to synchronize them. Unlike existing solutions, which either estimate and compensate the frequency difference (skew) among clocks or introduce offset corrections that can generate jitter and possibly even backward jumps, our solution achieves synchronization without these problems. We first analyze the convergence property of the algorithm and provide explicit necessary and sufficient conditions on the parameters to guarantee synchronization. We then study the effect of noisy measurements (jitter) and frequency drift (wander) on the offsets and synchronization frequency, and further optimize the parameter values to minimize their variance. Our study reveals a few insights, for example, we show that our algorithm can converge even in the presence of timing loops and noise, provided that there is a well defined leader. This marks a clear contrast with current standards such as NTP and PTP, where timing loops are specifically avoided. Furthermore, timing loops can even be beneficial in our scheme as it is demonstrated that highly connected subnetworks can collectively outperform individual clients when the time source has large jitter. The results are supported by experiments running on a cluster of IBM BladeCenter servers with Linux.",
    "lastUpdated": "2014-07-28T16:10:57Z",
    "categories": [
      "math.OC",
      "cs.DC",
      "cs.NI",
      "cs.SY"
    ],
    "url": "http://arxiv.org/abs/1405.6477v2"
  },
  {
    "title": "Quantum hacking: saturation attack on practical continuous-variable quantum key distribution",
    "authors": [
      "Hao Qin",
      "Rupesh Kumar",
      "Romain Alléaume"
    ],
    "abstract": "We identify and study a new security loophole in continuous-variable quantum key distribution (CV-QKD) implementations, related to the imperfect linearity of the homodyne detector. By exploiting this loophole, we propose an active side-channel attack on the Gaussian-modulated coherent state CV-QKD protocol combining an intercept-resend attack with an induced saturation of the homodyne detection on the receiver side (Bob). We show that an attacker can bias the excess noise estimation by displacing the quadratures of the coherent states received by Bob. We propose a saturation model that matches experimental measurements on the homodyne detection and use this model to study the impact of the saturation attack on parameter estimation in CV-QKD.We demonstrate that this attack can bias the excess noise estimation beyond the null key threshold for any system parameter, thus leading to a full security break. If we consider an additional criteria imposing that the channel transmission estimation should not be affected by the attack, then the saturation attack can only be launched if the attenuation on the quantum channel is sufficient, corresponding to attenuations larger than approximately 6 dB. We moreover discuss the possible counter-measures against the saturation attack and propose a new counter- measure based on Gaussian post-selection that can be implemented by classical post-processing and may allow to distill secret key when the raw measurement data is partly saturated.",
    "lastUpdated": "2015-11-03T17:38:34Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/1511.01007v1"
  },
  {
    "title": "Analysis and Design of Actuation-Sensing-Communication Interconnection Structures towards Secured/Resilient Closed-loop Systems",
    "authors": [
      "Sergio Pequito",
      "Farshad Khorrami",
      "Prashanth Krishnamurthy",
      "George J. Pappas"
    ],
    "abstract": "This paper considers the analysis and design of resilient/robust decentralized control systems. Specifically, we aim to assess how the pairing of sensors and actuators lead to architectures that are resilient to attacks/hacks for industrial control systems and other complex cyber-physical systems. We consider inherent structural properties such as internal fixed modes of a dynamical system depending on actuation, sensing, and interconnection/communication structure for linear discrete time-invariant dynamical systems. We introduce the notion of resilient fixed-modes free system that ensures the non-existence of fixed modes when the actuation-sensing-communication structure is compromised due to attacks by a malicious agent on actuators, sensors, or communication components and natural failures. Also, we provide a graph-theoretical characterization for the resilient structurally fixed modes that enables to capture the non-existence of resilient fixed modes for almost all possible systems' realizations. Additionally, we address the minimum actuation-sensing-communication co-design ensuring the non-existence of resiliently structurally fixed modes, which we show to be NP-hard. Notwithstanding, we identify conditions that are often satisfied in engineering settings and under which the co-design problem is solvable in polynomial-time complexity. Furthermore, we leverage the structural insights and properties to provide a convex optimization method to design the gain for a parametrized system and satisfying the sparsity of a given information pattern. Thus, exploring the interplay between structural and non-structural systems to ensure their resilience. Finally, the efficacy of the proposed approach is demonstrated on a power grid example.",
    "lastUpdated": "2017-02-22T23:22:50Z",
    "categories": [
      "math.OC",
      "cs.SY"
    ],
    "url": "http://arxiv.org/abs/1511.02963v2"
  },
  {
    "title": "Hacking in the Blind: (Almost) Invisible Runtime UI Attacks on Safety-Critical Terminals",
    "authors": [
      "Luka Malisa",
      "Kari Kostiainen",
      "Thomas Knell",
      "David Sommer",
      "Srdjan Capkun"
    ],
    "abstract": "Many terminals are used in safety-critical operations in which humans, through terminal user interfaces, become a part of the system control loop (e.g., medical and industrial systems). These terminals are typically embedded, single-purpose devices with restricted functionality, sometimes air-gapped and increasingly hardened. We describe a new way of attacking such terminals in which an adversary has only temporary, non-invasive, physical access to the terminal. In this attack, the adversary attaches a small device to the interface that connects user input peripherals to the terminal. The device executes the attack when the authorized user is performing safety-critical operations, by modifying or blocking user input, or injecting new input events. Given that the attacker has access to user input, the execution of this attack might seem trivial. However, to succeed, the attacker needs to overcome a number of challenges including the inability to directly observe the user interface and avoid being detected by the users. We present techniques that allow user interface state and input tracking. We evaluate these techniques and show that they can be implemented efficiently. We further evaluate the effectiveness of our attack through an online user study and find input modification attacks that are hard for the users to detect and would therefore lead to serious violations of the input integrity.",
    "lastUpdated": "2016-04-16T10:57:06Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1604.04723v1"
  },
  {
    "title": "High-dimensional quantum cloning and applications to quantum hacking",
    "authors": [
      "Frédéric Bouchard",
      "Robert Fickler",
      "Robert W Boyd",
      "Ebrahim Karimi"
    ],
    "abstract": "Attempts at cloning a quantum system result in the introduction of imperfections in the state of the copies. This is a consequence of the no-cloning theorem, which is a fundamental law of quantum physics and the backbone of security for quantum communications. Although such perfect copies are prohibited, a quantum state may be copied with maximal accuracy via various optimal cloning schemes. Optimal quantum cloning, which lies at the border of the physical limit imposed by the no-signalling theorem and the Heisenberg uncertainty principle, has been experimentally realized for low dimensional photonic states. However, an increase in the dimensionality of quantum systems is greatly beneficial to quantum computation and communication protocols. Nonetheless, no experimental demonstration of optimal cloning machines has hitherto been shown for high-dimensional quantum systems. Here, we perform optimal cloning of high-dimensional photonic states by means of the symmetrization method. We show the universality of our technique by conducting cloning of numerous arbitrary input states, and fully characterize our cloning machine by performing quantum state tomography on \\emph{cloned} photons. In addition, a cloning attack on a Bennett and Brassard (BB84) quantum key distribution protocol is experimentally demonstrated in order to reveal the robustness of high-dimensional states in quantum cryptography.",
    "lastUpdated": "2016-08-15T20:11:14Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/1608.04396v1"
  },
  {
    "title": "Hacking of the AES with Boolean Functions",
    "authors": [
      "Michel Dubois",
      "Eric Filiol"
    ],
    "abstract": "One of the major issues of cryptography is the cryptanalysis of cipher algorithms. Cryptanalysis is the study of methods for obtaining the meaning of encrypted information, without access to the secret information that is normally required. Some mechanisms for breaking codes include differential cryptanalysis, advanced statistics and brute-force. Recent works also attempt to use algebraic tools to reduce the cryptanalysis of a block cipher algorithm to the resolution of a system of quadratic equations describing the ciphering structure. In our study, we will also use algebraic tools but in a new way: by using Boolean functions and their properties. A Boolean function is a function from $F_2^n\\to F_2$ with $n>1$, characterized by its truth table. The arguments of Boolean functions are binary words of length $n$. Any Boolean function can be represented, uniquely, by its algebraic normal form which is an equation which only contains additions modulo 2 - the XOR function - and multiplications modulo 2 - the AND function. Our aim is to describe the AES algorithm as a set of Boolean functions then calculate their algebraic normal forms by using the M\\\"obius transforms. After, we use a specific representation for these equations to facilitate their analysis and particularly to try a combinatorial analysis. Through this approach we obtain a new kind of equations system. This equations system is more easily implementable and could open new ways to cryptanalysis.",
    "lastUpdated": "2016-09-13T09:12:33Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1609.03734v1"
  },
  {
    "title": "Context-aware System Service Call-oriented Symbolic Execution of Android Framework with Application to Exploit Generation",
    "authors": [
      "Lannan Luo",
      "Qiang Zeng",
      "Chen Cao",
      "Kai Chen",
      "Jian Liu",
      "Limin Liu",
      "Neng Gao",
      "Min Yang",
      "Xinyu Xing",
      "Peng Liu"
    ],
    "abstract": "Android Framework is a layer of software that exists in every Android system managing resources of all Android apps. A vulnerability in Android Framework can lead to severe hacks, such as destroying user data and leaking private information. With tens of millions of Android devices unpatched due to Android fragmentation, vulnerabilities in Android Framework certainly attract attackers to exploit them. So far, enormous manual effort is needed to craft such exploits. To our knowledge, no research has been done on automatic generation of exploits that take advantage of Android Framework vulnerabilities. We make a first step towards this goal by applying symbolic execution of Android Framework to finding bugs and generating exploits. Several challenges have been raised by the task. (1) The information of an app flows to Android Framework in multiple intricate steps, making it difficult to identify symbolic inputs. (2) Android Framework has a complex initialization phase, which exacerbates the state space explosion problem. (3) A straightforward design that builds the symbolic executor as a layer inside the Android system will not work well: not only does the implementation have to ensure the compatibility with the Android system, but it needs to be maintained whenever Android gets updated. We present novel ideas and techniques to resolve the challenges, and have built the first system for symbolic execution of Android Framework. It fundamentally changes the state of the art in exploit generation on the Android system, and has been applied to constructing new techniques for finding vulnerabilities.",
    "lastUpdated": "2016-11-02T23:09:23Z",
    "categories": [
      "cs.CR",
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/1611.00837v1"
  },
  {
    "title": "Principles for Measurability in Protocol Design",
    "authors": [
      "Mark Allman",
      "Robert Beverly",
      "Brian Trammell"
    ],
    "abstract": "Measurement has become fundamental to the operation of networks and at-scale services---whether for management, security, diagnostics, optimization, or simply enhancing our collective understanding of the Internet as a complex system. Further, measurements are useful across points of view---from end hosts to enterprise networks and data centers to the wide area Internet. We observe that many measurements are decoupled from the protocols and applications they are designed to illuminate. Worse, current measurement practice often involves the exploitation of side-effects and unintended features of the network, or, in other words, the artful piling of hacks atop one another. This state of affairs is a direct result of the relative paucity of diagnostic and measurement capabilities built into today's network stack. Given our modern dependence on ubiquitous measurement, we propose measurability as an explicit low-level goal of current protocol design, and argue that measurements should be available to all network protocols throughout the stack. We seek to generalize the idea of measurement within protocols, e.g., the way in which TCP relies on measurement to drive its end-to-end behavior. Rhetorically, we pose the question: what if the stack had been built with measurability and diagnostic support in mind? We start from a set of principles for explicit measurability, and define primitives that, were they supported by the stack, would not only provide a solid foundation for protocol design going forward, but also reduce the cost and increase the accuracy of measuring the network.",
    "lastUpdated": "2017-05-15T12:46:15Z",
    "categories": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1612.02902v2"
  },
  {
    "title": "Gregory's sixth operation",
    "authors": [
      "Tiziana Bascelli",
      "Piotr Blaszczyk",
      "Vladimir Kanovei",
      "Karin U. Katz",
      "Mikhail G. Katz",
      "Semen S. Kutateladze",
      "Tahl Nowik",
      "David M. Schaps",
      "David Sherry"
    ],
    "abstract": "In relation to a thesis put forward by Marx Wartofsky, we seek to show that a historiography of mathematics requires an analysis of the ontology of the part of mathematics under scrutiny. Following Ian Hacking, we point out that in the history of mathematics the amount of contingency is larger than is usually thought. As a case study, we analyze the historians' approach to interpreting James Gregory's expression ultimate terms in his paper attempting to prove the irrationality of pi. Here Gregory referred to the last or ultimate terms of a series. More broadly, we analyze the following questions: which modern framework is more appropriate for interpreting the procedures at work in texts from the early history of infinitesimal analysis? as well as the related question: what is a logical theory that is close to something early modern mathematicians could have used when studying infinite series and quadrature problems? We argue that what has been routinely viewed from the viewpoint of classical analysis as an example of an \"unrigorous\" practice, in fact finds close procedural proxies in modern infinitesimal theories. We analyze a mix of social and religious reasons that had led to the suppression of both the religious order of Gregory's teacher degli Angeli, and Gregory's books at Venice, in the late 1660s.",
    "lastUpdated": "2016-12-18T16:41:26Z",
    "categories": [
      "math.HO",
      "math.CA",
      "math.LO",
      "01A45, 26E35"
    ],
    "url": "http://arxiv.org/abs/1612.05944v1"
  },
  {
    "title": "Securing the Assets of Decentralized Applications using Financial Derivatives (DRAFT)",
    "authors": [
      "George Bissias",
      "Brian Levine",
      "Nikunj Kapadia"
    ],
    "abstract": "Ethereum contracts can be designed to function as fully decentralized applications called DAPPs. Many DAPPs have already been fielded, including an online marketplace, a role playing game, a prediction market, and an Internet service provider. Unfortunately, DAPPs can be hacked, and the assets they control can be stolen. A recent attack on an Ethereum decentralized application called The DAO demonstrated that smart contract bugs are more than an academic concern. Ether worth tens of millions of US dollars was extracted by an attacker from The DAO, sending the value of its tokens and the overall exchange price of ether tumbling. We present a market-based technique for insuring the ether holdings of a DAPP using futures contracts indexed by the trade price of ether for DAPP tokens. Under fairly general circumstances, our technique is capable of recovering the majority of ether lost from theft with high probability even when all of the ether holdings are stolen; and the only cost to DAPP token holders is an adjustable ether withdrawal fee. If the probability of a margin call in $d$ days is $p$ for a futures contract with 20 times leverage, then our approach will allow for the recovery of half the stolen ether with probability $p$ and a withdrawal fee of 5%. A higher withdrawal fee of 25% allows for more than 80% of the ether to be recovered with probability $p$.",
    "lastUpdated": "2017-01-14T16:35:03Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1701.03945v1"
  },
  {
    "title": "A Strategy for an Uncompromising Incremental Learner",
    "authors": [
      "Ragav Venkatesan",
      "Hemanth Venkateswara",
      "Sethuraman Panchanathan",
      "Baoxin Li"
    ],
    "abstract": "Multi-class supervised learning systems require the knowledge of the entire range of labels they predict. Often when learnt incrementally, they suffer from catastrophic forgetting. To avoid this, generous leeways have to be made to the philosophy of incremental learning that either forces a part of the machine to not learn, or to retrain the machine again with a selection of the historic data. While these hacks work to various degrees, they do not adhere to the spirit of incremental learning. In this article, we redefine incremental learning with stringent conditions that do not allow for any undesirable relaxations and assumptions. We design a strategy involving generative models and the distillation of dark knowledge as a means of hallucinating data along with appropriate targets from past distributions. We call this technique, phantom sampling.We show that phantom sampling helps avoid catastrophic forgetting during incremental learning. Using an implementation based on deep neural networks, we demonstrate that phantom sampling dramatically avoids catastrophic forgetting. We apply these strategies to competitive multi-class incremental learning of deep neural networks. Using various benchmark datasets and through our strategy, we demonstrate that strict incremental learning could be achieved. We further put our strategy to test on challenging cases, including cross-domain increments and incrementing on a novel label space. We also propose a trivial extension to unbounded-continual learning and identify potential for future development.",
    "lastUpdated": "2017-07-17T07:30:18Z",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1705.00744v2"
  },
  {
    "title": "Attack Detection in Sensor Network Target Localization Systems with Quantized Data",
    "authors": [
      "Jiangfan Zhang",
      "Xiaodong Wang",
      "Rick S. Blum",
      "Lance M. Kaplan"
    ],
    "abstract": "We consider a sensor network focused on target localization, where sensors measure the signal strength emitted from the target. Each measurement is quantized to one bit and sent to the fusion center. A general attack is considered at some sensors that attempts to cause the fusion center to produce an inaccurate estimation of the target location with a large mean-square-error. The attack is a combination of man-in-the-middle, hacking, and spoofing attacks that can effectively change both signals going into and coming out of the sensor nodes in a realistic manner. We show that the essential effect of attacks is to alter the estimated distance between the target and each attacked sensor to a different extent, giving rise to a geometric inconsistency among the attacked and unattacked sensors. Hence, with the help of two secure sensors, a class of detectors are proposed to detect the attacked sensors by scrutinizing the existence of the geometric inconsistency. We show that the false alarm and miss probabilities of the proposed detectors decrease exponentially as the number of measurement samples increases, which implies that for sufficiently large number of samples, the proposed detectors can identify the attacked and unattacked sensors with any required accuracy.",
    "lastUpdated": "2017-05-15T19:52:07Z",
    "categories": [
      "cs.IT",
      "math.IT"
    ],
    "url": "http://arxiv.org/abs/1705.05424v1"
  },
  {
    "title": "IoT-enabled Distributed Cyber-attacks on Transmission and Distribution Grids",
    "authors": [
      "Yury Dvorkin",
      "Siddharth Garg"
    ],
    "abstract": "The Internet of things (IoT) will make it possible to interconnect and simultaneously control distributed electrical loads. Various technical and regulatory concerns have been raised that IoT-operated loads are being deployed without appropriately considering and systematically addressing potential cyber-security challenges. Hence, one can envision a hypothetical scenario when an ensemble of IoT-controlled loads can be hacked with malicious intentions of compromising operations of the electrical grid. Under this scenario, the attacker would use geographically distributed IoT-controlled loads to alternate their net power injections into the electrical grid in such a way that may disrupt normal grid operations. This paper presents a modeling framework to analyze grid impacts of distributed cyber-attacks on IoT-controlled loads. This framework is used to demonstrate how a hypothetical distributed cyber-attack propagates from the distribution electrical grid, where IoT-controlled loads are expected to be installed, to the transmission electrical grid. The techno-economic interactions between the distribution and transmission electrical grids are accounted for by means of bilevel optimization. The case study is carried out on the modified versions of the 3-area IEEE Reliability Test System (RTS) and the IEEE 13-bus distribution feeder. Our numerical results demonstrate that the severity of such attacks depends on the penetration level of IoT-controlled loads and the strategy of the attacker.",
    "lastUpdated": "2017-06-22T20:45:21Z",
    "categories": [
      "cs.SY"
    ],
    "url": "http://arxiv.org/abs/1706.07485v1"
  },
  {
    "title": "A tropical and log geometric approach to algebraic structures in the ring of theta functions",
    "authors": [
      "Hülya Argüz"
    ],
    "abstract": "We study an algebro-geometric approach to symplectic cohomology in terms of tropical geometry and log Gromov-Witten theory. As the degree zero piece of symplectic cohomology conjecturally is isomorphic to the ring of theta functions of Gross-Hacking-Siebert, our main goal in this paper is to introduce algebro-geometric tools capturing analogues of the algebraic structures arising in symplectic cohomology, in the ring of theta functions. For this, we focus on the Tate curve $T$, a degeneration of elliptic curves to a cycle of projective lines, and investigate (a version of) the symplectic cohomology $SH^*(T\\setminus T_0)$ for the complement of the central fiber of $T$. We study $SH^*(T\\setminus T_0)$, first by going through the Lagrangian Floer cohomology of the elliptic curve, and then by investigating the Floer multiplication using tropical Morse trees introduced by Abouzaid-Gross-Siebert, as combinatorial analogues of holomorphic discs bounded by Lagrangians. From tropical Morse trees, we construct tropical analogues of holomorphic Riemann surfaces with punctures in $T$, which we call tropical corals, capturing the product in symplectic cohomology. Our main result is a tropical correspondence theorem between tropical corals and punctured log maps defined by Abramovich-Chen-Gross-Siebert. This uses an interpretation of punctured log maps as log maps with non-complete components.",
    "lastUpdated": "2020-03-01T19:51:02Z",
    "categories": [
      "math.AG",
      "math.SG"
    ],
    "url": "http://arxiv.org/abs/1712.10260v2"
  },
  {
    "title": "Impact Assessment of Hypothesized Cyberattacks on Interconnected Bulk Power Systems",
    "authors": [
      "Chee-Wooi Ten",
      "Koji Yamashita",
      "Zhiyuan Yang",
      "Athanasios V. Vasilakos",
      "Andrew Ginter"
    ],
    "abstract": "The first-ever Ukraine cyberattack on power grid has proven its devastation by hacking into their critical cyber assets. With administrative privileges accessing substation networks/local control centers, one intelligent way of coordinated cyberattacks is to execute a series of disruptive switching executions on multiple substations using compromised supervisory control and data acquisition (SCADA) systems. These actions can cause significant impacts to an interconnected power grid. Unlike the previous power blackouts, such high-impact initiating events can aggravate operating conditions, initiating instability that may lead to system-wide cascading failure. A systemic evaluation of \"nightmare\" scenarios is highly desirable for asset owners to manage and prioritize the maintenance and investment in protecting their cyberinfrastructure. This survey paper is a conceptual expansion of real-time monitoring, anomaly detection, impact analyses, and mitigation (RAIM) framework that emphasizes on the resulting impacts, both on steady-state and dynamic aspects of power system stability. Hypothetically, we associate the combinatorial analyses of steady state on substations/components outages and dynamics of the sequential switching orders as part of the permutation. The expanded framework includes (1) critical/noncritical combination verification, (2) cascade confirmation, and (3) combination re-evaluation. This paper ends with a discussion of the open issues for metrics and future design pertaining the impact quantification of cyber-related contingencies.",
    "lastUpdated": "2018-01-03T15:23:26Z",
    "categories": [
      "cs.CR",
      "cs.SY"
    ],
    "url": "http://arxiv.org/abs/1801.01048v1"
  },
  {
    "title": "The Information Content of Sarbanes-Oxley in Predicting Security Breaches",
    "authors": [
      "J. Christopher Westland"
    ],
    "abstract": "We investigated publicly reported security breaches of internal controls in corporate systems to determine whether SOX assessments are information bearing with respect to breaches which can lead to materially significant losses and misstatements. SOX Section 404 adverse decisions on effectiveness of controls occurred in 100% of credit card data breaches and around 33% of insider breaches. SOX 404 audits provided a contrarian \"effective\" control decisions on 88% of situations where there was a control breach concerning a portable device. We found that management and SOX 404 auditors do not general agree on the underlying internal control situation at any time; instead the SOX 404 team was likely to discover material weaknesses and \"educate\" management and internal audit teams about the importance of these control weaknesses. SOX attestations were poor at identifying control weaknesses from unintended disclosures, physical losses, hacking and malware. Hazard and occupancy models showed that both SOX 302 and 404 section audits provided information on the frequency of breaches, with SOX 404 being three times as informative as section 302 reports. The hazard model found an expected 2.88% reduction in breaches when SOX 302 controls are effective; management \"material weakness' attestations provided no information in this structural model, whereas there would be around a 1% increase in breach occurrence when there are significant deficiencies. SOX 404 attestations were the most informative, and a negative SOX 404 attestation is projected to increase the frequency of breaches by around 8.5%.",
    "lastUpdated": "2018-02-11T16:51:06Z",
    "categories": [
      "q-fin.GN"
    ],
    "url": "http://arxiv.org/abs/1802.10001v1"
  },
  {
    "title": "Cyberattack Detection using Deep Generative Models with Variational Inference",
    "authors": [
      "Sarin E. Chandy",
      "Amin Rasekh",
      "Zachary A. Barker",
      "M. Ehsan Shafiee"
    ],
    "abstract": "Recent years have witnessed a rise in the frequency and intensity of cyberattacks targeted at critical infrastructure systems. This study designs a versatile, data-driven cyberattack detection platform for infrastructure systems cybersecurity, with a special demonstration in water sector. A deep generative model with variational inference autonomously learns normal system behavior and detects attacks as they occur. The model can process the natural data in its raw form and automatically discover and learn its representations, hence augmenting system knowledge discovery and reducing the need for laborious human engineering and domain expertise. The proposed model is applied to a simulated cyberattack detection problem involving a drinking water distribution system subject to programmable logic controller hacks, malicious actuator activation, and deception attacks. The model is only provided with observations of the system, such as pump pressure and tank water level reads, and is blind to the internal structures and workings of the water distribution system. The simulated attacks are manifested in the model's generated reproduction probability plot, indicating its ability to discern the attacks. There is, however, need for improvements in reducing false alarms, especially by optimizing detection thresholds. Altogether, the results indicate ability of the model in distinguishing attacks and their repercussions from normal system operation in water distribution systems, and the promise it holds for cyberattack detection in other domains.",
    "lastUpdated": "2018-05-31T15:21:52Z",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1805.12511v1"
  },
  {
    "title": "Towards Privacy-Preserving Visual Recognition via Adversarial Training: A Pilot Study",
    "authors": [
      "Zhenyu Wu",
      "Zhangyang Wang",
      "Zhaowen Wang",
      "Hailin Jin"
    ],
    "abstract": "This paper aims to improve privacy-preserving visual recognition, an increasingly demanded feature in smart camera applications, by formulating a unique adversarial training framework. The proposed framework explicitly learns a degradation transform for the original video inputs, in order to optimize the trade-off between target task performance and the associated privacy budgets on the degraded video. A notable challenge is that the privacy budget, often defined and measured in task-driven contexts, cannot be reliably indicated using any single model performance, because a strong protection of privacy has to sustain against any possible model that tries to hack privacy information. Such an uncommon situation has motivated us to propose two strategies, i.e., budget model restarting and ensemble, to enhance the generalization of the learned degradation on protecting privacy against unseen hacker models. Novel training strategies, evaluation protocols, and result visualization methods have been designed accordingly. Two experiments on privacy-preserving action recognition, with privacy budgets defined in various ways, manifest the compelling effectiveness of the proposed framework in simultaneously maintaining high target task (action recognition) performance while suppressing the privacy breach risk.",
    "lastUpdated": "2020-10-22T23:05:53Z",
    "categories": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1807.08379v2"
  },
  {
    "title": "Robotics CTF (RCTF), a playground for robot hacking",
    "authors": [
      "Gorka Olalde Mendia",
      "Lander Usategui San Juan",
      "Xabier Perez Bascaran",
      "Asier Bilbao Calvo",
      "Alejandro Hernández Cordero",
      "Irati Zamalloa Ugarte",
      "Aday Muñiz Rosas",
      "David Mayoral Vilches",
      "Unai Ayucar Carbajo",
      "Laura Alzola Kirschgens",
      "Víctor Mayoral Vilches",
      "Endika Gil-Uriarte"
    ],
    "abstract": "Robots state of insecurity is onstage. There is an emerging concern about major robot vulnerabilities and their adverse consequences. However, there is still a considerable gap between robotics and cybersecurity domains. For the purpose of filling that gap, the present technical report presents the Robotics CTF (RCTF), an online playground to challenge robot security from any browser. We describe the architecture of the RCTF and provide 9 scenarios where hackers can challenge the security of different robotic setups. Our work empowers security researchers to a) reproduce virtual robotic scenarios locally and b) change the networking setup to mimic real robot targets. We advocate for hacker powered security in robotics and contribute by open sourcing our scenarios.",
    "lastUpdated": "2019-09-21T06:46:49Z",
    "categories": [
      "cs.CY",
      "cs.RO"
    ],
    "url": "http://arxiv.org/abs/1810.02690v3"
  },
  {
    "title": "Attack Graph Convolutional Networks by Adding Fake Nodes",
    "authors": [
      "Xiaoyun Wang",
      "Minhao Cheng",
      "Joe Eaton",
      "Cho-Jui Hsieh",
      "Felix Wu"
    ],
    "abstract": "In this paper, we study the robustness of graph convolutional networks (GCNs). Previous work have shown that GCNs are vulnerable to adversarial perturbation on adjacency or feature matrices of existing nodes; however, such attacks are usually unrealistic in real applications. For instance, in social network applications, the attacker will need to hack into either the client or server to change existing links or features. In this paper, we propose a new type of \"fake node attacks\" to attack GCNs by adding malicious fake nodes. This is much more realistic than previous attacks; in social network applications, the attacker only needs to register a set of fake accounts and link to existing ones. To conduct fake node attacks, a greedy algorithm is proposed to generate edges of malicious nodes and their corresponding features aiming to minimize the classification accuracy on the target nodes. In addition, we introduce a discriminator to classify malicious nodes from real nodes, and propose a Greedy-GAN attack to simultaneously update the discriminator and the attacker, to make malicious nodes indistinguishable from the real ones. Our non-targeted attack decreases the accuracy of GCN down to 0.03, and our targeted attack reaches a success rate of 78% on a group of 100 nodes, and 90% on average for attacking a single target node.",
    "lastUpdated": "2020-09-03T20:31:16Z",
    "categories": [
      "cs.LG",
      "cs.CR",
      "cs.SI"
    ],
    "url": "http://arxiv.org/abs/1810.10751v4"
  },
  {
    "title": "LRCoin: Leakage-resilient Cryptocurrency Based on Bitcoin for Data Trading in IoT",
    "authors": [
      "Yong Yu",
      "Yujie Ding",
      "Yanqi Zhao",
      "Yannan Li",
      "Xiaojiang Du",
      "Mohsen Guizani"
    ],
    "abstract": "Currently, the number of Internet of Thing (IoT) devices making up the IoT is more than 11 billion and this number has been continuously increasing. The prevalence of these devices leads to an emerging IoT business model called Device-as-a-service(DaaS), which enables sensor devices to collect data disseminated to all interested devices. The devices sharing data with other devices could receive some financial reward such as Bitcoin. However, side-channel attacks, which aim to exploit some information leaked from the IoT devices during data trade execution, are possible since most of the IoT devices are vulnerable to be hacked or compromised. Thus, it is challenging to securely realize data trading in IoT environment due to the information leakage such as leaking the private key for signing a Bitcoin transaction in Bitcoin system. In this paper, we propose LRCoin, a kind of leakage-resilient cryptocurrency based on bitcoin in which the signature algorithm used for authenticating bitcoin transactions is leakage-resilient. LRCoin is suitable for the scenarios where information leakage is inevitable such as IoT applications. Our core contribution is proposing an efficient bilinear-based continual-leakage-resilient ECDSA signature. We prove the proposed signature algorithm is unforgeable against adaptively chosen messages attack in the generic bilinear group model under the continual leakage setting. Both the theoretical analysis and the implementation demonstrate the practicability of the proposed scheme.",
    "lastUpdated": "2018-10-26T03:37:27Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1810.11175v1"
  },
  {
    "title": "Prediction Error Meta Classification in Semantic Segmentation: Detection via Aggregated Dispersion Measures of Softmax Probabilities",
    "authors": [
      "Matthias Rottmann",
      "Pascal Colling",
      "Thomas-Paul Hack",
      "Robin Chan",
      "Fabian Hüger",
      "Peter Schlicht",
      "Hanno Gottschalk"
    ],
    "abstract": "We present a method that \"meta\" classifies whether seg-ments predicted by a semantic segmentation neural networkintersect with the ground truth. For this purpose, we employ measures of dispersion for predicted pixel-wise class probability distributions, like classification entropy, that yield heat maps of the input scene's size. We aggregate these dispersion measures segment-wise and derive metrics that are well-correlated with the segment-wise IoU of prediction and ground truth. This procedure yields an almost plug and play post-processing tool to rate the prediction quality of semantic segmentation networks on segment level. This is especially relevant for monitoring neural networks in online applications like automated driving or medical imaging where reliability is of utmost importance. In our tests, we use publicly available state-of-the-art networks trained on the Cityscapes dataset and the BraTS2017 dataset and analyze the predictive power of different metrics as well as different sets of metrics. To this end, we compute logistic LASSO regression fits for the task of classifying IoU=0 vs. IoU>0 per segment and obtain AUROC values of up to 91.55%. We complement these tests with linear regression fits to predict the segment-wise IoU and obtain prediction standard deviations of down to 0.130 as well as $R^2$ values of up to 84.15%. We show that these results clearly outperform standard approaches.",
    "lastUpdated": "2019-10-02T14:38:24Z",
    "categories": [
      "cs.CV",
      "cs.LG",
      "stat.ML",
      "68T45, 62-07"
    ],
    "url": "http://arxiv.org/abs/1811.00648v2"
  },
  {
    "title": "Secure Distributed Dynamic State Estimation in Wide-Area Smart Grids",
    "authors": [
      "Mehmet Necip Kurt",
      "Yasin Yilmaz",
      "Xiaodong Wang"
    ],
    "abstract": "Smart grid is a large complex network with a myriad of vulnerabilities, usually operated in adversarial settings and regulated based on estimated system states. In this study, we propose a novel highly secure distributed dynamic state estimation mechanism for wide-area (multi-area) smart grids, composed of geographically separated subregions, each supervised by a local control center. We firstly propose a distributed state estimator assuming regular system operation, that achieves near-optimal performance based on the local Kalman filters and with the exchange of necessary information between local centers. To enhance the security, we further propose to (i) protect the network database and the network communication channels against attacks and data manipulations via a blockchain (BC)-based system design, where the BC operates on the peer-to-peer network of local centers, (ii) locally detect the measurement anomalies in real-time to eliminate their effects on the state estimation process, and (iii) detect misbehaving (hacked/faulty) local centers in real-time via a distributed trust management scheme over the network. We provide theoretical guarantees regarding the false alarm rates of the proposed detection schemes, where the false alarms can be easily controlled. Numerical studies illustrate that the proposed mechanism offers reliable state estimation under regular system operation, timely and accurate detection of anomalies, and good state recovery performance in case of anomalies.",
    "lastUpdated": "2019-07-15T03:22:18Z",
    "categories": [
      "cs.CR",
      "cs.IT",
      "math.IT"
    ],
    "url": "http://arxiv.org/abs/1902.07288v2"
  },
  {
    "title": "Short Datathon for the Interdisciplinary Development of Data Analysis and Visualization Skills",
    "authors": [
      "Myrian Noguera Salinas",
      "Maria Claudia Figueiredo Pereira Emer",
      "Adolfo Gustavo Serra Seca Neto"
    ],
    "abstract": "Understanding the major fraud problems in the world and interpreting the data available for analysis is a current challenge that requires interdisciplinary knowledge to complement the knowledge of computer professionals. Collaborative events (called Hackathons, Datathons, Codefests, Hack Days, etc.) have become relevant in several fields. Examples of fields which are explored in these events include startup development, open civic innovation, corporate innovation, and social issues. These events have features that favor knowledge exchange to solve challenges. In this paper, we present an event format called Short Datathon, a Hackathon for the development of exploratory data analysis and visualization skills. Our goal is to evaluate if participating in a Short Datathon can help participants learn basic data analysis and visualization concepts. We evaluated the Short Datathon in two case studies, with a total of 20 participants, carried out at the Federal University of Technology - Paran\\'a. In both case studies we addressed the issue of tax evasion using real world data. We describe, as a result of this work, the qualitative aspects of the case studies and the perception of the participants obtained through questionnaires. Participants stated that the event helped them understand more about data analysis and visualization and that the experience with people from other areas during the event made data analysis more efficient. Further studies are necessary to evolve the format of the event and to evaluate its effectiveness.",
    "lastUpdated": "2019-03-18T16:25:19Z",
    "categories": [
      "cs.SE",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1903.07539v1"
  },
  {
    "title": "A multi-layered blockchain framework for smart mobility data-markets",
    "authors": [
      "David Lopez",
      "Bilal Farooq"
    ],
    "abstract": "Blockchain has the potential to render the transaction of information more secure and transparent. Nowadays, transportation data are shared across multiple entities using heterogeneous mediums, from paper collected data to smartphone. Most of this data are stored in central servers that are susceptible to hacks. In some cases shady actors who may have access to such sources, share the mobility data with unwanted third parties. A multi-layered Blockchain framework for Smart Mobility Data-market (BSMD) is presented for addressing the associated privacy, security, management, and scalability challenges. Each participant shares their encrypted data to the blockchain network and can transact information with other participants as long as both parties agree to the transaction rules issued by the owner of the data. Data ownership, transparency, auditability and access control are the core principles of the proposed blockchain for smart mobility data-market. In a case study of real-time mobility data sharing, we demonstrate the performance of BSMD on a 370 nodes blockchain running on heterogeneous and geographically-separated devices communicating on a physical network. We also demonstrate how BSMD ensures the cybersecurity and privacy of individual by safeguarding against spoofing and message interception attacks and providing information access management control.",
    "lastUpdated": "2020-01-22T14:37:03Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1906.06435v3"
  },
  {
    "title": "V2S attack: building DNN-based voice conversion from automatic speaker verification",
    "authors": [
      "Taiki Nakamura",
      "Yuki Saito",
      "Shinnosuke Takamichi",
      "Yusuke Ijima",
      "Hiroshi Saruwatari"
    ],
    "abstract": "This paper presents a new voice impersonation attack using voice conversion (VC). Enrolling personal voices for automatic speaker verification (ASV) offers natural and flexible biometric authentication systems. Basically, the ASV systems do not include the users' voice data. However, if the ASV system is unexpectedly exposed and hacked by a malicious attacker, there is a risk that the attacker will use VC techniques to reproduce the enrolled user's voices. We name this the ``verification-to-synthesis (V2S) attack'' and propose VC training with the ASV and pre-trained automatic speech recognition (ASR) models and without the targeted speaker's voice data. The VC model reproduces the targeted speaker's individuality by deceiving the ASV model and restores phonetic property of an input voice by matching phonetic posteriorgrams predicted by the ASR model. The experimental evaluation compares converted voices between the proposed method that does not use the targeted speaker's voice data and the standard VC that uses the data. The experimental results demonstrate that the proposed method performs comparably to the existing VC methods that trained using a very small amount of parallel voice data.",
    "lastUpdated": "2019-08-05T03:28:13Z",
    "categories": [
      "cs.SD",
      "cs.CR",
      "cs.LG",
      "eess.AS"
    ],
    "url": "http://arxiv.org/abs/1908.01454v1"
  },
  {
    "title": "Intrinsic mitigation of the after-gate attack in quantum key distribution through fast-gated delayed detection",
    "authors": [
      "Alex Koehler-Sidki",
      "James F. Dynes",
      "Amos Martinez",
      "Marco Lucamarini",
      "George L. Roberts",
      "Andrew W. Sharpe",
      "Zhiliang Yuan",
      "Andrew J. Shields"
    ],
    "abstract": "The information theoretic security promised by quantum key distribution (QKD) holds as long as the assumptions in the theoretical model match the parameters in the physical implementation. The superlinear behaviour of sensitive single-photon detectors represents one such mismatch and can pave the way to powerful attacks hindering the security of QKD systems, a prominent example being the after-gate attack. A longstanding tenet is that trapped carriers causing delayed detection can help mitigate this attack, but despite intensive scrutiny, it remains largely unproven. Here we approach this problem from a physical perspective and find new evidence to support a detector's secure response. We experimentally investigate two different carrier trapping mechanisms causing delayed detection in fast-gated semiconductor avalanche photodiodes, one arising from the multiplication layer, the other from the heterojunction interface between absorption and charge layers. The release of trapped carriers increases the quantum bit error rate measured under the after-gate attack above the typical QKD security threshold, thus favouring the detector's inherent security. This represents a significant step to avert quantum hacking of QKD systems.",
    "lastUpdated": "2019-08-28T11:10:45Z",
    "categories": [
      "quant-ph",
      "physics.ins-det",
      "physics.optics"
    ],
    "url": "http://arxiv.org/abs/1908.10643v1"
  },
  {
    "title": "HEAX: An Architecture for Computing on Encrypted Data",
    "authors": [
      "M. Sadegh Riazi",
      "Kim Laine",
      "Blake Pelton",
      "Wei Dai"
    ],
    "abstract": "With the rapid increase in cloud computing, concerns surrounding data privacy, security, and confidentiality also have been increased significantly. Not only cloud providers are susceptible to internal and external hacks, but also in some scenarios, data owners cannot outsource the computation due to privacy laws such as GDPR, HIPAA, or CCPA. Fully Homomorphic Encryption (FHE) is a groundbreaking invention in cryptography that, unlike traditional cryptosystems, enables computation on encrypted data without ever decrypting it. However, the most critical obstacle in deploying FHE at large-scale is the enormous computation overhead. In this paper, we present HEAX, a novel hardware architecture for FHE that achieves unprecedented performance improvement. HEAX leverages multiple levels of parallelism, ranging from ciphertext-level to fine-grained modular arithmetic level. Our first contribution is a new highly-parallelizable architecture for number-theoretic transform (NTT) which can be of independent interest as NTT is frequently used in many lattice-based cryptography systems. Building on top of NTT engine, we design a novel architecture for computation on homomorphically encrypted data. We also introduce several techniques to enable an end-to-end, fully pipelined design as well as reducing on-chip memory consumption. Our implementation on reconfigurable hardware demonstrates 164-268x performance improvement for a wide range of FHE parameters.",
    "lastUpdated": "2020-01-23T21:17:05Z",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.AR",
      "cs.PF"
    ],
    "url": "http://arxiv.org/abs/1909.09731v2"
  },
  {
    "title": "Modeling and Detection of Future Cyber-Enabled DSM Data Attacks using Supervised Learning",
    "authors": [
      "Kostas Hatalis",
      "Parv Venkitasubramaniam",
      "Shalinee Kishore"
    ],
    "abstract": "Demand-Side Management (DSM) is a vital tool that can be used to ensure power system reliability and stability. In future smart grids, certain portions of a customers load usage could be under automatic control with a cyber-enabled DSM program which selectively schedules loads as a function of electricity prices to improve power balance and grid stability. In such a case, the security of DSM cyberinfrastructure will be critical as advanced metering infrastructure, and communication systems are susceptible to hacking, cyber-attacks. Such attacks, in the form of data injection, can manipulate customer load profiles and cause metering chaos and energy losses in the grid. These attacks are also exacerbated by the feedback mechanism between load management on the consumer side and dynamic price schemes by independent system operators. This work provides a novel methodology for modeling and simulating the nonlinear relationship between load management and real-time pricing. We then investigate the behavior of such a feedback loop under intentional cyber-attacks using our feedback model. We simulate and examine load-price data under different levels of DSM participation with three types of additive attacks: ramp, sudden, and point attacks. We apply change point and supervised learning methods for detection of DSM attacks. Results conclude that while higher levels of DSM participation can exacerbate attacks they also lead to better detection of such attacks. Further analysis of results shows that point attacks are the hardest to detect and supervised learning methods produce results on par or better than sequential detectors.",
    "lastUpdated": "2019-09-27T20:14:47Z",
    "categories": [
      "eess.SP",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1909.12894v1"
  },
  {
    "title": "MAT: A simple yet strong baseline for identifying self-admitted technical debt",
    "authors": [
      "Zhaoqiang Guo",
      "Shiran Liu",
      "Jinping Liu",
      "Yanhui Li",
      "Lin Chen",
      "Hongmin Lu",
      "Yuming Zhou",
      "Baowen Xu"
    ],
    "abstract": "In the process of software evolution, developers often sacrifice the long-term code quality to satisfy the short-term goals due to specific reasons, which is called technical debt. In particular, self-admitted technical debt (SATD) refers to those that were intentionally introduced and remarked by code comments. Those technical debts reduce the quality of software and increase the cost of subsequent software maintenance. Therefore, it is necessary to find out and resolve these debts in time. Recently, many approaches have been proposed to identify SATD. However, those approaches either have a low accuracy or are complex to implementation in practice. In this paper, we propose a simple unsupervised baseline approach that fuzzily matches task annotation tags (MAT) to identify SATD. MAT does not need any training data to build a prediction model. Instead, MAT only examines whether any of four task tags (i.e. TODO, FIXME, XXX, and HACK) appears in the comments of a target project to identify SATD. In this sense, MAT is a natural baseline approach, which has a good understandability, in SATD identification. In order to evaluate the usefulness of MAT, we use 10 open-source projects to conduct the experiment. The experimental results reveal that MAT has a surprisingly excellent performance for SATD identification compared with the state-of-the-art approaches. As such, we suggest that, in the future SATD identification studies, MAT should be considered as an easy-to-implement baseline to which any new approach should be compared against to demonstrate its usefulness.",
    "lastUpdated": "2019-10-29T12:59:27Z",
    "categories": [
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/1910.13238v1"
  },
  {
    "title": "Learning Human Objectives by Evaluating Hypothetical Behavior",
    "authors": [
      "Siddharth Reddy",
      "Anca D. Dragan",
      "Sergey Levine",
      "Shane Legg",
      "Jan Leike"
    ],
    "abstract": "We seek to align agent behavior with a user's objectives in a reinforcement learning setting with unknown dynamics, an unknown reward function, and unknown unsafe states. The user knows the rewards and unsafe states, but querying the user is expensive. To address this challenge, we propose an algorithm that safely and interactively learns a model of the user's reward function. We start with a generative model of initial states and a forward dynamics model trained on off-policy data. Our method uses these models to synthesize hypothetical behaviors, asks the user to label the behaviors with rewards, and trains a neural network to predict the rewards. The key idea is to actively synthesize the hypothetical behaviors from scratch by maximizing tractable proxies for the value of information, without interacting with the environment. We call this method reward query synthesis via trajectory optimization (ReQueST). We evaluate ReQueST with simulated users on a state-based 2D navigation task and the image-based Car Racing video game. The results show that ReQueST significantly outperforms prior methods in learning reward models that transfer to new environments with different initial state distributions. Moreover, ReQueST safely trains the reward model to detect unsafe states, and corrects reward hacking before deploying the agent.",
    "lastUpdated": "2019-12-05T18:25:48Z",
    "categories": [
      "cs.CY",
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1912.05652v1"
  },
  {
    "title": "Random number generation & distribution out of thin (or thick) air",
    "authors": [
      "Nicholas Bornman",
      "Andrew Forbes",
      "Achim Kempf"
    ],
    "abstract": "Much scientific work has focused on the generation of random numbers as well as the distribution of said random numbers for use as a cryptographic key. However, emphasis is often placed on one of the two to the exclusion of the other, but both are often simultaneously important. Here we present a simple hybrid free-space link scheme for both the generation and secure distribution of (pseudo-)random numbers between two remote parties, drawing the randomness from the stochastic nature of atmospheric turbulence. The atmosphere is simulated using digital micro-mirror devices for efficient, all-digital control. After outlining one potential algorithm for extracting random numbers based on finding the centre-of-mass (COM) of turbulent beam intensity profiles, the statistics of our experimental COM measurements is studied and found to agree well with the literature. After implementing the scheme in the laboratory, Alice and Bob are able to establish a string of correlated random bits with an 84% fidelity. Finally, we make a simple modification to the original setup in an attempt to thwart the hacking attempts of an eavesdropper, Eve, who has access to the free-space portion of the link. We find that the fidelity between Eve's key and that of Alice/Bob is 54%, only slightly above the theoretical minimum. Atmospheric turbulence could hence be leveraged as an added security measure, rather than being seen as a drawback.",
    "lastUpdated": "2020-08-13T12:13:31Z",
    "categories": [
      "physics.class-ph",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1912.08677v2"
  },
  {
    "title": "REST: A Thread Embedding Approach for Identifying and Classifying User-specified Information in Security Forums",
    "authors": [
      "Joobin Gharibshah",
      "Evangelos E. Papalexakis",
      "Michalis Faloutsos"
    ],
    "abstract": "How can we extract useful information from a security forum? We focus on identifying threads of interest to a security professional: (a) alerts of worrisome events, such as attacks, (b) offering of malicious services and products, (c) hacking information to perform malicious acts, and (d) useful security-related experiences. The analysis of security forums is in its infancy despite several promising recent works. Novel approaches are needed to address the challenges in this domain: (a) the difficulty in specifying the \"topics\" of interest efficiently, and (b) the unstructured and informal nature of the text. We propose, REST, a systematic methodology to: (a) identify threads of interest based on a, possibly incomplete, bag of words, and (b) classify them into one of the four classes above. The key novelty of the work is a multi-step weighted embedding approach: we project words, threads and classes in appropriate embedding spaces and establish relevance and similarity there. We evaluate our method with real data from three security forums with a total of 164k posts and 21K threads. First, REST robustness to initial keyword selection can extend the user-provided keyword set and thus, it can recover from missing keywords. Second, REST categorizes the threads into the classes of interest with superior accuracy compared to five other methods: REST exhibits an accuracy between 63.3-76.9%. We see our approach as a first step for harnessing the wealth of information of online forums in a user-friendly way, since the user can loosely specify her keywords of interest.",
    "lastUpdated": "2020-03-30T19:14:16Z",
    "categories": [
      "cs.CL",
      "cs.IR"
    ],
    "url": "http://arxiv.org/abs/2001.02660v2"
  },
  {
    "title": "'I Just Want to Hack Myself to Not Get Distracted': Evaluating Design Interventions for Self-Control on Facebook",
    "authors": [
      "Ulrik Lyngs",
      "Kai Lukoff",
      "Petr Slovak",
      "William Seymour",
      "Helena Webb",
      "Marina Jirotka",
      "Jun Zhao",
      "Max Van Kleek",
      "Nigel Shadbolt"
    ],
    "abstract": "Beyond being the world's largest social network, Facebook is for many also one of its greatest sources of digital distraction. For students, problematic use has been associated with negative effects on academic achievement and general wellbeing. To understand what strategies could help users regain control, we investigated how simple interventions to the Facebook UI affect behaviour and perceived control. We assigned 58 university students to one of three interventions: goal reminders, removed newsfeed, or white background (control). We logged use for 6 weeks, applied interventions in the middle weeks, and administered fortnightly surveys. Both goal reminders and removed newsfeed helped participants stay on task and avoid distraction. However, goal reminders were often annoying, and removing the newsfeed made some fear missing out on information. Our findings point to future interventions such as controls for adjusting types and amount of available information, and flexible blocking which matches individual definitions of 'distraction'.",
    "lastUpdated": "2020-05-20T15:51:14Z",
    "categories": [
      "cs.HC",
      "H.5.2"
    ],
    "url": "http://arxiv.org/abs/2001.04180v2"
  },
  {
    "title": "Network Information Theoretic Security",
    "authors": [
      "Hongchao Zhou",
      "Abbas El Gamal"
    ],
    "abstract": "Shannon showed that to achieve perfect secrecy in point-to-point communication, the message rate cannot exceed the shared secret key rate giving rise to the simple one-time pad encryption scheme. In this paper, we extend this work from point-to-point to networks. We consider a connected network with pairwise communication between the nodes. We assume that each node is provided with a certain amount of secret bits before communication commences. An eavesdropper with unlimited computing power has access to all communication and can hack a subset of the nodes not known to the rest of the nodes. We investigate the limits on information-theoretic secure communication for this network. We establish a tradeoff between the secure channel rate (for a node pair) and the secure network rate (sum over all node pair rates) and show that perfect secrecy can be achieved if and only if the sum rate of any subset of unhacked channels does not exceed the shared unhacked-secret-bit rate of these channels. We also propose two practical and efficient schemes that achieve a good balance of network and channel rates with perfect secrecy guarantee. This work has a wide range of potential applications for which perfect secrecy is desired, such as cyber-physical systems, distributed-control systems, and ad-hoc networks.",
    "lastUpdated": "2020-05-27T18:37:52Z",
    "categories": [
      "cs.IT",
      "cs.CR",
      "math.IT"
    ],
    "url": "http://arxiv.org/abs/2001.05169v2"
  },
  {
    "title": "Reference-Frame-Independent, Measurement-Device-Independent quantum key distribution using fewer quantum states",
    "authors": [
      "Donghwa Lee",
      "Seong-Jin Hong",
      "Young-Wook Cho",
      "Hyang-Tag Lim",
      "Sang-Wook Han",
      "Hojoong Jung",
      "Sung Moon",
      "Kwangjo Lee",
      "Yong-Su Kim"
    ],
    "abstract": "Reference-Frame-Independent Quantum Key Distribution (RFI-QKD) provides a practical way to generate secret keys between two remote parties without sharing common reference frames. On the other hand, Measurement-Device-Independent QKD (MDI-QKD) offers high level of security as it immunes against all the quantum hacking attempts to the measurement devices. The combination of these two QKD protocols, i.e., RFI-MDI-QKD, is one of the most fascinating QKD protocols since it holds both advantages of practicality and security. For further practicality of RFI-MDI-QKD, it is beneficial to reduce the implementation complexity. Here, we have shown that RFI-MDI-QKD can be implemented using fewer quantum states than those of its original proposal. We found that, in principle, the number of quantum states for one of the parties can be reduced from six to three without compromising security. Comparing to the conventional RFI-MDI-QKD where both parties should transmit six quantum states, it significantly simplifies the implementation of the QKD protocol. We also verify the feasibility of the scheme with the proof-of-principle experiment.",
    "lastUpdated": "2020-05-07T02:03:12Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/2002.01601v2"
  },
  {
    "title": "AnySeq: A High Performance Sequence Alignment Library based on Partial Evaluation",
    "authors": [
      "André Müller",
      "Bertil Schmidt",
      "Andreas Hildebrandt",
      "Richard Membarth",
      "Roland Leißa",
      "Matthis Kruse",
      "Sebastian Hack"
    ],
    "abstract": "Sequence alignments are fundamental to bioinformatics which has resulted in a variety of optimized implementations. Unfortunately, the vast majority of them are hand-tuned and specific to certain architectures and execution models. This not only makes them challenging to understand and extend, but also difficult to port to other platforms. We present AnySeq - a novel library for computing different types of pairwise alignments of DNA sequences. Our approach combines high performance with an intuitively understandable implementation, which is achieved through the concept of partial evaluation. Using the AnyDSL compiler framework, AnySeq enables the compilation of algorithmic variants that are highly optimized for specific usage scenarios and hardware targets with a single, uniform codebase. The resulting domain-specific library thus allows the variation of alignment parameters (such as alignment type, scoring scheme, and traceback vs.~plain score) by simple function composition rather than metaprogramming techniques which are often hard to understand. Our implementation supports multithreading and SIMD vectorization on CPUs, CUDA-enabled GPUs, and FPGAs. AnySeq is at most 7% slower and in many cases faster (up to 12%) than state-of-the art manually optimized alignment libraries on CPUs (SeqAn) and on GPUs (NVBio).",
    "lastUpdated": "2020-02-11T17:34:12Z",
    "categories": [
      "cs.DC",
      "cs.PF"
    ],
    "url": "http://arxiv.org/abs/2002.04561v1"
  },
  {
    "title": "AnyHLS: High-Level Synthesis with Partial Evaluation",
    "authors": [
      "M. Akif Özkan",
      "Arsène Pérard-Gayot",
      "Richard Membarth",
      "Philipp Slusallek",
      "Roland Leissa",
      "Sebastian Hack",
      "Jürgen Teich",
      "Frank Hannig"
    ],
    "abstract": "FPGAs excel in low power and high throughput computations, but they are challenging to program. Traditionally, developers rely on hardware description languages like Verilog or VHDL to specify the hardware behavior at the register-transfer level. High-Level Synthesis (HLS) raises the level of abstraction, but still requires FPGA design knowledge. Programmers usually write pragma-annotated C/C++ programs to define the hardware architecture of an application. However, each hardware vendor extends its own C dialect using its own vendor-specific set of pragmas. This prevents portability across different vendors. Furthermore, pragmas are not first-class citizens in the language. This makes it hard to use them in a modular way or design proper abstractions. In this paper, we present AnyHLS, an approach to synthesize FPGA designs in a modular and abstract way. AnyHLS is able to raise the abstraction level of existing HLS tools by resorting to programming language features such as types and higher-order functions as follows: It relies on partial evaluation to specialize and to optimize the user application based on a library of abstractions. Then, vendor-specific HLS code is generated for Intel and Xilinx FPGAs. Portability is obtained by avoiding any vendor-specific pragmas at the source code. In order to validate achievable gains in productivity, a library for the domain of image processing is introduced as a case study, and its synthesis results are compared with several state-of-theart Domain-Specific Language (DSL) approaches for this domain.",
    "lastUpdated": "2020-07-21T06:03:05Z",
    "categories": [
      "cs.PL"
    ],
    "url": "http://arxiv.org/abs/2002.05796v2"
  },
  {
    "title": "Safe Imitation Learning via Fast Bayesian Reward Inference from Preferences",
    "authors": [
      "Daniel S. Brown",
      "Russell Coleman",
      "Ravi Srinivasan",
      "Scott Niekum"
    ],
    "abstract": "Bayesian reward learning from demonstrations enables rigorous safety and uncertainty analysis when performing imitation learning. However, Bayesian reward learning methods are typically computationally intractable for complex control problems. We propose Bayesian Reward Extrapolation (Bayesian REX), a highly efficient Bayesian reward learning algorithm that scales to high-dimensional imitation learning problems by pre-training a low-dimensional feature encoding via self-supervised tasks and then leveraging preferences over demonstrations to perform fast Bayesian inference. Bayesian REX can learn to play Atari games from demonstrations, without access to the game score and can generate 100,000 samples from the posterior over reward functions in only 5 minutes on a personal laptop. Bayesian REX also results in imitation learning performance that is competitive with or better than state-of-the-art methods that only learn point estimates of the reward function. Finally, Bayesian REX enables efficient high-confidence policy evaluation without having access to samples of the reward function. These high-confidence performance bounds can be used to rank the performance and risk of a variety of evaluation policies and provide a way to detect reward hacking behaviors.",
    "lastUpdated": "2020-12-17T21:48:13Z",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2002.09089v4"
  },
  {
    "title": "PMEvo: Portable Inference of Port Mappings for Out-of-Order Processors by Evolutionary Optimization",
    "authors": [
      "Fabian Ritter",
      "Sebastian Hack"
    ],
    "abstract": "Achieving peak performance in a computer system requires optimizations in every layer of the system, be it hardware or software. A detailed understanding of the underlying hardware, and especially the processor, is crucial to optimize software. One key criterion for the performance of a processor is its ability to exploit instruction-level parallelism. This ability is determined by the port mapping of the processor, which describes the execution units of the processor for each instruction. Processor manufacturers usually do not share the port mappings of their microarchitectures. While approaches to automatically infer port mappings from experiments exist, they are based on processor-specific hardware performance counters that are not available on every platform. We present PMEvo, a framework to automatically infer port mappings solely based on the measurement of the execution time of short instruction sequences. PMEvo uses an evolutionary algorithm that evaluates the fitness of candidate mappings with an analytical throughput model formulated as a linear program. Our prototype implementation infers a port mapping for Intel's Skylake architecture that predicts measured instruction throughput with an accuracy that is competitive to existing work. Furthermore, it finds port mappings for AMD's Zen+ architecture and the ARM Cortex-A72 architecture, which are out of scope of existing techniques.",
    "lastUpdated": "2020-04-21T14:34:09Z",
    "categories": [
      "cs.AR",
      "cs.PF"
    ],
    "url": "http://arxiv.org/abs/2004.10044v1"
  },
  {
    "title": "Legal Risks of Adversarial Machine Learning Research",
    "authors": [
      "Ram Shankar Siva Kumar",
      "Jonathon Penney",
      "Bruce Schneier",
      "Kendra Albert"
    ],
    "abstract": "Adversarial Machine Learning is booming with ML researchers increasingly targeting commercial ML systems such as those used in Facebook, Tesla, Microsoft, IBM, Google to demonstrate vulnerabilities. In this paper, we ask, \"What are the potential legal risks to adversarial ML researchers when they attack ML systems?\" Studying or testing the security of any operational system potentially runs afoul the Computer Fraud and Abuse Act (CFAA), the primary United States federal statute that creates liability for hacking. We claim that Adversarial ML research is likely no different. Our analysis show that because there is a split in how CFAA is interpreted, aspects of adversarial ML attacks, such as model inversion, membership inference, model stealing, reprogramming the ML system and poisoning attacks, may be sanctioned in some jurisdictions and not penalized in others. We conclude with an analysis predicting how the US Supreme Court may resolve some present inconsistencies in the CFAA's application in Van Buren v. United States, an appeal expected to be decided in 2021. We argue that the court is likely to adopt a narrow construction of the CFAA, and that this will actually lead to better adversarial ML security outcomes in the long term.",
    "lastUpdated": "2020-06-29T16:45:15Z",
    "categories": [
      "cs.CY",
      "cs.CR",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2006.16179v1"
  },
  {
    "title": "T-BFA: Targeted Bit-Flip Adversarial Weight Attack",
    "authors": [
      "Adnan Siraj Rakin",
      "Zhezhi He",
      "Jingtao Li",
      "Fan Yao",
      "Chaitali Chakrabarti",
      "Deliang Fan"
    ],
    "abstract": "Traditional Deep Neural Network (DNN) security is mostly related to the well-known adversarial input example attack. Recently, another dimension of adversarial attack, namely, attack on DNN weight parameters, has been shown to be very powerful. As a representative one, the Bit-Flip-based adversarial weight Attack (BFA) injects an extremely small amount of faults into weight parameters to hijack the executing DNN function. Prior works of BFA focus on un-targeted attack that can hack all inputs into a random output class by flipping a very small number of weight bits stored in computer memory. This paper proposes the first work of targeted BFA based (T-BFA) adversarial weight attack on DNNs, which can intentionally mislead selected inputs to a target output class. The objective is achieved by identifying the weight bits that are highly associated with classification of a targeted output through a class-dependent weight bit ranking algorithm. Our proposed T-BFA performance is successfully demonstrated on multiple DNN architectures for image classification tasks. For example, by merely flipping 27 out of 88 million weight bits of ResNet-18, our T-BFA can misclassify all the images from 'Hen' class into 'Goose' class (i.e., 100 % attack success rate) in ImageNet dataset, while maintaining 59.35 % validation accuracy. Moreover, we successfully demonstrate our T-BFA attack in a real computer prototype system running DNN computation, with Ivy Bridge-based Intel i7 CPU and 8GB DDR3 memory.",
    "lastUpdated": "2021-01-08T04:54:21Z",
    "categories": [
      "cs.LG",
      "cs.CR",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2007.12336v3"
  },
  {
    "title": "Secondary fan, theta functions and moduli of Calabi-Yau pairs",
    "authors": [
      "Paul Hacking",
      "Sean Keel",
      "Tony Yue Yu"
    ],
    "abstract": "We conjecture that any connected component $Q$ of the moduli space of triples $(X,E=E_1+\\dots+E_n,\\Theta)$ where $X$ is a smooth projective variety, $E$ is a normal crossing anti-canonical divisor with a 0-stratum, every $E_i$ is smooth, and $\\Theta$ is an ample divisor not containing any 0-stratum of $E$, is unirational. More precisely: note that $Q$ has a natural embedding into the Koll\\'ar-Shepherd-Barron-Alexeev moduli space of stable pairs, we conjecture that its closure admits a finite cover by a complete toric variety. We construct the associated complete toric fan, generalizing the Gelfand-Kapranov-Zelevinski secondary fan for reflexive polytopes. Inspired by mirror symmetry, we speculate a synthetic construction of the universal family over this toric variety, as the Proj of a sheaf of graded algebras with a canonical basis, whose structure constants are given by counts of non-archimedean analytic disks. In the Fano case and under the assumption that the mirror contains a Zariski open torus, we construct the conjectural universal family, generalizing the families of Kapranov-Sturmfels-Zelevinski and Alexeev in the toric case. In the case of del Pezzo surfaces with an anti-canonical cycle of $(-1)$-curves, we prove the full conjecture.",
    "lastUpdated": "2020-08-05T18:08:29Z",
    "categories": [
      "math.AG",
      "Primary 14J33, Secondary 14J10, 14J32, 14E30, 14G22"
    ],
    "url": "http://arxiv.org/abs/2008.02299v1"
  },
  {
    "title": "SOK: Building a Launchpad for Impactful Satellite Cyber-Security Research",
    "authors": [
      "James Pavur",
      "Ivan Martinovic"
    ],
    "abstract": "As the space industry approaches a period of rapid change, securing both emerging and legacy satellite missions will become vital. However, space technology has been largely overlooked by the systems security community. This systematization of knowledge paper seeks to understand why this is the case and to offer a starting point for technical security researchers seeking impactful contributions beyond the Earth's mesosphere. The paper begins with a cross-disciplinary synthesis of relevant threat models from a diverse array of fields, ranging from legal and policy studies to aerospace engineering. This is presented as a \"threat matrix toolbox\" which security researchers may leverage to motivate technical research into given attack vectors and defenses. We subsequently apply this model to an original chronology of more than 100 significant satellite hacking incidents spanning the previous 60 years. Together, these are used to assess the state-of-the-art in satellite security across four sub-domains: satellite radio-link security, space hardware security, ground station security, and operational/mission security. In each area, we note significant findings and unresolved questions lingering in other disciplines which the systems security community is aptly poised to tackle. By consolidating this research, we present the case that satellite systems security researchers can build on strong, but disparate, academic foundations and rise to meet an urgent need for future space missions.",
    "lastUpdated": "2020-10-21T09:58:00Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/2010.10872v1"
  },
  {
    "title": "Mitigating the Impact of Adversarial Attacks in Very Deep Networks",
    "authors": [
      "Mohammed Hassanin",
      "Ibrahim Radwan",
      "Nour Moustafa",
      "Murat Tahtali",
      "Neeraj Kumar"
    ],
    "abstract": "Deep Neural Network (DNN) models have vulnerabilities related to security concerns, with attackers usually employing complex hacking techniques to expose their structures. Data poisoning-enabled perturbation attacks are complex adversarial ones that inject false data into models. They negatively impact the learning process, with no benefit to deeper networks, as they degrade a model's accuracy and convergence rates. In this paper, we propose an attack-agnostic-based defense method for mitigating their influence. In it, a Defensive Feature Layer (DFL) is integrated with a well-known DNN architecture which assists in neutralizing the effects of illegitimate perturbation samples in the feature space. To boost the robustness and trustworthiness of this method for correctly classifying attacked input samples, we regularize the hidden space of a trained model with a discriminative loss function called Polarized Contrastive Loss (PCL). It improves discrimination among samples in different classes and maintains the resemblance of those in the same class. Also, we integrate a DFL and PCL in a compact model for defending against data poisoning attacks. This method is trained and tested using the CIFAR-10 and MNIST datasets with data poisoning-enabled perturbation attacks, with the experimental results revealing its excellent performance compared with those of recent peer techniques.",
    "lastUpdated": "2020-12-08T21:25:44Z",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2012.04750v1"
  },
  {
    "title": "Towards Secure and Leak-Free Workflows Using Microservice Isolation",
    "authors": [
      "Loïc Miller",
      "Pascal Mérindol",
      "Antoine Gallais",
      "Cristel Pelsser"
    ],
    "abstract": "Data leaks and breaches are on the rise. They result in huge losses of money for businesses like the movie industry, as well as a loss of user privacy for businesses dealing with user data like the pharmaceutical industry. Preventing data exposures is challenging, because the causes for such events are various, ranging from hacking to misconfigured databases. Alongside the surge in data exposures, the recent rise of microservices as a paradigm brings the need to not only secure traffic at the border of the network, but also internally, pressing the adoption of new security models such as zero-trust to secure business processes. Business processes can be modeled as workflows, where the owner of the data at risk interacts with contractors to realize a sequence of tasks on this data. In this paper, we show how those workflows can be enforced while preventing data exposure. Following the principles of zero-trust, we develop an infrastructure using the isolation provided by a microservice architecture, to enforce owner policy. We show that our infrastructure is resilient to the set of attacks considered in our security model. We implement a simple, yet realistic, workflow with our infrastructure in a publicly available proof of concept. We then verify that the specified policy is correctly enforced by testing the deployment for policy violations, and estimate the overhead cost of authorization.",
    "lastUpdated": "2020-12-11T13:11:20Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/2012.06300v1"
  },
  {
    "title": "Sensifi: A Wireless Sensing System for Ultra-High-Rate Applications",
    "authors": [
      "Chia-Chi Li",
      "Vikram K. Ramanna",
      "Daniel Webber",
      "Cole Hunter",
      "Tyler Hack",
      "Behnam Dezfouli"
    ],
    "abstract": "Wireless Sensor Networks (WSNs) are being used in various applications such as structural health monitoring and industrial control. Since energy efficiency is one of the major design factors, the existing WSNs primarily rely on low-power, low-rate wireless technologies such as 802.15.4 and Bluetooth. In this paper, we strive to tackle the challenges of developing ultra-high-rate WSNs based on 802.11 (WiFi) standard by proposing Sensifi. As an illustrative application of this system, we consider vibration test monitoring of spacecraft and identify system design requirements and challenges. Our main contributions are as follows. First, we propose packet encoding methods to reduce the overhead of assigning accurate timestamps to samples. Second, we propose energy efficiency methods to enhance the system's lifetime. Third, we reduce the overhead of processing outgoing packets through network stack to enhance sampling rate and mitigate sampling rate instability. Fourth, we study and reduce the delay of processing incoming packets through network stack to enhance the accuracy of time synchronization among nodes. Fifth, we propose a low-power node design for ultra-high-rate applications. Sixth, we use our node design to empirically evaluate the system.",
    "lastUpdated": "2020-12-29T07:17:38Z",
    "categories": [
      "cs.NI",
      "cs.OS",
      "cs.PF"
    ],
    "url": "http://arxiv.org/abs/2012.14635v1"
  },
  {
    "title": "Eternal Inflation",
    "authors": [
      "Alan H. Guth"
    ],
    "abstract": "The basic workings of inflationary models are summarized, along with the arguments that strongly suggest that our universe is the product of inflation. It is argued that essentially all inflationary models lead to (future-)eternal inflation, which implies that an infinite number of pocket universes are produced. Although the other pocket universes are unobservable, their existence nonetheless has consequences for the way that we evaluate theories and extract consequences from them. The question of whether the universe had a beginning is discussed but not definitively answered. It appears likely, however, that eternally inflating universes do require a beginning.",
    "lastUpdated": "2001-01-29T13:51:04Z",
    "categories": [
      "astro-ph",
      "gr-qc",
      "hep-ph"
    ],
    "url": "http://arxiv.org/abs/astro-ph/0101507v1"
  },
  {
    "title": "Emergent Probability - A directed Scale-Free Network Approach to Lonergan's Generic Model of Development",
    "authors": [
      "Michael Bretz"
    ],
    "abstract": "An intriguing heuristic model of development, decline, and change conceived by Bernard J.F. Lonergan (BL) in the late 1940's was laid out in a manner now recognizable as representing an early model of complexity. This report is a first effort toward eventually translating that qualitative vision, designated Emergent Probability, into a viable network computer program. In his study of human understanding, Lonergan saw the task of constructing a cohesive body of explanatory knowledge as a convoluted building process of schemes of recurrence that act as foundational elements to further growth. Although BL's kernal recurrent scheme was composed of the cognitional dynamics surrounding Insight, other examples abound in nature: resource cycles, motor skills, biological routines, autocatalytic processes, etc. The corresponding growing generic World Process can alternatively be thought of as chemical, environmental, evolutionary, social, organizational, economical, psychological, or ethical, and its generality might be of particular interest to complex systems researchers.",
    "lastUpdated": "2002-07-09T16:30:58Z",
    "categories": [
      "cond-mat.soft",
      "cond-mat.stat-mech"
    ],
    "url": "http://arxiv.org/abs/cond-mat/0207241v1"
  },
  {
    "title": "Complexity and Philosophy",
    "authors": [
      "Francis Heylighen",
      "Paul Cilliers",
      "Carlos Gershenson"
    ],
    "abstract": "The science of complexity is based on a new way of thinking that stands in sharp contrast to the philosophy underlying Newtonian science, which is based on reductionism, determinism, and objective knowledge. This paper reviews the historical development of this new world view, focusing on its philosophical foundations. Determinism was challenged by quantum mechanics and chaos theory. Systems theory replaced reductionism by a scientifically based holism. Cybernetics and postmodern social science showed that knowledge is intrinsically subjective. These developments are being integrated under the header of \"complexity science\". Its central paradigm is the multi-agent system. Agents are intrinsically subjective and uncertain about their environment and future, but out of their local interactions, a global organization emerges. Although different philosophers, and in particular the postmodernists, have voiced similar ideas, the paradigm of complexity still needs to be fully assimilated by philosophy. This will throw a new light on old philosophical issues such as relativism, ethics and the role of the subject.",
    "lastUpdated": "2006-04-19T11:12:38Z",
    "categories": [
      "cs.CC",
      "cond-mat.other"
    ],
    "url": "http://arxiv.org/abs/cs/0604072v1"
  },
  {
    "title": "Uncovering Plagiarism Networks",
    "authors": [
      "Manuel Freire",
      "Manuel Cebrian",
      "Emilio del Rosal"
    ],
    "abstract": "Plagiarism detection in educational programming assignments is still a problematic issue in terms of resource waste, ethical controversy, legal risks, and technical complexity. This paper presents AC, a modular plagiarism detection system. The design is portable across platforms and assignment formats and provides easy extraction into the internal assignment representation. Multiple similarity measures have been incorporated, both existing and newly-developed. Statistical analysis and several graphical visualizations aid in the interpretation of analysis results. The system has been evaluated with a survey that encompasses several academic semesters of use at the authors' institution.",
    "lastUpdated": "2011-02-14T08:56:01Z",
    "categories": [
      "cs.IT",
      "cs.SI",
      "math.IT"
    ],
    "url": "http://arxiv.org/abs/cs/0703136v7"
  },
  {
    "title": "Philosophical Implications of Inflationary Cosmology",
    "authors": [
      "Joshua Knobe",
      "Ken D. Olum",
      "Alexander Vilenkin"
    ],
    "abstract": "Recent developments in cosmology indicate that every history having a nonzero probability is realized in infinitely many distinct regions of spacetime. Thus, it appears that the universe contains infinitely many civilizations exactly like our own, as well as infinitely many civilizations that differ from our own in any way permitted by physical laws. We explore the implications of this conclusion for ethical theory and for the doomsday argument. In the infinite universe, we find that the doomsday argument applies only to effects which change the average lifetime of all civilizations, and not those which affect our civilization alone.",
    "lastUpdated": "2005-10-26T14:07:37Z",
    "categories": [
      "physics.soc-ph",
      "gr-qc",
      "physics.hist-ph"
    ],
    "url": "http://arxiv.org/abs/physics/0302071v2"
  },
  {
    "title": "The New Paradigm for Gamma Ray Bursts: a Case of Unethical Behaviour?",
    "authors": [
      "A. De Rujula"
    ],
    "abstract": "One might have hoped that the immediacy and completeness of scientific information provided through the internet would have made the wrongful appropriation of someone else's ideas --now so easy to detect and document-- a sin of the past. Not so. Here I present evidence, which the reader should judge, of such an apparent misconduct by Sir Martin Rees, the British Astronomer Royal, and others. Unethical behaviour is not unknown in science. My sole intention is to call attention to the problem by way of example, in an attempt to contribute to a more ethical atmosphere, which would in my opinion be beneficial to the field.",
    "lastUpdated": "2003-11-02T14:07:01Z",
    "categories": [
      "physics.soc-ph",
      "astro-ph"
    ],
    "url": "http://arxiv.org/abs/physics/0310134v2"
  },
  {
    "title": "Necessity of Combining Mutually Incompatible Perspectives in the Construction of a Global View: Quantum Probability and Signal Analysis",
    "authors": [
      "Sven Aerts",
      "Diederik Aerts",
      "Franklin E. Schroeck"
    ],
    "abstract": "The scientific fields of quantum mechanics and signal-analysis originated within different settings, aimed at different goals and started from different scientific paradigms. Yet the development of the two subjects has become increasingly intertwined. We argue that these similarities are rooted in the fact that both fields of scientific inquiry had to deal with finding a single description for a phenomenon that yields complete information about itself only when we consider mutually incompatible accounts of that phenomenon.",
    "lastUpdated": "2005-03-12T02:08:44Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/quant-ph/0503112v2"
  },
  {
    "title": "Aid to Percutaneous Renal Access by Virtual Projection of the Ultrasound Puncture Tract onto Fluoroscopic Images",
    "authors": [
      "Pierre Mozer",
      "Pierre Conort",
      "Antoine Leroy",
      "Michael Baumann",
      "Yohan Payan",
      "Jocelyne Troccaz",
      "Emmanuel Chartier-Kastler",
      "François Richard"
    ],
    "abstract": "Background and Purpose: Percutaneous renal access in the context of percutaneous nephrolithotomy (PCNL) is a difficult technique, requiring rapid and precise access to a particular calix. We present a computerized system designed to improve percutaneous renal access by projecting the ultrasound puncture tract onto fluoroscopic images. Materials and Methods: The system consists of a computer and a localizer allowing spatial localization of the position of the various instruments. Without any human intervention, the ultrasound nephrostomy tract is superimposed in real time onto fluoroscopic images acquired in various views. Results: We tested our approach by laboratory experiments on a phantom. Also, after approval by our institution's Ethics Committee, we validated this technique in the operating room during PCNL in one patient. Conclusion: Our system is reliable, and the absence of image-processing procedures makes it robust. We have initiated a prospective study to validate this technique both for PCNL specialists and as a learning tool.",
    "lastUpdated": "2007-05-30T15:26:56Z",
    "categories": [
      "physics.med-ph"
    ],
    "url": "http://arxiv.org/abs/0705.4412v1"
  },
  {
    "title": "Risk management for analytical methods: conciliating objectives of methods, validation phase and routine decision rules",
    "authors": [
      "Myriam Maumy",
      "B. Boulanger",
      "W. Dewe",
      "A. Gilbert",
      "B. Govaerts"
    ],
    "abstract": "In the industries that involved either chemistry or biology, such as pharmaceutical industries, chemical industries or food industry, the analytical methods are the necessary eyes and hear of all the material produced or used. If the quality of an analytical method is doubtful, then the whole set of decision that will be based on those measures is questionable. For those reasons, being able to assess the quality of an analytical method is far more than a statistical challenge; it's a matter of ethic and good business practices. Many regulatory documents have been releases, primarily ICH and FDA documents in the pharmaceutical industry (FDA, 1995, 1997, 2001) to address that issue.",
    "lastUpdated": "2007-12-31T14:05:52Z",
    "categories": [
      "stat.AP",
      "math.ST",
      "stat.TH"
    ],
    "url": "http://arxiv.org/abs/0801.0207v1"
  },
  {
    "title": "Faith in the Algorithm, Part 2: Computational Eudaemonics",
    "authors": [
      "Marko A. Rodriguez",
      "Jennifer H. Watkins"
    ],
    "abstract": "Eudaemonics is the study of the nature, causes, and conditions of human well-being. According to the ethical theory of eudaemonia, reaping satisfaction and fulfillment from life is not only a desirable end, but a moral responsibility. However, in modern society, many individuals struggle to meet this responsibility. Computational mechanisms could better enable individuals to achieve eudaemonia by yielding practical real-world systems that embody algorithms that promote human flourishing. This article presents eudaemonic systems as the evolutionary goal of the present day recommender system.",
    "lastUpdated": "2009-04-01T16:28:20Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "K.4.1; H.1.2; H.3"
    ],
    "url": "http://arxiv.org/abs/0904.0027v1"
  },
  {
    "title": "The fourth Dimension",
    "authors": [
      "Eugen Schweitzer"
    ],
    "abstract": "In different passages of his dialogues, Plato showed deep mathematically-based physical insights. Regrettably most readers overlooked the respective statements, or they utterly did not understand those hints since they were full of philological fallacious terms. Respectable translators misinterpreted such statements and therefore Plato's respective remarks were not recognized as substantial knowledge. Furthermore, Plato often supplemented such basic remarks by diffusely veiled and varied allusions that were often ironically hidden somewhere in his dialogues by inconspicuous double meanings. However, this mode of intentionally coded discrete communication was generally not understood because such irony is not to everyone's taste. However, the attempts to reconstruct Plato's system on the basis of admittedly individually interpreted double meanings lead to a conclusive mathematical-physical cyclical system of dimensions. Additionally it was possible to assign Plato's system of philosophical ideas analogously to this cyclical system. Plato took the verifiability of the mathematical-physical results as proof of the system of his ideas and finally as proof of his ethical creed, the unconditional trust in the 'all surmounting Good.'",
    "lastUpdated": "2009-06-13T14:35:39Z",
    "categories": [
      "physics.gen-ph",
      "physics.hist-ph"
    ],
    "url": "http://arxiv.org/abs/0905.3048v2"
  },
  {
    "title": "Why the paper CERN-PH-EP-2009-015 (arXiv:0903.4762) is scientifically unacceptable",
    "authors": [
      "The HARP-CDP group",
      ":",
      "A. Bolshakova",
      "I. Boyko",
      "G. Chelkov",
      "D. Dedovitch",
      "A. Elagin",
      "M. Gostkin",
      "A. Guskov",
      "Z. Kroumchtein",
      "Yu. Nefedov",
      "K. Nikolaev",
      "A. Zhemchugov",
      "F. Dydak",
      "J. Wotschack",
      "A. De Min",
      "V. Ammosov",
      "V. Gapienko",
      "V. Koreshev",
      "A. Semak",
      "Yu. Sviridov",
      "E. Usenko",
      "V. Zaets"
    ],
    "abstract": "The paper CERN-PH-EP-2009-015 (arXiv:0903.4762) by A. Bagulya et al. violates standards of quality of work and scientific ethics on several counts. The paper contains assertions that contradict established detector physics. The paper falls short of proving the correctness of the authors' concepts and results. The paper ignores or quotes misleadingly pertinent published work. The paper ignores the fact that the authors' concepts and results have already been shown wrong in the published literature. The authors seem unaware that cross-section results from the 'HARP Collaboration' that are based on the paper's concepts and algorithms are in gross disagreement with the results of a second analysis of the same data, and with the results of other experiments.",
    "lastUpdated": "2009-09-15T08:37:07Z",
    "categories": [
      "physics.ins-det"
    ],
    "url": "http://arxiv.org/abs/0909.2745v1"
  },
  {
    "title": "Work on the Manhattan Project, Subsequent Events, and Little Known Facts Related to its Use",
    "authors": [
      "Lawrence S. Bartell"
    ],
    "abstract": "A personal account of work on the Manhattan Project in Chicago by one of the few remaining survivors of the war-time project is given, illustrating, among other things, how absurd things can happen at a time of great stress and concern.. As is well known, Los Alamos was the site specializing in the physics of the bomb while Chicago emphasized metallurgical and chemical research. Nevertheless, physics played a significant role in Chicago, as well. That is where Fermi constructed the worlds first uranium pile under the stands of Stagg field, a site at which this author got seriously irradiated. Some curious events occurring after the bomb was dropped are also related. In addition, at this time of public protest by sincere people who question the ethics of America for dropping the bomb on innocent civilians, certain facts, obviously unknown to the protesters, are presented which place the bombing in a rather different light.",
    "lastUpdated": "2009-11-20T17:26:51Z",
    "categories": [
      "physics.hist-ph"
    ],
    "url": "http://arxiv.org/abs/0911.4088v1"
  },
  {
    "title": "Ethics Understanding of Software Professional In Risk Reducing Reusability Coding Using Inclusion Set Theory",
    "authors": [
      "G. Singaravel",
      "Dr. V. Palanisamy",
      "Dr. A. Krishnan"
    ],
    "abstract": "The technical skill or ability of an individual is different to person in software developments of projects. So, it is necessary to identify the talent and attitude of an individual contribution can be uniformly distributed to the different phases of software development cycle. The line of code analysis metrics to understanding the various skills of the programmers in code development. By using the inclusion set theory of n (AUB) refer to strength and risk free code developed from union of software professionals and system must comprise of achievement of the system goal, effective memory utilization and intime delivery of the product.",
    "lastUpdated": "2009-12-05T05:49:57Z",
    "categories": [
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/0912.0982v1"
  },
  {
    "title": "Biomimetic Nanotechnology: A Powerful Means to address Global Challenges",
    "authors": [
      "Ille C. Gebeshuber",
      "Burhanuddin Y. Majlis"
    ],
    "abstract": "Biomimetic nanotechnology is a prominent research area at the meeting place of life sciences with engineering and physics: it is a continuously growing field that deals with knowledge transfer from biology to nanotechnology. Biomimetic nanotechnology is a field that has the potential to substantially support successful mastering of major global challenges. The Millennium Project was commissioned by the United Nations Secretary-General in 2002 to develop a concrete action plan for the world to reverse the grinding poverty, hunger and disease affecting billions of people. It states 15 Global Challenges: sustainable development, water, population and resources, democratization, long-term perspectives, information technology, the rich-poor gap, health, capacity to decide, peace and conflict, status of women, transnational crime, energy, science and technology and global ethics. The possible contributions to master these challenges with the help of biomimetic nanotechnology will be discussed in detail.",
    "lastUpdated": "2010-01-19T14:49:44Z",
    "categories": [
      "physics.bio-ph",
      "physics.soc-ph"
    ],
    "url": "http://arxiv.org/abs/1001.3319v1"
  },
  {
    "title": "ICT's role in e-Governance in India and Malaysia: A Review",
    "authors": [
      "Ganesh Ch Deka",
      "Jasni Mohamad Zain",
      "Prabhat Mahanti"
    ],
    "abstract": "Information and Communication Technologies (ICTs) play a key role in Development & Economic growth of the Developing countries of the World. Political, Cultural, Socio-economic Developmental & Behavioral decisions today rests on the ability to access, gather, analyze and utilize Information and Knowledge. Government of India is having an ambitious objective of transforming the citizen-government interaction at all levels to by the electronic mode by 2020.Similarly according to the Vision 2020-The Way Forward presented by His Excellency YAB Dato' Seri Dr Mahathir Mohamad at the Malaysian Business Council \"By the year 2020, Malaysia can be a united nation, with a confident Malaysian society, infused by strong moral and ethical values, living in a society that is democratic, liberal and tolerant, caring, economically just and equitable, progressive and prosperous, and in full possession of an economy that is competitive, dynamic, robust and resilient\". This paper presents a comparative study and review relating to e-Governance and application of ICT development between India & Malaysia.",
    "lastUpdated": "2012-03-29T07:41:54Z",
    "categories": [
      "cs.OH"
    ],
    "url": "http://arxiv.org/abs/1206.0681v1"
  },
  {
    "title": "The Process of Mobile Spectrum Allocation and its impact on Electronic Commerce and Mobile Commerce",
    "authors": [
      "Dr. Nour El-kadri",
      "Julia Ricketti",
      "Raja Pethanasamy",
      "Sowmyan Jegatheesan"
    ],
    "abstract": "Spectrum being a very scarce natural resource of a country has to be judicially used for the purpose of nation building and the allocation process to telecom operators should be very transparent and ethical. There are various ways of how spectrum can be allocated and there is no best way that can be adopted universally. The market situation, Government policies, competition etc determine the price of the spectrum and this is purely a regulatory or a government decision to sell spectrum to telecom companies. The different allocation methods, their implications with case studies across the globe is analysed and presented in this paper. The reason why spectrum allocation should be fair and transparent and the cost should be reasonable is analysed and described.",
    "lastUpdated": "2015-06-03T02:07:51Z",
    "categories": [
      "cs.CY",
      "cs.GT"
    ],
    "url": "http://arxiv.org/abs/1305.4632v3"
  },
  {
    "title": "Questions related to Bitcoin and other Informational Money",
    "authors": [
      "Jan A. Bergstra",
      "Karl de Leeuw"
    ],
    "abstract": "A collection of questions about Bitcoin and its hypothetical relatives Bitguilder and Bitpenny is formulated. These questions concern technical issues about protocols, security issues, issues about the formalizations of informational monies in various contexts, and issues about forms of use and misuse. Some questions are formulated in the more general setting of informational monies and near-monies. We also formulate questions about legal, psychological, and ethical aspects of informational money. Finally we formulate a number of questions concerning the economical merits of and outlooks for Bitcoin.",
    "lastUpdated": "2013-12-26T20:42:45Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1305.5956v2"
  },
  {
    "title": "New Index for Quantifying an Individual's Scientific Research Output",
    "authors": [
      "Mahmoud Abdel-Aty"
    ],
    "abstract": "Classifying researchers according to the quality of their published work rather than the quantity is a curtail issue. We attempt to introduce a new formula of the percentage range to be used for evaluating qualitatively the researchers' production. The suggested equation depends on the number of the single-author published papers and their citations to be added as a new factor to the known h-index. These factors give an advantage and make a clear evidence of innovative authors and reduce the known h-index for authors who are gaining citations by adding their names to multi-author papers. It is shown that various dimensions of ethical integrity and originality will be effective in this new index. An important scenario arising from the analysis is shown in terms of examples. It refers to larger differences between the h- and the new index which comes from the whole work and the one comes from the single-author papers only, is shown.",
    "lastUpdated": "2013-05-26T14:12:43Z",
    "categories": [
      "cs.DL"
    ],
    "url": "http://arxiv.org/abs/1305.6026v1"
  },
  {
    "title": "The Skin In The Game Heuristic for Protection Against Tail Events",
    "authors": [
      "Nassim N. Taleb",
      "Constantine Sandis"
    ],
    "abstract": "Standard economic theory makes an allowance for the agency problem, but not the compounding of moral hazard in the presence of informational opacity, particularly in what concerns high-impact events in fat tailed domains (under slow convergence for the law of large numbers). Nor did it look at exposure as a filter that removes nefarious risk takers from the system so they stop harming others. \\textcolor{red}{ (In the language of probability, skin in the game creates an absorbing state for the agent, not just the principal)}. But the ancients did; so did many aspects of moral philosophy. We propose a global and morally mandatory heuristic that anyone involved in an action which can possibly generate harm for others, even probabilistically, should be required to be exposed to some damage, regardless of context. While perhaps not sufficient, the heuristic is certainly necessary hence mandatory. It is supposed to counter voluntary and involuntary risk hiding$-$ and risk transfer $-$ in the tails. We link the rule to various philosophical approaches to ethics and moral luck.",
    "lastUpdated": "2014-01-11T11:28:33Z",
    "categories": [
      "q-fin.RM",
      "q-fin.GN"
    ],
    "url": "http://arxiv.org/abs/1308.0958v3"
  },
  {
    "title": "Conscript Your Friends into Larger Anonymity Sets with JavaScript",
    "authors": [
      "Henry Corrigan-Gibbs",
      "Bryan Ford"
    ],
    "abstract": "We present the design and prototype implementation of ConScript, a framework for using JavaScript to allow casual Web users to participate in an anonymous communication system. When a Web user visits a cooperative Web site, the site serves a JavaScript application that instructs the browser to create and submit \"dummy\" messages into the anonymity system. Users who want to send non-dummy messages through the anonymity system use a browser plug-in to replace these dummy messages with real messages. Creating such conscripted anonymity sets can increase the anonymity set size available to users of remailer, e-voting, and verifiable shuffle-style anonymity systems. We outline ConScript's architecture, we address a number of potential attacks against ConScript, and we discuss the ethical issues related to deploying such a system. Our implementation results demonstrate the practicality of ConScript: a workstation running our ConScript prototype JavaScript client generates a dummy message for a mix-net in 81 milliseconds and it generates a dummy message for a DoS-resistant DC-net in 156 milliseconds.",
    "lastUpdated": "2013-09-04T10:07:34Z",
    "categories": [
      "cs.CR",
      "K.4.1; C.2.0"
    ],
    "url": "http://arxiv.org/abs/1309.0958v1"
  },
  {
    "title": "Enhancing Template Security of Face Biometrics by Using Edge Detection and Hashing",
    "authors": [
      "Manoj Krishnaswamy",
      "G. Hemantha Kumar"
    ],
    "abstract": "In this paper we address the issues of using edge detection techniques on facial images to produce cancellable biometric templates and a novel method for template verification against tampering. With increasing use of biometrics, there is a real threat for the conventional systems using face databases, which store images of users in raw and unaltered form. If compromised not only it is irrevocable, but can be misused for cross-matching across different databases. So it is desirable to generate and store revocable templates for the same user in different applications to prevent cross-matching and to enhance security, while maintaining privacy and ethics. By comparing different edge detection methods it has been observed that the edge detection based on the Roberts Cross operator performs consistently well across multiple face datasets, in which the face images have been taken under a variety of conditions. We have proposed a novel scheme using hashing, for extra verification, in order to harden the security of the stored biometric templates.",
    "lastUpdated": "2014-01-22T11:50:08Z",
    "categories": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1401.5632v1"
  },
  {
    "title": "Post-Westgate SWAT : C4ISTAR Architectural Framework for Autonomous Network Integrated Multifaceted Warfighting Solutions Version 1.0 : A Peer-Reviewed Monograph",
    "authors": [
      "Nyagudi Musandu Nyagudi"
    ],
    "abstract": "Police SWAT teams and Military Special Forces face mounting pressure and challenges from adversaries that can only be resolved by way of ever more sophisticated inputs into tactical operations. Lethal Autonomy provides constrained military/security forces with a viable option, but only if implementation has got proper empirically supported foundations. Autonomous weapon systems can be designed and developed to conduct ground, air and naval operations. This monograph offers some insights into the challenges of developing legal, reliable and ethical forms of autonomous weapons, that address the gap between Police or Law Enforcement and Military operations that is growing exponentially small. National adversaries are today in many instances hybrid threats, that manifest criminal and military traits, these often require deployment of hybrid-capability autonomous weapons imbued with the capability to taken on both Military and/or Security objectives. The Westgate Terrorist Attack of 21st September 2013 in the Westlands suburb of Nairobi, Kenya is a very clear manifestation of the hybrid combat scenario that required military response and police investigations against a fighting cell of the Somalia based globally networked Al Shabaab terrorist group.",
    "lastUpdated": "2014-01-27T09:47:05Z",
    "categories": [
      "cs.CR",
      "68-68",
      "I.2.9"
    ],
    "url": "http://arxiv.org/abs/1401.6379v2"
  },
  {
    "title": "Quantitative patterns in drone wars",
    "authors": [
      "Javier Garcia-Bernardo",
      "Peter Sheridan Dodds",
      "Neil F. Johnson"
    ],
    "abstract": "Attacks by drones (i.e., unmanned combat air vehicles) continue to generate heated political and ethical debates. Here we examine the quantitative nature of drone attacks, focusing on how their intensity and frequency compare with that of other forms of human conflict. Instead of the power-law distribution found recently for insurgent and terrorist attacks, the severity of attacks is more akin to lognormal and exponential distributions, suggesting that the dynamics underlying drone attacks lie beyond these other forms of human conflict. We find that the pattern in the timing of attacks is consistent with one side having almost complete control, an important if expected result. We show that these novel features can be reproduced and understood using a generative mathematical model in which resource allocation to the dominant side is regulated through a feedback loop.",
    "lastUpdated": "2015-10-10T18:10:51Z",
    "categories": [
      "physics.soc-ph"
    ],
    "url": "http://arxiv.org/abs/1407.3999v5"
  },
  {
    "title": "Spreading of intolerance under economic stress: results from a model with reputation",
    "authors": [
      "Luis A. Martinez-Vaquero",
      "José A. Cuesta"
    ],
    "abstract": "When a population is engaged in successive prisoner's dilemmas, indirect reciprocity through reputation fosters cooperation through the emergence of moral and action rules. A simplified model has recently been proposed where individuals choose between helping or not others, and are judged good or bad for it by the rest of the population. The reputation so acquired will condition future actions. In this model, eight strategies (referred to as 'leading eight') enforce a high level of cooperation, generate high payoffs and are therefore resistant to invasions by other strategies. Here we show that, by assigning each individual one out of two labels that peers can distinguish (e.g., political ideas, religion, skin colour...) and allowing moral and action rules to depend on the label, intolerant behaviours can emerge within minorities under sufficient economic stress. We analyse the sets of conditions where this can happen and also discuss the circumstances under which tolerance can be restored. Our results agree with empirical observations that correlate intolerance and economic stress, and predict a correlation between the degree of tolerance of a population and its composition and ethical stance.",
    "lastUpdated": "2014-07-21T15:10:10Z",
    "categories": [
      "physics.soc-ph",
      "q-bio.PE"
    ],
    "url": "http://arxiv.org/abs/1407.5521v1"
  },
  {
    "title": "Hierarchical causality in financial economics",
    "authors": [
      "Diane Wilcox",
      "Tim Gebbie"
    ],
    "abstract": "Hierarchical analysis is considered and a multilevel model is presented in order to explore causality, chance and complexity in financial economics. A coupled system of models is used to describe multilevel interactions, consistent with market data: the lowest level is occupied by agents generating the prices of individual traded assets; the next level entails aggregation of stocks into markets; the third level combines shared risk factors with information variables and bottom-up, agent-generated structure, consistent with conditions for no-arbitrage pricing theory; the fourth level describes market factors which originate in the greater economy and the highest levels are described by regulated market structure and the customs and ethics which define the nature of acceptable transactions. A mechanism for emergence or innovation is considered and causal sources are discussed in terms of five causation classes.",
    "lastUpdated": "2014-09-26T04:11:39Z",
    "categories": [
      "q-fin.GN"
    ],
    "url": "http://arxiv.org/abs/1408.5585v2"
  },
  {
    "title": "Multiple imputation for sharing precise geographies in public use data",
    "authors": [
      "Hao Wang",
      "Jerome P. Reiter"
    ],
    "abstract": "When releasing data to the public, data stewards are ethically and often legally obligated to protect the confidentiality of data subjects' identities and sensitive attributes. They also strive to release data that are informative for a wide range of secondary analyses. Achieving both objectives is particularly challenging when data stewards seek to release highly resolved geographical information. We present an approach for protecting the confidentiality of data with geographic identifiers based on multiple imputation. The basic idea is to convert geography to latitude and longitude, estimate a bivariate response model conditional on attributes, and simulate new latitude and longitude values from these models. We illustrate the proposed methods using data describing causes of death in Durham, North Carolina. In the context of the application, we present a straightforward tool for generating simulated geographies and attributes based on regression trees, and we present methods for assessing disclosure risks with such simulated data.",
    "lastUpdated": "2012-03-19T14:42:41Z",
    "categories": [
      "stat.AP"
    ],
    "url": "http://arxiv.org/abs/1203.4122v1"
  },
  {
    "title": "Combining Probabilistic, Causal, and Normative Reasoning in CP-logic",
    "authors": [
      "Sander Beckers",
      "Joost Vennekens"
    ],
    "abstract": "In recent years the search for a proper formal definition of actual causation -- i.e., the relation of cause-effect as it is instantiated in specific observations, rather than general causal relations -- has taken on impressive proportions. In part this is due to the insight that this concept plays a fundamental role in many different fields, such as legal theory, engineering, medicine, ethics, etc. Because of this diversity in applications, some researchers have shifted focus from a single idealized definition towards a more pragmatic, context-based account. For instance, recent work by Halpern and Hitchcock draws on empirical research regarding people's causal judgments, to suggest a graded and context-sensitive notion of causation. Although we sympathize with many of their observations, their restriction to a merely qualitative ordering runs into trouble for more complex examples. Therefore we aim to improve on their approach, by using the formal language of CP-logic (Causal Probabilistic logic), and the framework for defining actual causation that was developed by the current authors using it. First we rephrase their ideas into our quantitative, probabilistic setting, after which we modify it to accommodate a greater class of examples. Further, we introduce a formal distinction between statistical and normative considerations.",
    "lastUpdated": "2015-03-03T18:50:40Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1503.01051v1"
  },
  {
    "title": "Prisoner's Dilemma with Semi-synchronous Updates: Evidence for a First Order Phase Transition",
    "authors": [
      "M Ali Saif",
      "P. M. Gade"
    ],
    "abstract": "Emergence of cooperation in self-centered individuals has been a major puzzle in the study of evolutionary ethics. Reciprocal altruism is one of explanations put forward and prisoner's dilemma has been a paradigm in this context. Emergence of cooperation was demonstrated for prisoner's dilemma on a lattice with synchronous update [Nature, 359, 826 (1992)]. However, the cooperation disappeared for asynchronous update and the general validity of the conclusions was questioned [PNAS, 90, 7716 (1993)]. Neither synchronous nor asynchronous updates are realistic for natural systems. In this paper, we make a detailed study of more realistic system of semi-synchronous updates where pN agents are updated at every time instant. We observe a transition from all-defector state to a mixed state as a function of p. Despite being transition from absorbing state, our studies indicate that it is a first order transition. Furthermore, we used damage spreading technique to demonstrate that, the transition in this system could be classified as a frozen-chaotic transition.",
    "lastUpdated": "2009-10-06T09:40:15Z",
    "categories": [
      "cond-mat.stat-mech",
      "physics.soc-ph"
    ],
    "url": "http://arxiv.org/abs/0910.0961v1"
  },
  {
    "title": "Applications of Algorithmic Probability to the Philosophy of Mind",
    "authors": [
      "Gabriel Leuenberger"
    ],
    "abstract": "This paper presents formulae that can solve various seemingly hopeless philosophical conundrums. We discuss the simulation argument, teleportation, mind-uploading, the rationality of utilitarianism, and the ethics of exploiting artificial general intelligence. Our approach arises from combining the essential ideas of formalisms such as algorithmic probability, the universal intelligence measure, space-time-embedded intelligence, and Hutter's observer localization. We argue that such universal models can yield the ultimate solutions, but a novel research direction would be required in order to find computationally efficient approximations thereof.",
    "lastUpdated": "2017-01-05T16:51:55Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1404.1718v8"
  },
  {
    "title": "Opportunities and challenges of mobile learning for promoting mathematical literacy",
    "authors": [
      "Zaenal Abidin",
      "Anuradha Mathrani",
      "David Parsons",
      "Suriadi Suriadi"
    ],
    "abstract": "Mathematical literacy plays an important role in supporting individuals to fulfil their professional roles in modern society. The affordances of mobile technologies as well as the emergence of new theories in mobile learning have the potential to promote mathematical literacy. However, implementation of mobile learning in Indonesian society faces challenges related to perceived ethical and learning issues in curriculum-based educational settings. This study aims to investigate the preparedness of teachers in integrating mathematics subject content with mobile technologies, especially in promoting mathematical literacy. An exploratory study has been conducted using mixed methods by performing questionnaire survey and semi-structured interviews to understand teacher's knowledge towards mathematical literacy and identifying opportunities and challenges of mobile learning within instruction. Findings indicate that teachers mostly do not know about mathematical literacy, indicating that the concept of mathematical literacy needs to be promoted. Further, most schools prohibit the use of mobile devices in classrooms as they are wary of inappropriate use of mobile devices which may harm students' mental health and distract them from learning. Study finds this to be the most common cause for teachers' reluctance in using mobile learning.",
    "lastUpdated": "2016-06-08T10:32:51Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1606.02497v1"
  },
  {
    "title": "What is Science?",
    "authors": [
      "P C Hohenberg"
    ],
    "abstract": "This paper proposes a new definition of science based on the distinction between the activity of scientists and the product of that activity: the former is denoted (lower-case) science and the latter (upper-case) Science. These definitions are intended to clarify the nature of scientific knowledge, its authority as well as its limitations, and how scientific knowledge differs from other forms of human knowledge. The body of knowledge we call Science is exemplified by elementary arithmetic: it has the following properties: (i) Science is collective, public knowledge; (ii) Science is universal and free of contradiction; (iii) Science emerges from science; (iv) Science is nevertheless bathed in ignorance and subject to change. These properties imply that many questions that are of great interest to humanity are out of reach to Science, since they necessarily involve individual and group commitments and beliefs. Examples are questions of ethics, religion, politics, art and even technology, for which diversity is a fundamental virtue.",
    "lastUpdated": "2017-04-05T19:05:04Z",
    "categories": [
      "physics.hist-ph"
    ],
    "url": "http://arxiv.org/abs/1704.01614v1"
  },
  {
    "title": "The Chills and Thrills of Whole Genome Sequencing",
    "authors": [
      "Erman Ayday",
      "Emiliano De Cristofaro",
      "Jean-Pierre Hubaux",
      "Gene Tsudik"
    ],
    "abstract": "In recent years, Whole Genome Sequencing (WGS) evolved from a futuristic-sounding research project to an increasingly affordable technology for determining complete genome sequences of complex organisms, including humans. This prompts a wide range of revolutionary applications, as WGS promises to improve modern healthcare and provide a better understanding of the human genome -- in particular, its relation to diseases and response to treatments. However, this progress raises worrisome privacy and ethical issues, since, besides uniquely identifying its owner, the genome contains a treasure trove of highly personal and sensitive information. In this article, after summarizing recent advances in genomics, we discuss some important privacy issues associated with human genomic information and identify a number of particularly relevant research challenges.",
    "lastUpdated": "2015-02-16T17:36:21Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1306.1264v5"
  },
  {
    "title": "Societal, Economic, Ethical and Legal Challenges of the Digital Revolution: From Big Data to Deep Learning, Artificial Intelligence, and Manipulative Technologies",
    "authors": [
      "Dirk Helbing"
    ],
    "abstract": "In the wake of the on-going digital revolution, we will see a dramatic transformation of our economy and most of our societal institutions. While the benefits of this transformation can be massive, there are also tremendous risks to our society. After the automation of many production processes and the creation of self-driving vehicles, the automation of society is next. This is moving us to a tipping point and to a crossroads: we must decide between a society in which the actions are determined in a top-down way and then implemented by coercion or manipulative technologies (such as personalized ads and nudging) or a society, in which decisions are taken in a free and participatory way and mutually coordinated. Modern information and communication systems (ICT) enable both, but the latter has economic and strategic benefits. The fundaments of human dignity, autonomous decision-making, and democracies are shaking, but I believe that they need to be vigorously defended, as they are not only core principles of livable societies, but also the basis of greater efficiency and success.",
    "lastUpdated": "2015-04-15T00:31:39Z",
    "categories": [
      "cs.CY",
      "physics.soc-ph"
    ],
    "url": "http://arxiv.org/abs/1504.03751v1"
  },
  {
    "title": "A legal perspective of E-business and E-marketing for small and medium enterprises",
    "authors": [
      "Muneeb Iqbal",
      "Atif Ali Khan",
      "Oumair Naseer"
    ],
    "abstract": "Electronic businesses are witnessing enormous growth as more and more people are switching to online platforms. The widespread use of Internet has opened new channels to operate trade for many businesses. Also electronic marketing has become a proven channel of passing on the word to the customers. Legal and ethical issues quickly become an area of concern. In this research recommendations are made to harmonize IT and Internet Laws. A novel approach is proposed to promote legal risk management culture in organizations. It begins with revising current state of regulations surrounding eBusinesses and electronic marketing. The proposed approach offers risk management by considering risk mitigation strategy, educating people and use of information technology. Monitoring compliance requirements are met by reviewing the latest changes in regulations and rewarding the employees who ensures the successful implementation of the strategy.",
    "lastUpdated": "2013-03-07T14:44:44Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1303.2675v1"
  },
  {
    "title": "A Study Of Cyber Security Challenges And Its Emerging Trends On Latest Technologies",
    "authors": [
      "G. Nikhita Reddy",
      "G. J. Ugander Reddy"
    ],
    "abstract": "Cyber Security plays an important role in the field of information technology .Securing the information have become one of the biggest challenges in the present day. When ever we think about the cyber security the first thing that comes to our mind is cyber crimes which are increasing immensely day by day. Various Governments and companies are taking many measures in order to prevent these cyber crimes. Besides various measures cyber security is still a very big concern to many. This paper mainly focuses on challenges faced by cyber security on the latest technologies .It also focuses on latest about the cyber security techniques, ethics and the trends changing the face of cyber security.",
    "lastUpdated": "2014-02-08T12:00:10Z",
    "categories": [
      "cs.CR",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1402.1842v1"
  },
  {
    "title": "Characterizing the Demographics Behind the #BlackLivesMatter Movement",
    "authors": [
      "Alexandra Olteanu",
      "Ingmar Weber",
      "Daniel Gatica-Perez"
    ],
    "abstract": "The debates on minority issues are often dominated by or held among the concerned minority: gender equality debates have often failed to engage men, while those about race fail to effectively engage the dominant group. To test this observation, we study the #BlackLivesMatter}movement and hashtag on Twitter--which has emerged and gained traction after a series of events typically involving the death of African-Americans as a result of police brutality--and aim to quantify the population biases across user types (individuals vs. organizations), and (for individuals) across various demographics factors (race, gender and age). Our results suggest that more African-Americans engage with the hashtag, and that they are also more active than other demographic groups. We also discuss ethical caveats with broader implications for studies on sensitive topics (e.g. discrimination, mental health, or religion) that focus on users.",
    "lastUpdated": "2015-12-17T16:57:33Z",
    "categories": [
      "cs.SI",
      "K.4.2; H.3.5"
    ],
    "url": "http://arxiv.org/abs/1512.05671v1"
  },
  {
    "title": "Modeling Progress in AI",
    "authors": [
      "Miles Brundage"
    ],
    "abstract": "Participants in recent discussions of AI-related issues ranging from intelligence explosion to technological unemployment have made diverse claims about the nature, pace, and drivers of progress in AI. However, these theories are rarely specified in enough detail to enable systematic evaluation of their assumptions or to extrapolate progress quantitatively, as is often done with some success in other technological domains. After reviewing relevant literatures and justifying the need for more rigorous modeling of AI progress, this paper contributes to that research program by suggesting ways to account for the relationship between hardware speed increases and algorithmic improvements in AI, the role of human inputs in enabling AI capabilities, and the relationships between different sub-fields of AI. It then outlines ways of tailoring AI progress models to generate insights on the specific issue of technological unemployment, and outlines future directions for research on AI progress.",
    "lastUpdated": "2015-12-18T04:17:39Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1512.05849v1"
  },
  {
    "title": "In The Wild Residual Data Research and Privacy",
    "authors": [
      "William Bradley Glisson",
      "Tim Storer",
      "Andrew Blyth",
      "George Grispos",
      "Matt Campbell"
    ],
    "abstract": "As the world becomes increasingly dependent on technology, researchers in both industry and academia endeavor to understand how technology is used, the impact it has on everyday life, the artifact life-cycle and overall integrations of digital information. In doing so, researchers are increasingly gathering 'real-world' or 'in-the-wild' residual data, obtained from a variety of sources, without the explicit consent of the original owners. This data gathering raises significant concerns regarding privacy, ethics and legislation, as well as practical considerations concerning investigator training, data storage, overall security and data disposal. This research surveys recent studies of residual data gathered in-the-wild and analyzes the challenges that were confronted. Amalgamating these insights, the research presents a compendium of practices for addressing the issues that can arise in-the-wild when conducting residual data research. The practices identified in this research can be used to critique current projects and assess the feasibility of proposed future research.",
    "lastUpdated": "2016-10-11T08:09:56Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1610.03229v1"
  },
  {
    "title": "Mind Control as a Guide for the Mind",
    "authors": [
      "John D. Medaglia",
      "Perry Zurn",
      "Walter Sinnott-Armstrong",
      "Danielle S. Bassett"
    ],
    "abstract": "The human brain is a complex network that supports mental function. The nascent field of network neuroscience applies tools from mathematics to neuroimaging data in the hopes of shedding light on cognitive function. A critical question arising from these empirical studies is how to modulate a human brain network to treat cognitive deficits or enhance mental abilities. While historically a number of tools have been employed to modulate mental states (such as cognitive behavioral therapy and brain stimulation), theoretical frameworks to guide these interventions - and to optimize them for clinical use - are fundamentally lacking. One promising and as-yet underexplored approach lies in a sub-discipline of engineering known as network control theory. Here, we posit that network control fundamentally relates to mind control, and that this relationship highlights important areas for future empirical research and opportunities to translate knowledge in practical domains. We clarify the conceptual intersection between neuroanatomy, cognition, and control engineering in the context of network neuroscience. Finally, we discuss the challenges, ethics, and promises of mind control.",
    "lastUpdated": "2017-04-25T17:49:25Z",
    "categories": [
      "q-bio.NC"
    ],
    "url": "http://arxiv.org/abs/1610.04134v2"
  },
  {
    "title": "Decision Tree Classification on Outsourced Data",
    "authors": [
      "Koray Mancuhan",
      "Chris Clifton"
    ],
    "abstract": "This paper proposes a client-server decision tree learning method for outsourced private data. The privacy model is anatomization/fragmentation: the server sees data values, but the link between sensitive and identifying information is encrypted with a key known only to clients. Clients have limited processing and storage capability. Both sensitive and identifying information thus are stored on the server. The approach presented also retains most processing at the server, and client-side processing is amortized over predictions made by the clients. Experiments on various datasets show that the method produces decision trees approaching the accuracy of a non-private decision tree, while substantially reducing the client's computing resource requirements.",
    "lastUpdated": "2016-10-18T20:49:21Z",
    "categories": [
      "cs.LG",
      "cs.CR",
      "cs.DB",
      "H.2.8; H.2.7"
    ],
    "url": "http://arxiv.org/abs/1610.05796v1"
  },
  {
    "title": "Virtual Embodiment: A Scalable Long-Term Strategy for Artificial Intelligence Research",
    "authors": [
      "Douwe Kiela",
      "Luana Bulat",
      "Anita L. Vero",
      "Stephen Clark"
    ],
    "abstract": "Meaning has been called the \"holy grail\" of a variety of scientific disciplines, ranging from linguistics to philosophy, psychology and the neurosciences. The field of Artifical Intelligence (AI) is very much a part of that list: the development of sophisticated natural language semantics is a sine qua non for achieving a level of intelligence comparable to humans. Embodiment theories in cognitive science hold that human semantic representation depends on sensori-motor experience; the abundant evidence that human meaning representation is grounded in the perception of physical reality leads to the conclusion that meaning must depend on a fusion of multiple (perceptual) modalities. Despite this, AI research in general, and its subdisciplines such as computational linguistics and computer vision in particular, have focused primarily on tasks that involve a single modality. Here, we propose virtual embodiment as an alternative, long-term strategy for AI research that is multi-modal in nature and that allows for the kind of scalability required to develop the field coherently and incrementally, in an ethically responsible fashion.",
    "lastUpdated": "2016-10-24T14:37:27Z",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "68T01",
      "I.2.6"
    ],
    "url": "http://arxiv.org/abs/1610.07432v1"
  },
  {
    "title": "The Promise and Prejudice of Big Data in Intelligence Community",
    "authors": [
      "Karan Jani"
    ],
    "abstract": "Big data holds critical importance in the current generation of information technology, with applications ranging from financial, industrial, academic to defense sectors. With the exponential rise of open source data from social media and increasing government monitoring, big data is now also linked with national security, and subsequently to the intelligence community. In this study I review the scope of big data sciences in the functioning of intelligence community. The major part of my study focuses on the inherent limitations of big data, which affects the intelligence agencies from gathering of information to anticipating surprises. The limiting factors range from technical to ethical issues connected with big data. My study concludes the need of experts with domain knowledge from intelligence community to efficiently guide big data analysis for timely filling the knowledge gaps. As a case study on limitations of using big data, I narrate some of the ongoing work in nuclear intelligence using simple analytics and argue on why big data analysis in that case would lead to unnecessary complications. For further investigation, I highlight cases of crowdsource forecasting tournaments and predicting unrest from social media.",
    "lastUpdated": "2016-10-27T06:20:00Z",
    "categories": [
      "cs.CY",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1610.08629v1"
  },
  {
    "title": "Preserving Differential Privacy Between Features in Distributed Estimation",
    "authors": [
      "Christina Heinze-Deml",
      "Brian McWilliams",
      "Nicolai Meinshausen"
    ],
    "abstract": "Privacy is crucial in many applications of machine learning. Legal, ethical and societal issues restrict the sharing of sensitive data making it difficult to learn from datasets that are partitioned between many parties. One important instance of such a distributed setting arises when information about each record in the dataset is held by different data owners (the design matrix is \"vertically-partitioned\"). In this setting few approaches exist for private data sharing for the purposes of statistical estimation and the classical setup of differential privacy with a \"trusted curator\" preparing the data does not apply. We work with the notion of $(\\epsilon,\\delta)$-distributed differential privacy which extends single-party differential privacy to the distributed, vertically-partitioned case. We propose PriDE, a scalable framework for distributed estimation where each party communicates perturbed random projections of their locally held features ensuring $(\\epsilon,\\delta)$-distributed differential privacy is preserved. For $\\ell_2$-penalized supervised learning problems PriDE has bounded estimation error compared with the optimal estimates obtained without privacy constraints in the non-distributed setting. We confirm this empirically on real world and synthetic datasets.",
    "lastUpdated": "2017-06-27T08:59:48Z",
    "categories": [
      "stat.ML",
      "cs.CR",
      "cs.DC",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1703.00403v2"
  },
  {
    "title": "Counterfactual Fairness",
    "authors": [
      "Matt J. Kusner",
      "Joshua R. Loftus",
      "Chris Russell",
      "Ricardo Silva"
    ],
    "abstract": "Machine learning can impact people with legal or ethical consequences when it is used to automate decisions in areas such as insurance, lending, hiring, and predictive policing. In many of these scenarios, previous decisions have been made that are unfairly biased against certain subpopulations, for example those of a particular race, gender, or sexual orientation. Since this past data may be biased, machine learning predictors must account for this to avoid perpetuating or creating discriminatory practices. In this paper, we develop a framework for modeling fairness using tools from causal inference. Our definition of counterfactual fairness captures the intuition that a decision is fair towards an individual if it is the same in (a) the actual world and (b) a counterfactual world where the individual belonged to a different demographic group. We demonstrate our framework on a real-world problem of fair prediction of success in law school.",
    "lastUpdated": "2018-03-08T11:23:13Z",
    "categories": [
      "stat.ML",
      "cs.CY",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1703.06856v3"
  },
  {
    "title": "Decoupled classifiers for fair and efficient machine learning",
    "authors": [
      "Cynthia Dwork",
      "Nicole Immorlica",
      "Adam Tauman Kalai",
      "Max Leiserson"
    ],
    "abstract": "When it is ethical and legal to use a sensitive attribute (such as gender or race) in machine learning systems, the question remains how to do so. We show that the naive application of machine learning algorithms using sensitive features leads to an inherent tradeoff in accuracy between groups. We provide a simple and efficient decoupling technique, that can be added on top of any black-box machine learning algorithm, to learn different classifiers for different groups. Transfer learning is used to mitigate the problem of having too little data on any one group. The method can apply to a range of fairness criteria. In particular, we require the application designer to specify as joint loss function that makes explicit the trade-off between fairness and accuracy. Our reduction is shown to efficiently find the minimum loss as long as the objective has a certain natural monotonicity property which may be of independent interest in the study of fairness in algorithms.",
    "lastUpdated": "2017-07-20T17:08:48Z",
    "categories": [
      "cs.LG",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1707.06613v1"
  },
  {
    "title": "Zoonoses Frontier: Veterinarian, Producer, Processor and Beyond",
    "authors": [
      "Min Yue",
      "Huanchun Chen"
    ],
    "abstract": "As many emerging and re-emerging infectious diseases are associated with food animals, the relationship between available healthy food sources and population health and social stability has become evident. A recent example of the importance of this relationship was observed during the current flu pandemic. This recent pandemic brought attention to novel target groups of susceptible people at the interface of the animal and human populations. Veterinarians, producers and processors are uniquely exposed to emerging zoonoses. Therefore these individuals may serve as key sentinels and allow efficient evaluation of the effectiveness of zoonoses prophylaxis and control, including evaluation of the cost-effectiveness in the broader view. We also suggest some valuable approaches for rapid diagnosis of emerging and re-emerging infectious diseases and supportive systemic research which may address related ethical questions. We also highly recommend more research investigations characterizing this human/animal zoonosis interface, a potentially productive target for emerging disease diagnosis and control.",
    "lastUpdated": "2013-12-24T19:42:25Z",
    "categories": [
      "q-bio.PE"
    ],
    "url": "http://arxiv.org/abs/1312.6879v1"
  },
  {
    "title": "Encore: Lightweight Measurement of Web Censorship with Cross-Origin Requests",
    "authors": [
      "Sam Burnett",
      "Nick Feamster"
    ],
    "abstract": "Despite the pervasiveness of Internet censorship, we have scant data on its extent, mechanisms, and evolution. Measuring censorship is challenging: it requires continual measurement of reachability to many target sites from diverse vantage points. Amassing suitable vantage points for longitudinal measurement is difficult; existing systems have achieved only small, short-lived deployments. We observe, however, that most Internet users access content via Web browsers, and the very nature of Web site design allows browsers to make requests to domains with different origins than the main Web page. We present Encore, a system that harnesses cross-origin requests to measure Web filtering from a diverse set of vantage points without requiring users to install custom software, enabling longitudinal measurements from many vantage points. We explain how Encore induces Web clients to perform cross-origin requests that measure Web filtering, design a distributed platform for scheduling and collecting these measurements, show the feasibility of a global-scale deployment with a pilot study and an analysis of potentially censored Web content, identify several cases of filtering in six months of measurements, and discuss ethical concerns that would arise with widespread deployment.",
    "lastUpdated": "2015-07-19T20:45:56Z",
    "categories": [
      "cs.NI",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1410.1211v2"
  },
  {
    "title": "Information-adaptive clinical trials with selective recruitment and binary outcomes",
    "authors": [
      "James E. Barrett"
    ],
    "abstract": "Selective recruitment designs preferentially recruit individuals that are estimated to be statistically informative onto a clinical trial. Individuals that are expected to contribute less information have a lower probability of recruitment. Furthermore, in an information-adaptive design recruits are allocated to treatment arms in a manner that maximises information gain. The informativeness of an individual depends on their covariate (or biomarker) values and how information is defined is a critical element of information-adaptive designs. In this paper we define and evaluate four different methods for quantifying statistical information. Using both experimental data and numerical simulations we show that selective recruitment designs can offer a substantial increase in statistical power compared to randomised designs. In trials without selective recruitment we find that allocating individuals to treatment arms according to information-adaptive protocols also leads to an increase in statistical power. Consequently, selective recruitment designs can potentially achieve successful trials using fewer recruits thereby offering economic and ethical advantages.",
    "lastUpdated": "2017-05-30T15:06:24Z",
    "categories": [
      "math.ST",
      "stat.ME",
      "stat.TH"
    ],
    "url": "http://arxiv.org/abs/1509.01058v3"
  },
  {
    "title": "Initial Analysis of a Simple Numerical Model that Exhibits Antifragile Behavior",
    "authors": [
      "Bryan A. Knowles"
    ],
    "abstract": "I present a simple numerical model based on iteratively updating subgroups of a population, individually modeled by nonnegative real numbers, by a constant decay factor; however, at each iteration, one group is selected to instead be updated by a constant growth factor. I discover a relationship between these variables and their respective probabilities for a given subgroup, summarized as the variable $c$. When $c>1$, the subgroup is found to tend towards behaviors reminiscent of antifragility; when at least one subgroup of the population has $c\\ge1$, the population as a whole tends towards significantly higher probabilities of \"living forever,\" although it may first suffer a drop in population size as less robust, fragile subgroups \"die off.\" In concluding, I discuss the limitations and ethics of such a model, notably the implications of when an upper limit is placed on the growth constant, requiring a population to facilitate an increase in the decay factor to lessen the impact of periods of failure.",
    "lastUpdated": "2015-08-31T19:08:41Z",
    "categories": [
      "q-bio.PE",
      "math.PR"
    ],
    "url": "http://arxiv.org/abs/1509.02548v1"
  },
  {
    "title": "Taxonomy of Pathways to Dangerous AI",
    "authors": [
      "Roman V. Yampolskiy"
    ],
    "abstract": "In order to properly handle a dangerous Artificially Intelligent (AI) system it is important to understand how the system came to be in such a state. In popular culture (science fiction movies/books) AIs/Robots became self-aware and as a result rebel against humanity and decide to destroy it. While it is one possible scenario, it is probably the least likely path to appearance of dangerous AI. In this work, we survey, classify and analyze a number of circumstances, which might lead to arrival of malicious AI. To the best of our knowledge, this is the first attempt to systematically classify types of pathways leading to malevolent AI. Previous relevant work either surveyed specific goals/meta-rules which might lead to malevolent behavior in AIs (\\\"Ozkural, 2014) or reviewed specific undesirable behaviors AGIs can exhibit at different stages of its development (Alexey Turchin, July 10 2015, July 10, 2015).",
    "lastUpdated": "2015-11-11T21:23:06Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1511.03246v2"
  },
  {
    "title": "EMBERS at 4 years: Experiences operating an Open Source Indicators Forecasting System",
    "authors": [
      "Sathappan Muthiah",
      "Patrick Butler",
      "Rupinder Paul Khandpur",
      "Parang Saraf",
      "Nathan Self",
      "Alla Rozovskaya",
      "Liang Zhao",
      "Jose Cadena",
      "Chang-Tien Lu",
      "Anil Vullikanti",
      "Achla Marathe",
      "Kristen Summers",
      "Graham Katz",
      "Andy Doyle",
      "Jaime Arredondo",
      "Dipak K. Gupta",
      "David Mares",
      "Naren Ramakrishnan"
    ],
    "abstract": "EMBERS is an anticipatory intelligence system forecasting population-level events in multiple countries of Latin America. A deployed system from 2012, EMBERS has been generating alerts 24x7 by ingesting a broad range of data sources including news, blogs, tweets, machine coded events, currency rates, and food prices. In this paper, we describe our experiences operating EMBERS continuously for nearly 4 years, with specific attention to the discoveries it has enabled, correct as well as missed forecasts, and lessons learnt from participating in a forecasting tournament including our perspectives on the limits of forecasting and ethical considerations.",
    "lastUpdated": "2016-03-31T20:06:40Z",
    "categories": [
      "cs.CY",
      "cs.SI"
    ],
    "url": "http://arxiv.org/abs/1604.00033v1"
  },
  {
    "title": "Chaos and Stochastic Models in Physics: Ontic and Epistemic Aspects",
    "authors": [
      "Sergio Caprara",
      "Angelo Vulpiani"
    ],
    "abstract": "There is a persistent confusion about determinism and predictability. In spite of the opinions of some eminent philosophers (e.g., Popper), it is possible to understand that the two concepts are completely unrelated. In few words we can say that determinism is ontic and has to do with how Nature behaves, while predictability is epistemic and is related to what the human beings are able to compute. An analysis of the Lyapunov exponents and the Kolmogorov-Sinai entropy shows how deterministic chaos, although with an epistemic character, is non subjective at all. This should clarify the role and content of stochastic models in the description of the physical world.",
    "lastUpdated": "2016-05-09T12:07:44Z",
    "categories": [
      "nlin.CD",
      "physics.hist-ph"
    ],
    "url": "http://arxiv.org/abs/1605.02550v1"
  },
  {
    "title": "Overcoming the language barrier in mobile user interface design: A case study on a mobile health app",
    "authors": [
      "Jason Ross",
      "Jing Gao"
    ],
    "abstract": "This research report proposes a structured solution to address the need for awareness of cultural and language in user design. It will include evaluated research on established methods that already exist. Discussed ideas about how to address this situation include: what others have found to take into consideration when using design principles to develop an interface, detailed troubles and critical issues that have been previously identified and also ways that have been found already to overcome such issues. This will also involve designing a prototype application catering to resolving these issues. Overcoming the language barrier plays an important role in the process of implementing a user design interface that will satisfy users. This issue must be researched and examined to identify the issues and concerns associated in order to provide a solution in an ethical manner.",
    "lastUpdated": "2016-05-16T09:27:36Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1605.04693v1"
  },
  {
    "title": "Mind the scales: Harnessing spatial big data for infectious disease surveillance and inference",
    "authors": [
      "Elizabeth C. Lee",
      "Jason M. Asher",
      "Sandra Goldlust",
      "John D. Kraemer",
      "Andrew B. Lawson",
      "Shweta Bansal"
    ],
    "abstract": "Spatial big data have the \"velocity,\" \"volume,\" and \"variety\" of big data sources and additional geographic information about the record. Digital data sources, such as medical claims, mobile phone call data records, and geo-tagged tweets, have entered infectious disease epidemiology as novel sources of data to complement traditional infectious disease surveillance. In this work, we provide examples of how spatial big data have been used thus far in epidemiological analyses and describe opportunities for these sources to improve public health coordination and disease mitigation strategies. In addition, we consider the technical, practical, and ethical challenges with the use of spatial big data in infectious disease surveillance and inference. Finally, we discuss the implications of the rising use of spatial big data in epidemiology to health risk communications, across-scale public health coordination, and public health policy recommendation.",
    "lastUpdated": "2016-08-26T20:31:56Z",
    "categories": [
      "q-bio.PE",
      "physics.soc-ph",
      "stat.AP"
    ],
    "url": "http://arxiv.org/abs/1605.08740v3"
  },
  {
    "title": "A Model for Partial Kantian Cooperation",
    "authors": [
      "Ioannis Kordonis"
    ],
    "abstract": "In several game situations, the behavior of the players may depend not only on individual interests, but also on what each player considers as the correct thing to do. This work presents a game theoretic model, aiming to describe game situations in which the players' behavior is affected by ethical considerations. Particularly, we assume that they partially follow, Kant's `Categorical Imperative'. The model is stated for games with a continuum of players. The basic assumption made is that the participants perceive that they belong to virtual (imagined) groups, in which they optimize their actions as if they were bound to follow the same strategy. A partially cooperative equilibrium, called $r$-Kant-Nash equilibrium is then introduced. We then study the relationship of the $r$-Kant-Nash equilibrium with the Nash, (Bentham-) Harsanyi, Rawls difference and Roemer solutions. For the case where the set of possible player types is finite, we prove sufficient conditions for the existence and uniqueness of the $r$-Kant-Nash equilibrium and the equilibrium is characterized in terms of a variational inequality. For the case of continuous types, necessary conditions characterizing the partial Kantian equilibria are derived using a reduction to a set of optimal control problems. Finally, some numerical examples are given.",
    "lastUpdated": "2018-07-15T20:10:53Z",
    "categories": [
      "cs.GT"
    ],
    "url": "http://arxiv.org/abs/1609.01921v2"
  },
  {
    "title": "Long-Term Trends in the Public Perception of Artificial Intelligence",
    "authors": [
      "Ethan Fast",
      "Eric Horvitz"
    ],
    "abstract": "Analyses of text corpora over time can reveal trends in beliefs, interest, and sentiment about a topic. We focus on views expressed about artificial intelligence (AI) in the New York Times over a 30-year period. General interest, awareness, and discussion about AI has waxed and waned since the field was founded in 1956. We present a set of measures that captures levels of engagement, measures of pessimism and optimism, the prevalence of specific hopes and concerns, and topics that are linked to discussions about AI over decades. We find that discussion of AI has increased sharply since 2009, and that these discussions have been consistently more optimistic than pessimistic. However, when we examine specific concerns, we find that worries of loss of control of AI, ethical concerns for AI, and the negative impact of AI on work have grown in recent years. We also find that hopes for AI in healthcare and education have increased over time.",
    "lastUpdated": "2016-12-02T17:18:42Z",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1609.04904v2"
  },
  {
    "title": "Toward a Science of Autonomy for Physical Systems: Defense",
    "authors": [
      "Ronald C. Arkin",
      "Gaurav S. Sukhatme"
    ],
    "abstract": "Militaries around the world have long been cognizant of the potential benefits associated with autonomous systems both in the conduct of warfare and in its prevention. This has lead to the declaration by some that this technology will lead to a fundamental change in the ways in which war is conducted, i.e., a revolution in military affairs (RMA) not unlike gunpowder, the long bow, the rifled bullet, the aircraft carrier, etc. Indeed the United States has created roadmaps for robotics with ever-increasing autonomous capability that span almost 40 years. These systems span air, sea, sea surface, littoral, ground and subterranean environments. There are serious societal and ethical concerns associated with the deployment of this technology that remain unaddressed. How can sufficient protection be afforded noncombatants? What about civilian blowback, where this technology may end up being used in policing operations against domestic groups? How can we protect the fundamental human rights of all involved? Considerable discussion is being conducted at an international level, including at the United Nations Convention on Certain Conventional Weapons (CCW) over the past two years, debating if and how such systems, particularly lethal platforms should be banned or regulated.",
    "lastUpdated": "2016-09-19T15:30:09Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1609.05782v1"
  },
  {
    "title": "Beyond the EULA: Improving consent for data mining",
    "authors": [
      "Luke Hutton",
      "Tristan Henderson"
    ],
    "abstract": "Companies and academic researchers may collect, process, and distribute large quantities of personal data without the explicit knowledge or consent of the individuals to whom the data pertains. Existing forms of consent often fail to be appropriately readable and ethical oversight of data mining may not be sufficient. This raises the question of whether existing consent instruments are sufficient, logistically feasible, or even necessary, for data mining. In this chapter, we review the data collection and mining landscape, including commercial and academic activities, and the relevant data protection concerns, to determine the types of consent instruments used. Using three case studies, we use the new paradigm of human-data interaction to examine whether these existing approaches are appropriate. We then introduce an approach to consent that has been empirically demonstrated to improve on the state of the art and deliver meaningful consent. Finally, we propose some best practices for data collectors to ensure their data mining activities do not violate the expectations of the people to whom the data relate.",
    "lastUpdated": "2017-01-27T10:22:10Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1701.07999v1"
  },
  {
    "title": "Blue Sky Ideas in Artificial Intelligence Education from the EAAI 2017 New and Future AI Educator Program",
    "authors": [
      "Eric Eaton",
      "Sven Koenig",
      "Claudia Schulz",
      "Francesco Maurelli",
      "John Lee",
      "Joshua Eckroth",
      "Mark Crowley",
      "Richard G. Freedman",
      "Rogelio E. Cardona-Rivera",
      "Tiago Machado",
      "Tom Williams"
    ],
    "abstract": "The 7th Symposium on Educational Advances in Artificial Intelligence (EAAI'17, co-chaired by Sven Koenig and Eric Eaton) launched the EAAI New and Future AI Educator Program to support the training of early-career university faculty, secondary school faculty, and future educators (PhD candidates or postdocs who intend a career in academia). As part of the program, awardees were asked to address one of the following \"blue sky\" questions: * How could/should Artificial Intelligence (AI) courses incorporate ethics into the curriculum? * How could we teach AI topics at an early undergraduate or a secondary school level? * AI has the potential for broad impact to numerous disciplines. How could we make AI education more interdisciplinary, specifically to benefit non-engineering fields? This paper is a collection of their responses, intended to help motivate discussion around these issues in AI education.",
    "lastUpdated": "2017-02-01T05:16:55Z",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1702.00137v1"
  },
  {
    "title": "Narratives of Quantum Theory in the Age of Quantum Technologies",
    "authors": [
      "Alexei Grinbaum"
    ],
    "abstract": "Quantum technologies can be presented to the public with or without introducing a strange trait of quantum theory responsible for their non-classical efficiency. Traditionally the message was centered on the superposition principle, while entanglement and properties such as contextuality have been gaining ground recently. A less theoretical approach is focused on simple protocols that enable technological applications. It results in a pragmatic narrative built with the help of the resource paradigm and principle-based reconstructions. I discuss the advantages and weaknesses of these methods. To illustrate the importance of new metaphors beyond the Schr\\\"odinger cat, I briefly describe a non-mathematical narrative about entanglement that conveys an idea of some of its unusual properties. If quantum technologists are to succeed in building trust in their work, they ought to provoke an aesthetic perception in the public commensurable with the mathematical beauty of quantum theory experienced by the physicist. The power of the narrative method lies in its capacity to do so.",
    "lastUpdated": "2017-04-14T12:43:28Z",
    "categories": [
      "physics.pop-ph",
      "physics.soc-ph",
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/1702.03001v2"
  },
  {
    "title": "Interface and Data Biopolitics in the Age of Hyperconnectivity",
    "authors": [
      "Salvatore Iaconesi"
    ],
    "abstract": "This article describes their biopolitical implications for design from psychological, cultural, legal, functional and aesthetic/perceptive ways, in the framework of Hyperconnectivity: the condition according to which person-to-person, person-to-machine and machine-to-machine communication progressively shift to networked and digital means. A definition is given for the terms of \"interface biopolitics\" and \"data biopolitics\", as well as evidence supporting these definitions and a description of the technological, theoretical and practice-based innovations bringing them into meaningful existence. Interfaces, algorithms, artificial intelligences of various types, the tendency in quantified self and the concept of \"information bubbles\" will be examined in terms of interface and data biopolitics, from the point of view of design, and for their implications in terms of freedoms, transparency, justice and accessibility to human rights. A working hypothesis is described for technologically relevant design practices and education processes, in order to confront with these issues in critical, ethical and inclusive ways.",
    "lastUpdated": "2017-05-06T05:37:49Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1705.02449v1"
  },
  {
    "title": "Instrument-Armed Bandits",
    "authors": [
      "Nathan Kallus"
    ],
    "abstract": "We extend the classic multi-armed bandit (MAB) model to the setting of noncompliance, where the arm pull is a mere instrument and the treatment applied may differ from it, which gives rise to the instrument-armed bandit (IAB) problem. The IAB setting is relevant whenever the experimental units are human since free will, ethics, and the law may prohibit unrestricted or forced application of treatment. In particular, the setting is relevant in bandit models of dynamic clinical trials and other controlled trials on human interventions. Nonetheless, the setting has not been fully investigate in the bandit literature. We show that there are various and divergent notions of regret in this setting, all of which coincide only in the classic MAB setting. We characterize the behavior of these regrets and analyze standard MAB algorithms. We argue for a particular kind of regret that captures the causal effect of treatments but show that standard MAB algorithms cannot achieve sublinear control on this regret. Instead, we develop new algorithms for the IAB problem, prove new regret bounds for them, and compare them to standard MAB algorithms in numerical examples.",
    "lastUpdated": "2017-05-21T02:23:36Z",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1705.07377v1"
  },
  {
    "title": "Methodological Approach for the Design of a Complex Inclusive Human-Machine System",
    "authors": [
      "Lorenzo Sabattini",
      "Valeria Villani",
      "Julia N. Czerniak",
      "Alexander Mertens",
      "Cesare Fantuzzi"
    ],
    "abstract": "Modern industrial automatic machines and robotic cells are equipped with highly complex human-machine interfaces (HMIs) that often prevent human operators from an effective use of the automatic systems. In particular, this applies to vulnerable users, such as those with low experience or education level, the elderly and the disabled. To tackle this issue, it becomes necessary to design user-oriented HMIs, which adapt to the capabilities and skills of users, thus compensating their limitations and taking full advantage of their knowledge. In this paper, we propose a methodological approach to the design of complex adaptive human-machine systems that might be inclusive of all users, in particular the vulnerable ones. The proposed approach takes into account both the technical requirements and the requirements for ethical, legal and social implications (ELSI) for the design of automatic systems. The technical requirements derive from a thorough analysis of three use cases taken from the European project INCLUSIVE. To achieve the ELSI requirements, the MEESTAR approach is combined with the specific legal issues for occupational systems and requirements of the target users.",
    "lastUpdated": "2017-06-26T16:30:20Z",
    "categories": [
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/1706.08461v1"
  },
  {
    "title": "Network maps of student work with physics, other sciences, and math in an integrated science course",
    "authors": [
      "Jesper Bruun",
      "Ida Viola Andersen"
    ],
    "abstract": "In 2004 Denmark introduced a compulsory integrated science course the most popular upper secondary study program. One of the nation-wide course aims are for students to \"achieve knowledge about some of the central scientific issues and their social, ethical, and historical perspectives\". This is to be done via collaboration between the subjects, and often involves physics and another scientific subject. The official teaching plans further state that mathematics must be used for analysing data. We use network analysis to study six different implementations of the course in terms of the structure of different kinds of teaching/learning activities. By creating networks maps of each lesson, we show that teaching/learning activities in the course seldom tends to address how sciences can work together to solve a problem, but rather stages each natural science as a distinct and separate activity with a distinct identity.",
    "lastUpdated": "2017-08-04T06:16:04Z",
    "categories": [
      "physics.ed-ph"
    ],
    "url": "http://arxiv.org/abs/1708.01389v1"
  },
  {
    "title": "A European research roadmap for optimizing societal impact of big data on environment and energy efficiency",
    "authors": [
      "Martí Cuquet",
      "Anna Fensel",
      "Lorenzo Bigagli"
    ],
    "abstract": "We present a roadmap to guide European research efforts towards a socially responsible big data economy that maximizes the positive impact of big data in environment and energy efficiency. The goal of the roadmap is to allow stakeholders and the big data community to identify and meet big data challenges, and to proceed with a shared understanding of the societal impact, positive and negative externalities, and concrete problems worth investigating. It builds upon a case study focused on the impact of big data practices in the context of Earth Observation that reveals both positive and negative effects in the areas of economy, society and ethics, legal frameworks and political issues. The roadmap identifies European technical and non-technical priorities in research and innovation to be addressed in the upcoming five years in order to deliver societal impact, develop skills and contribute to standardization.",
    "lastUpdated": "2017-08-25T19:44:41Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1708.07871v1"
  },
  {
    "title": "Counterfactual Conditionals in Quantified Modal Logic",
    "authors": [
      "Naveen Sundar Govindarajulu",
      "Selmer Bringsjord"
    ],
    "abstract": "We present a novel formalization of counterfactual conditionals in a quantified modal logic. Counterfactual conditionals play a vital role in ethical and moral reasoning. Prior work has shown that moral reasoning systems (and more generally, theory-of-mind reasoning systems) should be at least as expressive as first-order (quantified) modal logic (QML) to be well-behaved. While existing work on moral reasoning has focused on counterfactual-free QML moral reasoning, we present a fully specified and implemented formal system that includes counterfactual conditionals. We validate our model with two projects. In the first project, we demonstrate that our system can be used to model a complex moral principle, the doctrine of double effect. In the second project, we use the system to build a data-set with true and false counterfactuals as licensed by our theory, which we believe can be useful for other researchers. This project also shows that our model can be computationally feasible.",
    "lastUpdated": "2017-11-02T23:04:57Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1710.04161v2"
  },
  {
    "title": "Maintaining The Humanity of Our Models",
    "authors": [
      "Umang Bhatt"
    ],
    "abstract": "Artificial intelligence and machine learning have been major research interests in computer science for the better part of the last few decades. However, all too recently, both AI and ML have rapidly grown to be media frenzies, pressuring companies and researchers to claim they use these technologies. As ML continues to percolate into daily life, we, as computer scientists and machine learning researchers, are responsible for ensuring we clearly convey the extent of our work and the humanity of our models. Regularizing ML for mass adoption requires a rigorous standard for model interpretability, a deep consideration for human bias in data, and a transparent understanding of a model's societal effects.",
    "lastUpdated": "2017-12-10T22:51:24Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1711.05791v2"
  },
  {
    "title": "Modeling Epistemological Principles for Bias Mitigation in AI Systems: An Illustration in Hiring Decisions",
    "authors": [
      "Marisa Vasconcelos",
      "Carlos Cardonha",
      "Bernardo Gonçalves"
    ],
    "abstract": "Artificial Intelligence (AI) has been used extensively in automatic decision making in a broad variety of scenarios, ranging from credit ratings for loans to recommendations of movies. Traditional design guidelines for AI models focus essentially on accuracy maximization, but recent work has shown that economically irrational and socially unacceptable scenarios of discrimination and unfairness are likely to arise unless these issues are explicitly addressed. This undesirable behavior has several possible sources, such as biased datasets used for training that may not be detected in black-box models. After pointing out connections between such bias of AI and the problem of induction, we focus on Popper's contributions after Hume's, which offer a logical theory of preferences. An AI model can be preferred over others on purely rational grounds after one or more attempts at refutation based on accuracy and fairness. Inspired by such epistemological principles, this paper proposes a structured approach to mitigate discrimination and unfairness caused by bias in AI systems. In the proposed computational framework, models are selected and enhanced after attempts at refutation. To illustrate our discussion, we focus on hiring decision scenarios where an AI system filters in which job applicants should go to the interview phase.",
    "lastUpdated": "2017-11-20T00:27:57Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1711.07111v1"
  },
  {
    "title": "The Promise and Peril of Human Evaluation for Model Interpretability",
    "authors": [
      "Bernease Herman"
    ],
    "abstract": "Transparency, user trust, and human comprehension are popular ethical motivations for interpretable machine learning. In support of these goals, researchers evaluate model explanation performance using humans and real world applications. This alone presents a challenge in many areas of artificial intelligence. In this position paper, we propose a distinction between descriptive and persuasive explanations. We discuss reasoning suggesting that functional interpretability may be correlated with cognitive function and user preferences. If this is indeed the case, evaluation and optimization using functional metrics could perpetuate implicit cognitive bias in explanations that threaten transparency. Finally, we propose two potential research directions to disambiguate cognitive function and explanation models, retaining control over the tradeoff between accuracy and interpretability.",
    "lastUpdated": "2019-10-30T13:01:44Z",
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1711.07414v2"
  },
  {
    "title": "What's up with Privacy?: User Preferences and Privacy Concerns in Intelligent Personal Assistants",
    "authors": [
      "Lydia Manikonda",
      "Aditya Deotale",
      "Subbarao Kambhampati"
    ],
    "abstract": "The recent breakthroughs in Artificial Intelligence (AI) have allowed individuals to rely on automated systems for a variety of reasons. Some of these systems are the currently popular voice-enabled systems like Echo by Amazon and Home by Google that are also called as Intelligent Personal Assistants (IPAs). Though there are raising concerns about privacy and ethical implications, users of these IPAs seem to continue using these systems. We aim to investigate why users are concerned about privacy and how they are handling these concerns while using the IPAs. By utilizing the reviews posted online along with the responses to a survey, this paper provides a set of insights about the detected markers related to user interests and privacy challenges. The insights suggest that users of these systems irrespective of their concerns about privacy, are generally positive in terms of utilizing IPAs in their everyday lives. However, there is a significant percentage of users who are concerned about privacy and took further actions to address the related concerns. Some percentage of users expressed that they do not have any privacy concerns but when they learned about the \"always listening\" feature of these devices, their concern about privacy increased.",
    "lastUpdated": "2017-11-20T21:05:10Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1711.07543v1"
  },
  {
    "title": "Fluctuations in pedestrian evacuation times: Going one step beyond the exit capacity paradigm for bottlenecks",
    "authors": [
      "Alexandre Nicolas"
    ],
    "abstract": "For safety reasons, it is important that the design of buildings and public facilities comply with the guidelines compiled in building codes.The latter are often premised on the concept of exit capacity, \\emph{i.e.}, the mean pedestrian flow rate through a bottleneck (at congestion). Here, we argue that one should duly take into account the evacuation time fluctuations when devising these guidelines. This is particularly true when the narrowing isabrupt and the crowd may behave competitively. We suggest a simple way to assess the extent of (part of) these fluctuations on the basis of the statistics of time gaps between successive escapes through the consideredbottleneck, which in practice could be garnered by analysing recordings of future real evacuations or, perhaps, realistic drills (in the limits of what is ethically possible). We briefly present a test of the proposed strategy using a cellular automaton model and confirm its validity under some conditions, but alsodisclose some of its limitations. In particular, it may severely underestimate fluctuations in the presence of strong correlations in the pedestrians' behaviours(while still performing better than only the mean capacity).",
    "lastUpdated": "2017-12-06T07:47:25Z",
    "categories": [
      "physics.soc-ph"
    ],
    "url": "http://arxiv.org/abs/1712.02067v1"
  },
  {
    "title": "Cogniculture: Towards a Better Human-Machine Co-evolution",
    "authors": [
      "Rakesh R Pimplikar",
      "Kushal Mukherjee",
      "Gyana Parija",
      "Harit Vishwakarma",
      "Ramasuri Narayanam",
      "Sarthak Ahuja",
      "Rohith D Vallam",
      "Ritwik Chaudhuri",
      "Joydeep Mondal"
    ],
    "abstract": "Research in Artificial Intelligence is breaking technology barriers every day. New algorithms and high performance computing are making things possible which we could only have imagined earlier. Though the enhancements in AI are making life easier for human beings day by day, there is constant fear that AI based systems will pose a threat to humanity. People in AI community have diverse set of opinions regarding the pros and cons of AI mimicking human behavior. Instead of worrying about AI advancements, we propose a novel idea of cognitive agents, including both human and machines, living together in a complex adaptive ecosystem, collaborating on human computation for producing essential social goods while promoting sustenance, survival and evolution of the agents' life cycle. We highlight several research challenges and technology barriers in achieving this goal. We propose a governance mechanism around this ecosystem to ensure ethical behaviors of all cognitive agents. Along with a novel set of use-cases of Cogniculture, we discuss the road map ahead for this journey.",
    "lastUpdated": "2017-12-11T11:31:28Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/1712.03724v1"
  },
  {
    "title": "Open data, open review and open dialogue in making social sciences plausible",
    "authors": [
      "Quan-Hoang Vuong"
    ],
    "abstract": "Nowadays, protecting trust in social sciences also means engaging in open community dialogue, which helps to safeguard robustness and improve efficiency of research methods. The combination of open data, open review and open dialogue may sound simple but implementation in the real world will not be straightforward. However, in view of Begley and Ellis's (2012) statement that, \"the scientific process demands the highest standards of quality, ethics and rigour,\" they are worth implementing. More importantly, they are feasible to work on and likely will help to restore plausibility to social sciences research. Therefore, I feel it likely that the triplet of open data, open review and open dialogue will gradually emerge to become policy requirements regardless of the research funding source.",
    "lastUpdated": "2017-12-13T14:47:26Z",
    "categories": [
      "stat.OT",
      "stat.ME"
    ],
    "url": "http://arxiv.org/abs/1712.04801v1"
  },
  {
    "title": "Fair Forests: Regularized Tree Induction to Minimize Model Bias",
    "authors": [
      "Edward Raff",
      "Jared Sylvester",
      "Steven Mills"
    ],
    "abstract": "The potential lack of fairness in the outputs of machine learning algorithms has recently gained attention both within the research community as well as in society more broadly. Surprisingly, there is no prior work developing tree-induction algorithms for building fair decision trees or fair random forests. These methods have widespread popularity as they are one of the few to be simultaneously interpretable, non-linear, and easy-to-use. In this paper we develop, to our knowledge, the first technique for the induction of fair decision trees. We show that our \"Fair Forest\" retains the benefits of the tree-based approach, while providing both greater accuracy and fairness than other alternatives, for both \"group fairness\" and \"individual fairness.'\" We also introduce new measures for fairness which are able to handle multinomial and continues attributes as well as regression problems, as opposed to binary attributes and labels only. Finally, we demonstrate a new, more robust evaluation procedure for algorithms that considers the dataset in its entirety rather than only a specific protected attribute.",
    "lastUpdated": "2017-12-21T20:19:48Z",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1712.08197v1"
  },
  {
    "title": "A Formalization of Kant's Second Formulation of the Categorical Imperative",
    "authors": [
      "Felix Lindner",
      "Martin Mose Bentzen"
    ],
    "abstract": "We present a formalization and computational implementation of the second formulation of Kant's categorical imperative. This ethical principle requires an agent to never treat someone merely as a means but always also as an end. Here we interpret this principle in terms of how persons are causally affected by actions. We introduce Kantian causal agency models in which moral patients, actions, goals, and causal influence are represented, and we show how to formalize several readings of Kant's categorical imperative that correspond to Kant's concept of strict and wide duties towards oneself and others. Stricter versions handle cases where an action directly causally affects oneself or others, whereas the wide version maximizes the number of persons being treated as an end. We discuss limitations of our formalization by pointing to one of Kant's cases that the machinery cannot handle in a satisfying way.",
    "lastUpdated": "2019-07-11T13:22:27Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1801.03160v3"
  },
  {
    "title": "A Computational Model of Commonsense Moral Decision Making",
    "authors": [
      "Richard Kim",
      "Max Kleiman-Weiner",
      "Andres Abeliuk",
      "Edmond Awad",
      "Sohan Dsouza",
      "Josh Tenenbaum",
      "Iyad Rahwan"
    ],
    "abstract": "We introduce a new computational model of moral decision making, drawing on a recent theory of commonsense moral learning via social dynamics. Our model describes moral dilemmas as a utility function that computes trade-offs in values over abstract moral dimensions, which provide interpretable parameter values when implemented in machine-led ethical decision-making. Moreover, characterizing the social structures of individuals and groups as a hierarchical Bayesian model, we show that a useful description of an individual's moral values - as well as a group's shared values - can be inferred from a limited amount of observed data. Finally, we apply and evaluate our approach to data from the Moral Machine, a web application that collects human judgments on moral dilemmas involving autonomous vehicles.",
    "lastUpdated": "2018-01-12T22:47:22Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1801.04346v1"
  },
  {
    "title": "Algorithms for the Greater Good! On Mental Modeling and Acceptable Symbiosis in Human-AI Collaboration",
    "authors": [
      "Tathagata Chakraborti",
      "Subbarao Kambhampati"
    ],
    "abstract": "Effective collaboration between humans and AI-based systems requires effective modeling of the human in the loop, both in terms of the mental state as well as the physical capabilities of the latter. However, these models can also open up pathways for manipulating and exploiting the human in the hopes of achieving some greater good, especially when the intent or values of the AI and the human are not aligned or when they have an asymmetrical relationship with respect to knowledge or computation power. In fact, such behavior does not necessarily require any malicious intent but can rather be borne out of cooperative scenarios. It is also beyond simple misinterpretation of intents, as in the case of value alignment problems, and thus can be effectively engineered if desired. Such techniques already exist and pose several unresolved ethical and moral questions with regards to the design of autonomy. In this paper, we illustrate some of these issues in a teaming scenario and investigate how they are perceived by participants in a thought experiment.",
    "lastUpdated": "2018-01-30T05:23:28Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1801.09854v1"
  },
  {
    "title": "Fairness and Accountability Design Needs for Algorithmic Support in High-Stakes Public Sector Decision-Making",
    "authors": [
      "Michael Veale",
      "Max Van Kleek",
      "Reuben Binns"
    ],
    "abstract": "Calls for heightened consideration of fairness and accountability in algorithmically-informed public decisions---like taxation, justice, and child protection---are now commonplace. How might designers support such human values? We interviewed 27 public sector machine learning practitioners across 5 OECD countries regarding challenges understanding and imbuing public values into their work. The results suggest a disconnect between organisational and institutional realities, constraints and needs, and those addressed by current research into usable, transparent and 'discrimination-aware' machine learning---absences likely to undermine practical initiatives unless addressed. We see design opportunities in this disconnect, such as in supporting the tracking of concept drift in secondary data sources, and in building usable transparency tools to identify risks and incorporate domain knowledge, aimed both at managers and at the 'street-level bureaucrats' on the frontlines of public service. We conclude by outlining ethical challenges and future directions for collaboration in these high-stakes applications.",
    "lastUpdated": "2018-02-03T20:57:13Z",
    "categories": [
      "cs.CY",
      "cs.HC",
      "cs.LG",
      "K.4.1; H.1.2; J.1"
    ],
    "url": "http://arxiv.org/abs/1802.01029v1"
  },
  {
    "title": "Understanding Convolutional Networks with APPLE : Automatic Patch Pattern Labeling for Explanation",
    "authors": [
      "Sandeep Konam",
      "Ian Quah",
      "Stephanie Rosenthal",
      "Manuela Veloso"
    ],
    "abstract": "With the success of deep learning, recent efforts have been focused on analyzing how learned networks make their classifications. We are interested in analyzing the network output based on the network structure and information flow through the network layers. We contribute an algorithm for 1) analyzing a deep network to find neurons that are 'important' in terms of the network classification outcome, and 2)automatically labeling the patches of the input image that activate these important neurons. We propose several measures of importance for neurons and demonstrate that our technique can be used to gain insight into, and explain how a network decomposes an image to make its final classification.",
    "lastUpdated": "2018-02-11T01:33:33Z",
    "categories": [
      "cs.LG",
      "cs.CY",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1802.03675v1"
  },
  {
    "title": "The Trusted Server: A secure computational environment for privacy compliant evaluations on plain personal data",
    "authors": [
      "Nikolaus von Bomhard",
      "Bernd Ahlborn",
      "Catherine Mason",
      "Ulrich Mansmann"
    ],
    "abstract": "A growing framework of legal and ethical requirements limit scientific and commercial evalua-tion of personal data. Typically, pseudonymization, encryption, or methods of distributed com-puting try to protect individual privacy. However, computational infrastructures still depend on human system administrators. This introduces severe security risks and has strong impact on privacy: system administrators have unlimited access to the computers that they manage in-cluding encryption keys and pseudonymization-tables. Distributed computing and data obfuscation technologies reduce but do not eliminate the risk of privacy leakage by administrators. They produce higher implementation effort and possible data quality degradation. This paper proposes the Trusted Server as an alternative approach that provides a sealed and inaccessible computational environment in a cryptographically strict sense. During operation or by direct physical access to storage media, data stored and processed inside the Trusted Server can by no means be read, manipulated or leaked, other than by brute-force. Thus, secure and privacy-compliant data processing or evaluation of plain person-related data becomes possible even from multiple sources, which want their data kept mutually secret.",
    "lastUpdated": "2018-07-27T08:15:21Z",
    "categories": [
      "cs.CR",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1802.09220v2"
  },
  {
    "title": "Machine learning and genomics: precision medicine vs. patient privacy",
    "authors": [
      "Chloé-Agathe Azencott"
    ],
    "abstract": "Machine learning can have major societal impact in computational biology applications. In particular, it plays a central role in the development of precision medicine, whereby treatment is tailored to the clinical or genetic features of the patient. However, these advances require collecting and sharing among researchers large amounts of genomic data, which generates much concern about privacy. Researchers, study participants and governing bodies should be aware of the ways in which the privacy of participants might be compromised, as well as of the large body of research on technical solutions to these issues. We review how breaches in patient privacy can occur, present recent developments in computational data protection, and discuss how they can be combined with legal and ethical perspectives to provide secure frameworks for genomic data sharing.",
    "lastUpdated": "2018-05-23T10:56:44Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1802.10568v3"
  },
  {
    "title": "Value Alignment, Fair Play, and the Rights of Service Robots",
    "authors": [
      "Daniel Estrada"
    ],
    "abstract": "Ethics and safety research in artificial intelligence is increasingly framed in terms of \"alignment\" with human values and interests. I argue that Turing's call for \"fair play for machines\" is an early and often overlooked contribution to the alignment literature. Turing's appeal to fair play suggests a need to correct human behavior to accommodate our machines, a surprising inversion of how value alignment is treated today. Reflections on \"fair play\" motivate a novel interpretation of Turing's notorious \"imitation game\" as a condition not of intelligence but instead of value alignment: a machine demonstrates a minimal degree of alignment (with the norms of conversation, for instance) when it can go undetected when interrogated by a human. I carefully distinguish this interpretation from the Moral Turing Test, which is not motivated by a principle of fair play, but instead depends on imitation of human moral behavior. Finally, I consider how the framework of fair play can be used to situate the debate over robot rights within the alignment literature. I argue that extending rights to service robots operating in public spaces is \"fair\" in precisely the sense that it encourages an alignment of interests between humans and machines.",
    "lastUpdated": "2018-03-07T19:33:08Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1803.02852v1"
  },
  {
    "title": "Design optimisation and post-trial analysis in group sequential stepped-wedge cluster randomised trials",
    "authors": [
      "Michael Grayling",
      "David Robertson",
      "James Wason",
      "Adrian Mander"
    ],
    "abstract": "Recently, methodology was presented to facilitate the incorporation of interim analyses in stepped-wedge (SW) cluster randomised trials (CRTs). Here, we extend this previous discussion. We detail how the stopping boundaries, allocation sequences, and per-cluster per-period sample size of a group sequential SW-CRT can be optimised. We then describe methods by which point estimates, p-values, and confidence intervals, which account for the sequential nature of the design, can be calculated. We demonstrate that optimal sequential designs can reduce the expected required number of measurements under the null hypothesis, compared to the classical design, by up to 30%, with no cost to the maximal possible required number of measurements. Furthermore, the adjusted analysis procedure almost universally reduces the average bias in the point estimate, and consistently provides a confidence interval with coverage close to the nominal level. In contrast, the coverage of a naive 95% confidence interval is observed to range between 92 and 98%. Methodology is now readily available for the efficient design and analysis of group sequential SW-CRTs. In scenarios in which there are substantial ethical or financial reasons to terminate a SW-CRT as soon as possible, trialists should strongly consider a group sequential approach.",
    "lastUpdated": "2018-03-26T16:13:58Z",
    "categories": [
      "stat.ME"
    ],
    "url": "http://arxiv.org/abs/1803.09691v1"
  },
  {
    "title": "Review: the development of neural stem cell biology and technology in regenerative medicine",
    "authors": [
      "Divyanjali Shanmuganathan",
      "Nivethika Sivakumaran"
    ],
    "abstract": "In the middle of the last century, it has been known that neural stem cells (NSCs) play a key role in regenerative medicine to cure the neurodegenerative disease. This review article covers about the introduction to neural stem cell biology and the isolation, differentiation and transplantation methods/techniques of neural stem cells. The neural stem cells can be transplanted into the human brain in the future to replace the damaged and dead neurons. The highly limited access to embryonic stem cells and ethical issues have escalated the search for other NSC sources. The developing technologies are indicating that it can be achieved before the end of this century. In addition, the differentiation and the maturation of NSCs can artificially accelerate by modern methods.",
    "lastUpdated": "2018-04-05T07:32:21Z",
    "categories": [
      "q-bio.NC",
      "q-bio.TO"
    ],
    "url": "http://arxiv.org/abs/1804.01704v1"
  },
  {
    "title": "Generation of Infra sound to replicate a wind turbine",
    "authors": [
      "Richard Mann",
      "William Mann"
    ],
    "abstract": "We have successfully produced infrasound, as a duplicate of that produced by Industrial Wind Turbines. We have been able to produce this Infrasound inside a research chamber, capable of accommodating a human test subject. It is our vision that this project will permit others, with appropriate medical training and ethical oversight, to research human thresholds and the effects of this infrasound on humans. Our role has focused on producing the tools, systems, and hardware required, to permit this research to go forward. This paper describes the evolution of our project from the original vision, through the construction of proof of concept prototypes, a series of improved models and their associated accessories /operating systems, to the final test chamber as it stands now ready to deploy. Also included are the mathematical and computational data supporting our claim that infrasound conditions inside the chamber can be made to duplicate those from actual Industrial wind turbines at approved setback distances.",
    "lastUpdated": "2018-05-02T16:53:07Z",
    "categories": [
      "cs.SD",
      "eess.AS",
      "physics.med-ph"
    ],
    "url": "http://arxiv.org/abs/1805.01297v1"
  },
  {
    "title": "How To Solve Moral Conundrums with Computability Theory",
    "authors": [
      "Min Baek"
    ],
    "abstract": "Various moral conundrums plague population ethics: the Non-Identity Problem, the Procreation Asymmetry, the Repugnant Conclusion, and more. I argue that the aforementioned moral conundrums have a structure neatly accounted for, and solved by, some ideas in computability theory. I introduce a mathematical model based on computability theory and show how previous arguments pertaining to these conundrums fit into the model. This paper proceeds as follows. First, I do a very brief survey of the history of computability theory in moral philosophy. Second, I follow various papers, and show how their arguments fit into, or don't fit into, our model. Third, I discuss the implications of our model to the question why the human race should or should not continue to exist. Finally, I show that our model may be interpreted according to a Confucian-Taoist moral principle.",
    "lastUpdated": "2020-12-07T22:46:39Z",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LO"
    ],
    "url": "http://arxiv.org/abs/1805.08347v2"
  },
  {
    "title": "Local Rule-Based Explanations of Black Box Decision Systems",
    "authors": [
      "Riccardo Guidotti",
      "Anna Monreale",
      "Salvatore Ruggieri",
      "Dino Pedreschi",
      "Franco Turini",
      "Fosca Giannotti"
    ],
    "abstract": "The recent years have witnessed the rise of accurate but obscure decision systems which hide the logic of their internal decision processes to the users. The lack of explanations for the decisions of black box systems is a key ethical issue, and a limitation to the adoption of machine learning components in socially sensitive and safety-critical contexts. %Therefore, we need explanations that reveals the reasons why a predictor takes a certain decision. In this paper we focus on the problem of black box outcome explanation, i.e., explaining the reasons of the decision taken on a specific instance. We propose LORE, an agnostic method able to provide interpretable and faithful explanations. LORE first leans a local interpretable predictor on a synthetic neighborhood generated by a genetic algorithm. Then it derives from the logic of the local interpretable predictor a meaningful explanation consisting of: a decision rule, which explains the reasons of the decision; and a set of counterfactual rules, suggesting the changes in the instance's features that lead to a different outcome. Wide experiments show that LORE outperforms existing methods and baselines both in the quality of explanations and in the accuracy in mimicking the black box.",
    "lastUpdated": "2018-05-28T08:56:40Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1805.10820v1"
  },
  {
    "title": "Data-driven Design: A Case for Maximalist Game Design",
    "authors": [
      "Gabriella A. B. Barros",
      "Michael Cerny Green",
      "Antonios Liapis",
      "Julian Togelius"
    ],
    "abstract": "Maximalism in art refers to drawing on and combining multiple different sources for art creation, embracing the resulting collisions and heterogeneity. This paper discusses the use of maximalism in game design and particularly in data games, which are games that are generated partly based on open data. Using Data Adventures, a series of generators that create adventure games from data sources such as Wikipedia and OpenStreetMap, as a lens we explore several tradeoffs and issues in maximalist game design. This includes the tension between transformation and fidelity, between decorative and functional content, and legal and ethical issues resulting from this type of generativity. This paper sketches out the design space of maximalist data-driven games, a design space that is mostly unexplored.",
    "lastUpdated": "2018-05-30T00:43:03Z",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1805.12475v1"
  },
  {
    "title": "System Level Framework for Assessing the Accuracy of Neonatal EEG Acquisition",
    "authors": [
      "Mark O'Sullivan",
      "Emanuel Popovici",
      "Andrea Bocchino",
      "Conor O'Mahony",
      "Geraldine Boylan",
      "Andriy Temko"
    ],
    "abstract": "Significant research has been conducted in recent years to design low-cost alternatives to the current EEG monitoring systems used in healthcare facilities. Testing such systems on a vulnerable population such as newborns is complicated due to ethical and regulatory considerations that slow down the technical development. This paper presents and validates a method for quantifying the accuracy of neonatal EEG acquisition systems and electrode technologies via clinical data simulations that do not require neonatal participants. The proposed method uses an extensive neonatal EEG database to simulate analogue signals, which are subsequently passed through electrical models of the skin-electrode interface, which are developed using wet and dry EEG electrode designs. The signal losses in the system are quantified at each stage of the acquisition process for electrode and acquisition board losses. SNR, correlation and noise values were calculated. The results verify that low-cost EEG acquisition systems are capable of obtaining clinical grade EEG. Although dry electrodes result in a significant increase in the skin-electrode impedance, accurate EEG recordings are still achievable.",
    "lastUpdated": "2018-06-08T09:34:44Z",
    "categories": [
      "physics.med-ph",
      "stat.AP"
    ],
    "url": "http://arxiv.org/abs/1806.03045v1"
  },
  {
    "title": "Technology, Propaganda, and the Limits of Human Intellect",
    "authors": [
      "Panagiotis Metaxas"
    ],
    "abstract": "\"Fake news\" is a recent phenomenon, but misinformation and propaganda are not. Our new communication technologies make it easy for us to be exposed to high volumes of true, false, irrelevant, and unprovable information. Future AI is expected to amplify the problem even more. At the same time, our brains are reaching their limits in handling information. How should we respond to propaganda? Technology can help, but relying on it alone will not suffice in the long term. We also need ethical policies, laws, regulations, and trusted authorities, including fact-checkers. However, we will not solve the problem without the active engagement of the educated citizen. Epistemological education, recognition of self biases and protection of our channels of communication and trusted networks are all needed to overcome the problem and continue our progress as democratic societies.",
    "lastUpdated": "2018-06-06T10:47:20Z",
    "categories": [
      "cs.GL",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1806.09541v1"
  },
  {
    "title": "Robustness to fundamental uncertainty in AGI alignment",
    "authors": [
      "G Gordon Worley III"
    ],
    "abstract": "The AGI alignment problem has a bimodal distribution of outcomes with most outcomes clustering around the poles of total success and existential, catastrophic failure. Consequently, attempts to solve AGI alignment should, all else equal, prefer false negatives (ignoring research programs that would have been successful) to false positives (pursuing research programs that will unexpectedly fail). Thus, we propose adopting a policy of responding to points of philosophical and practical uncertainty associated with the alignment problem by limiting and choosing necessary assumptions to reduce the risk of false positives. Herein we explore in detail two relevant points of uncertainty that AGI alignment research hinges on---meta-ethical uncertainty and uncertainty about mental phenomena---and show how to reduce false positives in response to them.",
    "lastUpdated": "2019-08-24T10:03:09Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1807.09836v2"
  },
  {
    "title": "Exploring Author Gender in Book Rating and Recommendation",
    "authors": [
      "Michael D. Ekstrand",
      "Daniel Kluver"
    ],
    "abstract": "Collaborative filtering algorithms find useful patterns in rating and consumption data and exploit these patterns to guide users to good items. Many of the patterns in rating datasets reflect important real-world differences between the various users and items in the data; other patterns may be irrelevant or possibly undesirable for social or ethical reasons, particularly if they reflect undesired discrimination, such as discrimination in publishing or purchasing against authors who are women or ethnic minorities. In this work, we examine the response of collaborative filtering recommender algorithms to the distribution of their input data with respect to a dimension of social concern, namely content creator gender. Using publicly-available book ratings data, we measure the distribution of the genders of the authors of books in user rating profiles and recommendation lists produced from this data. We find that common collaborative filtering algorithms differ in the gender distribution of their recommendation lists, and in the relationship of that output distribution to user profile distribution.",
    "lastUpdated": "2020-07-25T00:14:02Z",
    "categories": [
      "cs.IR",
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/1808.07586v2"
  },
  {
    "title": "Debiasing Desire: Addressing Bias & Discrimination on Intimate Platforms",
    "authors": [
      "Jevan Hutson",
      "Jessie G. Taft",
      "Solon Barocas",
      "Karen Levy"
    ],
    "abstract": "Designing technical systems to be resistant to bias and discrimination represents vital new terrain for researchers, policymakers, and the anti-discrimination project more broadly. We consider bias and discrimination in the context of popular online dating and hookup platforms in the United States, which we call intimate platforms. Drawing on work in social-justice-oriented and Queer HCI, we review design features of popular intimate platforms and their potential role in exacerbating or mitigating interpersonal bias. We argue that focusing on platform design can reveal opportunities to reshape troubling patterns of intimate contact without overriding users' decisional autonomy. We identify and address the difficult ethical questions that nevertheless come along with such intervention, while urging the social computing community to engage more deeply with issues of bias, discrimination, and exclusion in the study and design of intimate platforms.",
    "lastUpdated": "2018-09-06T12:59:40Z",
    "categories": [
      "cs.CY",
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/1809.01563v2"
  },
  {
    "title": "A Game of Tax Evasion: evidences from an agent-based model",
    "authors": [
      "L. S. Di Mauro",
      "A. Pluchino",
      "A. E. Biondo"
    ],
    "abstract": "This paper presents a simple agent-based model of an economic system, populated by agents playing different games according to their different view about social cohesion and tax payment. After a first set of simulations, correctly replicating results of existing literature, a wider analysis is presented in order to study the effects of a dynamic-adaptation rule, in which citizens may possibly decide to modify their individual tax compliance according to individual criteria, such as, the strength of their ethical commitment, the satisfaction gained by consumption of the public good and the perceived opinion of neighbors. Results show the presence of thresholds levels in the composition of society - between taxpayers and evaders - which explain the extent of damages deriving from tax evasion.",
    "lastUpdated": "2018-09-21T14:34:58Z",
    "categories": [
      "q-fin.GN",
      "physics.soc-ph"
    ],
    "url": "http://arxiv.org/abs/1809.08146v1"
  },
  {
    "title": "Defining the Collective Intelligence Supply Chain",
    "authors": [
      "Iain Barclay",
      "Alun Preece",
      "Ian Taylor"
    ],
    "abstract": "Organisations are increasingly open to scrutiny, and need to be able to prove that they operate in a fair and ethical way. Accountability should extend to the production and use of the data and knowledge assets used in AI systems, as it would for any raw material or process used in production of physical goods. This paper considers collective intelligence, comprising data and knowledge generated by crowd-sourced workforces, which can be used as core components of AI systems. A proposal is made for the development of a supply chain model for tracking the creation and use of crowdsourced collective intelligence assets, with a blockchain based decentralised architecture identified as an appropriate means of providing validation, accountability and fairness.",
    "lastUpdated": "2018-09-25T12:57:30Z",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1809.09444v1"
  },
  {
    "title": "What might matter in autonomous cars adoption: first person versus third person scenarios",
    "authors": [
      "Eva Zackova",
      "Jan Romportl"
    ],
    "abstract": "The discussion between the automotive industry, governments, ethicists, policy makers and general public about autonomous cars' moral agency is widening, and therefore we see the need to bring more insight into what meta-factors might actually influence the outcomes of such discussions, surveys and plebiscites. In our study, we focus on the psychological (personality traits), practical (active driving experience), gender and rhetoric/framing factors that might impact and even determine respondents' a priori preferences of autonomous cars' operation. We conducted an online survey (N=430) to collect data that show that the third person scenario is less biased than the first person scenario when presenting ethical dilemma related to autonomous cars. According to our analysis, gender bias should be explored in more extensive future studies as well. We recommend any participatory technology assessment discourse to use the third person scenario and to direct attention to the way any autonomous car related debate is introduced, especially in terms of linguistic and communication aspects and gender.",
    "lastUpdated": "2018-10-17T10:24:22Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/1810.07460v1"
  },
  {
    "title": "Linguistic Legal Concept Extraction in Portuguese",
    "authors": [
      "Alessandra Cid",
      "Alexandre Rademaker",
      "Bruno Cuconato",
      "Valeria de Paiva"
    ],
    "abstract": "This work investigates legal concepts and their expression in Portuguese, concentrating on the \"Order of Attorneys of Brazil\" Bar exam. Using a corpus formed by a collection of multiple-choice questions, three norms related to the Ethics part of the OAB exam, language resources (Princeton WordNet and OpenWordNet-PT) and tools (AntConc and Freeling), we began to investigate the concepts and words missing from our repertory of concepts and words in Portuguese, the knowledge base OpenWordNet-PT. We add these concepts and words to OpenWordNet-PT and hence obtain a representation of these texts that is \"contained\" in the lexical knowledge base.",
    "lastUpdated": "2018-10-22T15:58:57Z",
    "categories": [
      "cs.CL"
    ],
    "url": "http://arxiv.org/abs/1810.09379v1"
  },
  {
    "title": "What can AI do for me: Evaluating Machine Learning Interpretations in Cooperative Play",
    "authors": [
      "Shi Feng",
      "Jordan Boyd-Graber"
    ],
    "abstract": "Machine learning is an important tool for decision making, but its ethical and responsible application requires rigorous vetting of its interpretability and utility: an understudied problem, particularly for natural language processing models. We propose an evaluation of interpretation on a real task with real human users, where the effectiveness of interpretation is measured by how much it improves human performance. We design a grounded, realistic human-computer cooperative setting using a question answering task, Quizbowl. We recruit both trivia experts and novices to play this game with computer as their teammate, who communicates its prediction via three different interpretations. We also provide design guidance for natural language processing human-in-the-loop settings.",
    "lastUpdated": "2019-06-10T02:39:28Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1810.09648v3"
  },
  {
    "title": "Mimetic vs Anchored Value Alignment in Artificial Intelligence",
    "authors": [
      "Tae Wan Kim",
      "Thomas Donaldson",
      "John Hooker"
    ],
    "abstract": "\"Value alignment\" (VA) is considered as one of the top priorities in AI research. Much of the existing research focuses on the \"A\" part and not the \"V\" part of \"value alignment.\" This paper corrects that neglect by emphasizing the \"value\" side of VA and analyzes VA from the vantage point of requirements in value theory, in particular, of avoiding the \"naturalistic fallacy\"--a major epistemic caveat. The paper begins by isolating two distinct forms of VA: \"mimetic\" and \"anchored.\" Then it discusses which VA approach better avoids the naturalistic fallacy. The discussion reveals stumbling blocks for VA approaches that neglect implications of the naturalistic fallacy. Such problems are more serious in mimetic VA since the mimetic process imitates human behavior that may or may not rise to the level of correct ethical behavior. Anchored VA, including hybrid VA, in contrast, holds more promise for future VA since it anchors alignment by normative concepts of intrinsic value.",
    "lastUpdated": "2018-10-25T21:34:21Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1810.11116v1"
  },
  {
    "title": "Are the Dead Taking Over Facebook? A Big Data Approach to the Future of Death Online",
    "authors": [
      "Carl Öhman",
      "David Watson"
    ],
    "abstract": "We project the future accumulation of profiles belonging to deceased Facebook users. Our analysis suggests that a minimum of 1.4 billion users will pass away before 2100 if Facebook ceases to attract new users as of 2018. If the network continues expanding at current rates, however, this number will exceed 4.9 billion. In both cases, a majority of the profiles will belong to non-Western users. In discussing our findings, we draw on the emerging scholarship on digital preservation and stress the challenges arising from curating the profiles of the deceased. We argue that an exclusively commercial approach to data preservation poses important ethical and political risks that demand urgent consideration. We call for a scalable, sustainable, and dignified curation model that incorporates the interests of multiple stakeholders.",
    "lastUpdated": "2019-05-06T09:29:57Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1811.03416v4"
  },
  {
    "title": "How Do Fairness Definitions Fare? Examining Public Attitudes Towards Algorithmic Definitions of Fairness",
    "authors": [
      "Nripsuta Saxena",
      "Karen Huang",
      "Evan DeFilippis",
      "Goran Radanovic",
      "David Parkes",
      "Yang Liu"
    ],
    "abstract": "What is the best way to define algorithmic fairness? While many definitions of fairness have been proposed in the computer science literature, there is no clear agreement over a particular definition. In this work, we investigate ordinary people's perceptions of three of these fairness definitions. Across two online experiments, we test which definitions people perceive to be the fairest in the context of loan decisions, and whether fairness perceptions change with the addition of sensitive information (i.e., race of the loan applicants). Overall, one definition (calibrated fairness) tends to be more preferred than the others, and the results also provide support for the principle of affirmative action.",
    "lastUpdated": "2019-01-27T19:56:07Z",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1811.03654v2"
  },
  {
    "title": "Intersectionality: Multiple Group Fairness in Expectation Constraints",
    "authors": [
      "Jack Fitzsimons",
      "Michael Osborne",
      "Stephen Roberts"
    ],
    "abstract": "Group fairness is an important concern for machine learning researchers, developers, and regulators. However, the strictness to which models must be constrained to be considered fair is still under debate. The focus of this work is on constraining the expected outcome of subpopulations in kernel regression and, in particular, decision tree regression, with application to random forests, boosted trees and other ensemble models. While individual constraints were previously addressed, this work addresses concerns about incorporating multiple constraints simultaneously. The proposed solution does not affect the order of computational or memory complexity of the decision trees and is easily integrated into models post training.",
    "lastUpdated": "2018-11-25T06:31:13Z",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1811.09960v1"
  },
  {
    "title": "Linking Artificial Intelligence Principles",
    "authors": [
      "Yi Zeng",
      "Enmeng Lu",
      "Cunqing Huangfu"
    ],
    "abstract": "Artificial Intelligence principles define social and ethical considerations to develop future AI. They come from research institutes, government organizations and industries. All versions of AI principles are with different considerations covering different perspectives and making different emphasis. None of them can be considered as complete and can cover the rest AI principle proposals. Here we introduce LAIP, an effort and platform for linking and analyzing different Artificial Intelligence Principles. We want to explicitly establish the common topics and links among AI Principles proposed by different organizations and investigate on their uniqueness. Based on these efforts, for the long-term future of AI, instead of directly adopting any of the AI principles, we argue for the necessity of incorporating various AI Principles into a comprehensive framework and focusing on how they can interact and complete each other.",
    "lastUpdated": "2018-12-12T05:43:57Z",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1812.04814v1"
  },
  {
    "title": "Trichotomic Argumentation Representation",
    "authors": [
      "Merlin Göttlinger",
      "Lutz Schröder"
    ],
    "abstract": "The Aristotelian trichotomy distinguishes three aspects of argumentation: Logos, Ethos, and Pathos. Even rich argumentation representations like the Argument Interchange Format (AIF) are only concerned with capturing the Logos aspect. Inference Anchoring Theory (IAT) adds the possibility to represent ethical requirements on the illocutionary force edges linking locutions to illocutions, thereby allowing to capture some aspects of ethos. With the recent extensions AIF+ and Social Argument Interchange Format (S-AIF), which embed dialogue and speakers into the AIF argumentation representation, the basis for representing all three aspects identified by Aristotle was formed. In the present work, we develop the Trichotomic Argument Interchange Format (T-AIF), building on the idea from S-AIF of adding the speakers to the argumentation graph. We capture Logos in the usual known from AIF+, Ethos in form of weighted edges between actors representing trust, and Pathos via weighted edges from actors to illocutions representing their level of commitment to the propositions. This extended structured argumentation representation opens up new possibilities of defining semantic properties on this rich graph in order to characterize and profile the reasoning patterns of the participating actors.",
    "lastUpdated": "2018-12-17T13:12:03Z",
    "categories": [
      "cs.AI",
      "cs.LO",
      "68T30"
    ],
    "url": "http://arxiv.org/abs/1812.06745v1"
  },
  {
    "title": "Interaction Design for Explainable AI: Workshop Proceedings",
    "authors": [
      "Prashan Madumal",
      "Ronal Singh",
      "Joshua Newn",
      "Frank Vetere"
    ],
    "abstract": "As artificial intelligence (AI) systems become increasingly complex and ubiquitous, these systems will be responsible for making decisions that directly affect individuals and society as a whole. Such decisions will need to be justified due to ethical concerns as well as trust, but achieving this has become difficult due to the `black-box' nature many AI models have adopted. Explainable AI (XAI) can potentially address this problem by explaining its actions, decisions and behaviours of the system to users. However, much research in XAI is done in a vacuum using only the researchers' intuition of what constitutes a `good' explanation while ignoring the interaction and the human aspect. This workshop invites researchers in the HCI community and related fields to have a discourse about human-centred approaches to XAI rooted in interaction and to shed light and spark discussion on interaction design challenges in XAI.",
    "lastUpdated": "2018-12-13T12:45:26Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1812.08597v1"
  },
  {
    "title": "Improving the Interpretability of Deep Neural Networks with Knowledge Distillation",
    "authors": [
      "Xuan Liu",
      "Xiaoguang Wang",
      "Stan Matwin"
    ],
    "abstract": "Deep Neural Networks have achieved huge success at a wide spectrum of applications from language modeling, computer vision to speech recognition. However, nowadays, good performance alone is not sufficient to satisfy the needs of practical deployment where interpretability is demanded for cases involving ethics and mission critical applications. The complex models of Deep Neural Networks make it hard to understand and reason the predictions, which hinders its further progress. To tackle this problem, we apply the Knowledge Distillation technique to distill Deep Neural Networks into decision trees in order to attain good performance and interpretability simultaneously. We formulate the problem at hand as a multi-output regression problem and the experiments demonstrate that the student model achieves significantly better accuracy performance (about 1\\% to 5\\%) than vanilla decision trees at the same level of tree depth. The experiments are implemented on the TensorFlow platform to make it scalable to big datasets. To the best of our knowledge, we are the first to distill Deep Neural Networks into vanilla decision trees on multi-class datasets.",
    "lastUpdated": "2018-12-28T08:50:04Z",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1812.10924v1"
  },
  {
    "title": "Explaining Explanations to Society",
    "authors": [
      "Leilani H. Gilpin",
      "Cecilia Testart",
      "Nathaniel Fruchter",
      "Julius Adebayo"
    ],
    "abstract": "There is a disconnect between explanatory artificial intelligence (XAI) methods and the types of explanations that are useful for and demanded by society (policy makers, government officials, etc.) Questions that experts in artificial intelligence (AI) ask opaque systems provide inside explanations, focused on debugging, reliability, and validation. These are different from those that society will ask of these systems to build trust and confidence in their decisions. Although explanatory AI systems can answer many questions that experts desire, they often don't explain why they made decisions in a way that is precise (true to the model) and understandable to humans. These outside explanations can be used to build trust, comply with regulatory and policy changes, and act as external validation. In this paper, we focus on XAI methods for deep neural networks (DNNs) because of DNNs' use in decision-making and inherent opacity. We explore the types of questions that explanatory DNN systems can answer and discuss challenges in building explanatory systems that provide outside explanations for societal requirements and benefit.",
    "lastUpdated": "2019-01-19T17:33:10Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1901.06560v1"
  },
  {
    "title": "Examining the Presence of Gender Bias in Customer Reviews Using Word Embedding",
    "authors": [
      "A. Mishra",
      "H. Mishra",
      "S. Rathee"
    ],
    "abstract": "Humans have entered the age of algorithms. Each minute, algorithms shape countless preferences from suggesting a product to a potential life partner. In the marketplace algorithms are trained to learn consumer preferences from customer reviews because user-generated reviews are considered the voice of customers and a valuable source of information to firms. Insights mined from reviews play an indispensable role in several business activities ranging from product recommendation, targeted advertising, promotions, segmentation etc. In this research, we question whether reviews might hold stereotypic gender bias that algorithms learn and propagate Utilizing data from millions of observations and a word embedding approach, GloVe, we show that algorithms designed to learn from human language output also learn gender bias. We also examine why such biases occur: whether the bias is caused because of a negative bias against females or a positive bias for males. We examine the impact of gender bias in reviews on choice and conclude with policy implications for female consumers, especially when they are unaware of the bias, and the ethical implications for firms.",
    "lastUpdated": "2019-02-01T18:36:09Z",
    "categories": [
      "cs.CL"
    ],
    "url": "http://arxiv.org/abs/1902.00496v1"
  },
  {
    "title": "Motion Scaling Solutions for Improved Performance in High Delay Surgical Teleoperation",
    "authors": [
      "Florian Richter",
      "Ryan K. Orosco",
      "Michael C. Yip"
    ],
    "abstract": "Robotic teleoperation brings great potential for advances within the field of surgery. The ability of a surgeon to reach patient remotely opens exciting opportunities. Early experience with telerobotic surgery has been interesting, but the clinical feasibility remains out of reach, largely due to the deleterious effects of communication delays. Teleoperation tasks are significantly impacted by unavoidable signal latency, which directly results in slower operations, less precision in movements, and increased human errors. Introducing significant changes to the surgical workflow, for example by introducing semi-automation or self-correction, present too significant a technological and ethical burden for commercial surgical robotic systems to adopt. In this paper, we present three simple and intuitive motion scaling solutions to combat teleoperated robotic systems under delay and help improve operator accuracy. Motion scaling offers potentially improved user performance and reduction in errors with minimal change to the underlying teleoperation architecture. To validate the use of motion scaling as a performance enhancer in telesurgery, we conducted a user study with 17 participants, and our results show that the proposed solutions do indeed reduce the error rate when operating under high delay.",
    "lastUpdated": "2019-02-08T20:51:42Z",
    "categories": [
      "cs.RO"
    ],
    "url": "http://arxiv.org/abs/1902.03290v1"
  },
  {
    "title": "Crowd Work on a CV? Understanding How AMT Fits into Turkers' Career Goals and Professional Profiles",
    "authors": [
      "Anna Kasunic",
      "Chun-Wei Chiang",
      "Geoff Kaufman",
      "Saiph Savage"
    ],
    "abstract": "In 2013, scholars laid out a framework for a sustainable, ethical future of crowd work, recommending career ladders so that crowd work can lead to career advancement and more economic mobility. Five years later, we consider this vision in the context of Amazon Mechanical Turk (AMT). To understand how workers currently view their experiences on AMT, and how they publicly present and share these experiences in their professional lives, we conducted a survey study with workers on AMT (n=98). The survey we administered included a combination of multiple choice, binary, and open-ended (short paragraph) items gauging Turkers' perceptions of their experiences on AMT within the context of their broader work experience and career goals. This work extends existing understandings of who crowd workers are and why they crowd work by seeking to better understand how crowd work factors into Turkers' professional profiles, and how we can subsequently better support crowd workers in their career advancement. Our survey results can inform the design of better tools to empower crowd workers in their professional development both inside and outside of AMT.",
    "lastUpdated": "2019-02-13T17:22:41Z",
    "categories": [
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/1902.05361v1"
  },
  {
    "title": "An Exploration of User and Bystander Attitudes About Mobile Live-Streaming Video",
    "authors": [
      "Cori Faklaris",
      "Asa Blevins",
      "Matthew O'Haver",
      "Neha Singhal",
      "Francesco Cafaro"
    ],
    "abstract": "Thanks to mobile apps such as Periscope and Facebook Live, live-streaming video is having a moment again. It has not been clear, however, to what extent the current ubiquity of smartphones is impacting this technology's acceptance in everyday social situations and how mobile contexts or affordances will affect and be affected by shifts in social norms and policy debates regarding privacy, surveillance and intellectual property. This ethnographic-style research explores familiarity with and attitudes about mobile live-streaming video and related legal and ethical issues among a sample of \"Middle America\" participants at two typical outdoor social events: sports tailgating and a rooftop party. In situ observations of n=110 bystanders to the use of a smartphone, including interviews with n=20, revealed that many are not fully aware of when their image or speech is being live-streamed in a casual context and want stronger notifications of and ability to consent to such broadcasting.",
    "lastUpdated": "2019-02-18T17:45:31Z",
    "categories": [
      "cs.HC",
      "K.4.0"
    ],
    "url": "http://arxiv.org/abs/1902.06671v1"
  },
  {
    "title": "Conservative Agency via Attainable Utility Preservation",
    "authors": [
      "Alexander Matt Turner",
      "Dylan Hadfield-Menell",
      "Prasad Tadepalli"
    ],
    "abstract": "Reward functions are easy to misspecify; although designers can make corrections after observing mistakes, an agent pursuing a misspecified reward function can irreversibly change the state of its environment. If that change precludes optimization of the correctly specified reward function, then correction is futile. For example, a robotic factory assistant could break expensive equipment due to a reward misspecification; even if the designers immediately correct the reward function, the damage is done. To mitigate this risk, we introduce an approach that balances optimization of the primary reward function with preservation of the ability to optimize auxiliary reward functions. Surprisingly, even when the auxiliary reward functions are randomly generated and therefore uninformative about the correctly specified reward function, this approach induces conservative, effective behavior.",
    "lastUpdated": "2020-06-10T15:10:04Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1902.09725v3"
  },
  {
    "title": "Degenerate Feedback Loops in Recommender Systems",
    "authors": [
      "Ray Jiang",
      "Silvia Chiappa",
      "Tor Lattimore",
      "András György",
      "Pushmeet Kohli"
    ],
    "abstract": "Machine learning is used extensively in recommender systems deployed in products. The decisions made by these systems can influence user beliefs and preferences which in turn affect the feedback the learning system receives - thus creating a feedback loop. This phenomenon can give rise to the so-called \"echo chambers\" or \"filter bubbles\" that have user and societal implications. In this paper, we provide a novel theoretical analysis that examines both the role of user dynamics and the behavior of recommender systems, disentangling the echo chamber from the filter bubble effect. In addition, we offer practical solutions to slow down system degeneracy. Our study contributes toward understanding and developing solutions to commonly cited issues in the complex temporal scenario, an area that is still largely unexplored.",
    "lastUpdated": "2019-03-27T11:30:57Z",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1902.10730v3"
  },
  {
    "title": "Dungeons for Science: Mapping Belief Places and Spaces",
    "authors": [
      "Aaron Dant",
      "Philip Feldman",
      "Wayne Lutters"
    ],
    "abstract": "Tabletop fantasy role-playing games (TFRPGs) have existed in offline and online contexts for many decades, yet are rarely featured in scientific literature. This paper presents a case study where TFRPGs were used to generate and collect data for maps of belief environments using fiction co-created by multiple small groups of online tabletop gamers. The affordances of TFRPGs allowed us to collect repeatable, targeted data in online field conditions. These data not only included terms that allowed us to build our maps, but also to explore nuanced ethical problems from a situated, collaborative perspective.",
    "lastUpdated": "2019-07-09T09:45:16Z",
    "categories": [
      "cs.CY",
      "cs.SI",
      "J.4; H.5.1; H.5.3; I.3.0; K.4.3; K.8.0"
    ],
    "url": "http://arxiv.org/abs/1904.05216v4"
  },
  {
    "title": "Robust Blocked Response-Adaptive Randomization Designs",
    "authors": [
      "Thevaa Chandereng",
      "Rick Chappell"
    ],
    "abstract": "In most clinical trials, patients are randomized with equal probability among treatments to obtain an unbiased estimate of the treatment effect. Response-adaptive randomization (RAR) has been proposed for ethical reasons, where the randomization ratio is tilted successively to favor the better performing treatment. However, the substantial disagreement regarding bias due to time-trends in adaptive randomization is not fully recognized. The type-I error is inflated in the traditional Bayesian RAR approaches when a time-trend is present. In our approach, patients are assigned in blocks and the randomization ratio is recomputed for blocks rather than traditional adaptive randomization where it is done per patient. We further investigate the design with a range of scenarios for both frequentist and Bayesian designs. We compare our method with equal randomization and with different numbers of blocks including the traditional RAR design where randomization ratio is altered patient by patient basis. The analysis is stratified if there are two or more patients in each block. Small blocks should be avoided due to the possibility of not acquiring any information from the $\\mu_i$. On the other hand, RAR with large blocks has a good balance between efficiency and treating more subjects to the better-performing treatment, while retaining blocked RAR's unique unbiasedness.",
    "lastUpdated": "2019-09-12T17:21:44Z",
    "categories": [
      "stat.AP"
    ],
    "url": "http://arxiv.org/abs/1904.07758v2"
  },
  {
    "title": "On Social Machines for Algorithmic Regulation",
    "authors": [
      "Nello Cristianini",
      "Teresa Scantamburlo"
    ],
    "abstract": "Autonomous mechanisms have been proposed to regulate certain aspects of society and are already being used to regulate business organisations. We take seriously recent proposals for algorithmic regulation of society, and we identify the existing technologies that can be used to implement them, most of them originally introduced in business contexts. We build on the notion of 'social machine' and we connect it to various ongoing trends and ideas, including crowdsourced task-work, social compiler, mechanism design, reputation management systems, and social scoring. After showing how all the building blocks of algorithmic regulation are already well in place, we discuss possible implications for human autonomy and social order. The main contribution of this paper is to identify convergent social and technical trends that are leading towards social regulation by algorithms, and to discuss the possible social, political, and ethical consequences of taking this path.",
    "lastUpdated": "2019-04-30T15:31:09Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1904.13316v1"
  },
  {
    "title": "Mapping Missing Population in Rural India: A Deep Learning Approach with Satellite Imagery",
    "authors": [
      "Wenjie Hu",
      "Jay Harshadbhai Patel",
      "Zoe-Alanah Robert",
      "Paul Novosad",
      "Samuel Asher",
      "Zhongyi Tang",
      "Marshall Burke",
      "David Lobell",
      "Stefano Ermon"
    ],
    "abstract": "Millions of people worldwide are absent from their country's census. Accurate, current, and granular population metrics are critical to improving government allocation of resources, to measuring disease control, to responding to natural disasters, and to studying any aspect of human life in these communities. Satellite imagery can provide sufficient information to build a population map without the cost and time of a government census. We present two Convolutional Neural Network (CNN) architectures which efficiently and effectively combine satellite imagery inputs from multiple sources to accurately predict the population density of a region. In this paper, we use satellite imagery from rural villages in India and population labels from the 2011 SECC census. Our best model achieves better performance than previous papers as well as LandScan, a community standard for global population distribution.",
    "lastUpdated": "2019-05-04T18:33:22Z",
    "categories": [
      "cs.CV",
      "eess.IV",
      "I.2.10; I.2.6; J.2; J.4"
    ],
    "url": "http://arxiv.org/abs/1905.02196v1"
  },
  {
    "title": "Integrating Artificial Intelligence into Weapon Systems",
    "authors": [
      "Philip Feldman",
      "Aaron Dant",
      "Aaron Massey"
    ],
    "abstract": "The integration of Artificial Intelligence (AI) into weapon systems is one of the most consequential tactical and strategic decisions in the history of warfare. Current AI development is a remarkable combination of accelerating capability, hidden decision mechanisms, and decreasing costs. Implementation of these systems is in its infancy and exists on a spectrum from resilient and flexible to simplistic and brittle. Resilient systems should be able to effectively handle the complexities of a high-dimensional battlespace. Simplistic AI implementations could be manipulated by an adversarial AI that identifies and exploits their weaknesses. In this paper, we present a framework for understanding the development of dynamic AI/ML systems that interactively and continuously adapt to their user's needs. We explore the implications of increasingly capable AI in the kill chain and how this will lead inevitably to a fully automated, always on system, barring regulation by treaty. We examine the potential of total integration of cyber and physical security and how this likelihood must inform the development of AI-enabled systems with respect to the \"fog of war\", human morals, and ethics.",
    "lastUpdated": "2019-05-10T00:38:35Z",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.RO",
      "I.2.0; K.4.1; J.7"
    ],
    "url": "http://arxiv.org/abs/1905.03899v1"
  },
  {
    "title": "Optimizing Interim Analysis Timing for Bayesian Adaptive Commensurate Designs",
    "authors": [
      "Xiao Wu",
      "Yi Xu",
      "Bradley P. Carlin"
    ],
    "abstract": "In developing products for rare diseases, statistical challenges arise due to the limited number of patients available for participation in drug trials and other clinical research. Bayesian adaptive clinical trial designs offer the possibility of increased statistical efficiency, reduced development cost and ethical hazard prevention via their incorporation of evidence from external sources (historical data, expert opinions, and real-world evidence), and flexibility in the specification of interim looks. In this paper, we propose a novel Bayesian adaptive commensurate design that borrows adaptively from historical information and also uses a particular payoff function to optimize the timing of the study's interim analysis. The trial payoff is a function of how many samples can be saved via early stopping and the probability of making correct early decisions for either futility or efficacy. We calibrate our Bayesian algorithm to have acceptable long-run frequentist properties (Type I error and power) via simulation at the design stage. We illustrate our approach using a pediatric trial design setting testing the effect of a new drug for a rare genetic disease. The optimIA R package available at https://github.com/wxwx1993/Bayesian_IA_Timing provides an easy-to-use implementation of our approach.",
    "lastUpdated": "2019-09-18T04:23:06Z",
    "categories": [
      "stat.AP",
      "stat.CO",
      "stat.ME"
    ],
    "url": "http://arxiv.org/abs/1905.07456v2"
  },
  {
    "title": "CERTIFAI: Counterfactual Explanations for Robustness, Transparency, Interpretability, and Fairness of Artificial Intelligence models",
    "authors": [
      "Shubham Sharma",
      "Jette Henderson",
      "Joydeep Ghosh"
    ],
    "abstract": "As artificial intelligence plays an increasingly important role in our society, there are ethical and moral obligations for both businesses and researchers to ensure that their machine learning models are designed, deployed, and maintained responsibly. These models need to be rigorously audited for fairness, robustness, transparency, and interpretability. A variety of methods have been developed that focus on these issues in isolation, however, managing these methods in conjunction with model development can be cumbersome and timeconsuming. In this paper, we introduce a unified and model-agnostic approach to address these issues: Counterfactual Explanations for Robustness, Transparency, Interpretability, and Fairness of Artificial Intelligence models (CERTIFAI). Unlike previous methods in this domain, CERTIFAI is a general tool that can be applied to any black-box model and any type of input data. Given a model and an input instance, CERTIFAI uses a custom genetic algorithm to generate counterfactuals: instances close to the input that change the prediction of the model. We demonstrate how these counterfactuals can be used to examine issues of robustness, interpretability, transparency, and fairness. Additionally, we introduce CERScore, the first black-box model robustness score that performs comparably to methods that have access to model internals.",
    "lastUpdated": "2019-05-20T03:15:06Z",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1905.07857v1"
  },
  {
    "title": "Digital Normativity: A challenge for human subjectivization and free will",
    "authors": [
      "Éric Fourneret",
      "Blaise Yvert"
    ],
    "abstract": "Over the past decade, artificial intelligence has demonstrated its efficiency in many different applications and a huge number of algorithms have become central and ubiquitous in our life. Their growing interest is essentially based on their capability to synthesize and process large amounts of data, and to help humans making decisions in a world of increasing complexity. Yet, the effectiveness of algorithms in bringing more and more relevant recommendations to humans may start to compete with human-alone decisions based on values other than pure efficacy. Here, we examine this tension in light of the emergence of several forms of digital normativity, and analyze how this normative role of AI may influence the ability of humans to remain subject of their life. The advent of AI technology imposes a need to achieve a balance between concrete material progress and progress of the mind to avoid any form of servitude. It has become essential that an ethical reflection accompany the current developments of intelligent algorithms beyond the sole question of their social acceptability. Such reflection should be anchored where AI technologies are being developed as well as in educational programs where their implications can be explained.",
    "lastUpdated": "2019-05-23T15:53:21Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1905.09735v1"
  },
  {
    "title": "Tracing Antisemitic Language Through Diachronic Embedding Projections: France 1789-1914",
    "authors": [
      "Rocco Tripodi",
      "Massimo Warglien",
      "Simon Levis Sullam",
      "Deborah Paci"
    ],
    "abstract": "We investigate some aspects of the history of antisemitism in France, one of the cradles of modern antisemitism, using diachronic word embeddings. We constructed a large corpus of French books and periodicals issues that contain a keyword related to Jews and performed a diachronic word embedding over the 1789-1914 period. We studied the changes over time in the semantic spaces of 4 target words and performed embedding projections over 6 streams of antisemitic discourse. This allowed us to track the evolution of antisemitic bias in the religious, economic, socio-politic, racial, ethic and conspiratorial domains. Projections show a trend of growing antisemitism, especially in the years starting in the mid-80s and culminating in the Dreyfus affair. Our analysis also allows us to highlight the peculiar adverse bias towards Judaism in the broader context of other religions.",
    "lastUpdated": "2019-06-04T13:54:47Z",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DL"
    ],
    "url": "http://arxiv.org/abs/1906.01440v1"
  },
  {
    "title": "Blocking Mechanism of Porn Website in India: Claim and Truth",
    "authors": [
      "Saurabh Pandey",
      "Dr. Harish Sharma"
    ],
    "abstract": "In last few years, the addiction of internet is apparently recognized as the serious threat to the health of society. This internet addiction gives an impetus to pornographic addiction because most of the pornographic content is accessible through internet. There have been ethical concerns on blocking the contents over internet. In India Uttarakhand High court has taken initiative for the blocking of pornographic content over internet. Technocrats are coming up with various innovative mechanisms to block the content over internet with various techniques, although long ago in 2015. The Supreme Court of India has already asked to block some of the websites but it could not be materialized. The focus of this research paper is to review the effectiveness of blocking existing web content blocking mechanism of pornographic websites in Indian context.",
    "lastUpdated": "2019-06-25T08:31:41Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1906.10379v1"
  },
  {
    "title": "Towards Interpretable Deep Extreme Multi-label Learning",
    "authors": [
      "Yihuang Kang",
      "I-Ling Cheng",
      "Wenjui Mao",
      "Bowen Kuo",
      "Pei-Ju Lee"
    ],
    "abstract": "Many Machine Learning algorithms, such as deep neural networks, have long been criticized for being \"black-boxes\"-a kind of models unable to provide how it arrive at a decision without further efforts to interpret. This problem has raised concerns on model applications' trust, safety, nondiscrimination, and other ethical issues. In this paper, we discuss the machine learning interpretability of a real-world application, eXtreme Multi-label Learning (XML), which involves learning models from annotated data with many pre-defined labels. We propose a two-step XML approach that combines deep non-negative autoencoder with other multi-label classifiers to tackle different data applications with a large number of labels. Our experimental result shows that the proposed approach is able to cope with many-label problems as well as to provide interpretable label hierarchies and dependencies that helps us understand how the model recognizes the existences of objects in an image.",
    "lastUpdated": "2019-07-03T03:51:31Z",
    "categories": [
      "stat.ML",
      "cs.LG",
      "stat.AP"
    ],
    "url": "http://arxiv.org/abs/1907.01723v1"
  },
  {
    "title": "Sim2real transfer learning for 3D human pose estimation: motion to the rescue",
    "authors": [
      "Carl Doersch",
      "Andrew Zisserman"
    ],
    "abstract": "Synthetic visual data can provide practically infinite diversity and rich labels, while avoiding ethical issues with privacy and bias. However, for many tasks, current models trained on synthetic data generalize poorly to real data. The task of 3D human pose estimation is a particularly interesting example of this sim2real problem, because learning-based approaches perform reasonably well given real training data, yet labeled 3D poses are extremely difficult to obtain in the wild, limiting scalability. In this paper, we show that standard neural-network approaches, which perform poorly when trained on synthetic RGB images, can perform well when the data is pre-processed to extract cues about the person's motion, notably as optical flow and the motion of 2D keypoints. Therefore, our results suggest that motion can be a simple way to bridge a sim2real gap when video is available. We evaluate on the 3D Poses in the Wild dataset, the most challenging modern benchmark for 3D pose estimation, where we show full 3D mesh recovery that is on par with state-of-the-art methods trained on real 3D sequences, despite training only on synthetic humans from the SURREAL dataset.",
    "lastUpdated": "2019-11-14T15:36:28Z",
    "categories": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1907.02499v2"
  },
  {
    "title": "Manipulating the Online Marketplace of Ideas",
    "authors": [
      "Xiaodan Lou",
      "Alessandro Flammini",
      "Filippo Menczer"
    ],
    "abstract": "Social media, the modern marketplace of ideas, is vulnerable to manipulation. Deceptive inauthentic actors impersonate humans to amplify misinformation and influence public opinions. Little is known about the large-scale consequences of such operations, due to the ethical challenges posed by online experiments that manipulate human behavior. Here we introduce a model of information spreading where agents prefer quality information but have limited attention. We evaluate the impact of manipulation strategies aimed at degrading the overall quality of the information ecosystem. The model reproduces empirical patterns about amplification of low-quality information. We find that infiltrating a critical fraction of the network is more damaging than generating attention-grabbing content or targeting influentials. We discuss countermeasures suggested by these insights to increase the resilience of social media users to manipulation, and legal issues arising from regulations aimed at protecting human speech from suppression by inauthentic actors.",
    "lastUpdated": "2020-04-12T01:01:00Z",
    "categories": [
      "cs.CY",
      "cs.SI",
      "physics.soc-ph"
    ],
    "url": "http://arxiv.org/abs/1907.06130v2"
  },
  {
    "title": "The Elusive Model of Technology, Media, Social Development, and Financial Sustainability",
    "authors": [
      "Aaditeshwar Seth"
    ],
    "abstract": "We recount in this essay the decade-long story of Gram Vaani, a social enterprise with a vision to build appropriate ICTs (Information and Communication Technologies) for participatory media in rural and low-income settings, to bring about social development and community empowerment. Other social enterprises will relate to the learning gained and the strategic pivots that Gram Vaani had to undertake to survive and deliver on its mission, while searching for a robust financial sustainability model. While we believe the ideal model still remains elusive, we conclude this essay with an open question about the reason to differentiate between different kinds of enterprises - commercial or social, for-profit or not-for-profit - and argue that all enterprises should have an ethical underpinning to their work.",
    "lastUpdated": "2019-07-15T08:20:02Z",
    "categories": [
      "cs.CY",
      "cs.HC",
      "cs.SI"
    ],
    "url": "http://arxiv.org/abs/1907.06360v1"
  },
  {
    "title": "What do the founders of online communities owe to their users?",
    "authors": [
      "Cathy Chua",
      "Manny Rayner"
    ],
    "abstract": "We discuss the organisation of internet communities, focusing on what we call the principle of \"bait and switch\": founders of internet communities often find it advantageous to recruit members by promising inducements which are later not honoured. We look at some of the dilemmas and ways of attempting to resolve them through two paradigmatic examples, Wikispaces and Wordpress. Our analysis is to a large extent motivated by the demands of CALLector, a university-centred social network we are in the process of establishing. We consider the question of what ethical standards are imposed on universities engaged in this type of activity.",
    "lastUpdated": "2019-07-30T12:57:33Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1908.02121v1"
  },
  {
    "title": "Adapting SQuaRE for Quality Assessment of Artificial Intelligence Systems",
    "authors": [
      "Hiroshi Kuwajima",
      "Fuyuki Ishikawa"
    ],
    "abstract": "More and more software practitioners are tackling towards industrial applications of artificial intelligence (AI) systems, especially those based on machine learning (ML). However, many of existing principles and approaches to traditional systems do not work effectively for the system behavior obtained by training not by logical design. In addition, unique kinds of requirements are emerging such as fairness and explainability. To provide clear guidance to understand and tackle these difficulties, we present an analysis on what quality concepts we should evaluate for AI systems. We base our discussion on ISO/IEC 25000 series, known as SQuaRE, and identify how it should be adapted for the unique nature of ML and $\\textit{Ethics guidelines for trustworthy AI}$ from European Commission. We thus provide holistic insights for quality of AI systems by incorporating the ML nature and AI ethics to the traditional software quality concepts.",
    "lastUpdated": "2019-07-31T18:31:06Z",
    "categories": [
      "cs.CY",
      "cs.LG",
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/1908.02134v1"
  },
  {
    "title": "A 20-Year Community Roadmap for Artificial Intelligence Research in the US",
    "authors": [
      "Yolanda Gil",
      "Bart Selman"
    ],
    "abstract": "Decades of research in artificial intelligence (AI) have produced formidable technologies that are providing immense benefit to industry, government, and society. AI systems can now translate across multiple languages, identify objects in images and video, streamline manufacturing processes, and control cars. The deployment of AI systems has not only created a trillion-dollar industry that is projected to quadruple in three years, but has also exposed the need to make AI systems fair, explainable, trustworthy, and secure. Future AI systems will rightfully be expected to reason effectively about the world in which they (and people) operate, handling complex tasks and responsibilities effectively and ethically, engaging in meaningful communication, and improving their awareness through experience. Achieving the full potential of AI technologies poses research challenges that require a radical transformation of the AI research enterprise, facilitated by significant and sustained investment. These are the major recommendations of a recent community effort coordinated by the Computing Community Consortium and the Association for the Advancement of Artificial Intelligence to formulate a Roadmap for AI research and development over the next two decades.",
    "lastUpdated": "2019-08-07T13:24:36Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1908.02624v1"
  },
  {
    "title": "Tackling Online Abuse: A Survey of Automated Abuse Detection Methods",
    "authors": [
      "Pushkar Mishra",
      "Helen Yannakoudakis",
      "Ekaterina Shutova"
    ],
    "abstract": "Abuse on the Internet represents an important societal problem of our time. Millions of Internet users face harassment, racism, personal attacks, and other types of abuse on online platforms. The psychological effects of such abuse on individuals can be profound and lasting. Consequently, over the past few years, there has been a substantial research effort towards automated abuse detection in the field of natural language processing (NLP). In this paper, we present a comprehensive survey of the methods that have been proposed to date, thus providing a platform for further development of this area. We describe the existing datasets and review the computational approaches to abuse detection, analyzing their strengths and limitations. We discuss the main trends that emerge, highlight the challenges that remain, outline possible solutions, and propose guidelines for ethics and explainability",
    "lastUpdated": "2020-09-30T11:42:04Z",
    "categories": [
      "cs.CL"
    ],
    "url": "http://arxiv.org/abs/1908.06024v2"
  },
  {
    "title": "Bayesian leveraging of historical control data for a clinical trial with time-to-event endpoint",
    "authors": [
      "Satrajit Roychoudhury",
      "Beat Neuenschwander"
    ],
    "abstract": "The recent 21st Century Cures Act propagates innovations to accelerate the discovery, development, and delivery of 21st century cures. It includes the broader application of Bayesian statistics and the use of evidence from clinical expertise. An example of the latter is the use of trial-external (or historical) data, which promises more efficient or ethical trial designs. We propose a Bayesian meta-analytic approach to leveraging historical data for time-to-event endpoints, which are common in oncology and cardiovascular diseases. The approach is based on a robust hierarchical model for piecewise exponential data. It allows for various degrees of between trial-heterogeneity and for leveraging individual as well as aggregate data. An ovarian carcinoma trial and a non-small-cell cancer trial illustrate methodological and practical aspects of leveraging historical data for the analysis and design of time-to-event trials.",
    "lastUpdated": "2020-02-07T01:54:24Z",
    "categories": [
      "stat.AP"
    ],
    "url": "http://arxiv.org/abs/1908.07265v2"
  },
  {
    "title": "Fairness Issues in AI Systems that Augment Sensory Abilities",
    "authors": [
      "Leah Findlater",
      "Steven Goodman",
      "Yuhang Zhao",
      "Shiri Azenkot",
      "Margot Hanley"
    ],
    "abstract": "Systems that augment sensory abilities are increasingly employing AI and machine learning (ML) approaches, with applications ranging from object recognition and scene description tools for blind users to sound awareness tools for d/Deaf users. However, unlike many other AI-enabled technologies, these systems provide information that is already available to non-disabled people. In this paper, we discuss unique AI fairness challenges that arise in this context, including accessibility issues with data and models, ethical implications in deciding what sensory information to convey to the user, and privacy concerns both for the primary user and for others.",
    "lastUpdated": "2019-08-16T20:25:49Z",
    "categories": [
      "cs.CY",
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/1908.07333v1"
  },
  {
    "title": "Interpreting Social Respect: A Normative Lens for ML Models",
    "authors": [
      "Ben Hutchinson",
      "KJ Pittl",
      "Margaret Mitchell"
    ],
    "abstract": "Machine learning is often viewed as an inherently value-neutral process: statistical tendencies in the training inputs are \"simply\" used to generalize to new examples. However when models impact social systems such as interactions between humans, these patterns learned by models have normative implications. It is important that we ask not only \"what patterns exist in the data?\", but also \"how do we want our system to impact people?\" In particular, because minority and marginalized members of society are often statistically underrepresented in data sets, models may have undesirable disparate impact on such groups. As such, objectives of social equity and distributive justice require that we develop tools for both identifying and interpreting harms introduced by models.",
    "lastUpdated": "2019-08-01T23:33:28Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1908.07336v1"
  },
  {
    "title": "Artificial Intelligence Fairness in the Context of Accessibility Research on Intelligent Systems for People who are Deaf or Hard of Hearing",
    "authors": [
      "Sushant Kafle",
      "Abraham Glasser",
      "Sedeeq Al-khazraji",
      "Larwan Berke",
      "Matthew Seita",
      "Matt Huenerfauth"
    ],
    "abstract": "We discuss issues of Artificial Intelligence (AI) fairness for people with disabilities, with examples drawn from our research on human-computer interaction (HCI) for AI-based systems for people who are Deaf or Hard of Hearing (DHH). In particular, we discuss the need for inclusion of data from people with disabilities in training sets, the lack of interpretability of AI systems, ethical responsibilities of access technology researchers and companies, the need for appropriate evaluation metrics for AI-based access technologies (to determine if they are ready to be deployed and if they can be trusted by users), and the ways in which AI systems influence human behavior and influence the set of abilities needed by users to successfully interact with computing systems.",
    "lastUpdated": "2019-09-02T16:56:28Z",
    "categories": [
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/1908.10414v2"
  },
  {
    "title": "Pretrained AI Models: Performativity, Mobility, and Change",
    "authors": [
      "Lav R. Varshney",
      "Nitish Shirish Keskar",
      "Richard Socher"
    ],
    "abstract": "The paradigm of pretrained deep learning models has recently emerged in artificial intelligence practice, allowing deployment in numerous societal settings with limited computational resources, but also embedding biases and enabling unintended negative uses. In this paper, we treat pretrained models as objects of study and discuss the ethical impacts of their sociological position. We discuss how pretrained models are developed and compared under the common task framework, but that this may make self-regulation inadequate. Further how pretrained models may have a performative effect on society that exacerbates biases. We then discuss how pretrained models move through actor networks as a kind of computationally immutable mobile, but that users also act as agents of technological change by reinterpreting them via fine-tuning and transfer. We further discuss how users may use pretrained models in malicious ways, drawing a novel connection between the responsible innovation and user-centered innovation literatures. We close by discussing how this sociological understanding of pretrained models can inform AI governance frameworks for fairness, accountability, and transparency.",
    "lastUpdated": "2019-09-07T15:40:22Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1909.03290v1"
  },
  {
    "title": "Attesting Biases and Discrimination using Language Semantics",
    "authors": [
      "Xavier Ferrer Aran",
      "Jose M. Such",
      "Natalia Criado"
    ],
    "abstract": "AI agents are increasingly deployed and used to make automated decisions that affect our lives on a daily basis. It is imperative to ensure that these systems embed ethical principles and respect human values. We focus on how we can attest to whether AI agents treat users fairly without discriminating against particular individuals or groups through biases in language. In particular, we discuss human unconscious biases, how they are embedded in language, and how AI systems inherit those biases by learning from and processing human language. Then, we outline a roadmap for future research to better understand and attest problematic AI biases derived from language.",
    "lastUpdated": "2019-09-10T10:12:01Z",
    "categories": [
      "cs.AI",
      "cs.CL",
      "68T50"
    ],
    "url": "http://arxiv.org/abs/1909.04386v1"
  },
  {
    "title": "Methods, Models, and the Evolution of Moral Psychology",
    "authors": [
      "Cailin O'Connor"
    ],
    "abstract": "Why are we good? Why are we bad? Questions regarding the evolution of morality have spurred an astoundingly large interdisciplinary literature. Some significant subset of this body of work addresses questions regarding our moral psychology: how did humans evolve the psychological properties which underpin our systems of ethics and morality? Here I do three things. First, I discuss some methodological issues, and defend particularly effective methods for addressing many research questions in this area. Second, I give an in-depth example, describing how an explanation can be given for the evolution of guilt---one of the core moral emotions---using the methods advocated here. Last, I lay out which sorts of strategic scenarios generally are the ones that our moral psychology evolved to `solve', and thus which models are the most useful in further exploring this evolution.",
    "lastUpdated": "2019-09-09T22:01:12Z",
    "categories": [
      "econ.GN",
      "q-fin.EC"
    ],
    "url": "http://arxiv.org/abs/1909.09198v1"
  },
  {
    "title": "Challenges of Designing and Developing Tangible Interfaces for Mental Well-being",
    "authors": [
      "Kieran Woodward",
      "Eiman Kanjo",
      "David Brown"
    ],
    "abstract": "Mental well-being technologies possess many qualities that give them the potential to help people receive assessment and treatment who may otherwise not receive help due to fear of stigma or lack of resources. The combination of advances in sensors, microcontrollers and machine learning is leading to the emergence of dedicated tangible interfaces to monitor and promote positive mental well-being. However, there are key technical, ergonomic and aesthetic challenges to be overcome in order to make these interfaces effective and respond to users' needs. In this paper, the barriers to develop mental well-being tangible interfaces are discussed by identifying and examining the recent technological challenges machine learning, sensors, microcontrollers and batteries create.User-oriented challenges that face the development of mental well-being technologies are then considered ranging from user engagement during co-design and trials to ethical and privacy concerns.",
    "lastUpdated": "2019-06-17T09:03:58Z",
    "categories": [
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/1909.11752v1"
  },
  {
    "title": "Design of fractional-order controllers for simultaneous control of Mean Arterial Blood Pressure and Cardiac Output: a simulation study",
    "authors": [
      "Shaival H. Nagarsheth",
      "Shambhu N. Sharma"
    ],
    "abstract": "This paper presents a fractional-order framework for control of blood pressure. A new perspective is explored to control the blood pressure in lieu of the conventional control framework. A multi-variable scenario is adopted to control two outputs: Mean Arterial Blood Pressure (MABP) and Cardiac Output (CO) simultaneously.",
    "lastUpdated": "2020-03-11T15:53:06Z",
    "categories": [
      "math.OC",
      "90C31-Sensitivity, stability, parametric optimization,\n  26A33-Fractional derivatives and integrals, 93B52-Feedbackcontrol,\n  92C30-Physiology, 92C50-Medicalapplication"
    ],
    "url": "http://arxiv.org/abs/1910.01530v3"
  },
  {
    "title": "Critical Requirements Engineering in Practice",
    "authors": [
      "Leticia Duboc",
      "Curtis McCord",
      "Christoph Becker",
      "Syed Ishtiaque Ahmed"
    ],
    "abstract": "The design of software systems inevitably enacts normative boundaries around the site of intervention. These boundaries are, in part, a reflection of the values, ethics, power, and politics of the situation and the process of design itself. This paper argues that Requirements Engineering (RE) require more robust frameworks and techniques to navigate the values implicit in systems design work. To this end, we present the findings from a case of action research where we employed Critical Systems Heuristics (CSH), a framework from Critical Systems Thinking (CST) during requirements gathering for Homesound, a system to safeguard elderly people living alone while protecting their autonomy. We use categories from CSH to inform expert interviews and reflection, showing how CSH can be simply combined with RE techniques (such as the Volere template) to explore and reveal the value-judgements underlying requirements.",
    "lastUpdated": "2019-10-03T18:38:36Z",
    "categories": [
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/1910.01678v1"
  },
  {
    "title": "Challenges of Human-Aware AI Systems",
    "authors": [
      "Subbarao Kambhampati"
    ],
    "abstract": "From its inception, AI has had a rather ambivalent relationship to humans---swinging between their augmentation and replacement. Now, as AI technologies enter our everyday lives at an ever increasing pace, there is a greater need for AI systems to work synergistically with humans. To do this effectively, AI systems must pay more attention to aspects of intelligence that helped humans work with each other---including social intelligence. I will discuss the research challenges in designing such human-aware AI systems, including modeling the mental states of humans in the loop, recognizing their desires and intentions, providing proactive support, exhibiting explicable behavior, giving cogent explanations on demand, and engendering trust. I will survey the progress made so far on these challenges, and highlight some promising directions. I will also touch on the additional ethical quandaries that such systems pose. I will end by arguing that the quest for human-aware AI systems broadens the scope of AI enterprise, necessitates and facilitates true inter-disciplinary collaborations, and can go a long way towards increasing public acceptance of AI technologies.",
    "lastUpdated": "2019-10-15T22:34:50Z",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1910.07089v1"
  },
  {
    "title": "The other side of the Coin: Risks of the Libra Blockchain",
    "authors": [
      "Louis Abraham",
      "Dominique Guégan"
    ],
    "abstract": "Libra was presented as a cryptocurrency on June 18, 2019 by Facebook. On the same day, Facebook announced plans for Calibra, a subsidiary in charge of the development of an electronic wallet and financial services. In view of the primary risk of sovereignty posed by the creation of Libra, regulators and Central Banks quickly took very clear positions against the project and expressed a lot of questions focusing on regulation aspects and national sovereignty. The purpose of this paper is to provide a holistic analysis of the project encompassing several aspects of its implementation and the issues it raises. We address a set of questions that are part of the cryptocurrency environment and blockchain technology that support the Libra project. We describe the governance of the project based on two levels, one for the Association and the other for the Libra Blockchain. We identify the main risks considering at the same time political, financial, economic, technological and ethical risks. We emphasize the difficulty to regulate such a project as it will depend on several countries whose legislations are very different. Finally, the future of this kind of projects is discussed through the emergence of Central Bank Digital Currencies.",
    "lastUpdated": "2020-01-24T09:47:41Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1910.07775v3"
  },
  {
    "title": "Building the National Radio Recordings Database: A Big Data Approach to Documenting Audio Heritage",
    "authors": [
      "Emily Goodmann",
      "Mark A. Matienzo",
      "Shawn VanCour",
      "William Vanden Dries"
    ],
    "abstract": "This paper traces strategies used by the Radio Preservation Task Force of the Library of Congress's National Recording Preservation Board to develop a publicly searchable database documenting extant radio materials held by collecting institutions throughout the country. Having aggregated metadata on 2,500 unique collections to date, the project has encountered a series of logistical challenges that are not only technical in nature but also institutional and social, raising critical issues involving organizational structure, political representation, and the ethics of data access. As the project continues to expand and evolve, lessons from its early development offer valuable reminders of the human judgment, hidden labor, and interpersonal relations required for successful big data work.",
    "lastUpdated": "2019-11-12T00:59:54Z",
    "categories": [
      "cs.DL",
      "cs.CY",
      "H.3.7; K.4.1; J.5"
    ],
    "url": "http://arxiv.org/abs/1911.04625v1"
  },
  {
    "title": "Causal inference using Bayesian non-parametric quasi-experimental design",
    "authors": [
      "Max Hinne",
      "Marcel A. J. van Gerven",
      "Luca Ambrogioni"
    ],
    "abstract": "The de facto standard for causal inference is the randomized controlled trial, where one compares an manipulated group with a control group in order to determine the effect of an intervention. However, this research design is not always realistically possible due to pragmatic or ethical concerns. In these situations, quasi-experimental designs may provide a solution, as these allow for causal conclusions at the cost of additional design assumptions. In this paper, we provide a framework for quasi-experimental design using Bayesian model comparison. We provide a theoretical motivation for a Gaussian process based approach, and demonstrate its convenient use in a number of simulations. Finally, we apply the framework to determine the effect the 2005 smoking ban in Sicily on the number of acute coronary events, and of the effect of an alleged historical phantom border in the Netherlands on Dutch voting behaviour.",
    "lastUpdated": "2020-07-16T15:17:40Z",
    "categories": [
      "stat.ME",
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1911.06722v2"
  },
  {
    "title": "Forbidden knowledge in machine learning -- Reflections on the limits of research and publication",
    "authors": [
      "Thilo Hagendorff"
    ],
    "abstract": "Certain research strands can yield \"forbidden knowledge\". This term refers to knowledge that is considered too sensitive, dangerous or taboo to be produced or shared. Discourses about such publication restrictions are already entrenched in scientific fields like IT security, synthetic biology or nuclear physics research. This paper makes the case for transferring this discourse to machine learning research. Some machine learning applications can very easily be misused and unfold harmful consequences, for instance with regard to generative video or text synthesis, personality analysis, behavior manipulation, software vulnerability detection and the like. Up to now, the machine learning research community embraces the idea of open access. However, this is opposed to precautionary efforts to prevent the malicious use of machine learning applications. Information about or from such applications may, if improperly disclosed, cause harm to people, organizations or whole societies. Hence, the goal of this work is to outline norms that can help to decide whether and when the dissemination of such information should be prevented. It proposes review parameters for the machine learning community to establish an ethical framework on how to deal with forbidden knowledge and dual-use applications.",
    "lastUpdated": "2019-11-19T21:43:06Z",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1911.08603v1"
  },
  {
    "title": "Targeting the Uniformly Most Powerful Unbiased Test in Sample Size Reassessment Adaptive Clinical Trials with Deep Learning",
    "authors": [
      "Tianyu Zhan",
      "Jian Kang"
    ],
    "abstract": "In recent pharmaceutical drug development, adaptive clinical trials become more and more appealing due to ethical considerations, and the ability to accommodate uncertainty while conducting the trial. Several methods have been proposed to optimize a certain study design within a class of candidates, but finding an optimal hypothesis testing strategy for a given design remains challenging, mainly due to the complex likelihood function involved. This problem is of great interest from both patient and sponsor perspectives, because the smallest sample size is required for the optimal hypothesis testing method to achieve a desired level of power. To address these issues, we propose a novel application of the deep neural network to construct the test statistics and the critical value with a controlled type I error rate in a computationally efficient manner. We apply the proposed method to a sample size reassessment confirmatory adaptive study MUSEC (MUltiple Sclerosis and Extract of Cannabis), demonstrating the proposed method outperforms the existing alternatives. Simulation studies are also performed to demonstrate that our proposed method essentially establishes the underlying uniformly most powerful (UMP) unbiased test in several non-adaptive designs.",
    "lastUpdated": "2019-12-16T15:08:24Z",
    "categories": [
      "stat.ME"
    ],
    "url": "http://arxiv.org/abs/1912.07433v1"
  },
  {
    "title": "Exploring AI Futures Through Role Play",
    "authors": [
      "Shahar Avin",
      "Ross Gruetzemacher",
      "James Fox"
    ],
    "abstract": "We present an innovative methodology for studying and teaching the impacts of AI through a role play game. The game serves two primary purposes: 1) training AI developers and AI policy professionals to reflect on and prepare for future social and ethical challenges related to AI and 2) exploring possible futures involving AI technology development, deployment, social impacts, and governance. While the game currently focuses on the inter relations between short --, mid and long term impacts of AI, it has potential to be adapted for a broad range of scenarios, exploring in greater depths issues of AI policy research and affording training within organizations. The game presented here has undergone two years of development and has been tested through over 30 events involving between 3 and 70 participants. The game is under active development, but preliminary findings suggest that role play is a promising methodology for both exploring AI futures and training individuals and organizations in thinking about, and reflecting on, the impacts of AI and strategic mistakes that can be avoided today.",
    "lastUpdated": "2019-12-19T00:41:11Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1912.08964v1"
  },
  {
    "title": "CAT(0) geometry, robots, and society",
    "authors": [
      "Federico Ardila"
    ],
    "abstract": "How do we move a robot efficiently from one position to another? To answer this question, we need to understand its configuration space, a 'map' where we can find every possible position of the robot. Unfortunately, these maps are very large, they live in high dimensions, and they are very difficult to visualize. Fortunately, for some discrete robots they are CAT(0) cubical complexes, a family of spaces with favorable properties. In this case, using ideas from combinatorics and geometric group theory, we can construct a 'remote control' to navigate these complicated maps, and move the robots optimally. Along the way, we face larger ethical questions that we cannot ignore.",
    "lastUpdated": "2020-08-06T19:05:36Z",
    "categories": [
      "math.HO",
      "cs.RO",
      "math.CO",
      "05-02, 67-02, 51F99, 68T40, 97A40, 97P70"
    ],
    "url": "http://arxiv.org/abs/1912.10007v2"
  },
  {
    "title": "Defining AI in Policy versus Practice",
    "authors": [
      "P. M. Krafft",
      "Meg Young",
      "Michael Katell",
      "Karen Huang",
      "Ghislain Bugingo"
    ],
    "abstract": "Recent concern about harms of information technologies motivate consideration of regulatory action to forestall or constrain certain developments in the field of artificial intelligence (AI). However, definitional ambiguity hampers the possibility of conversation about this urgent topic of public concern. Legal and regulatory interventions require agreed-upon definitions, but consensus around a definition of AI has been elusive, especially in policy conversations. With an eye towards practical working definitions and a broader understanding of positions on these issues, we survey experts and review published policy documents to examine researcher and policy-maker conceptions of AI. We find that while AI researchers favor definitions of AI that emphasize technical functionality, policy-makers instead use definitions that compare systems to human thinking and behavior. We point out that definitions adhering closely to the functionality of AI systems are more inclusive of technologies in use today, whereas definitions that emphasize human-like capabilities are most applicable to hypothetical future technologies. As a result of this gap, ethical and regulatory efforts may overemphasize concern about future technologies at the expense of pressing issues with existing deployed technologies.",
    "lastUpdated": "2019-12-23T20:18:21Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG",
      "physics.soc-ph"
    ],
    "url": "http://arxiv.org/abs/1912.11095v1"
  },
  {
    "title": "Detecting Deepfake-Forged Contents with Separable Convolutional Neural Network and Image Segmentation",
    "authors": [
      "Chia-Mu Yu",
      "Ching-Tang Chang",
      "Yen-Wu Ti"
    ],
    "abstract": "Recent advances in AI technology have made the forgery of digital images and videos easier, and it has become significantly more difficult to identify such forgeries. These forgeries, if disseminated with malicious intent, can negatively impact social and political stability, and pose significant ethical and legal challenges as well. Deepfake is a variant of auto-encoders that use deep learning techniques to identify and exchange images of a person's face in a picture or film. Deepfake can result in an erosion of public trust in digital images and videos, which has far-reaching effects on political and social stability. This study therefore proposes a solution for facial forgery detection to determine if a picture or film has ever been processed by Deepfake. The proposed solution reaches detection efficiency by using the recently proposed separable convolutional neural network (CNN) and image segmentation. In addition, this study also examined how different image segmentation methods affect detection results. Finally, the ensemble model is used to improve detection capabilities. Experiment results demonstrated the excellent performance of the proposed solution.",
    "lastUpdated": "2019-12-21T08:32:27Z",
    "categories": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1912.12184v1"
  },
  {
    "title": "U.S. Public Opinion on the Governance of Artificial Intelligence",
    "authors": [
      "Baobao Zhang",
      "Allan Dafoe"
    ],
    "abstract": "Artificial intelligence (AI) has widespread societal implications, yet social scientists are only beginning to study public attitudes toward the technology. Existing studies find that the public's trust in institutions can play a major role in shaping the regulation of emerging technologies. Using a large-scale survey (N=2000), we examined Americans' perceptions of 13 AI governance challenges as well as their trust in governmental, corporate, and multistakeholder institutions to responsibly develop and manage AI. While Americans perceive all of the AI governance issues to be important for tech companies and governments to manage, they have only low to moderate trust in these institutions to manage AI applications.",
    "lastUpdated": "2019-12-30T07:38:38Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1912.12835v1"
  },
  {
    "title": "Declarative Mechanism Design",
    "authors": [
      "Andrés García-Camino"
    ],
    "abstract": "Regulation of Multi-Agent Systems (MAS) and Declarative Electronic Institutions (DEIs) was a multidisciplinary research topic of the past decade involving (Physical and Software) Agents and Law since the beginning, but recently evolved towards News-claimed Robot Lawyer since 2016. One of these first proposals of restricting the behaviour of Software Agentswas Electronic Institutions.However, with the recent reformulation of Artificial Neural Networks (ANNs) as Deep Learning (DL), Security, Privacy,Ethical and Legal issues regarding the use of DL has raised concerns in the Artificial Intelligence (AI) Community. Now that the Regulation of MAS is almost correctly addressed, we propose the Regulation of Artificial Neural Networks as Agent-based Training of a special type of regulated Artificial Neural Network that we call Institutional Neural Network (INN).The main purpose of this paper is to bring attention to Artificial Teaching (AT) and to give a tentative answer showing a proof-of-concept implementation of Regulated Deep Learning (RDL). This paper introduces the former concept and provide sI, a language previously used to model declaratively and extend Electronic Institutions, as a means to regulate the execution of Artificial Neural Networks and their interactions with Artificial Teachers (ATs)",
    "lastUpdated": "2020-07-24T17:19:26Z",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.LO",
      "cs.MA",
      "cs.PL"
    ],
    "url": "http://arxiv.org/abs/1912.13122v3"
  },
  {
    "title": "Measuring Non-Expert Comprehension of Machine Learning Fairness Metrics",
    "authors": [
      "Debjani Saha",
      "Candice Schumann",
      "Duncan C. McElfresh",
      "John P. Dickerson",
      "Michelle L. Mazurek",
      "Michael Carl Tschantz"
    ],
    "abstract": "Bias in machine learning has manifested injustice in several areas, such as medicine, hiring, and criminal justice. In response, computer scientists have developed myriad definitions of fairness to correct this bias in fielded algorithms. While some definitions are based on established legal and ethical norms, others are largely mathematical. It is unclear whether the general public agrees with these fairness definitions, and perhaps more importantly, whether they understand these definitions. We take initial steps toward bridging this gap between ML researchers and the public, by addressing the question: does a lay audience understand a basic definition of ML fairness? We develop a metric to measure comprehension of three such definitions--demographic parity, equal opportunity, and equalized odds. We evaluate this metric using an online survey, and investigate the relationship between comprehension and sentiment, demographics, and the definition itself.",
    "lastUpdated": "2020-07-02T21:13:01Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2001.00089v3"
  },
  {
    "title": "Multi-Gradient Descent for Multi-Objective Recommender Systems",
    "authors": [
      "Nikola Milojkovic",
      "Diego Antognini",
      "Giancarlo Bergamin",
      "Boi Faltings",
      "Claudiu Musat"
    ],
    "abstract": "Recommender systems need to mirror the complexity of the environment they are applied in. The more we know about what might benefit the user, the more objectives the recommender system has. In addition there may be multiple stakeholders - sellers, buyers, shareholders - in addition to legal and ethical constraints. Simultaneously optimizing for a multitude of objectives, correlated and not correlated, having the same scale or not, has proven difficult so far. We introduce a stochastic multi-gradient descent approach to recommender systems (MGDRec) to solve this problem. We show that this exceeds state-of-the-art methods in traditional objective mixtures, like revenue and recall. Not only that, but through gradient normalization we can combine fundamentally different objectives, having diverse scales, into a single coherent framework. We show that uncorrelated objectives, like the proportion of quality products, can be improved alongside accuracy. Through the use of stochasticity, we avoid the pitfalls of calculating full gradients and provide a clear setting for its applicability.",
    "lastUpdated": "2020-04-17T07:35:21Z",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2001.00846v3"
  },
  {
    "title": "Decentralization in Digital Societies -- A Design Paradox",
    "authors": [
      "Evangelos Pournaras"
    ],
    "abstract": "Digital societies come with a design paradox: On the one hand, technologies, such as Internet of Things, pervasive and ubiquitous systems, allow a distributed local intelligence in interconnected devices of our everyday life such as smart phones, smart thermostats, self-driving cars, etc. On the other hand, Big Data collection and storage is managed in a highly centralized fashion, resulting in privacy-intrusion, surveillance actions, discriminatory and segregation social phenomena. What is the difference between a distributed and a decentralized system design? How \"decentralized\" is the processing of our data nowadays? Does centralized design undermine autonomy? Can the level of decentralization in the implemented technologies influence ethical and social dimensions, such as social justice? Can decentralization convey sustainability? Are there parallelisms between the decentralization of digital technology and the decentralization of urban development?",
    "lastUpdated": "2020-01-06T12:10:59Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2001.01511v1"
  },
  {
    "title": "Social and Governance Implications of Improved Data Efficiency",
    "authors": [
      "Aaron D. Tucker",
      "Markus Anderljung",
      "Allan Dafoe"
    ],
    "abstract": "Many researchers work on improving the data efficiency of machine learning. What would happen if they succeed? This paper explores the social-economic impact of increased data efficiency. Specifically, we examine the intuition that data efficiency will erode the barriers to entry protecting incumbent data-rich AI firms, exposing them to more competition from data-poor firms. We find that this intuition is only partially correct: data efficiency makes it easier to create ML applications, but large AI firms may have more to gain from higher performing AI systems. Further, we find that the effect on privacy, data markets, robustness, and misuse are complex. For example, while it seems intuitive that misuse risk would increase along with data efficiency -- as more actors gain access to any level of capability -- the net effect crucially depends on how much defensive measures are improved. More investigation into data efficiency, as well as research into the \"AI production function\", will be key to understanding the development of the AI industry and its societal impacts.",
    "lastUpdated": "2020-01-14T22:26:12Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2001.05068v1"
  },
  {
    "title": "AAAI FSS-19: Human-Centered AI: Trustworthiness of AI Models and Data Proceedings",
    "authors": [
      "Florian Buettner",
      "John Piorkowski",
      "Ian McCulloh",
      "Ulli Waltinger"
    ],
    "abstract": "To facilitate the widespread acceptance of AI systems guiding decision-making in real-world applications, it is key that solutions comprise trustworthy, integrated human-AI systems. Not only in safety-critical applications such as autonomous driving or medicine, but also in dynamic open world systems in industry and government it is crucial for predictive models to be uncertainty-aware and yield trustworthy predictions. Another key requirement for deployment of AI at enterprise scale is to realize the importance of integrating human-centered design into AI systems such that humans are able to use systems effectively, understand results and output, and explain findings to oversight committees. While the focus of this symposium was on AI systems to improve data quality and technical robustness and safety, we welcomed submissions from broadly defined areas also discussing approaches addressing requirements such as explainable models, human trust and ethical aspects of AI.",
    "lastUpdated": "2020-01-15T15:30:29Z",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2001.05375v1"
  },
  {
    "title": "Approximate Bayesian Bootstrap Procedures to Estimate Multilevel Treatment Effects in Observational Studies with Application to Type 2 Diabetes Treatment Regimens",
    "authors": [
      "Anthony D. Scotina",
      "Andrew R. Zullo",
      "Robert J. Smith",
      "Roee Gutman"
    ],
    "abstract": "Randomized clinical trials are considered the gold standard for estimating causal effects. Nevertheless, in studies that are aimed at examining adverse effects of interventions, such trials are often impractical because of ethical and financial considerations. In observational studies, matching on the generalized propensity scores was proposed as a possible solution to estimate the treatment effects of multiple interventions. However, the derivation of point and interval estimates for these matching procedures can become complex with non-continuous or censored outcomes. We propose a novel Approximate Bayesian Bootstrap algorithm that result in statistically valid point and interval estimates of the treatment effects with categorical outcomes. The procedure relies on the estimated generalized propensity scores and multiply imputes the unobserved potential outcomes for each unit. In addition, we describe a corresponding interpretable sensitivity analysis to examine the unconfoundedness assumption. We apply this approach to examines the cardiovascular safety of common, real-world anti-diabetic treatment regimens for Type 2 diabetes mellitus in a large observational database.",
    "lastUpdated": "2020-01-17T01:00:18Z",
    "categories": [
      "stat.ME"
    ],
    "url": "http://arxiv.org/abs/2001.06125v1"
  },
  {
    "title": "Teaching Software Engineering for AI-Enabled Systems",
    "authors": [
      "Christian Kästner",
      "Eunsuk Kang"
    ],
    "abstract": "Software engineers have significant expertise to offer when building intelligent systems, drawing on decades of experience and methods for building systems that are scalable, responsive and robust, even when built on unreliable components. Systems with artificial-intelligence or machine-learning (ML) components raise new challenges and require careful engineering. We designed a new course to teach software-engineering skills to students with a background in ML. We specifically go beyond traditional ML courses that teach modeling techniques under artificial conditions and focus, in lecture and assignments, on realism with large and changing datasets, robust and evolvable infrastructure, and purposeful requirements engineering that considers ethics and fairness as well. We describe the course and our infrastructure and share experience and all material from teaching the course for the first time.",
    "lastUpdated": "2020-01-18T15:24:17Z",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2001.06691v1"
  },
  {
    "title": "Block the blocker: Studying the effects of Anti Ad-blocking",
    "authors": [
      "Rohit Gupta",
      "Rohit Panda"
    ],
    "abstract": "Advertisements generate huge chunks of revenues for websites and online businesses. Ad-blocker and tracker blocking programs have gained momentum in the last few years with massive debates raging on privacy concerns and improving user experience online. Acceptable Ads programme and Anti Ad-blockers are primary elements emerging in recent years that combat ad-blockers. In this paper, we discuss at length data collection of top websites in the world, Germany, DACH region and news category. We generate feature based A/B testing metrics and employ classifier evaluations on them along with then analysing the result. Our paper also discusses how Anti Ad-blockers impact the economic, legal and ethical usage in Germany along with the recent changes in GDPR while taking a look at Acceptable ads programme and Whitelisting.",
    "lastUpdated": "2020-01-26T10:58:48Z",
    "categories": [
      "cs.CY",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/2001.09434v1"
  },
  {
    "title": "Artificial Artificial Intelligence: Measuring Influence of AI 'Assessments' on Moral Decision-Making",
    "authors": [
      "Lok Chan",
      "Kenzie Doyle",
      "Duncan McElfresh",
      "Vincent Conitzer",
      "John P. Dickerson",
      "Jana Schaich Borg",
      "Walter Sinnott-Armstrong"
    ],
    "abstract": "Given AI's growing role in modeling and improving decision-making, how and when to present users with feedback is an urgent topic to address. We empirically examined the effect of feedback from false AI on moral decision-making about donor kidney allocation. We found some evidence that judgments about whether a patient should receive a kidney can be influenced by feedback about participants' own decision-making perceived to be given by AI, even if the feedback is entirely random. We also discovered different effects between assessments presented as being from human experts and assessments presented as being from AI.",
    "lastUpdated": "2020-01-13T14:15:18Z",
    "categories": [
      "cs.CY",
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/2001.09766v1"
  },
  {
    "title": "Credit Scoring for Good: Enhancing Financial Inclusion with Smartphone-Based Microlending",
    "authors": [
      "María Óskarsdóttir",
      "Cristián Bravo",
      "Carlos Sarraute",
      "Bart Baesens",
      "Jan Vanthienen"
    ],
    "abstract": "Globally, two billion people and more than half of the poorest adults do not use formal financial services. Consequently, there is increased emphasis on developing financial technology that can facilitate access to financial products for the unbanked. In this regard, smartphone-based microlending has emerged as a potential solution to enhance financial inclusion. We propose a methodology to improve the predictive performance of credit scoring models used by these applications. Our approach is composed of several steps, where we mostly focus on engineering appropriate features from the user data. Thereby, we construct pseudo-social networks to identify similar people and combine complex network analysis with representation learning. Subsequently we build credit scoring models using advanced machine learning techniques with the goal of obtaining the most accurate credit scores, while also taking into consideration ethical and privacy regulations to avoid unfair discrimination. A successful deployment of our proposed methodology could improve the performance of microlending smartphone applications and help enhance financial wellbeing worldwide.",
    "lastUpdated": "2020-01-29T18:07:32Z",
    "categories": [
      "cs.SI",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2001.10994v1"
  },
  {
    "title": "An internal fraud model for operational losses in retail banking",
    "authors": [
      "Rocío Paredes",
      "Marco Vega"
    ],
    "abstract": "This paper develops a dynamic internal fraud model for operational losses in retail banking. It considers public operational losses arising from internal fraud in retail banking within a group of international banks. Additionally, the model takes into account internal factors such as the ethical quality of workers and the risk controls set by bank managers. The model is validated by measuring the impact of macroeconomic indicators such as GDP growth and the corruption perception upon the severity and frequency of losses implied by the model. In general,results show that internal fraud losses are pro-cyclical, and that country specific corruption perceptions positively affects internal fraud losses. Namely, when a country is perceived to be more corrupt, retail banking in that country will feature more severe internal fraud losses.",
    "lastUpdated": "2020-02-08T21:39:22Z",
    "categories": [
      "q-fin.RM"
    ],
    "url": "http://arxiv.org/abs/2002.03235v1"
  },
  {
    "title": "Trust dynamics and user attitudes on recommendation errors: preliminary results",
    "authors": [
      "David A. Pelta",
      "Jose L. Verdegay",
      "Maria T. Lamata",
      "Carlos Cruz Corona"
    ],
    "abstract": "Artificial Intelligence based systems may be used as digital nudging techniques that can steer or coerce users to make decisions not always aligned with their true interests. When such systems properly address the issues of Fairness, Accountability, Transparency, and Ethics, then the trust of the user in the system would just depend on the system's output. The aim of this paper is to propose a model for exploring how good and bad recommendations affect the overall trust in an idealized recommender system that issues recommendations over a resource with limited capacity. The impact of different users attitudes on trust dynamics is also considered. Using simulations, we ran a large set of experiments that allowed to observe that: 1) under certain circumstances, all the users ended accepting the recommendations; and 2) the user attitude (controlled by a single parameter balancing the gain/loss of trust after a good/bad recommendation) has a great impact in the trust dynamics.",
    "lastUpdated": "2020-02-11T10:52:53Z",
    "categories": [
      "cs.SI",
      "cs.GT",
      "cs.IR",
      "cs.MA"
    ],
    "url": "http://arxiv.org/abs/2002.04302v1"
  },
  {
    "title": "Multi-Agent Reinforcement Learning and Human Social Factors in Climate Change Mitigation",
    "authors": [
      "Kyle Tilbury",
      "Jesse Hoey"
    ],
    "abstract": "Many complex real-world problems, such as climate change mitigation, are intertwined with human social factors. Climate change mitigation, a social dilemma made difficult by the inherent complexities of human behavior, has an impact at a global scale. We propose applying multi-agent reinforcement learning (MARL) in this setting to develop intelligent agents that can influence the social factors at play in climate change mitigation. There are ethical, practical, and technical challenges that must be addressed when deploying MARL in this way. In this paper, we present these challenges and outline an approach to address them. Understanding how intelligent agents can be used to impact human social factors is important to prevent their abuse and can be beneficial in furthering our knowledge of these complex problems as a whole. The challenges we present are not limited to our specific application but are applicable to broader MARL. Thus, developing MARL for social factors in climate change mitigation helps address general problems hindering MARL's applicability to other real-world problems while also motivating discussion on the social implications of MARL deployment.",
    "lastUpdated": "2020-02-12T18:46:48Z",
    "categories": [
      "cs.MA"
    ],
    "url": "http://arxiv.org/abs/2002.05147v1"
  },
  {
    "title": "Learning Occupational Task-Shares Dynamics for the Future of Work",
    "authors": [
      "Subhro Das",
      "Sebastian Steffen",
      "Wyatt Clarke",
      "Prabhat Reddy",
      "Erik Brynjolfsson",
      "Martin Fleming"
    ],
    "abstract": "The recent wave of AI and automation has been argued to differ from previous General Purpose Technologies (GPTs), in that it may lead to rapid change in occupations' underlying task requirements and persistent technological unemployment. In this paper, we apply a novel methodology of dynamic task shares to a large dataset of online job postings to explore how exactly occupational task demands have changed over the past decade of AI innovation, especially across high, mid and low wage occupations. Notably, big data and AI have risen significantly among high wage occupations since 2012 and 2016, respectively. We built an ARIMA model to predict future occupational task demands and showcase several relevant examples in Healthcare, Administration, and IT. Such task demands predictions across occupations will play a pivotal role in retraining the workforce of the future.",
    "lastUpdated": "2020-01-28T21:20:33Z",
    "categories": [
      "cs.CY",
      "cs.LG",
      "stat.AP",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2002.05655v1"
  },
  {
    "title": "Convex Fairness Constrained Model Using Causal Effect Estimators",
    "authors": [
      "Hikaru Ogura",
      "Akiko Takeda"
    ],
    "abstract": "Recent years have seen much research on fairness in machine learning. Here, mean difference (MD) or demographic parity is one of the most popular measures of fairness. However, MD quantifies not only discrimination but also explanatory bias which is the difference of outcomes justified by explanatory features. In this paper, we devise novel models, called FairCEEs, which remove discrimination while keeping explanatory bias. The models are based on estimators of causal effect utilizing propensity score analysis. We prove that FairCEEs with the squared loss theoretically outperform a naive MD constraint model. We provide an efficient algorithm for solving FairCEEs in regression and binary classification tasks. In our experiment on synthetic and real-world data in these two tasks, FairCEEs outperformed an existing model that considers explanatory bias in specific cases.",
    "lastUpdated": "2020-02-16T03:40:04Z",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2002.06501v1"
  },
  {
    "title": "Investigating Potential Factors Associated with Gender Discrimination in Collaborative Recommender Systems",
    "authors": [
      "Masoud Mansoury",
      "Himan Abdollahpouri",
      "Jessie Smith",
      "Arman Dehpanah",
      "Mykola Pechenizkiy",
      "Bamshad Mobasher"
    ],
    "abstract": "The proliferation of personalized recommendation technologies has raised concerns about discrepancies in their recommendation performance across different genders, age groups, and racial or ethnic populations. This varying degree of performance could impact users' trust in the system and may pose legal and ethical issues in domains where fairness and equity are critical concerns, like job recommendation. In this paper, we investigate several potential factors that could be associated with discriminatory performance of a recommendation algorithm for women versus men. We specifically study several characteristics of user profiles and analyze their possible associations with disparate behavior of the system towards different genders. These characteristics include the anomaly in rating behavior, the entropy of users' profiles, and the users' profile size. Our experimental results on a public dataset using four recommendation algorithms show that, based on all the three mentioned factors, women get less accurate recommendations than men indicating an unfair nature of recommendation algorithms across genders.",
    "lastUpdated": "2020-02-18T18:30:17Z",
    "categories": [
      "cs.IR",
      "cs.SI"
    ],
    "url": "http://arxiv.org/abs/2002.07786v1"
  },
  {
    "title": "The Problem with Metrics is a Fundamental Problem for AI",
    "authors": [
      "Rachel Thomas",
      "David Uminsky"
    ],
    "abstract": "Optimizing a given metric is a central aspect of most current AI approaches, yet overemphasizing metrics leads to manipulation, gaming, a myopic focus on short-term goals, and other unexpected negative consequences. This poses a fundamental contradiction for AI development. Through a series of real-world case studies, we look at various aspects of where metrics go wrong in practice and aspects of how our online environment and current business practices are exacerbating these failures. Finally, we propose a framework towards mitigating the harms caused by overemphasis of metrics within AI by: (1) using a slate of metrics to get a fuller and more nuanced picture, (2) combining metrics with qualitative accounts, and (3) involving a range of stakeholders, including those who will be most impacted.",
    "lastUpdated": "2020-02-20T00:56:11Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2002.08512v1"
  },
  {
    "title": "DeBayes: a Bayesian method for debiasing network embeddings",
    "authors": [
      "Maarten Buyl",
      "Tijl De Bie"
    ],
    "abstract": "As machine learning algorithms are increasingly deployed for high-impact automated decision making, ethical and increasingly also legal standards demand that they treat all individuals fairly, without discrimination based on their age, gender, race or other sensitive traits. In recent years much progress has been made on ensuring fairness and reducing bias in standard machine learning settings. Yet, for network embedding, with applications in vulnerable domains ranging from social network analysis to recommender systems, current options remain limited both in number and performance. We thus propose DeBayes: a conceptually elegant Bayesian method that is capable of learning debiased embeddings by using a biased prior. Our experiments show that these representations can then be used to perform link prediction that is significantly more fair in terms of popular metrics such as demographic parity and equalized opportunity.",
    "lastUpdated": "2020-03-06T10:41:11Z",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2002.11442v2"
  },
  {
    "title": "\"Playing the whole game\": A data collection and analysis exercise with Google Calendar",
    "authors": [
      "Albert Y. Kim",
      "Johanna Hardin"
    ],
    "abstract": "We provide a computational exercise suitable for early introduction in an undergraduate statistics or data science course that allows students to 'play the whole game' of data science: performing both data collection and data analysis. While many teaching resources exist for data analysis, such resources are not as abundant for data collection given the inherent difficulty of the task. Our proposed exercise centers around student use of Google Calendar to collect data with the goal of answering the question 'How do I spend my time?' On the one hand, the exercise involves answering a question with near universal appeal, but on the other hand, the data collection mechanism is not beyond the reach of a typical undergraduate student. A further benefit of the exercise is that it provides an opportunity for discussions on ethical questions and considerations that data providers and data analysts face in today's age of large-scale internet-based data collection.",
    "lastUpdated": "2020-06-18T19:14:16Z",
    "categories": [
      "stat.OT",
      "stat.AP"
    ],
    "url": "http://arxiv.org/abs/2002.11767v2"
  },
  {
    "title": "Expected participation and mentality of smart citizen in smart cities",
    "authors": [
      "Katalin Feher"
    ],
    "abstract": "The purpose is to investigate the expected participation and mentality of smart citizens in smart cities. The key question is the role of the human factor in smart environments globally studied through a research corpus of 150 documents including mainstream summaries trend reports, white papers and visions of business, governmental and university research cooperations reaching a wide audience of the subject. Foremost, a short review of the changing scholarly trends is presented as a theoretical framework. Concerning its key ideas, the corpus based findings are recapped and analysed by content networks and the most referred city strategies. Besides, a critical approach reveal further required factors and risks to investigate. The ultimate goal is to understand how the smart city landscape is shaped by citizen-based strategies, open data, empowerment and responsibility. Accordingly, the paper closes with further considerations regarding the importance of anonymous open data, advantages of neighbourhood-based implementations, aspects of permanent and temporary citizen-engagements, interpretation of metaphors or upcoming technologies, and also, privacy and ethical issues. The results provide the policy development and the emerging scholarly interest with a framework study.",
    "lastUpdated": "2020-03-05T20:37:25Z",
    "categories": [
      "cs.CY",
      "91, 94, 68",
      "K.4"
    ],
    "url": "http://arxiv.org/abs/2003.02910v1"
  },
  {
    "title": "Link Prediction using Graph Neural Networks for Master Data Management",
    "authors": [
      "Balaji Ganesan",
      "Srinivas Parkala",
      "Neeraj R Singh",
      "Sumit Bhatia",
      "Gayatri Mishra",
      "Matheen Ahmed Pasha",
      "Hima Patel",
      "Somashekar Naganna"
    ],
    "abstract": "Learning graph representations of n-ary relational data has a number of real world applications like anti-money laundering, fraud detection, and customer due diligence. Contact tracing of COVID19 positive persons could also be posed as a Link Prediction problem. Predicting links between people using Graph Neural Networks requires careful ethical and privacy considerations than in domains where GNNs have typically been applied so far. We introduce novel methods for anonymizing data, model training, explainability and verification for Link Prediction in Master Data Management, and discuss our results.",
    "lastUpdated": "2020-08-28T19:01:32Z",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2003.04732v2"
  },
  {
    "title": "Super-reflective Data: Speculative Imaginings of a World Where Data Works for People",
    "authors": [
      "Max Van Kleek"
    ],
    "abstract": "It's the year 2020, and every space and place on- and off-line has been augmented with digital things that observe, record, transmit, and compute, for the purposes of recording endless data traces of what is happening in the world. Individually, these things (and the invisible services the power them) have reached considerable sophistication in their ability to analyse and dissect such observations, turning streams of audio and video into informative data fragments. Yet somehow, individuals as end-users of platforms and services have not seen the full potential of such data. In this speculative paper, we propose two hypothetical mini scenarios different from our current digital world. In the former, instead of hoarding it, data controllers turn captured data over to those who need it as quickly as possible, working together to combine, validate, and refine it for maximum usefulness. This simultaneously addresses the data fragmentation and privacy problem, by handing over long-term data governance to those that value it the most In the latter, we discuss ethical dilemmas using the long-term use of such rich data and its tendency to cause people to relentlessly optimise.",
    "lastUpdated": "2020-03-10T22:54:10Z",
    "categories": [
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/2003.05026v1"
  },
  {
    "title": "Harnessing Explanations to Bridge AI and Humans",
    "authors": [
      "Vivian Lai",
      "Samuel Carton",
      "Chenhao Tan"
    ],
    "abstract": "Machine learning models are increasingly integrated into societally critical applications such as recidivism prediction and medical diagnosis, thanks to their superior predictive power. In these applications, however, full automation is often not desired due to ethical and legal concerns. The research community has thus ventured into developing interpretable methods that explain machine predictions. While these explanations are meant to assist humans in understanding machine predictions and thereby allowing humans to make better decisions, this hypothesis is not supported in many recent studies. To improve human decision-making with AI assistance, we propose future directions for closing the gap between the efficacy of explanations and improvement in human performance.",
    "lastUpdated": "2020-03-16T18:00:02Z",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2003.07370v1"
  },
  {
    "title": "Designing Tools for Semi-Automated Detection of Machine Learning Biases: An Interview Study",
    "authors": [
      "Po-Ming Law",
      "Sana Malik",
      "Fan Du",
      "Moumita Sinha"
    ],
    "abstract": "Machine learning models often make predictions that bias against certain subgroups of input data. When undetected, machine learning biases can constitute significant financial and ethical implications. Semi-automated tools that involve humans in the loop could facilitate bias detection. Yet, little is known about the considerations involved in their design. In this paper, we report on an interview study with 11 machine learning practitioners for investigating the needs surrounding semi-automated bias detection tools. Based on the findings, we highlight four considerations in designing to guide system designers who aim to create future tools for bias detection.",
    "lastUpdated": "2020-03-18T01:41:40Z",
    "categories": [
      "cs.CY",
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2003.07680v2"
  },
  {
    "title": "Gender Representation in Open Source Speech Resources",
    "authors": [
      "Mahault Garnerin",
      "Solange Rossato",
      "Laurent Besacier"
    ],
    "abstract": "With the rise of artificial intelligence (AI) and the growing use of deep-learning architectures, the question of ethics, transparency and fairness of AI systems has become a central concern within the research community. We address transparency and fairness in spoken language systems by proposing a study about gender representation in speech resources available through the Open Speech and Language Resource platform. We show that finding gender information in open source corpora is not straightforward and that gender balance depends on other corpus characteristics (elicited/non elicited speech, low/high resource language, speech task targeted). The paper ends with recommendations about metadata and gender information for researchers in order to assure better transparency of the speech systems built using such corpora.",
    "lastUpdated": "2020-03-18T10:23:36Z",
    "categories": [
      "cs.CL"
    ],
    "url": "http://arxiv.org/abs/2003.08132v1"
  },
  {
    "title": "Virtues of Priority",
    "authors": [
      "Michael Harris"
    ],
    "abstract": "The conjecture that every elliptic curve with rational coefficients is a so-called modular curve -- since 2000 a theorem due in large part to Andrew Wiles and, in complete generality, to Breuil-Conrad-Diamond-Taylor -- has been known by various names: Weil Conjecture, Taniyama-Weil Conjecture, Shimura-Taniyama-Weil Conjecture, or Shimura-Taniyama Conjecture, among others. The question of the authorship of this conjecture, one of whose corollaries is Fermat's Last Theorem, has been the subject of a priority dispute that has often been quite bitter, but the principles behind one attribution or another have (almost) never been made explicit. The author proposes a reading inspired in part by the \"virtue ethics\" of Alasdair MacIntyre, analyzing each of the attributions as the expression of a specific value, or virtue, appreciated by the community of mathematicians.",
    "lastUpdated": "2020-03-18T14:37:21Z",
    "categories": [
      "math.HO",
      "math.NT",
      "01A99"
    ],
    "url": "http://arxiv.org/abs/2003.08242v1"
  },
  {
    "title": "An Empirical Analysis of Privacy in the Lightning Network",
    "authors": [
      "George Kappos",
      "Haaroon Yousaf",
      "Ania Piotrowska",
      "Sanket Kanjalkar",
      "Sergi Delgado-Segura",
      "Andrew Miller",
      "Sarah Meiklejohn"
    ],
    "abstract": "Payment channel networks, and the Lightning Network in particular, seem to offer a solution to the lack of scalability and privacy offered by Bitcoin and other blockchain-based cryptocurrencies. Previous research has already focused on the scalability, availability, and crypto-economics of the Lightning Network, but relatively little attention has been paid to exploring the level of privacy it achieves in practice. This paper presents a thorough analysis of the privacy offered by the Lightning Network. We present three main attacks that exploit publicly available information about the network topology and its active nodes and channels in order to learn information that is designed to be kept secret, such as how many coins a node has available to spend or who the sender and recipient are in a payment routed through the network. We evaluate one of our attacks on the live network and, due to cost and ethical considerations, evaluate our other two attacks on a simulated Lightning network that faithfully mimics the real one.",
    "lastUpdated": "2020-07-02T12:37:13Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/2003.12470v2"
  },
  {
    "title": "Mining International Political Norms from the GDELT Database",
    "authors": [
      "Rohit Murali",
      "Suravi Patnaik",
      "Stephen Cranefield"
    ],
    "abstract": "Researchers have long been interested in the role that norms can play in governing agent actions in multi-agent systems. Much work has been done on formalising normative concepts from human society and adapting them for the government of open software systems, and on the simulation of normative processes in human and artificial societies. However, there has been comparatively little work on applying normative MAS mechanisms to understanding the norms in human society. This work investigates this issue in the context of international politics. Using the GDELT dataset, containing machine-encoded records of international events extracted from news reports, we extracted bilateral sequences of inter-country events and applied a Bayesian norm mining mechanism to identify norms that best explained the observed behaviour. A statistical evaluation showed that the normative model fitted the data significantly better than a probabilistic discrete event model.",
    "lastUpdated": "2020-04-20T16:11:13Z",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "url": "http://arxiv.org/abs/2003.14027v2"
  },
  {
    "title": "Applying Transparency in Artificial Intelligence based Personalization Systems",
    "authors": [
      "Laura Schelenz",
      "Avi Segal",
      "Kobi Gal"
    ],
    "abstract": "Artificial Intelligence based systems increasingly use personalization to provide users with relevant content, products, and solutions. Personalization is intended to support users and address their respective needs and preferences. However, users are becoming increasingly vulnerable to online manipulation due to algorithmic advancements and lack of transparency. Such manipulation decreases users' levels of trust, autonomy, and satisfaction concerning the systems with which they interact. Increasing transparency is an important goal for personalization based systems. Unfortunately, system designers lack guidance in assessing and implementing transparency in their developed systems. In this work we combine insights from technology ethics and computer science to generate a list of transparency best practices for machine generated personalization. Based on these best practices, we develop a checklist to be used by designers wishing to evaluate and increase the transparency of their algorithmic systems. Adopting a designer perspective, we apply the checklist to prominent online services and discuss its advantages and shortcomings. We encourage researchers to adopt the checklist in various environments and to work towards a consensus-based tool for measuring transparency in the personalization community.",
    "lastUpdated": "2020-08-21T13:49:54Z",
    "categories": [
      "cs.CY",
      "cs.HC",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2004.00935v2"
  },
  {
    "title": "Under the Hood of Neural Networks: Characterizing Learned Representations by Functional Neuron Populations and Network Ablations",
    "authors": [
      "Richard Meyes",
      "Constantin Waubert de Puiseau",
      "Andres Posada-Moreno",
      "Tobias Meisen"
    ],
    "abstract": "The need for more transparency of the decision-making processes in artificial neural networks steadily increases driven by their applications in safety critical and ethically challenging domains such as autonomous driving or medical diagnostics. We address today's lack of transparency of neural networks and shed light on the roles of single neurons and groups of neurons within the network fulfilling a learned task. Inspired by research in the field of neuroscience, we characterize the learned representations by activation patterns and network ablations, revealing functional neuron populations that a) act jointly in response to specific stimuli or b) have similar impact on the network's performance after being ablated. We find that neither a neuron's magnitude or selectivity of activation, nor its impact on network performance are sufficient stand-alone indicators for its importance for the overall task. We argue that such indicators are essential for future advances in transfer learning and modern neuroscience.",
    "lastUpdated": "2020-05-11T09:09:15Z",
    "categories": [
      "cs.NE",
      "cs.LG",
      "q-bio.NC"
    ],
    "url": "http://arxiv.org/abs/2004.01254v2"
  },
  {
    "title": "Data augmentation using generative networks to identify dementia",
    "authors": [
      "Bahman Mirheidari",
      "Yilin Pan",
      "Daniel Blackburn",
      "Ronan O'Malley",
      "Traci Walker",
      "Annalena Venneri",
      "Markus Reuber",
      "Heidi Christensen"
    ],
    "abstract": "Data limitation is one of the most common issues in training machine learning classifiers for medical applications. Due to ethical concerns and data privacy, the number of people that can be recruited to such experiments is generally smaller than the number of participants contributing to non-healthcare datasets. Recent research showed that generative models can be used as an effective approach for data augmentation, which can ultimately help to train more robust classifiers sparse data domains. A number of studies proved that this data augmentation technique works for image and audio data sets. In this paper, we investigate the application of a similar approach to different types of speech and audio-based features extracted from interactions recorded with our automatic dementia detection system. Using two generative models we show how the generated synthesized samples can improve the performance of a DNN based classifier. The variational autoencoder increased the F-score of a four-way classifier distinguishing the typical patient groups seen in memory clinics from 58% to around 74%, a 16% improvement",
    "lastUpdated": "2020-04-13T15:05:24Z",
    "categories": [
      "eess.AS",
      "cs.CL",
      "cs.LG",
      "cs.SD"
    ],
    "url": "http://arxiv.org/abs/2004.05989v1"
  },
  {
    "title": "A Practical Response Adaptive Block Randomization Design with Analytic Type I Error Protection",
    "authors": [
      "Tianyu Zhan",
      "Lu Cui",
      "Ziqian Geng",
      "Lanju Zhang",
      "Yihua Gu",
      "Ivan S. F. Chan"
    ],
    "abstract": "Response adaptive randomization is appealing in confirmatory adaptive clinical trials from statistical, ethical, and pragmatic perspectives, in the sense that subjects are more likely to be randomized to better performing treatment groups based on accumulating data. The Doubly Adaptive Biased Coin Design (DBCD) is a popular solution due to its asymptotic normal property of final allocations, which further justifies its asymptotic type I error rate control. As an alternative, we propose a Response Adaptive Block Randomization (RABR) design with pre-specified randomization ratios for the control and high-performing groups to robustly achieve desired final sample size per group under different underlying responses, which is usually required in industry-sponsored clinical studies. We show that the usual test statistic has a controlled type I error rate. Our simulations further highlight the advantages of the proposed design over the DBCD in terms of consistently achieving final sample allocations and of power performance. We further apply this design to a Phase III study evaluating the efficacy of two dosing regimens of adjunctive everolimus in treating tuberous sclerosis complex but with no previous dose-finding studies in this indication.",
    "lastUpdated": "2020-04-15T21:36:15Z",
    "categories": [
      "stat.ME"
    ],
    "url": "http://arxiv.org/abs/2004.07356v1"
  },
  {
    "title": "The Moral Burden of Ambiguity Aversion",
    "authors": [
      "Brian Jabarian"
    ],
    "abstract": "In their article, \"Egalitarianism under Severe Uncertainty\", Philosophy and Public Affairs, 46:3, 2018, Thomas Rowe and Alex Voorhoeve develop an original moral decision theory for cases under uncertainty, called \"pluralist egalitarianism under uncertainty\". In this paper, I firstly sketch their views and arguments. I then elaborate on their moral decision theory by discussing how it applies to choice scenarios in health ethics. Finally, I suggest a new two-stage Ellsberg thought experiment challenging the core of the principle of their theory. In such an experiment pluralist egalitarianism seems to suggest the wrong, morally and rationally speaking, course of action -- no matter whether I consider my thought experiment in a simultaneous or a sequential setting.",
    "lastUpdated": "2020-04-26T15:57:29Z",
    "categories": [
      "econ.TH",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2004.08892v2"
  },
  {
    "title": "How Value-Sensitive Design Can Empower Sustainable Consumption",
    "authors": [
      "Thomas Asikis",
      "Johannes Klinglmayr",
      "Dirk Helbing",
      "Evangelos Pournaras"
    ],
    "abstract": "In a so-called overpopulated world, sustainable consumption is of existential importance.However, the expanding spectrum of product choices and their production complexity challenge consumers to make informed and value-sensitive decisions. Recent approaches based on (personalized) psychological manipulation are often intransparent, potentially privacy-invasive and inconsistent with (informational) self-determination. In contrast, responsible consumption based on informed choices currently requires reasoning to an extent that tends to overwhelm human cognitive capacity. As a result, a collective shift towards sustainable consumption remains a grand challenge. Here we demonstrate a novel personal shopping assistant implemented as a smart phone app that supports a value-sensitive design and leverages sustainability awareness, using experts' knowledge and \"wisdom of the crowd\" for transparent product information and explainable product ratings. Real-world field experiments in two supermarkets confirm higher sustainability awareness and a bottom-up behavioral shift towards more sustainable consumption. These results encourage novel business models for retailers and producers, ethically aligned with consumer preferences and with higher sustainability.",
    "lastUpdated": "2020-12-04T14:56:03Z",
    "categories": [
      "cs.CY",
      "cs.DC",
      "cs.HC",
      "cs.IR",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2004.09180v4"
  },
  {
    "title": "Having our omic cake and eating it too: Evaluating User Response to using Blockchain Technology for Private & Secure Health Data Management and Sharing",
    "authors": [
      "Victoria L. Lemieux",
      "Darra Hofman",
      "Hoda Hamouda",
      "Danielle Batista",
      "Ravneet Kaur",
      "Wen Pan",
      "Ian Costanzo",
      "Dean Regier",
      "Samantha Pollard",
      "Deirdre Weymann",
      "Rob Fraser"
    ],
    "abstract": "This paper reports on the development and evaluation of a prototype blockchain solution for private and secure individual omics health data management and sharing. This solution is one output of a multidisciplinary project investigating the social, data and technical issues surrounding application of blockchain technology in the context of personalized healthcare research. The project studies potential ethical, legal, social and cognitive constraints of self-sovereign healthcare data management and sharing, and whether such constraints can be addressed through careful user interface design of a blockchain solution.",
    "lastUpdated": "2020-04-24T01:11:40Z",
    "categories": [
      "cs.CR",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2004.11502v1"
  },
  {
    "title": "Genetic programming approaches to learning fair classifiers",
    "authors": [
      "William La Cava",
      "Jason H. Moore"
    ],
    "abstract": "Society has come to rely on algorithms like classifiers for important decision making, giving rise to the need for ethical guarantees such as fairness. Fairness is typically defined by asking that some statistic of a classifier be approximately equal over protected groups within a population. In this paper, current approaches to fairness are discussed and used to motivate algorithmic proposals that incorporate fairness into genetic programming for classification. We propose two ideas. The first is to incorporate a fairness objective into multi-objective optimization. The second is to adapt lexicase selection to define cases dynamically over intersections of protected groups. We describe why lexicase selection is well suited to pressure models to perform well across the potentially infinitely many subgroups over which fairness is desired. We use a recent genetic programming approach to construct models on four datasets for which fairness constraints are necessary, and empirically compare performance to prior methods utilizing game-theoretic solutions. Methods are assessed based on their ability to generate trade-offs of subgroup fairness and accuracy that are Pareto optimal. The result show that genetic programming methods in general, and random search in particular, are well suited to this task.",
    "lastUpdated": "2020-04-28T04:20:25Z",
    "categories": [
      "cs.NE",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2004.13282v1"
  },
  {
    "title": "Gender Gap in Natural Language Processing Research: Disparities in Authorship and Citations",
    "authors": [
      "Saif M. Mohammad"
    ],
    "abstract": "Disparities in authorship and citations across gender can have substantial adverse consequences not just on the disadvantaged genders, but also on the field of study as a whole. Measuring gender gaps is a crucial step towards addressing them. In this work, we examine female first author percentages and the citations to their papers in Natural Language Processing (1965 to 2019). We determine aggregate-level statistics using an existing manually curated author--gender list as well as first names strongly associated with a gender. We find that only about 29% of first authors are female and only about 25% of last authors are female. Notably, this percentage has not improved since the mid 2000s. We also show that, on average, female first authors are cited less than male first authors, even when controlling for experience and area of research. Finally, we discuss the ethical considerations involved in automatic demographic analysis.",
    "lastUpdated": "2020-09-03T20:00:08Z",
    "categories": [
      "cs.DL",
      "cs.CL"
    ],
    "url": "http://arxiv.org/abs/2005.00962v2"
  },
  {
    "title": "How good is good enough for COVID19 apps? The influence of benefits, accuracy, and privacy on willingness to adopt",
    "authors": [
      "Gabriel Kaptchuk",
      "Daniel G. Goldstein",
      "Eszter Hargittai",
      "Jake Hofman",
      "Elissa M. Redmiles"
    ],
    "abstract": "A growing number of contact tracing apps are being developed to complement manual contact tracing. A key question is whether users will be willing to adopt these contact tracing apps. In this work, we survey over 4,500 Americans to evaluate (1) the effect of both accuracy and privacy concerns on reported willingness to install COVID19 contact tracing apps and (2) how different groups of users weight accuracy vs. privacy. Drawing on our findings from these first two research questions, we (3) quantitatively model how the amount of public health benefit (reduction in infection rate), amount of individual benefit (true-positive detection of exposures to COVID), and degree of privacy risk in a hypothetical contact tracing app may influence American's willingness to install. Our work takes a descriptive ethics approach toward offering implications for the development of policy and app designs related to COVID19.",
    "lastUpdated": "2020-05-18T23:13:05Z",
    "categories": [
      "cs.CY",
      "cs.CR",
      "cs.HC",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2005.04343v4"
  },
  {
    "title": "Cyberbullying Detection with Fairness Constraints",
    "authors": [
      "Oguzhan Gencoglu"
    ],
    "abstract": "Cyberbullying is a widespread adverse phenomenon among online social interactions in today's digital society. While numerous computational studies focus on enhancing the cyberbullying detection performance of machine learning algorithms, proposed models tend to carry and reinforce unintended social biases. In this study, we try to answer the research question of \"Can we mitigate the unintended bias of cyberbullying detection models by guiding the model training with fairness constraints?\". For this purpose, we propose a model training scheme that can employ fairness constraints and validate our approach with different datasets. We demonstrate that various types of unintended biases can be successfully mitigated without impairing the model quality. We believe our work contributes to the pursuit of unbiased, transparent, and ethical machine learning solutions for cyber-social health.",
    "lastUpdated": "2020-09-29T21:54:00Z",
    "categories": [
      "cs.CL",
      "cs.LG",
      "cs.SI"
    ],
    "url": "http://arxiv.org/abs/2005.06625v2"
  },
  {
    "title": "Mitigating Gender Bias in Machine Learning Data Sets",
    "authors": [
      "Susan Leavy",
      "Gerardine Meaney",
      "Karen Wade",
      "Derek Greene"
    ],
    "abstract": "Artificial Intelligence has the capacity to amplify and perpetuate societal biases and presents profound ethical implications for society. Gender bias has been identified in the context of employment advertising and recruitment tools, due to their reliance on underlying language processing and recommendation algorithms. Attempts to address such issues have involved testing learned associations, integrating concepts of fairness to machine learning and performing more rigorous analysis of training data. Mitigating bias when algorithms are trained on textual data is particularly challenging given the complex way gender ideology is embedded in language. This paper proposes a framework for the identification of gender bias in training data for machine learning.The work draws upon gender theory and sociolinguistics to systematically indicate levels of bias in textual training data and associated neural word embedding models, thus highlighting pathways for both removing bias from training data and critically assessing its impact.",
    "lastUpdated": "2020-05-18T08:04:53Z",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2005.06898v2"
  },
  {
    "title": "A Risk Assessment of a Pretrial Risk Assessment Tool: Tussles, Mitigation Strategies, and Inherent Limits",
    "authors": [
      "Marc Faddoul",
      "Henriette Ruhrmann",
      "Joyce Lee"
    ],
    "abstract": "We perform a risk assessment of the Public Safety Assessment (PSA), a software used in San Francisco and other jurisdictions to assist judges in deciding whether defendants need to be detained before their trial. With a mixed-methods approach including stakeholder interviews and the use of theoretical frameworks, we lay out the values at play as pretrial justice is automated. After identifying value implications of delegating decision making to technology, we articulate benefits and limitations of the PSA solution, as well as suggest mitigation strategies. We then draft the Handoff Tree, a novel algorithmic approach to pretrial justice that accommodates some of the inherent limitations of risk assessment tools by design. The model pairs every prediction with an associated error rate, and hands off the decision to the judge if the uncertainty is too high. By explicitly stating error rate, the Handoff Tree aims both to limit the impact of predictive disparity between race and gender, and to prompt judges to be more critical of retention recommendations, given the high rate of false positives they often entail.",
    "lastUpdated": "2020-05-14T23:56:57Z",
    "categories": [
      "cs.CY",
      "97P70",
      "K.4.1; J.4; J.1"
    ],
    "url": "http://arxiv.org/abs/2005.07299v1"
  },
  {
    "title": "Regulating Artificial Intelligence: Proposal for a Global Solution",
    "authors": [
      "Olivia J. Erdélyi",
      "Judy Goldsmith"
    ],
    "abstract": "With increasing ubiquity of artificial intelligence (AI) in modern societies, individual countries and the international community are working hard to create an innovation-friendly, yet safe, regulatory environment. Adequate regulation is key to maximize the benefits and minimize the risks stemming from AI technologies. Developing regulatory frameworks is, however, challenging due to AI's global reach and the existence of widespread misconceptions about the notion of regulation. We argue that AI-related challenges cannot be tackled effectively without sincere international coordination supported by robust, consistent domestic and international governance arrangements. Against this backdrop, we propose the establishment of an international AI governance framework organized around a new AI regulatory agency that -- drawing on interdisciplinary expertise -- could help creating uniform standards for the regulation of AI technologies and inform the development of AI policies around the world. We also believe that a fundamental change of mindset on what constitutes regulation is necessary to remove existing barriers that hamper contemporary efforts to develop AI regulatory regimes, and put forward some recommendations on how to achieve this, and what opportunities doing so would present.",
    "lastUpdated": "2020-05-22T09:24:07Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2005.11072v1"
  },
  {
    "title": "Github Data Exposure and Accessing Blocked Data using the GraphQL Security Design Flaw",
    "authors": [
      "Shahriar Yazdipour"
    ],
    "abstract": "This research study was conducted to illustrate how it is easily possible to get data access to disabled or blocked repositories in Github using GraphQL. There are situations in which you can lose access to your Github repositories; When you use the paid version of Github services and do not pay the monthly payment or another situation is that when you use Github from the countries in the United States sanction list. Having an insecure repository with malicious usages can also put your repository in Github blacklist. In all of these situations, Github will block and disable your repository and you will lose access to your files, codes and project assets. Here, we will discuss the procedure of how an Ethical Hacker can gain access to all those blocked data with GraphQL functionality.",
    "lastUpdated": "2020-05-27T16:00:48Z",
    "categories": [
      "cs.CR",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/2005.13448v1"
  },
  {
    "title": "Challenges in Combating COVID-19 Infodemic -- Data, Tools, and Ethics",
    "authors": [
      "Kaize Ding",
      "Kai Shu",
      "Yichuan Li",
      "Amrita Bhattacharjee",
      "Huan Liu"
    ],
    "abstract": "While the COVID-19 pandemic continues its global devastation, numerous accompanying challenges emerge. One important challenge we face is to efficiently and effectively use recently gathered data and find computational tools to combat the COVID-19 infodemic, a typical information overloading problem. Novel coronavirus presents many questions without ready answers; its uncertainty and our eagerness in search of solutions offer a fertile environment for infodemic. It is thus necessary to combat the infodemic and make a concerted effort to confront COVID-19 and mitigate its negative impact in all walks of life when saving lives and maintaining normal orders during trying times. In this position paper of combating the COVID-19 infodemic, we illustrate its need by providing real-world examples of rampant conspiracy theories, misinformation, and various types of scams that take advantage of human kindness, fear, and ignorance. We present three key challenges in this fight against the COVID-19 infodemic where researchers and practitioners instinctively want to contribute and help. We demonstrate that these three challenges can and will be effectively addressed by collective wisdom, crowdsourcing, and collaborative research.",
    "lastUpdated": "2020-05-27T22:41:02Z",
    "categories": [
      "cs.SI",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2005.13691v1"
  },
  {
    "title": "Explainable deep learning models in medical image analysis",
    "authors": [
      "Amitojdeep Singh",
      "Sourya Sengupta",
      "Vasudevan Lakshminarayanan"
    ],
    "abstract": "Deep learning methods have been very effective for a variety of medical diagnostic tasks and has even beaten human experts on some of those. However, the black-box nature of the algorithms has restricted clinical use. Recent explainability studies aim to show the features that influence the decision of a model the most. The majority of literature reviews of this area have focused on taxonomy, ethics, and the need for explanations. A review of the current applications of explainable deep learning for different medical imaging tasks is presented here. The various approaches, challenges for clinical deployment, and the areas requiring further research are discussed here from a practical standpoint of a deep learning researcher designing a system for the clinical end-users.",
    "lastUpdated": "2020-05-28T06:31:05Z",
    "categories": [
      "cs.CV",
      "cs.LG",
      "eess.IV"
    ],
    "url": "http://arxiv.org/abs/2005.13799v1"
  },
  {
    "title": "Participatory Design to build better contact- and proximity-tracing apps",
    "authors": [
      "Abhishek Gupta",
      "Tania De Gasperis"
    ],
    "abstract": "With the push for contact- and proximity-tracing solutions as a means to manage the spread of the pandemic, there is a distrust between the citizens and authorities that are deploying these solutions. The efficacy of the solutions relies on meeting a minimum uptake threshold which is hitting a barrier because of a lack of trust and transparency in how these solutions are being developed. We propose participatory design as a mechanism to evoke trust and explore how it might be applied to co-create technological solutions that not only meet the needs of the users better but also expand their reach to underserved and high-risk communities. We also highlight the role of the bazaar model of development and complement that with quantitative and qualitative metrics for evaluating the solutions and convincing policymakers and other stakeholders in the value of this approach with empirical evidence.",
    "lastUpdated": "2020-05-31T04:30:45Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2006.00432v1"
  },
  {
    "title": "An optimizable scalar objective value cannot be objective and should not be the sole objective",
    "authors": [
      "Isabel Kloumann",
      "Mark Tygert"
    ],
    "abstract": "This paper concerns the ethics and morality of algorithms and computational systems, and has been circulating internally at Facebook for the past couple years. The paper reviews many Nobel laureates' work, as well as the work of other prominent scientists such as Richard Dawkins, Andrei Kolmogorov, Vilfredo Pareto, and John von Neumann. The paper draws conclusions based on such works, as summarized in the title. The paper argues that the standard approach to modern machine learning and artificial intelligence is bound to be biased and unfair, and that longstanding traditions in the professions of law, justice, politics, and medicine should help.",
    "lastUpdated": "2020-06-03T23:10:38Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY",
      "math.OC"
    ],
    "url": "http://arxiv.org/abs/2006.02577v1"
  },
  {
    "title": "A multi-objective-based approach for Fair Principal Component Analysis",
    "authors": [
      "Guilherme D. Pelegrina",
      "Renan D. B. Brotto",
      "Leonardo T. Duarte",
      "João M. T. Romano",
      "Romis Attux"
    ],
    "abstract": "In dimension reduction problems, the adopted technique may produce disparities between the representation errors of two or more different groups. For instance, in the projected space, a specific class can be better represented in comparison with the other ones. Depending on the situation, this unfair result may introduce ethical concerns. In this context, this paper investigates how a fairness measure can be considered when performing dimension reduction through principal component analysis. Since both reconstruction error and fairness measure must be taken into account, we propose a multi-objective-based approach to tackle the Fair Principal Component Analysis problem. The experiments attest that a fairer result can be achieved with a very small loss in the reconstruction error.",
    "lastUpdated": "2020-06-11T01:00:22Z",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2006.06137v1"
  },
  {
    "title": "A Variational Approach to Privacy and Fairness",
    "authors": [
      "Borja Rodríguez-Gálvez",
      "Ragnar Thobaben",
      "Mikael Skoglund"
    ],
    "abstract": "In this article, we propose a new variational approach to learn private and/or fair representations. This approach is based on the Lagrangians of a new formulation of the privacy and fairness optimization problems that we propose. In this formulation, we aim at generating representations of the data that keep a prescribed level of the relevant information that is not shared by the private or sensitive data, while minimizing the remaining information they keep. The proposed approach (i) exhibits the similarities of the privacy and fairness problems, (ii) allows us to control the trade-off between utility and privacy or fairness through the Lagrange multiplier parameter, and (iii) can be comfortably incorporated to common representation learning algorithms such as the VAE, the $\\beta$-VAE, the VIB, or the nonlinear IB.",
    "lastUpdated": "2021-01-11T10:24:59Z",
    "categories": [
      "stat.ML",
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "url": "http://arxiv.org/abs/2006.06332v2"
  },
  {
    "title": "Cloud as an Attack Platform",
    "authors": [
      "Moitrayee Chatterjee",
      "Prerit Datta",
      "Faranak Abri",
      "Akbar Siami Namin",
      "Keith S. Jones"
    ],
    "abstract": "We present an exploratory study of responses from $75$ security professionals and ethical hackers in order to understand how they abuse cloud platforms for attack purposes. The participants were recruited at the Black Hat and DEF CON conferences. We presented the participants' with various attack scenarios and asked them to explain the steps they would have carried out for launching the attack in each scenario. Participants' responses were studied to understand attackers' mental models, which would improve our understanding of necessary security controls and recommendations regarding precautionary actions to circumvent the exploitation of clouds for malicious activities. We observed that in 93.78% of the responses, participants are abusing cloud services to establish their attack environment and launch attacks.",
    "lastUpdated": "2020-06-14T14:32:45Z",
    "categories": [
      "cs.CR",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/2006.07914v1"
  },
  {
    "title": "The Social Contract for AI",
    "authors": [
      "Mirka Snyder Caron",
      "Abhishek Gupta"
    ],
    "abstract": "Like any technology, AI systems come with inherent risks and potential benefits. It comes with potential disruption of established norms and methods of work, societal impacts and externalities. One may think of the adoption of technology as a form of social contract, which may evolve or fluctuate in time, scale, and impact. It is important to keep in mind that for AI, meeting the expectations of this social contract is critical, because recklessly driving the adoption and implementation of unsafe, irresponsible, or unethical AI systems may trigger serious backlash against industry and academia involved which could take decades to resolve, if not actually seriously harm society. For the purpose of this paper, we consider that a social contract arises when there is sufficient consensus within society to adopt and implement this new technology. As such, to enable a social contract to arise for the adoption and implementation of AI, developing: 1) A socially accepted purpose, through 2) A safe and responsible method, with 3) A socially aware level of risk involved, for 4) A socially beneficial outcome, is key.",
    "lastUpdated": "2020-06-15T05:30:48Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2006.08140v1"
  },
  {
    "title": "Where Responsible AI meets Reality: Practitioner Perspectives on Enablers for shifting Organizational Practices",
    "authors": [
      "Bogdana Rakova",
      "Jingying Yang",
      "Henriette Cramer",
      "Rumman Chowdhury"
    ],
    "abstract": "Large and ever-evolving technology companies continue to invest more time and resources to incorporate responsible Artificial Intelligence (AI) into production-ready systems to increase algorithmic accountability. This paper examines and seeks to offer a framework for analyzing how organizational culture and structure impact the effectiveness of responsible AI initiatives in practice. We present the results of semi-structured qualitative interviews with practitioners working in industry, investigating common challenges, ethical tensions, and effective enablers for responsible AI initiatives. Focusing on major companies developing or utilizing AI, we have mapped what organizational structures currently support or hinder responsible AI initiatives, what aspirational future processes and structures would best enable effective initiatives, and what key elements comprise the transition from current work practices to the aspirational future.",
    "lastUpdated": "2020-11-17T16:57:58Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2006.12358v3"
  },
  {
    "title": "Encoding Legal Balancing: Automating an Abstract Ethico-Legal Value Ontology in Preference Logic",
    "authors": [
      "Christoph Benzmüller",
      "David Fuenmayor",
      "Bertram Lomfeld"
    ],
    "abstract": "Enabling machines to legal balancing is a non-trivial task challenged by a multitude of factors some of which are addressed and explored in this work. We propose a holistic approach to formal modeling at different abstraction layers supported by a pluralistic framework in which the encoding of an ethico-legal value and upper ontology is developed in combination with the exploration of a formalization logic, with legal domain knowledge and with exemplary use cases until a reflective equilibrium is reached. Our work is enabled by a meta-logical approach to universal logical reasoning and it applies the recently introduced \\logikey\\ methodology for designing normative theories for ethical and legal reasoning. The particular focus in this paper is on the formalization and encoding of a value ontology suitable e.g. for explaining and resolving legal conflicts in property law (wild animal cases).",
    "lastUpdated": "2020-06-23T06:57:15Z",
    "categories": [
      "cs.AI",
      "cs.LO",
      "68T01 68T27 68T30 03Axx 03B16 03B35 03B45 03B60 03B70",
      "I.2.0; I.2.3; I.2.4; J.1"
    ],
    "url": "http://arxiv.org/abs/2006.12789v1"
  },
  {
    "title": "A Methodology for Creating AI FactSheets",
    "authors": [
      "John Richards",
      "David Piorkowski",
      "Michael Hind",
      "Stephanie Houde",
      "Aleksandra Mojsilović"
    ],
    "abstract": "As AI models and services are used in a growing number of highstakes areas, a consensus is forming around the need for a clearer record of how these models and services are developed to increase trust. Several proposals for higher quality and more consistent AI documentation have emerged to address ethical and legal concerns and general social impacts of such systems. However, there is little published work on how to create this documentation. This is the first work to describe a methodology for creating the form of AI documentation we call FactSheets. We have used this methodology to create useful FactSheets for nearly two dozen models. This paper describes this methodology and shares the insights we have gathered. Within each step of the methodology, we describe the issues to consider and the questions to explore with the relevant people in an organization who will be creating and consuming the AI facts in a FactSheet. This methodology will accelerate the broader adoption of transparent AI documentation.",
    "lastUpdated": "2020-06-28T01:47:46Z",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2006.13796v2"
  },
  {
    "title": "A Statistical Overview on Data Privacy",
    "authors": [
      "Fang Liu"
    ],
    "abstract": "The eruption of big data with the increasing collection and processing of vast volumes and variety of data have led to breakthrough discoveries and innovation in science, engineering, medicine, commerce, criminal justice, and national security that would not have been possible in the past. While there are many benefits to the collection and usage of big data, there are also growing concerns among the general public on what personal information is collected and how it is used. In addition to legal policies and regulations, technological tools and statistical strategies also exist to promote and safeguard individual privacy, while releasing and sharing useful population-level information. In this overview, I introduce some of these approaches, as well as the existing challenges and opportunities in statistical data privacy research and applications to better meet the practical needs of privacy protection and information sharing.",
    "lastUpdated": "2020-07-01T21:21:20Z",
    "categories": [
      "cs.CR",
      "stat.OT"
    ],
    "url": "http://arxiv.org/abs/2007.00765v1"
  },
  {
    "title": "Green Lighting ML: Confidentiality, Integrity, and Availability of Machine Learning Systems in Deployment",
    "authors": [
      "Abhishek Gupta",
      "Erick Galinkin"
    ],
    "abstract": "Security and ethics are both core to ensuring that a machine learning system can be trusted. In production machine learning, there is generally a hand-off from those who build a model to those who deploy a model. In this hand-off, the engineers responsible for model deployment are often not privy to the details of the model and thus, the potential vulnerabilities associated with its usage, exposure, or compromise. Techniques such as model theft, model inversion, or model misuse may not be considered in model deployment, and so it is incumbent upon data scientists and machine learning engineers to understand these potential risks so they can communicate them to the engineers deploying and hosting their models. This is an open problem in the machine learning community and in order to help alleviate this issue, automated systems for validating privacy and security of models need to be developed, which will help to lower the burden of implementing these hand-offs and increasing the ubiquity of their adoption.",
    "lastUpdated": "2020-07-09T10:38:59Z",
    "categories": [
      "cs.CY",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "url": "http://arxiv.org/abs/2007.04693v1"
  },
  {
    "title": "Algorithmic Fairness in Education",
    "authors": [
      "René F. Kizilcec",
      "Hansol Lee"
    ],
    "abstract": "Data-driven predictive models are increasingly used in education to support students, instructors, and administrators. However, there are concerns about the fairness of the predictions and uses of these algorithmic systems. In this introduction to algorithmic fairness in education, we draw parallels to prior literature on educational access, bias, and discrimination, and we examine core components of algorithmic systems (measurement, model learning, and action) to identify sources of bias and discrimination in the process of developing and deploying these systems. Statistical, similarity-based, and causal notions of fairness are reviewed and contrasted in the way they apply in educational contexts. Recommendations for policy makers and developers of educational technology offer guidance for how to promote algorithmic fairness in education.",
    "lastUpdated": "2020-09-18T01:25:59Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2007.05443v2"
  },
  {
    "title": "Grading video interviews with fairness considerations",
    "authors": [
      "Abhishek Singhania",
      "Abhishek Unnam",
      "Varun Aggarwal"
    ],
    "abstract": "There has been considerable interest in predicting human emotions and traits using facial images and videos. Lately, such work has come under criticism for poor labeling practices, inconclusive prediction results and fairness considerations. We present a careful methodology to automatically derive social skills of candidates based on their video response to interview questions. We, for the first time, include video data from multiple countries encompassing multiple ethnicities. Also, the videos were rated by individuals from multiple racial backgrounds, following several best practices, to achieve a consensus and unbiased measure of social skills. We develop two machine-learning models to predict social skills. The first model employs expert-guidance to use plausibly causal features. The second uses deep learning and depends solely on the empirical correlations present in the data. We compare errors of both these models, study the specificity of the models and make recommendations. We further analyze fairness by studying the errors of models by race and gender. We verify the usefulness of our models by determining how well they predict interview outcomes for candidates. Overall, the study provides strong support for using artificial intelligence for video interview scoring, while taking care of fairness and ethical considerations.",
    "lastUpdated": "2020-07-02T10:06:13Z",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2007.05461v1"
  },
  {
    "title": "Linguistic Taboos and Euphemisms in Nepali",
    "authors": [
      "Nobal B. Niraula",
      "Saurab Dulal",
      "Diwa Koirala"
    ],
    "abstract": "Languages across the world have words, phrases, and behaviors -- the taboos -- that are avoided in public communication considering them as obscene or disturbing to the social, religious, and ethical values of society. However, people deliberately use these linguistic taboos and other language constructs to make hurtful, derogatory, and obscene comments. It is nearly impossible to construct a universal set of offensive or taboo terms because offensiveness is determined entirely by different factors such as socio-physical setting, speaker-listener relationship, and word choices. In this paper, we present a detailed corpus-based study of offensive language in Nepali. We identify and describe more than 18 different categories of linguistic offenses including politics, religion, race, and sex. We discuss 12 common euphemisms such as synonym, metaphor and circumlocution. In addition, we introduce a manually constructed data set of over 1000 offensive and taboo terms popular among contemporary speakers. This in-depth study of offensive language and resource will provide a foundation for several downstream tasks such as offensive language detection and language learning.",
    "lastUpdated": "2020-07-27T18:25:01Z",
    "categories": [
      "cs.CL"
    ],
    "url": "http://arxiv.org/abs/2007.13798v1"
  },
  {
    "title": "Application of Bayesian Dynamic Linear Models to Random Allocation Clinical Trials",
    "authors": [
      "Albert. H. Lee III",
      "Edward L Boone",
      "Roy T. Sabo",
      "Erin Donahue"
    ],
    "abstract": "Random allocation models used in clinical trials aid researchers in determining which of a particular treatment provides the best results by reducing bias between groups. Often however, this determination leaves researchers battling ethical issues of providing patients with unfavorable treatments. Many methods such as Play the Winner and Randomized Play the Winner Rule have historically been utilized to determine patient allocation, however, these methods are prone to the increased assignment of unfavorable treatments. Recently a new Bayesian Method using Decreasingly Informative Priors has been proposed by \\citep{sabo2014adaptive}, and later \\citep{donahue2020allocation}. Yet this method can be time consuming if MCMC methods are required. We propose the use of a new method which uses Dynamic Linear Model (DLM) \\citep{harrison1999bayesian} to increase allocation speed while also decreasing patient allocation samples necessary to identify the more favorable treatment. Furthermore, a sensitivity analysis is conducted on multiple parameters. Finally, a Bayes Factor is calculated to determine the proportion of unused patient budget remaining at a specified cut off and this will be used to determine decisive evidence in favor of the better treatment.",
    "lastUpdated": "2020-08-01T20:47:08Z",
    "categories": [
      "stat.AP"
    ],
    "url": "http://arxiv.org/abs/2008.00339v1"
  },
  {
    "title": "Congenial Differential Privacy under Mandated Disclosure",
    "authors": [
      "Ruobin Gong",
      "Xiao-Li Meng"
    ],
    "abstract": "Differentially private data releases are often required to satisfy a set of external constraints that reflect the legal, ethical, and logical mandates to which the data curator is obligated. The enforcement of constraints, when treated as post-processing, adds an extra phase in the production of privatized data. It is well understood in the theory of multi-phase processing that congeniality, a form of procedural compatibility between phases, is a prerequisite for the end users to straightforwardly obtain statistically valid results. Congenial differential privacy is theoretically principled, which facilitates transparency and intelligibility of the mechanism that would otherwise be undermined by ad-hoc post-processing procedures. We advocate for the systematic integration of mandated disclosure into the design of the privacy mechanism via standard probabilistic conditioning on the invariant margins. Conditioning automatically renders congeniality because any extra post-processing phase becomes unnecessary. We provide both initial theoretical guarantees and a Markov chain algorithm for our proposal. We also discuss intriguing theoretical issues that arise in comparing congenital differential privacy and optimization-based post-processing, as well as directions for further research.",
    "lastUpdated": "2020-08-24T05:51:12Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/2008.10202v1"
  },
  {
    "title": "Improving Fair Predictions Using Variational Inference In Causal Models",
    "authors": [
      "Rik Helwegen",
      "Christos Louizos",
      "Patrick Forré"
    ],
    "abstract": "The importance of algorithmic fairness grows with the increasing impact machine learning has on people's lives. Recent work on fairness metrics shows the need for causal reasoning in fairness constraints. In this work, a practical method named FairTrade is proposed for creating flexible prediction models which integrate fairness constraints on sensitive causal paths. The method uses recent advances in variational inference in order to account for unobserved confounders. Further, a method outline is proposed which uses the causal mechanism estimates to audit black box models. Experiments are conducted on simulated data and on a real dataset in the context of detecting unlawful social welfare. This research aims to contribute to machine learning techniques which honour our ethical and legal boundaries.",
    "lastUpdated": "2020-08-25T08:27:11Z",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2008.10880v1"
  },
  {
    "title": "Respect for Human Autonomy in Recommender Systems",
    "authors": [
      "Lav R. Varshney"
    ],
    "abstract": "Recommender systems can influence human behavior in significant ways, in some cases making people more machine-like. In this sense, recommender systems may be deleterious to notions of human autonomy. Many ethical systems point to respect for human autonomy as a key principle arising from human rights considerations, and several emerging frameworks for AI include this principle. Yet, no specific formalization has been defined. Separately, self-determination theory shows that autonomy is an innate psychological need for people, and moreover has a significant body of experimental work that formalizes and measures level of human autonomy. In this position paper, we argue that there is a need to specifically operationalize respect for human autonomy in the context of recommender systems. Moreover, that such an operational definition can be developed based on well-established approaches from experimental psychology, which can then be used to design future recommender systems that respect human autonomy.",
    "lastUpdated": "2020-09-05T21:39:34Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2009.02603v1"
  },
  {
    "title": "On the Fairness of 'Fake' Data in Legal AI",
    "authors": [
      "Lauren Boswell",
      "Arjun Prakash"
    ],
    "abstract": "The economics of smaller budgets and larger case numbers necessitates the use of AI in legal proceedings. We examine the concept of disparate impact and how biases in the training data lead to the search for fairer AI. This paper seeks to begin the discourse on what such an implementation would actually look like with a criticism of pre-processing methods in a legal context . We outline how pre-processing is used to correct biased data and then examine the legal implications of effectively changing cases in order to achieve a fairer outcome including the black box problem and the slow encroachment on legal precedent. Finally we present recommendations on how to avoid the pitfalls of pre-processed data with methods that either modify the classifier or correct the output in the final step.",
    "lastUpdated": "2020-09-11T08:35:55Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2009.04640v2"
  },
  {
    "title": "Teaching Tech to Talk: K-12 Conversational Artificial Intelligence Literacy Curriculum and Development Tools",
    "authors": [
      "Jessica Van Brummelen",
      "Tommy Heng",
      "Viktoriya Tabunshchyk"
    ],
    "abstract": "With children talking to smart-speakers, smart-phones and even smart-microwaves daily, it is increasingly important to educate students on how these agents work-from underlying mechanisms to societal implications. Researchers are developing tools and curriculum to teach K-12 students broadly about artificial intelligence (AI); however, few studies have evaluated these tools with respect to AI-specific learning outcomes, and even fewer have addressed student learning about AI-based conversational agents. We evaluate our Conversational Agent Interface for MIT App Inventor and workshop curriculum with respect to eight AI competencies from the literature. Furthermore, we analyze teacher (n=9) and student (n=47) feedback from workshops with the interface and recommend that future work leverages design considerations from the literature to optimize engagement, collaborates with teachers, and addresses a range of student abilities through pacing and opportunities for extension. We found students struggled most with the concepts of AI ethics and learning, and recommend emphasizing these topics when teaching. The appendix, including a demo video, can be found here: https://gist.github.com/jessvb/1cd959e32415a6ad4389761c49b54bbf",
    "lastUpdated": "2020-09-11T20:52:46Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "I.2.0; I.2.5; I.2.7; K.3.2"
    ],
    "url": "http://arxiv.org/abs/2009.05653v1"
  },
  {
    "title": "Machine Learning Applications in Misuse and Anomaly Detection",
    "authors": [
      "Jaydip Sen",
      "Sidra Mehtab"
    ],
    "abstract": "Machine learning and data mining algorithms play important roles in designing intrusion detection systems. Based on their approaches toward the detection of attacks in a network, intrusion detection systems can be broadly categorized into two types. In the misuse detection systems, an attack in a system is detected whenever the sequence of activities in the network matches with a known attack signature. In the anomaly detection approach, on the other hand, anomalous states in a system are identified based on a significant difference in the state transitions of the system from its normal states. This chapter presents a comprehensive discussion on some of the existing schemes of intrusion detection based on misuse detection, anomaly detection and hybrid detection approaches. Some future directions of research in the design of algorithms for intrusion detection are also identified.",
    "lastUpdated": "2020-09-10T19:52:00Z",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2009.06709v1"
  },
  {
    "title": "Engaging Teachers to Co-Design Integrated AI Curriculum for K-12 Classrooms",
    "authors": [
      "Jessica Van Brummelen",
      "Phoebe Lin"
    ],
    "abstract": "Artificial Intelligence (AI) education is an increasingly popular topic area for K-12 teachers. However, little research has investigated how AI education can be designed to be more accessible to all learners. We organized co-design workshops with 15 K-12 teachers to identify opportunities to integrate AI education into core curriculum to leverage learners' interests. During the co-design workshops, teachers and researchers co-created lesson plans where AI concepts were embedded into various core subjects. We found that K-12 teachers need additional scaffolding in the curriculum to facilitate ethics and data discussions, and value supports for learner engagement, collaboration, and reflection. We identify opportunities for researchers and teachers to collaborate to make AI education more accessible, and present an exemplar lesson plan that shows entry points for teaching AI in non-computing subjects. We also reflect on co-designing with K-12 teachers in a remote setting.",
    "lastUpdated": "2020-09-22T00:56:41Z",
    "categories": [
      "physics.ed-ph",
      "cs.CY",
      "K.3.2; I.2"
    ],
    "url": "http://arxiv.org/abs/2009.11100v1"
  },
  {
    "title": "A novel estimand to adjust for rescue treatment in clinical trials",
    "authors": [
      "Hege Michiels",
      "Cristina Sotto",
      "An Vandebosch",
      "Stijn Vansteelandt"
    ],
    "abstract": "The interpretation of randomised clinical trial results is often complicated by intercurrent events. For instance, rescue medication is sometimes given to patients in response to worsening of their disease, either in addition to the randomised treatment or in its place. The use of such medication complicates the interpretation of the intention-to-treat analysis. In view of this, we propose a novel estimand defined as the intention-to-treat effect that would have been observed, had patients on the active arm been switched to rescue medication if and only if they would have been switched when randomised to control. This enables us to disentangle the treatment effect from the effect of rescue medication on a patient's outcome, while avoiding the strong extrapolations that are typically needed when inferring what the intention-to-treat effect would have been in the absence of rescue medication. We develop an inverse probability weighting method to estimate this estimand under specific untestable assumptions, in view of which we propose a sensitivity analysis. We use the method for the analysis of a clinical trial conducted by Janssen Pharmaceuticals, in which chronically ill patients can switch to rescue medication for ethical reasons. Monte Carlo simulations confirm that the proposed estimator is unbiased in moderate sample sizes.",
    "lastUpdated": "2020-09-25T06:37:28Z",
    "categories": [
      "stat.ME"
    ],
    "url": "http://arxiv.org/abs/2009.12052v1"
  },
  {
    "title": "Differentially Private and Fair Deep Learning: A Lagrangian Dual Approach",
    "authors": [
      "Cuong Tran",
      "Ferdinando Fioretto",
      "Pascal Van Hentenryck"
    ],
    "abstract": "A critical concern in data-driven decision making is to build models whose outcomes do not discriminate against some demographic groups, including gender, ethnicity, or age. To ensure non-discrimination in learning tasks, knowledge of the sensitive attributes is essential, while, in practice, these attributes may not be available due to legal and ethical requirements. To address this challenge, this paper studies a model that protects the privacy of the individuals sensitive information while also allowing it to learn non-discriminatory predictors. The method relies on the notion of differential privacy and the use of Lagrangian duality to design neural networks that can accommodate fairness constraints while guaranteeing the privacy of sensitive attributes. The paper analyses the tension between accuracy, privacy, and fairness and the experimental evaluation illustrates the benefits of the proposed model on several prediction tasks.",
    "lastUpdated": "2020-09-26T10:50:33Z",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2009.12562v1"
  },
  {
    "title": "Target Privacy Threat Modeling for COVID-19 Exposure Notification Systems",
    "authors": [
      "Ananya Gangavarapu",
      "Ellie Daw",
      "Abhishek Singh",
      "Rohan Iyer",
      "Gabriel Harp",
      "Sam Zimmerman",
      "Ramesh Raskar"
    ],
    "abstract": "The adoption of digital contact tracing (DCT) technology during the COVID-19pandemic has shown multiple benefits, including helping to slow the spread of infectious disease and to improve the dissemination of accurate information. However, to support both ethical technology deployment and user adoption, privacy must be at the forefront. With the loss of privacy being a critical threat, thorough threat modeling will help us to strategize and protect privacy as digital contact tracing technologies advance. Various threat modeling frameworks exist today, such as LINDDUN, STRIDE, PASTA, and NIST, which focus on software system privacy, system security, application security, and data-centric risk, respectively. When applied to the exposure notification system (ENS) context, these models provide a thorough view of the software side but fall short in addressing the integrated nature of hardware, humans, regulations, and software involved in such systems. Our approach addresses ENSsas a whole and provides a model that addresses the privacy complexities of a multi-faceted solution. We define privacy principles, privacy threats, attacker capabilities, and a comprehensive threat model. Finally, we outline threat mitigation strategies that address the various threats defined in our model",
    "lastUpdated": "2020-09-25T02:09:51Z",
    "categories": [
      "cs.CR",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2009.13300v1"
  },
  {
    "title": "DCFIT: Initial Trigger-Based PFC Deadlock Detection in the Data Plane",
    "authors": [
      "Xinyu Crystal Wu",
      "T. S. Eugene Ng"
    ],
    "abstract": "Recent data center applications rely on lossless networks to achieve high network performance. Lossless networks, however, can suffer from in-network deadlocks induced by hop-by-hop flow control protocols like PFC. Once deadlocks occur, large parts of the network could be blocked. Existing solutions mainly center on a deadlock avoidance strategy; unfortunately, they are not foolproof. Thus, deadlock detection is a necessary last resort. In this paper, we propose DCFIT, a new mechanism performed entirely in the data plane to detect and solve deadlocks for arbitrary network topologies and routing protocols. Unique to DCFIT is the use of deadlock initial triggers, which contribute to efficient deadlock detection and deadlock recurrence prevention. Preliminary results indicate that DCFIT can detect deadlocks quickly with minimal overhead and mitigate the recurrence of the same deadlocks effectively. This work does not raise any ethical issues.",
    "lastUpdated": "2020-09-28T16:10:40Z",
    "categories": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/2009.13446v1"
  },
  {
    "title": "Using sex and gender in survey adjustment",
    "authors": [
      "Lauren Kennedy",
      "Katharine Khanna",
      "Daniel Simpson",
      "Andrew Gelman"
    ],
    "abstract": "Accounting for sex and gender characteristics is a complex, structural challenge in social science research. While other methodology papers consider issues surrounding appropriate measurement, we consider how gender and sex impact adjustments for non-response patterns in sampling and survey estimates. We consider the problem of survey adjustment arising from the recent push toward measuring sex or gender as a non-binary construct. This is challenging not only in that response categories differ between sex and gender measurement, but also in that both of these attributes are potentially multidimensional. In this manuscript we reflect on similarities to measuring race/ethnicity before considering the ethical and statistical implications of the options available to us. We do not conclude with a single best recommendation but rather an awareness of the complexity of the issues surrounding this challenge and the benefits and weaknesses of different approaches.",
    "lastUpdated": "2020-09-30T02:59:35Z",
    "categories": [
      "stat.AP"
    ],
    "url": "http://arxiv.org/abs/2009.14401v1"
  },
  {
    "title": "Compositional Demographic Word Embeddings",
    "authors": [
      "Charles Welch",
      "Jonathan K. Kummerfeld",
      "Verónica Pérez-Rosas",
      "Rada Mihalcea"
    ],
    "abstract": "Word embeddings are usually derived from corpora containing text from many individuals, thus leading to general purpose representations rather than individually personalized representations. While personalized embeddings can be useful to improve language model performance and other language processing tasks, they can only be computed for people with a large amount of longitudinal data, which is not the case for new users. We propose a new form of personalized word embeddings that use demographic-specific word representations derived compositionally from full or partial demographic information for a user (i.e., gender, age, location, religion). We show that the resulting demographic-aware word representations outperform generic word representations on two tasks for English: language modeling and word associations. We further explore the trade-off between the number of available attributes and their relative effectiveness and discuss the ethical implications of using them.",
    "lastUpdated": "2020-10-29T18:54:53Z",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2010.02986v2"
  },
  {
    "title": "A survey of algorithmic recourse: definitions, formulations, solutions, and prospects",
    "authors": [
      "Amir-Hossein Karimi",
      "Gilles Barthe",
      "Bernhard Schölkopf",
      "Isabel Valera"
    ],
    "abstract": "Machine learning is increasingly used to inform decision-making in sensitive situations where decisions have consequential effects on individuals' lives. In these settings, in addition to requiring models to be accurate and robust, socially relevant values such as fairness, privacy, accountability, and explainability play an important role for the adoption and impact of said technologies. In this work, we focus on algorithmic recourse, which is concerned with providing explanations and recommendations to individuals who are unfavourably treated by automated decision-making systems. We first perform an extensive literature review, and align the efforts of many authors by presenting unified definitions, formulations, and solutions to recourse. Then, we provide an overview of the prospective research directions towards which the community may engage, challenging existing assumptions and making explicit connections to other ethical challenges such as security, privacy, and fairness.",
    "lastUpdated": "2020-10-08T15:15:34Z",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2010.04050v1"
  },
  {
    "title": "A Framework for Addressing the Risks and Opportunities In AI-Supported Virtual Health Coaches",
    "authors": [
      "Sonia Baee",
      "Mark Rucker",
      "Anna Baglione",
      "Mawulolo K. Ameko",
      "Laura Barnes"
    ],
    "abstract": "Virtual coaching has rapidly evolved into a foundational component of modern clinical practice. At a time when healthcare professionals are in short supply and the demand for low-cost treatments is ever-increasing, virtual health coaches (VHCs) offer intervention-on-demand for those limited by finances or geographic access to care. More recently, AI-powered virtual coaches have become a viable complement to human coaches. However, the push for AI-powered coaching systems raises several important issues for researchers, designers, clinicians, and patients. In this paper, we present a novel framework to guide the design and development of virtual coaching systems. This framework augments a traditional data science pipeline with four key guiding goals: reliability, fairness, engagement, and ethics.",
    "lastUpdated": "2020-10-12T22:41:35Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2010.06059v1"
  },
  {
    "title": "Non-Additive Axiologies in Large Worlds",
    "authors": [
      "Christian Tarsney",
      "Teruji Thomas"
    ],
    "abstract": "Is the overall value of a world just the sum of values contributed by each value-bearing entity in that world? Additively separable axiologies (like total utilitarianism, prioritarianism, and critical level views) say 'yes', but non-additive axiologies (like average utilitarianism, rank-discounted utilitarianism, and variable value views) say 'no'. This distinction is practically important: additive axiologies support 'arguments from astronomical scale' which suggest (among other things) that it is overwhelmingly important for humanity to avoid premature extinction and ensure the existence of a large future population, while non-additive axiologies need not. We show, however, that when there is a large enough 'background population' unaffected by our choices, a wide range of non-additive axiologies converge in their implications with some additive axiology -- for instance, average utilitarianism converges to critical-level utilitarianism and various egalitarian theories converge to prioritiarianism. We further argue that real-world background populations may be large enough to make these limit results practically significant. This means that arguments from astronomical scale, and other arguments in practical ethics that seem to presuppose additive separability, may be truth-preserving in practice whether or not we accept additive separability as a basic axiological principle.",
    "lastUpdated": "2020-10-14T07:02:23Z",
    "categories": [
      "econ.TH"
    ],
    "url": "http://arxiv.org/abs/2010.06842v1"
  },
  {
    "title": "Altruist: Argumentative Explanations through Local Interpretations of Predictive Models",
    "authors": [
      "Ioannis Mollas",
      "Nick Bassiliades",
      "Grigorios Tsoumakas"
    ],
    "abstract": "Interpretable machine learning is an emerging field providing solutions on acquiring insights into machine learning models' rationale. It has been put in the map of machine learning by suggesting ways to tackle key ethical and societal issues. However, existing techniques of interpretable machine learning are far from being comprehensible and explainable to the end user. Another key issue in this field is the lack of evaluation and selection criteria, making it difficult for the end user to choose the most appropriate interpretation technique for its use. In this study, we introduce a meta-explanation methodology that will provide truthful interpretations, in terms of feature importance, to the end user through argumentation. At the same time, this methodology can be used as an evaluation or selection tool for multiple interpretation techniques based on feature importance.",
    "lastUpdated": "2020-10-15T10:36:48Z",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.LO",
      "I.2.0; I.2.6"
    ],
    "url": "http://arxiv.org/abs/2010.07650v1"
  },
  {
    "title": "Leveraging Technology for Healthcare and Retaining Access to Personal Health Data to Enhance Personal Health and Well-being",
    "authors": [
      "Ayan Chatterjee",
      "Ali Shahaab",
      "Martin W. Gerdes",
      "Santiago Martinez",
      "Pankaj Khatiwada"
    ],
    "abstract": "Health data is a sensitive category of personal data. It might result in a high risk to individual and health information handling rights and opportunities unless there is a palatable defense. Reasonable security standards are needed to protect electronic health records (EHR). All personal data handling needs adequate explanation. Maintaining access to medical data even in the developing world would favor health and well-being across the world. Unfortunately, there are still countries that hinder the portability of medical records. Numerous occurrences have shown that it still takes weeks for the medical data to be ported from one general physician (GP) to another. Cross border portability is nearly impossible due to the lack of technical infrastructure and standardization. We demonstrate the difficulty of the portability of medical records with some example case studies as a collaborative engagement exercise through a data mapping process to describe how different people and datapoints interact and evaluate EHR portability techniques. We then propose a blockchain-based EHR system that allows secure, and cross border sharing of medical data. The ethical and technical challenges around having such a system have also been discussed in this study.",
    "lastUpdated": "2020-10-20T13:56:15Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/2010.10285v1"
  },
  {
    "title": "Artificial Tikkun Olam: AI Can Be Our Best Friend in Building an Open Human-Computer Society",
    "authors": [
      "Simon Kasif"
    ],
    "abstract": "Technological advances of virtually every kind pose risks to society including fairness and bias. We review a long-standing wisdom that a widespread practical deployment of any technology may produce adverse side effects misusing the knowhow. This includes AI but AI systems are not solely responsible for societal risks. We describe some of the common and AI specific risks in health industries and other sectors and propose both broad and specific solutions. Each technology requires very specialized and informed tracking, monitoring and creative solutions. We postulate that AI systems are uniquely poised to produce conceptual and methodological solutions to both fairness and bias in automated decision-making systems. We propose a simple intelligent system quotient that may correspond to their adverse societal impact and outline a multi-tier architecture for producing solutions of increasing complexity to these risks. We also propose that universities may consider forming interdisciplinary Study of Future Technology Centers to investigate and predict the fuller range of risks posed by technology and seek both common and AI specific solutions using computational, technical, conceptual and ethical analysis",
    "lastUpdated": "2020-10-20T23:29:45Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2010.12015v1"
  },
  {
    "title": "Biases in Generative Art---A Causal Look from the Lens of Art History",
    "authors": [
      "Ramya Srinivasan",
      "Kanji Uchino"
    ],
    "abstract": "With rapid progress in artificial intelligence (AI), popularity of generative art has grown substantially. From creating paintings to generating novel art styles, AI based generative art has showcased a variety of applications. However, there has been little focus concerning the ethical impacts of AI based generative art. In this work, we investigate biases in the generative art AI pipeline right from those that can originate due to improper problem formulation to those related to algorithm design. Viewing from the lens of art history, we discuss the socio-cultural impacts of these biases. Leveraging causal models, we highlight how current methods fall short in modeling the process of art creation and thus contribute to various types of biases. We illustrate the same through case studies. To the best of our knowledge, this is the first extensive analysis that investigates biases in the generative art AI pipeline from the perspective of art history. We hope our work sparks interdisciplinary discussions related to accountability of generative art.",
    "lastUpdated": "2020-10-26T00:49:09Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2010.13266v1"
  },
  {
    "title": "Exploring the Nuances of Designing (with/for) Artificial Intelligence",
    "authors": [
      "Niya Stoimenova",
      "Rebecca Price"
    ],
    "abstract": "Solutions relying on artificial intelligence are devised to predict data patterns and answer questions that are clearly defined, involve an enumerable set of solutions, clear rules, and inherently binary decision mechanisms. Yet, as they become exponentially implemented in our daily activities, they begin to transcend these initial boundaries and to affect the larger sociotechnical system in which they are situated. In this arrangement, a solution is under pressure to surpass true or false criteria and move to an ethical evaluation of right and wrong. Neither algorithmic solutions, nor purely humanistic ones will be enough to fully mitigate undesirable outcomes in the narrow state of AI or its future incarnations. We must take a holistic view. In this paper we explore the construct of infrastructure as a means to simultaneously address algorithmic and societal issues when designing AI.",
    "lastUpdated": "2020-10-22T20:34:35Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2010.15578v1"
  },
  {
    "title": "Enjeux éthiques de l'IA en santé : une humanisation du parcours de soin par l'intelligence artificielle ?",
    "authors": [
      "Fabrice Muhlenbach"
    ],
    "abstract": "Considering the use of artificial intelligence for greater personalization of patient care and better management of human and material resources may seem like an opportunity not to be missed. In order to offer a better humanization of the care pathway, artificial intelligence is a tool that decision-makers in the hospital sector must appropriate by taking care of the new ethical issues and conflicts of values that this technology generates. Envisager le recours \\`a l'intelligence artificielle pour une plus grande personnalisation de la prise en charge du patient et une meilleure gestion des ressources humaines et mat\\'erielles peut sembler une opportunit\\'e \\`a ne pas manquer. Afin de proposer une meilleure humanisation du parcours de soin, l'intelligence artificielle est un outil que les d\\'ecideurs du milieu hospitalier doivent s'approprier en veillant aux nouveaux enjeux \\'ethiques et conflits de valeurs que cette technologie engendre.",
    "lastUpdated": "2020-10-23T20:34:19Z",
    "categories": [
      "cs.CY",
      "I.2; J.3"
    ],
    "url": "http://arxiv.org/abs/2010.15590v1"
  },
  {
    "title": "University of Washington at TREC 2020 Fairness Ranking Track",
    "authors": [
      "Yunhe Feng",
      "Daniel Saelid",
      "Ke Li",
      "Ruoyuan Gao",
      "Chirag Shah"
    ],
    "abstract": "InfoSeeking Lab's FATE (Fairness Accountability Transparency Ethics) group at University of Washington participated in 2020 TREC Fairness Ranking Track. This report describes that track, assigned data and tasks, our group definitions, and our results. Our approach to bringing fairness in retrieval and re-ranking tasks with Semantic Scholar data was to extract various dimensions of author identity. These dimensions included gender and location. We developed modules for these extractions in a way that allowed us to plug them in for either of the tasks as needed. After trying different combinations of relative weights assigned to relevance, gender, and location information, we chose five runs for retrieval and five runs for re-ranking tasks. The results showed that our runs performed below par for re-ranking task, but above average for retrieval.",
    "lastUpdated": "2020-11-22T06:55:24Z",
    "categories": [
      "cs.IR"
    ],
    "url": "http://arxiv.org/abs/2011.02066v2"
  },
  {
    "title": "The Gray Rhino of Pandemic Preparedness: Proactive digital, data, and organizational infrastructure to help humanity build resilience in the face of pandemics",
    "authors": [
      "Abhishek Gupta"
    ],
    "abstract": "COVID-19 has exposed glaring holes in our existing digital, data, and organizational practices. Researchers ensconced in epidemiological and human health work have repeatedly pointed out how urban encroachment, climate change, and other human-triggered activities and patterns are going to make zoonotic pandemics more frequent and commonplace. The Gray Rhino mindset provides a useful reframing (as opposed to viewing pandemics such as the current one as a Black Swan event) that can help us recover faster from these (increasingly) frequent occurrences and build resiliency in our digital, data, and organizational infrastructure. Mitigating the social and economic impacts of pandemics can be eased through building infrastructure that elucidate leading indicators via passive intelligence gathering so that responses to containing the spread of pandemics are not blanket measures; instead, they can be fine-grained allowing for more efficient utilization of scarce resources and minimizing disruption to our way of life.",
    "lastUpdated": "2020-11-05T11:55:42Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2011.02773v1"
  },
  {
    "title": "Reliable Off-policy Evaluation for Reinforcement Learning",
    "authors": [
      "Jie Wang",
      "Rui Gao",
      "Hongyuan Zha"
    ],
    "abstract": "In a sequential decision-making problem, off-policy evaluation (OPE) estimates the expected cumulative reward of a target policy using logged transition data generated from a different behavior policy, without execution of the target policy. Reinforcement learning in high-stake environments, such as healthcare and education, is often limited to off-policy settings due to safety or ethical concerns, or inability of exploration. Hence it is imperative to quantify the uncertainty of the off-policy estimate before deployment of the target policy. In this paper, we propose a novel framework that provides robust and optimistic cumulative reward estimates with statistical guarantees and develop non-asymptotic as well as asymptotic confidence intervals for OPE, leveraging methodologies from distributionally robust optimization. Our theoretical results are also supported by empirical analysis.",
    "lastUpdated": "2020-11-08T23:16:19Z",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2011.04102v1"
  },
  {
    "title": "A Survey of Requirements for COVID-19 Mitigation Strategies. Part I: Newspaper Clips",
    "authors": [
      "Wojciech Jamroga",
      "David Mestel",
      "Peter B. Roenne",
      "Peter Y. A. Ryan",
      "Marjan Skrobot"
    ],
    "abstract": "The COVID-19 pandemic has influenced virtually all aspects of our lives. Across the world, countries have applied various mitigation strategies for the epidemic, based on social, political, and technological instruments. We postulate that one should {identify the relevant requirements} before committing to a particular mitigation strategy. One way to achieve it is through an overview of what is considered relevant by the general public, and referred to in the media. To this end, we have collected a number of news clips that mention the possible goals and requirements for a mitigation strategy. The snippets are sorted thematically into several categories, such as health-related goals, social and political impact, civil rights, ethical requirements, and so on. In a forthcoming companion paper, we will present a digest of the requirements, derived from the news clips, and a preliminary take on their formal specification.",
    "lastUpdated": "2020-12-14T11:12:04Z",
    "categories": [
      "cs.CY",
      "cs.MA"
    ],
    "url": "http://arxiv.org/abs/2011.07887v2"
  },
  {
    "title": "AI Governance for Businesses",
    "authors": [
      "Johannes Schneider",
      "Rene Abraham",
      "Christian Meske"
    ],
    "abstract": "Artificial Intelligence (AI) governance regulates the exercise of authority and control over the management of AI. It aims at leveraging AI through effective use of data and minimization of AI-related cost and risk. While topics such as AI governance and AI ethics are thoroughly discussed on a theoretical, philosophical, societal and regulatory level, there is limited work on AI governance targeted to companies and corporations. This work views AI products as systems, where key functionality is delivered by machine learning (ML) models leveraging (training) data. We derive a conceptual framework by synthesizing literature on AI and related fields such as ML. Our framework decomposes AI governance into governance of data, (ML) models and (AI) systems along four dimensions. It relates to existing IT and data governance frameworks and practices. It can be adopted by practitioners and academics alike. For practitioners the synthesis of mainly research papers, but also practitioner publications and publications of regulatory bodies provides a valuable starting point to implement AI governance, while for academics the paper highlights a number of areas of AI governance that deserve more attention.",
    "lastUpdated": "2020-11-20T22:31:37Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2011.10672v1"
  },
  {
    "title": "Social Determinants of Recidivism: A Machine Learning Solution",
    "authors": [
      "Vik Shirvaikar",
      "Choudur Lakshminarayan"
    ],
    "abstract": "Current literature in criminal justice analytics often focuses on predicting the likelihood of recidivism (repeat offenses committed by released defendants), but this problem is fraught with ethical missteps ranging from selection bias in data collection to model interpretability. This paper re-purposes Machine Learning (ML) in criminal justice to identify social determinants of recidivism, with contributions along three dimensions. (1) We shift the focus from predicting which individuals will re-offend to identifying the broader underlying factors that explain differences in recidivism, with the goal of providing a reliable framework for preventative policy intervention. (2) Recidivism models typically agglomerate all individuals into one dataset to carry out ML tasks. We instead apply unsupervised learning to reduce noise and extract homogeneous subgroups of individuals, with a novel heuristic to find the optimal number of subgroups. (3) We subsequently apply supervised learning within the subgroups to determine statistically significant features that are correlated to recidivism. It is our view that this new approach to a long-standing question will serve as a useful guide for the practical application of ML in policymaking.",
    "lastUpdated": "2020-12-04T18:25:26Z",
    "categories": [
      "cs.LG",
      "cs.CY",
      "stat.AP"
    ],
    "url": "http://arxiv.org/abs/2011.11483v2"
  },
  {
    "title": "Argument from Old Man's View: Assessing Social Bias in Argumentation",
    "authors": [
      "Maximilian Spliethöver",
      "Henning Wachsmuth"
    ],
    "abstract": "Social bias in language - towards genders, ethnicities, ages, and other social groups - poses a problem with ethical impact for many NLP applications. Recent research has shown that machine learning models trained on respective data may not only adopt, but even amplify the bias. So far, however, little attention has been paid to bias in computational argumentation. In this paper, we study the existence of social biases in large English debate portals. In particular, we train word embedding models on portal-specific corpora and systematically evaluate their bias using WEAT, an existing metric to measure bias in word embeddings. In a word co-occurrence analysis, we then investigate causes of bias. The results suggest that all tested debate corpora contain unbalanced and biased data, mostly in favor of male people with European-American names. Our empirical insights contribute towards an understanding of bias in argumentative data sources.",
    "lastUpdated": "2020-11-24T10:39:44Z",
    "categories": [
      "cs.CL",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2011.12014v1"
  },
  {
    "title": "Like a Researcher Stating Broader Impact For the Very First Time",
    "authors": [
      "Grace Abuhamad",
      "Claudel Rheault"
    ],
    "abstract": "In requiring that a statement of broader impact accompany all submissions for this year's conference, the NeurIPS program chairs made ethics part of the stake in groundbreaking AI research. While there is precedent from other fields and increasing awareness within the NeurIPS community, this paper seeks to answer the question of how individual researchers reacted to the new requirement, including not just their views, but also their experience in drafting and their reflections after paper acceptances. We present survey results and considerations to inform the next iteration of the broader impact requirement should it remain a requirement for future NeurIPS conferences.",
    "lastUpdated": "2020-11-25T21:32:29Z",
    "categories": [
      "cs.CY",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2011.13032v1"
  },
  {
    "title": "A Critique of Immunity Passports and W3C Decentralized Identifiers",
    "authors": [
      "Harry Halpin"
    ],
    "abstract": "Due to the widespread COVID-19 pandemic, there has been a push for `immunity passports' and even technical proposals. Although the debate about the medical and ethical problems of immunity passports has been widespread, there has been less inspection of the technical foundations of immunity passport schemes. These schemes are envisaged to be used for sharing COVID-19 test and vaccination results in general. The most prominent immunity passport schemes have involved a stack of little-known standards, such as Decentralized Identifiers (DIDs) and Verifiable Credentials (VCs) from the World Wide Web Consortium (W3C). Our analysis shows that this group of technical identity standards are based on under-specified and often non-standardized documents that have substantial security and privacy issues, due in part to the questionable use of blockchain technology. One concrete proposal for immunity passports is even susceptible to dictionary attacks. The use of `cryptography theater' in efforts like immunity passports, where cryptography is used to allay the privacy concerns of users, should be discouraged in standardization. Deployment of these W3C standards for `self-sovereign identity' in use-cases like immunity passports could just as well lead to a dangerous form identity totalitarianism.",
    "lastUpdated": "2020-11-30T22:10:43Z",
    "categories": [
      "cs.CR",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2012.00136v1"
  },
  {
    "title": "The future of cancer treatments: a critical review of mathematical models for combination cancer therapy",
    "authors": [
      "Joseph Malinzi",
      "Kevin Bosire Basita",
      "Sara Padidar",
      "Henry A. Adeola"
    ],
    "abstract": "The long-term efficacy of targeted therapeutics for cancer treatment can be significantly limited by the type of therapy and development of drug resistance, inter alia. Experimental studies indicate that the factors enhancing acquisition of drug resistance in cancer cells include cell heterogeneity, drug target alteration, drug inactivation, DNA damage repair, drug efflux, cell death inhibition, as well as microenvironmental adaptations to targeted therapy, among others. Combination cancer therapies (CCTs) are employed to overcome these molecular and pathophysiological bottlenecks and improve the overall survival of cancer patients. CCTs often utilize multiple combinatorial modes of action and thus potentially constitute a promising approach to overcome drug resistance. Considering the colossal cost, human effort, time and ethical issues involved in clinical drug trials and basic medical research, mathematical modeling and analysis can potentially contribute immensely to the discovery of better cancer treatment regimens. In this article, we review mathematical models on CCTs developed thus far for cancer management. Open questions are highlighted and plausible combinations are discussed based on the level of toxicity, drug resistance, survival benefits, preclinical trials and other side effects.",
    "lastUpdated": "2020-11-12T12:39:50Z",
    "categories": [
      "q-bio.TO",
      "92B05, 49K20, 92D25, 35Q92"
    ],
    "url": "http://arxiv.org/abs/2012.00683v1"
  },
  {
    "title": "Verifiable Proof of Health using Public Key Cryptography",
    "authors": [
      "Abhishek Singh",
      "Ramesh Raskar"
    ],
    "abstract": "In the current pandemic, testing continues to be the most important tool for monitoring and curbing the disease spread and early identification of the disease to perform health-related interventions like quarantine, contact tracing and etc. Therefore, the ability to verify the testing status is pertinent as public places prepare to safely open. Recent advances in cryptographic tools have made it possible to build a secure and resilient digital-id system. In this work, we propose to build an end to end COVID-19 results verification protocol that takes privacy, computation, and other practical concerns into account for designing an inter-operable layer of testing results verification system that could potentially enable less stringent and more selective lockdowns. We also discuss various concerns encompassing the security, privacy, ethics and equity aspect of the proposed system.",
    "lastUpdated": "2020-12-04T22:54:33Z",
    "categories": [
      "cs.CR",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2012.02885v1"
  },
  {
    "title": "An Approach to Intelligent Pneumonia Detection and Integration",
    "authors": [
      "Bonaventure F. P. Dossou",
      "Alena Iureva",
      "Sayali R. Rajhans",
      "Vamsi S. Pidikiti"
    ],
    "abstract": "Each year, over 2.5 million people, most of them in developed countries, die from pneumonia [1]. Since many studies have proved pneumonia is successfully treatable when timely and correctly diagnosed, many of diagnosis aids have been developed, with AI-based methods achieving high accuracies [2]. However, currently, the usage of AI in pneumonia detection is limited, in particular, due to challenges in generalizing a locally achieved result. In this report, we propose a roadmap for creating and integrating a system that attempts to solve this challenge. We also address various technical, legal, ethical, and logistical issues, with a blueprint of possible solutions.",
    "lastUpdated": "2020-12-07T07:27:45Z",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2012.03487v1"
  },
  {
    "title": "Technology-driven Alteration of Nonverbal Cues and its Effects on Negotiation",
    "authors": [
      "Raiyan Abdul Baten",
      "Ehsan Hoque"
    ],
    "abstract": "A person's appearance, identity, and other nonverbal cues can substantially influence how one is perceived by a negotiation counterpart, potentially impacting the outcome of the negotiation. With recent advances in technology, it is now possible to alter such cues through real-time video communication. In many cases, a person's physical presence can explicitly be replaced by 2D/3D representations in live interactive media. In other cases, technologies such as deepfake can subtly and implicitly alter many nonverbal cues -- including a person's appearance and identity -- in real-time. In this article, we look at some state-of-the-art technological advances that can enable such explicit and implicit alteration of nonverbal cues. We also discuss the implications of such technology for the negotiation landscape and highlight ethical considerations that warrant deep, ongoing attention from stakeholders.",
    "lastUpdated": "2020-12-08T01:01:38Z",
    "categories": [
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/2012.04142v1"
  },
  {
    "title": "Cyber Autonomy: Automating the Hacker- Self-healing, self-adaptive, automatic cyber defense systems and their impact to the industry, society and national security",
    "authors": [
      "Ryan K L Ko"
    ],
    "abstract": "This paper sets the context for the urgency for cyber autonomy, and the current gaps of the cyber security industry. A novel framework proposing four phases of maturity for full cyber autonomy will be discussed. The paper also reviews new and emerging cyber security automation techniques and tools, and discusses their impact on society, the perceived cyber security skills gap/shortage and national security. We will also be discussing the delicate balance between national security, human rights and ethics, and the potential demise of the manual penetration testing industry in the face of automation.",
    "lastUpdated": "2020-12-08T12:50:09Z",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY",
      "cs.SE",
      "I.2.2; I.2.m; K.4.0; K.4.1"
    ],
    "url": "http://arxiv.org/abs/2012.04405v1"
  },
  {
    "title": "Data and its (dis)contents: A survey of dataset development and use in machine learning research",
    "authors": [
      "Amandalynne Paullada",
      "Inioluwa Deborah Raji",
      "Emily M. Bender",
      "Emily Denton",
      "Alex Hanna"
    ],
    "abstract": "Datasets have played a foundational role in the advancement of machine learning research. They form the basis for the models we design and deploy, as well as our primary medium for benchmarking and evaluation. Furthermore, the ways in which we collect, construct and share these datasets inform the kinds of problems the field pursues and the methods explored in algorithm development. However, recent work from a breadth of perspectives has revealed the limitations of predominant practices in dataset collection and use. In this paper, we survey the many concerns raised about the way we collect and use data in machine learning and advocate that a more cautious and thorough understanding of data is necessary to address several of the practical and ethical issues of the field.",
    "lastUpdated": "2020-12-09T22:13:13Z",
    "categories": [
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2012.05345v1"
  },
  {
    "title": "Privacy-preserving medical image analysis",
    "authors": [
      "Alexander Ziller",
      "Jonathan Passerat-Palmbach",
      "Théo Ryffel",
      "Dmitrii Usynin",
      "Andrew Trask",
      "Ionésio Da Lima Costa Junior",
      "Jason Mancuso",
      "Marcus Makowski",
      "Daniel Rueckert",
      "Rickmer Braren",
      "Georgios Kaissis"
    ],
    "abstract": "The utilisation of artificial intelligence in medicine and healthcare has led to successful clinical applications in several domains. The conflict between data usage and privacy protection requirements in such systems must be resolved for optimal results as well as ethical and legal compliance. This calls for innovative solutions such as privacy-preserving machine learning (PPML). We present PriMIA (Privacy-preserving Medical Image Analysis), a software framework designed for PPML in medical imaging. In a real-life case study we demonstrate significantly better classification performance of a securely aggregated federated learning model compared to human experts on unseen datasets. Furthermore, we show an inference-as-a-service scenario for end-to-end encrypted diagnosis, where neither the data nor the model are revealed. Lastly, we empirically evaluate the framework's security against a gradient-based model inversion attack and demonstrate that no usable information can be recovered from the model.",
    "lastUpdated": "2020-12-10T13:56:00Z",
    "categories": [
      "cs.CR",
      "cs.CV",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2012.06354v1"
  },
  {
    "title": "Recent advances in deep learning theory",
    "authors": [
      "Fengxiang He",
      "Dacheng Tao"
    ],
    "abstract": "Deep learning is usually described as an experiment-driven field under continuous criticizes of lacking theoretical foundations. This problem has been partially fixed by a large volume of literature which has so far not been well organized. This paper reviews and organizes the recent advances in deep learning theory. The literature is categorized in six groups: (1) complexity and capacity-based approaches for analyzing the generalizability of deep learning; (2) stochastic differential equations and their dynamic systems for modelling stochastic gradient descent and its variants, which characterize the optimization and generalization of deep learning, partially inspired by Bayesian inference; (3) the geometrical structures of the loss landscape that drives the trajectories of the dynamic systems; (4) the roles of over-parameterization of deep neural networks from both positive and negative perspectives; (5) theoretical foundations of several special structures in network architectures; and (6) the increasingly intensive concerns in ethics and security and their relationships with generalizability.",
    "lastUpdated": "2020-12-20T14:16:41Z",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2012.10931v1"
  },
  {
    "title": "A Survey on Neural Network Interpretability",
    "authors": [
      "Yu Zhang",
      "Peter Tiňo",
      "Aleš Leonardis",
      "Ke Tang"
    ],
    "abstract": "Along with the great success of deep neural networks, there is also growing concern about their black-box nature. The interpretability issue affects people's trust on deep learning systems. It is also related to many ethical problems, e.g., algorithmic discrimination. Moreover, interpretability is a desired property for deep networks to become powerful tools in other research fields, e.g., drug discovery and genomics. In this survey, we conduct a comprehensive review of the neural network interpretability research. We first clarify the definition of interpretability as it has been used in many different contexts. Then we elaborate on the importance of interpretability and propose a novel taxonomy organized along three dimensions: type of engagement (passive vs. active interpretation approaches), the type of explanation, and the focus (from local to global interpretability). This taxonomy provides a meaningful 3D view of distribution of papers from the relevant literature as two of the dimensions are not simply categorical but allow ordinal subcategories. Finally, we summarize the existing interpretability evaluation methods and suggest possible research directions inspired by our new taxonomy.",
    "lastUpdated": "2020-12-28T15:09:50Z",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2012.14261v1"
  },
  {
    "title": "A Maximal Correlation Approach to Imposing Fairness in Machine Learning",
    "authors": [
      "Joshua Lee",
      "Yuheng Bu",
      "Prasanna Sattigeri",
      "Rameswar Panda",
      "Gregory Wornell",
      "Leonid Karlinsky",
      "Rogerio Feris"
    ],
    "abstract": "As machine learning algorithms grow in popularity and diversify to many industries, ethical and legal concerns regarding their fairness have become increasingly relevant. We explore the problem of algorithmic fairness, taking an information-theoretic view. The maximal correlation framework is introduced for expressing fairness constraints and shown to be capable of being used to derive regularizers that enforce independence and separation-based fairness criteria, which admit optimization algorithms for both discrete and continuous variables which are more computationally efficient than existing algorithms. We show that these algorithms provide smooth performance-fairness tradeoff curves and perform competitively with state-of-the-art methods on both discrete datasets (COMPAS, Adult) and continuous datasets (Communities and Crimes).",
    "lastUpdated": "2020-12-30T18:15:05Z",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2012.15259v1"
  },
  {
    "title": "Do Abstractions Have Politics? Towards a More Critical Algorithm Analysis",
    "authors": [
      "Kevin Lin"
    ],
    "abstract": "The expansion of computer science (CS) education in K--12 and higher-education in the United States has prompted deeper engagement with equity that moves beyond inclusion towards a more critical CS education. Rather than frame computing as a value-neutral tool, a justice-centered approach to equitable CS education draws on critical pedagogy to ensure the rightful presence of political struggles -- emphasizing the development of not only knowledge and skills, but also CS disciplinary identities. While recent efforts have integrated ethics into several areas of the undergraduate CS curriculum, critical approaches for teaching data structures and algorithms in particular are undertheorized. Basic Data Structures remains focused on runtime-centered algorithm analysis. We argue for a more critical algorithm analysis that centers an affordance account of value embedding. Drawing on critical traditions in science and technology studies, philosophy of technology, and algorithmic ethnography, affordance analysis examines how the design of abstractions such as data structures and algorithms embody affordances, which in turn embody values with political consequences. Through three case studies, we illustrate how affordance analysis refutes social determination of technology, foregrounds the limitations of data abstractions, and implicates the design of algorithms towards reinforcing benefits and harms along the matrix of domination.",
    "lastUpdated": "2021-01-04T05:59:26Z",
    "categories": [
      "cs.CY",
      "K.3.2"
    ],
    "url": "http://arxiv.org/abs/2101.00786v1"
  },
  {
    "title": "Towards a Smart Data Processing and Storage Model",
    "authors": [
      "Ronie Salgado",
      "Marcus Denker",
      "Stéphane Ducasse",
      "Anne Etien",
      "Vincent Aranega"
    ],
    "abstract": "In several domains it is crucial to store and manipulate data whose origin needs to be completely traceable to guarantee the consistency, trustworthiness and reliability on the data itself typically for ethical and legal reasons. It is also important to guarantee that such properties are also carried further when such data is composed and processed into new data. In this article we present the main requirements and theorethical problems that arise by the design of a system supporting data with such capabilities. We present an architecture for implementing a system as well as a prototype developed in Pharo.",
    "lastUpdated": "2021-01-07T12:52:11Z",
    "categories": [
      "cs.CL",
      "cs.PL",
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/2101.02522v1"
  },
  {
    "title": "Discussing the Risks of Adaptive Virtual Environments for User Autonomy",
    "authors": [
      "Tobias Drey",
      "Enrico Rukzio"
    ],
    "abstract": "Adaptive virtual environments are an opportunity to support users and increase their flow, presence, immersion, and overall experience. Possible fields of application are adaptive individual education, gameplay adjustment, professional work, and personalized content. But who benefits more from this adaptivity, the users who can enjoy a greater user experience or the companies or governments who are completely in control of the provided content. While the user autonomy decreases for individuals, the power of institutions raises, and the risk exists that personal opinions are precisely controlled. In this position paper, we will argue that researchers should not only propose the benefits of their work but also critically discuss what are possible abusive use cases. Therefore, we will examine two use cases in the fields of professional work and personalized content and show possible abusive use.",
    "lastUpdated": "2021-01-07T14:55:09Z",
    "categories": [
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/2101.02576v1"
  },
  {
    "title": "What Makes a Dark Pattern... Dark? Design Attributes, Normative Considerations, and Measurement Methods",
    "authors": [
      "Arunesh Mathur",
      "Jonathan Mayer",
      "Mihir Kshirsagar"
    ],
    "abstract": "There is a rapidly growing literature on dark patterns, user interface designs -- typically related to shopping or privacy -- that researchers deem problematic. Recent work has been predominantly descriptive, documenting and categorizing objectionable user interfaces. These contributions have been invaluable in highlighting specific designs for researchers and policymakers. But the current literature lacks a conceptual foundation: What makes a user interface a dark pattern? Why are certain designs problematic for users or society? We review recent work on dark patterns and demonstrate that the literature does not reflect a singular concern or consistent definition, but rather, a set of thematically related considerations. Drawing from scholarship in psychology, economics, ethics, philosophy, and law, we articulate a set of normative perspectives for analyzing dark patterns and their effects on individuals and society. We then show how future research on dark patterns can go beyond subjective criticism of user interface designs and apply empirical methods grounded in normative perspectives.",
    "lastUpdated": "2021-01-13T02:52:12Z",
    "categories": [
      "cs.HC",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2101.04843v1"
  },
  {
    "title": "The Mid-Infrared Color-Luminosity Relation and the Local 12 micron Luminosity Function",
    "authors": [
      "Fan Fang",
      "David L. Shupe",
      "Cong Xu",
      "Perry B. Hacking"
    ],
    "abstract": "We have established a model to systematically estimate the contribution of the mid-infrared emission features between 3 and 11.6 micron to the IRAS in-band fluxes, using the results of ISO PHT-S observation of 16 galaxies by Lu et al. (1997). The model is used to estimate more properly the k-corrections for calculating the restframe 12 and 25 micron fluxes and luminosities of IRAS galaxies. We have studied the 12-25 micron color-luminosity relation for a sample of galaxies selected at 25 microns. The color is found to correlate well with the 25 micron luminosity, the far-infrared and the blue luminosities. The relations with the mid-infrared luminosities are more sensitive to different populations of galaxies, while a single relation of the 12-25 micron color vs. the ratio of the far-infrared and the blue luminosities applies equally well to these different populations. The luminous and ultraluminous infrared galaxies have redder 12-25 micron colors than those of the quasars. These relations provide powerful tools to differentiate different populations of galaxies. We have also selected a sample of 668 galaxies from the IRAS Faint Source Survey flux-density limited at 200 mJy at 12 microns. A 12 micron local luminosity function is derived and, for the first time in the literature, effects of density variation in the local universe are considered and corrected in the calculation of the 12 micron luminosity function. It is also found that the 12 micron-selected sample are dominated by quasars and active galaxies, which therefore strongly affect the 12 micron luminosity function at high luminosities. The ultraluminous infrared galaxies are relatively rare at 12 micron comparing with a 25 micron sample.",
    "lastUpdated": "1998-03-13T23:43:48Z",
    "categories": [
      "astro-ph"
    ],
    "url": "http://arxiv.org/abs/astro-ph/9803162v1"
  },
  {
    "title": "Emission Features and Source Counts of Galaxies in Mid-Infrared",
    "authors": [
      "Cong Xu",
      "Perry B. Hacking",
      "Fan Fang",
      "David L. Shupe",
      "Carol J. Lonsdale",
      "Nanyao Y. Lu",
      "George Helou",
      "Gordon J. Stacey",
      "Matthew L. N. Ashby"
    ],
    "abstract": "In this work we incorporate the newest ISO results on the mid-infrared spectral-energy-distributions (MIR SEDs) of galaxies into models for the number counts and redshift distributions of MIR surveys. A three-component model, with empirically determined MIR SED templates of (1) a cirrus/PDR component (2) a starburst component and (3) an AGN component, is developed for infrared (3--120\\micron) SEDs of galaxies. The model includes a complete IRAS 25\\micron selected sample of 1406 local galaxies ($z \\leq 0.1$; Shupe et al. 1998a). Results based on these 1406 spectra show that the MIR emission features cause significant effects on the redshift dependence of the K-corrections for fluxes in the WIRE 25\\micron band and ISOCAM 15\\micron band. This in turn will affect deep counts and redshift distributions in these two bands, as shown by the predictions of two evolution models (a luminosity evolution model with $L\\propto (1+z)^3$ and a density evolution model with $\\rho\\propto (1+z)^4$). The dips-and-bumps on curves of MIR number counts, caused by the emission features, should be useful indicators of evolution mode. The strong emission features at $\\sim 6$--8\\micron will help the detections of relatively high redshift ($z\\sim 2$) galaxies in MIR surveys. On the other hand, determinations of the evolutionary rate based on the slope of source counts, and studies on the large scale structures using the redshift distribution of MIR sources, will have to treat the effects of the MIR emission features carefully. We have also estimated a 15\\micron local luminosity function from the predicted 15\\micron fluxes of the 1406 galaxies using the bivariate (15\\micron vs. 25\\micron luminosities) method. This luminosity function will improve our understanding of the ISOCAM 15\\micron surveys.",
    "lastUpdated": "1998-06-14T22:44:10Z",
    "categories": [
      "astro-ph"
    ],
    "url": "http://arxiv.org/abs/astro-ph/9806194v1"
  },
  {
    "title": "Pre-Heated Isentropic Gas in Groups of Galaxies",
    "authors": [
      "Mike L. Balogh",
      "Arif Babul",
      "David R. Patton"
    ],
    "abstract": "We confirm that the standard assumption of isothermal, shock-heated gas in cluster potentials is unable to reproduce the observed X-ray luminosity- temperature relation of groups of galaxies. As an alternative, we construct a physically motivated model for the adiabatic collapse of pre-heated gas into an isothermal potential that improves upon the original work of Kaiser (1991). The luminosity and temperature of the gas is calculated, assuming an appropriate distribution of halo formation times and radiation due to both bremsstrahlung and recombination processes. This model successfully reproduces the slope and dispersion of the luminosity-temperature relation of galaxy groups. We also present calculations of the temperature and luminosity functions for galaxy groups under the prescription of this model. This model makes two strong predictions for haloes with total masses M<10^13 M_sun, which are not yet testable with current data: (1) the gas mass fraction will increase in direct proportion to the halo mass; (2) the gas temperature will be larger than the virial temperature of the mass. The second effect is strong enough that group masses determined from gas temperatures will be overestimated by about an order of magnitude if it is assumed that the gas temperature is the virial temperature. The entropy required to match observations can be obtained by heating the gas at the turnaround time, for example, to about 3 X 10^6 K at z=1, which is too high to be generated by a normal rate of supernova explosions. This model breaks down on the scale of low mass clusters, but this is an acceptable limitation, as we expect accretion shocks to contribute significantly to the entropy of the gas in such objects.",
    "lastUpdated": "1999-02-28T17:04:59Z",
    "categories": [
      "astro-ph"
    ],
    "url": "http://arxiv.org/abs/astro-ph/9809159v2"
  },
  {
    "title": "The Submillimeter Frontier: A Space Science Imperative",
    "authors": [
      "John C. Mather",
      "S. Harvey Moseley, Jr.",
      "David Leisawitz",
      "Eli Dwek",
      "Perry Hacking",
      "Martin Harwit",
      "Lee G. Mundy",
      "Richard F. Mushotzky",
      "David Neufeld",
      "David Spergel",
      "Edward L. Wright"
    ],
    "abstract": "A major goal of modern astrophysics is to understand the processes by which the universe evolved from its initial simplicity, as seen in measurements of the Cosmic Microwave Background, to the universe we see today, with complexity on all scales. While the diffuse background measurements of COBE reveal the importance of the far infrared and submillimeter in early galaxy and star formation, the understanding of the development of complex structure requires high resolution imaging and spectroscopy. We present a concept for a space mission called SPECS, the Submillimeter Probe of the Evolution of Cosmic Structure, which provides these capabilities. SPECS is a cold, spatial and spectral Michelson interferometer with adjustable baselines ranging up to 1 km. It has Hubble sensitivity and angular resolution in the far IR and submillimeter, spectral resolution up to 10,000, and a 14' field of view. SPECS will be able to image thermal dust continuum and infrared cooling and diagnostic line emission over a wide range of redshifts, providing extinction-free astrophysical probes of young galaxies and early cosmic structures, and measures of the luminosity and heavy element formation history of the universe. SPECS would also have the potential to improve vastly our knowledge of protostars, protoplanetary systems, Active Galactic Nuclei and other objects in the local universe. We recommend that a concerted effort be made during the next decade to develop and test certain critical technologies (photon-counting far IR detectors, formation flying spacecraft, cold, lightweight mirrors, and active coolers), so that SPECS can be deployed in about 2015.",
    "lastUpdated": "1998-12-28T20:16:00Z",
    "categories": [
      "astro-ph"
    ],
    "url": "http://arxiv.org/abs/astro-ph/9812454v1"
  },
  {
    "title": "The symbiotic binary system RX Puppis: a possible recurrent nova with a Mira companion",
    "authors": [
      "Joanna Mikolajewska",
      "Estela Brandi",
      "Warren Hack",
      "Patricia A. Whitelock",
      "Rodolfo Barba",
      "Lia Garcia",
      "Freddy Marang"
    ],
    "abstract": "We present an analysis of photometric and spectroscopic observations of the symbiotic binary system RX Pup with the aims of developing a reliable binary for the system and identifying mechanisms responsible for its spectacular activity. The binary is composed of a long-perod Mira variable surrounded by a thick dust shell and a hot white dwarf companion. The hot component produces practically all activity observed in the UV, optical and radio range, while variable obscuration of the Mira by circumstellar dust is responsible for long-term changes in the near-IR magnitudes. The observations show RX Pup underwent a nova-like eruption during the last three decades. The hot component contracted in radius at roughly constant luminosity from 1975 to 1986, and was the source of a strong stellar wind which prevented it from accreting material lost in the Mira wind. Around 1988/9 the hot component turned over in the HR diagram and by 1991 its luminosity had faded by a factor of about 30 with respect to the maximum plateau value and the hot wind had practically ceased. By 1995 the nova remnant started to accrete material from the Mira wind, as indicated by a general increase in intensity of the optical continuum and HI emission. The quiescent spectrum resembles the quiescent spectra of symbiotic recurrent novae, and its intensity indicates the hot component must accrete as much as about 1 per cent of the Mira wind, which is more or less the amount predicted by Bondi-Hoyle theory. The earliest observational records from the 1890s suggest that another nova-like eruption of RX Pup occurred around 1894.",
    "lastUpdated": "1999-01-05T17:03:59Z",
    "categories": [
      "astro-ph"
    ],
    "url": "http://arxiv.org/abs/astro-ph/9901044v1"
  },
  {
    "title": "Electromagnetism, local covariance, the Aharonov-Bohm effect and Gauss' law",
    "authors": [
      "Ko Sanders",
      "Claudio Dappiaggi",
      "Thomas-Paul Hack"
    ],
    "abstract": "We quantise the massless vector potential A of electromagnetism in the presence of a classical electromagnetic (background) current, j, in a generally covariant way on arbitrary globally hyperbolic spacetimes M. By carefully following general principles and procedures we clarify a number of topological issues. First we combine the interpretation of A as a connection on a principal U(1)-bundle with the perspective of general covariance to deduce a physical gauge equivalence relation, which is intimately related to the Aharonov-Bohm effect. By Peierls' method we subsequently find a Poisson bracket on the space of local, affine observables of the theory. This Poisson bracket is in general degenerate, leading to a quantum theory with non-local behaviour. We show that this non-local behaviour can be fully explained in terms of Gauss' law. Thus our analysis establishes a relationship, via the Poisson bracket, between the Aharonov-Bohm effect and Gauss' law (a relationship which seems to have gone unnoticed so far). Furthermore, we find a formula for the space of electric monopole charges in terms of the topology of the underlying spacetime. Because it costs little extra effort, we emphasise the cohomological perspective and derive our results for general p-form fields A (p < dim(M)), modulo exact fields. In conclusion we note that the theory is not locally covariant, in the sense of Brunetti-Fredenhagen-Verch. It is not possible to obtain such a theory by dividing out the centre of the algebras, nor is it physically desirable to do so. Instead we argue that electromagnetism forces us to weaken the axioms of the framework of local covariance, because the failure of locality is physically well-understood and should be accommodated.",
    "lastUpdated": "2014-03-26T08:56:00Z",
    "categories": [
      "math-ph",
      "gr-qc",
      "math.MP",
      "81T20 (Primary) 81T13, 81T05 (Secondary)"
    ],
    "url": "http://arxiv.org/abs/1211.6420v3"
  },
  {
    "title": "An Empirical Study on Android for Saving Non-shared Data on Public Storage",
    "authors": [
      "Xiangyu Liu",
      "Zhe Zhou",
      "Wenrui Diao",
      "Zhou Li",
      "Kehuan Zhang"
    ],
    "abstract": "With millions of apps that can be downloaded from official or third-party market, Android has become one of the most popular mobile platforms today. These apps help people in all kinds of ways and thus have access to lots of user's data that in general fall into three categories: sensitive data, data to be shared with other apps, and non-sensitive data not to be shared with others. For the first and second type of data, Android has provided very good storage models: an app's private sensitive data are saved to its private folder that can only be access by the app itself, and the data to be shared are saved to public storage (either the external SD card or the emulated SD card area on internal FLASH memory). But for the last type, i.e., an app's non-sensitive and non-shared data, there is a big problem in Android's current storage model which essentially encourages an app to save its non-sensitive data to shared public storage that can be accessed by other apps. At first glance, it seems no problem to do so, as those data are non-sensitive after all, but it implicitly assumes that app developers could correctly identify all sensitive data and prevent all possible information leakage from private-but-non-sensitive data. In this paper, we will demonstrate that this is an invalid assumption with a thorough survey on information leaks of those apps that had followed Android's recommended storage model for non-sensitive data. Our studies showed that highly sensitive information from billions of users can be easily hacked by exploiting the mentioned problematic storage model. Although our empirical studies are based on a limited set of apps, the identified problems are never isolated or accidental bugs of those apps being investigated. On the contrary, the problem is rooted from the vulnerable storage model recommended by Android. To mitigate the threat, we also propose a defense framework.",
    "lastUpdated": "2014-11-10T13:30:22Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1407.5410v3"
  },
  {
    "title": "Causality, Information and Biological Computation: An algorithmic software approach to life, disease and the immune system",
    "authors": [
      "Hector Zenil",
      "Angelika Schmidt",
      "Jesper Tegnér"
    ],
    "abstract": "Biology has taken strong steps towards becoming a computer science aiming at reprogramming nature after the realisation that nature herself has reprogrammed organisms by harnessing the power of natural selection and the digital prescriptive nature of replicating DNA. Here we further unpack ideas related to computability, algorithmic information theory and software engineering, in the context of the extent to which biology can be (re)programmed, and with how we may go about doing so in a more systematic way with all the tools and concepts offered by theoretical computer science in a translation exercise from computing to molecular biology and back. These concepts provide a means to a hierarchical organization thereby blurring previously clear-cut lines between concepts like matter and life, or between tumour types that are otherwise taken as different and may not have however a different cause. This does not diminish the properties of life or make its components and functions less interesting. On the contrary, this approach makes for a more encompassing and integrated view of nature, one that subsumes observer and observed within the same system, and can generate new perspectives and tools with which to view complex diseases like cancer, approaching them afresh from a software-engineering viewpoint that casts evolution in the role of programmer, cells as computing machines, DNA and genes as instructions and computer programs, viruses as hacking devices, the immune system as a software debugging tool, and diseases as an information-theoretic battlefield where all these forces deploy. We show how information theory and algorithmic programming may explain fundamental mechanisms of life and death.",
    "lastUpdated": "2016-01-20T01:54:15Z",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1508.06538v5"
  },
  {
    "title": "One Time Pad Password Protection: Using T.E.C. Steganography and Secure Password Transmission Protocols",
    "authors": [
      "Givon Zirkind"
    ],
    "abstract": "A while ago, I developed what I called an encryption method. The most favorable of reviews did not see a method but a collection of techniques. Be that as it may, the process used, is described in the paper, Windtalking Computers. This paper is about the steganographic method described, the cryptanalysis efforts of that method and; a real world application of that method as an answer to the increasing problem of password file hacking. The premise is that the technique is a variant of one time pad, using a novel way to produce one time pad output for digital input. There is no record in the literature of such a method being used for encryption at all. Digital encryption generally treats the letters of the plaintext as a binary number and does some mathematical computation to produce ciphertext. The idea of inserting bits with a random generated key is new. Therefore (because a uniquely random generated key is used), the encryption is cryptanalytically unbreakable and/or computationally secure and/or information theoretic. An academic version was made. Challenges for decryption have not produced to-date a decryption. Advantages and disadvantages of the method are discussed. Hackers are constantly penetrating networks and stealing password files. Which, once in possession of a password file, hackers individually or collectively with distributed processing over the Internet, decrypt the values of the hash passwords. Thereby gaining access to systems. This problem has become sufficiently significant for CAESAR (Competition for Authenticated Encryption: Security, Applicability, and Robustness) to make calls for papers for solutions. Herein is one proposed solution. While one time pad presents a problem being computationally intensive, for the relatively short length of passwords, the cost of computation may be cost effective for the security provided.",
    "lastUpdated": "2013-05-14T22:02:02Z",
    "categories": [
      "cs.CR",
      "94A60, 14G50",
      "D.2.11; E.0; E.3; E.3; E.m; F.2.0; F.2.1; F.2.2; F.2.m; H.0; H.1.0;\n  H.1.1"
    ],
    "url": "http://arxiv.org/abs/1306.0497v1"
  },
  {
    "title": "Donaldson-Thomas trasnsformations of moduli spaces of G-local systems",
    "authors": [
      "Alexander Goncharov",
      "Linhui Shen"
    ],
    "abstract": "Kontsevich and Soibelman defined Donaldson-Thomas invariants of a 3d Calabi-Yau category equipped with a stability condition. Any cluster variety gives rise to a family of such categories. Their DT invariants are encapsulated in a single formal automorphism of the cluster variety, called the DT-transformation. Let S be an oriented surface with punctures, and a finite number of special points on the boundary considered modulo isotopy. It give rise to a moduli space X(m, S), closely related to the moduli space of PGL(m)-local systems on S, which carries a canonical cluster Poisson variety structure. For each puncture of S, there is a birational Weyl group action on the space X(m, S). We prove that it is given by cluster Poisson transformations. We prove a similar result for the involution * of the space X(m,S) provided by dualising a local system on S. We calculate the DT-transformation of the moduli space X(m,S), with few exceptions. Namely, let C(m,S) be the transformation of the space X(m,S) given by the product of three commuting maps: the involution *, the product, over all punctures of S, of the longest element of the Weyl group action corresponding to the puncture, and the \"shift of the special points on the boundary by one\" map. Using a characterisation of a class of DT-transformations due to Keller, we prove that C(m,S) = DT. We prove that, burring few exceptions, the Weyl group and the involution * act by cluster transformations of the dual moduli space A(m, S). So the formula C(m,S) = DT is valid for the space A(m,S). Our main result, combined with the work of Gross, Hacking, Keel and Kontsevich, deliver a canonical basis in the space of regular functions on the cluster variety X(m,S), and in the upper cluster algebra with principal coefficients related to the pair (SL(m), S), with few exceptions.",
    "lastUpdated": "2016-03-03T18:29:24Z",
    "categories": [
      "math.AG",
      "math-ph",
      "math.MP",
      "math.RT"
    ],
    "url": "http://arxiv.org/abs/1602.06479v2"
  },
  {
    "title": "Experimental demonstration of Gaussian protocols for one-sided device-independent quantum key distribution",
    "authors": [
      "Nathan Walk",
      "Sara Hosseni",
      "Jiao Geng",
      "Oliver Thearle",
      "Jing Yan Haw",
      "Seiji Armstrong",
      "Syed M Assad",
      "Jiri Janousek",
      "Timothy C Ralph",
      "Thomas Symul",
      "Howard M Wiseman",
      "Ping Koy Lam"
    ],
    "abstract": "Nonlocal correlations, a longstanding foundational topic in quantum information, have recently found application as a resource for cryptographic tasks where not all devices are trusted, for example in settings with a highly secure central hub, such as a bank or government department, and less secure satellite stations which are inherently more vulnerable to hardware \"hacking\" attacks. The asymmetric phenomena of Einstein-Podolsky-Rosen steering plays a key role in one-sided device-independent quantum key distribution (1sDI-QKD) protocols. In the context of continuous-variable (CV) QKD schemes utilizing Gaussian states and measurements, we identify all protocols that can be 1sDI and their maximum loss tolerance. Surprisingly, this includes a protocol that uses only coherent states. We also establish a direct link between the relevant EPR steering inequality and the secret key rate, further strengthening the relationship between these asymmetric notions of nonlocality and device independence. We experimentally implement both entanglement-based and coherent-state protocols, and measure the correlations necessary for 1sDI key distribution up to an applied loss equivalent to 7.5 km and 3.5 km of optical fiber transmission respectively. We also engage in detailed modelling to understand the limits of our current experiment and the potential for further improvements. The new protocols we uncover apply the cheap and efficient hardware of CVQKD systems in a significantly more secure setting.",
    "lastUpdated": "2016-06-16T15:01:19Z",
    "categories": [
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/1405.6593v3"
  },
  {
    "title": "Cross-boundary Behavioural Reprogrammability Reveals Evidence of Pervasive Universality",
    "authors": [
      "Jürgen Riedel",
      "Hector Zenil"
    ],
    "abstract": "We exhaustively explore the reprogrammability capabilities and the intrinsic universality of the Cartesian product $P \\times C$ of the space $P$ of all possible computer programs of increasing size and the space $C$ of all possible compilers of increasing length such that $p \\in P$ emulates $p^\\prime \\in P$ with $T|p^\\prime|=|p|$ under a coarse-graining transformation $T$. Our approach yields a novel perspective on the complexity, controllability, causality and (re)programmability discrete dynamical systems. We find evidence that the density of (qualitatively different) computer programs that can be reprogrammed grows asymptotically as a function of program and compiler size. To illustrate these findings we show a series of behavioural boundary crossing results, including emulations (for all initial conditions) of Wolfram class 2 Elementary Cellular Automata (ECA) by Class 1 ECA, emulations of Classes 1, 2 and 3 ECA by Class 2 and 3 ECA, and of Classes 1, 2 and 3 by Class 3 ECA, along with results of even greater emulability for general CA (neighbourhood $r=3/2$), including Class 1 CA emulating Classes 2 and 3, and Classes 3 and 4 emulating all other classes (1, 2, 3 and 4). The emulations occur with only a linear overhead and can be considered computationally efficient. We also found that there is no hacking strategy to compress the search space based on compiler profiling in terms of e.g. similarity or complexity, suggesting that no strategy other than exhaustive search is viable. We also introduce emulation networks, derive a topologically-based measure of complexity based upon out- and in-degree connectivity, and establish bridges to fundamental ideas of complexity, universality, causality and dynamical systems.",
    "lastUpdated": "2018-02-01T16:34:22Z",
    "categories": [
      "cs.FL",
      "cs.CC",
      "nlin.CG"
    ],
    "url": "http://arxiv.org/abs/1510.01671v15"
  },
  {
    "title": "Study of Peer-to-Peer Network Based Cybercrime Investigation: Application on Botnet Technologies",
    "authors": [
      "Mark Scanlon"
    ],
    "abstract": "The scalable, low overhead attributes of Peer-to-Peer (P2P) Internet protocols and networks lend themselves well to being exploited by criminals to execute a large range of cybercrimes. The types of crimes aided by P2P technology include copyright infringement, sharing of illicit images of children, fraud, hacking/cracking, denial of service attacks and virus/malware propagation through the use of a variety of worms, botnets, malware, viruses and P2P file sharing. This project is focused on study of active P2P nodes along with the analysis of the undocumented communication methods employed in many of these large unstructured networks. This is achieved through the design and implementation of an efficient P2P monitoring and crawling toolset. The requirement for investigating P2P based systems is not limited to the more obvious cybercrimes listed above, as many legitimate P2P based applications may also be pertinent to a digital forensic investigation, e.g, voice over IP, instant messaging, etc. Investigating these networks has become increasingly difficult due to the broad range of network topologies and the ever increasing and evolving range of P2P based applications. In this work we introduce the Universal P2P Network Investigation Framework (UP2PNIF), a framework which enables significantly faster and less labour intensive investigation of newly discovered P2P networks through the exploitation of the commonalities in P2P network functionality. In combination with a reference database of known network characteristics, it is envisioned that any known P2P network can be instantly investigated using the framework, which can intelligently determine the best investigation methodology and greatly expedite the evidence gathering process. A proof of concept tool was developed for conducting investigations on the BitTorrent network.",
    "lastUpdated": "2017-12-10T00:18:58Z",
    "categories": [
      "cs.CR",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1712.03455v1"
  },
  {
    "title": "Developing a system for securely time-stamping and visualizing the changes made to online news content",
    "authors": [
      "Waqar Detho"
    ],
    "abstract": "Nowadays, the Internet is indispensable when it comes to information dissemination. People rely on the Internet to inform themselves on current news events, as well as to verify facts. We, as a community, are quickly approaching an 'electronic information age' where the majority of information will be distributed electronically and tools to preserve this information will become essential. While archiving online digital information is a good way to preserve online information for future generations, it has many disadvantages including the easy manipulation of archived information, e.g. by the archiving authority. Online information is also prone to getting hacked or being taken offline. Therefore, it is necessary that archived online news information is securely time-stamped with the date and time when it was first archived in a way that cannot be manipulated. The process of 'trusted timestamping' is an established approach for claiming that particular digital information existed at a particular 'point in time' in the past. However, traditional approaches for trusted timestamping depend on the time-stamping authority's fidelity. Directly embedding the hash of a digital file into the blockchain of a cryptocurrency is a more recent method that allows for secure time-stamping, since digital information is stored as part of the transaction information in, e.g. Bitcoin's, blockchain, and not stored at a centralized time-stamping authority. However, there is no system yet available, which uses this approach for archiving and time-stamping online news articles. Therefore, the aim of this thesis is to develop a system that 1) enables decentralized trusted time-stamping of web and news articles as a means of making future manipulation of online information identifiable, and 2) allows users to determine the authenticity of articles by checking different versions of the same article online.",
    "lastUpdated": "2018-09-17T12:01:28Z",
    "categories": [
      "cs.DL",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1802.07285v2"
  },
  {
    "title": "The Off-Topic Memento Toolkit",
    "authors": [
      "Shawn M. Jones",
      "Michele C. Weigle",
      "Michael L. Nelson"
    ],
    "abstract": "Web archive collections are created with a particular purpose in mind. A curator selects seeds, or original resources, which are then captured by an archiving system and stored as archived web pages, or mementos. The systems that build web archive collections are often configured to revisit the same original resource multiple times. This is incredibly useful for understanding an unfolding news story or the evolution of an organization. Unfortunately, over time, some of these original resources can go off-topic and no longer suit the purpose for which the collection was originally created. They can go off-topic due to web site redesigns, changes in domain ownership, financial issues, hacking, technical problems, or because their content has moved on from the original topic. Even though they are off-topic, the archiving system will still capture them, thus it becomes imperative to anyone performing research on these collections to identify these off-topic mementos. Hence, we present the Off-Topic Memento Toolkit, which allows users to detect off-topic mementos within web archive collections. The mementos identified by this toolkit can then be separately removed from a collection or merely excluded from downstream analysis. The following similarity measures are available: byte count, word count, cosine similarity, Jaccard distance, S{\\o}rensen-Dice distance, Simhash using raw text content, Simhash using term frequency, and Latent Semantic Indexing via the gensim library. We document the implementation of each of these similarity measures. We possess a gold standard dataset generated by manual analysis, which contains both off-topic and on-topic mementos. Using this gold standard dataset, we establish a default threshold corresponding to the best F1 score for each measure. We also provide an overview of potential future directions that the toolkit may take.",
    "lastUpdated": "2018-09-17T17:52:02Z",
    "categories": [
      "cs.DL",
      "cs.IR",
      "H.3.7; H.3.6; H.3.4"
    ],
    "url": "http://arxiv.org/abs/1806.06870v2"
  },
  {
    "title": "Extracting Randomness From The Trend of IPI for Cryptographic Operators in Implantable Medical Devices",
    "authors": [
      "Hassan Chizari",
      "Emil Lupu"
    ],
    "abstract": "Achieving secure communication between an Implantable Medical Device (IMD) inside the body and a gateway outside the body has showed its criticality with recent reports of hackings. The use of asymmetric cryptography is not a practical solution for IMDs due to the scarce computational and power resources, symmetric key cryptography is preferred. One of the factors in security of a symmetric cryptographic system is to use a strong key for encryption. A solution without using extensive resources in an IMD, is to extract it from the body physiological signals. To have a strong enough key, the physiological signal must be a strong source of randomness and InterPulse Interval (IPI) has been advised to be such that. A strong randomness source should have five conditions: Universality, Liveness, Robustness Permanence and Uniqueness. Nevertheless, for current proposed random extraction methods from IPI these conditions (mainly last three conditions) were not examined. In this study, firstly, we proposed a methodology to measure the last three conditions. Then, using a huge dataset of IPI values, we showed that IPI does not have conditions of Robustness and Permanence. Thus, extraction of a strong uniform random number from IPI value, mathematically, is impossible. Thirdly, rather than using the value of IPI, we proposed the trend of IPI as a source for a new randomness extraction method named as Martingale Randomness Extraction from IPI (MRE-IPI). MRE-IPI satisfies the Robustness condition completely and Permanence to some level. We, also, used randomness test suites and showed that MRE-IPI is able to outperform all recent randomness extraction methods from IPIs and its quality is half of the AES random number. To the best of our knowledge, this is the first work in this area which uses such a comprehensive method and large dataset to examine the randomness of a physiological signal.",
    "lastUpdated": "2018-06-28T14:07:58Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1806.10984v1"
  },
  {
    "title": "Stochastic receptivity analysis of boundary layer flow",
    "authors": [
      "Wei Ran",
      "Armin Zare",
      "M. J. Philipp Hack",
      "Mihailo R. Jovanović"
    ],
    "abstract": "We utilize the externally forced linearized Navier-Stokes equations to study the receptivity of pre-transitional boundary layers to persistent sources of stochastic excitation. Stochastic forcing is used to model the effect of free-stream turbulence that enters at various wall-normal locations and the fluctuation dynamics are studied via linearized models that arise from locally parallel and global perspectives. In contrast to the widely used resolvent analysis that quantifies the amplification of deterministic disturbances at a given temporal frequency, our approach examines the steady-state response to stochastic excitation that is uncorrelated in time. In addition to stochastic forcing with identity covariance, we utilize the spatial spectrum of homogeneous isotropic turbulence to model the effect of free-stream turbulence. Even though locally parallel analysis does not account for the effect of the spatially evolving base flow, we demonstrate that it captures the essential mechanisms and the prevailing length-scales in stochastically forced boundary layer flows. On the other hand, global analysis, which accounts for the spatially evolving nature of the boundary layer flow, predicts the amplification of a cascade of streamwise scales throughout the streamwise domain. We show that the flow structures that can be extracted from a modal decomposition of the resulting velocity covariance matrix, can be closely captured by conducting locally parallel analysis at various streamwise locations and over different wall-parallel wavenumber pairs. Our approach does not rely on costly stochastic simulations and it provides insight into mechanisms for perturbation growth including the interaction of the slowly varying base flow with streaks and Tollmien-Schlichting waves.",
    "lastUpdated": "2019-06-03T23:45:08Z",
    "categories": [
      "physics.flu-dyn",
      "math.AP",
      "math.DS"
    ],
    "url": "http://arxiv.org/abs/1807.07759v2"
  },
  {
    "title": "Testing Cannot Tell Whether Ballot-Marking Devices Alter Election Outcomes",
    "authors": [
      "Philip B. Stark",
      "Ran Xie"
    ],
    "abstract": "Like all computerized systems, ballot-marking devices (BMDs) can be hacked, misprogrammed, and misconfigured. Several approaches to testing BMDs have been proposed. In _logic and accuracy_ (_L&A_) tests, trusted agents input known test patterns into the BMD and check whether the printout matches. In _parallel_ or _live_ testing, agents use the BMDs on election day, emulating voters. In _passive_ testing, agents monitor the rate at which voters \"spoil\" ballots and request another opportunity to mark a ballot: an anomalously high rate might result from BMD malfunctions. In practice, none of these methods can protect against outcome-altering problems. L&A testing is ineffective in part because BMDs \"know\" the time and date of the test and the election. Neither L&A nor parallel testing can probe even a small fraction of the possible voting transactions that could comprise enough votes to change outcomes. Under mild assumptions, to develop a model of voter interactions with BMDs accurate enough to ensure that parallel tests could reliably detect changes to 5% of the votes (which could change margins by 10% or more) would require monitoring the behavior of more than a million voters in each jurisdiction in minute detail---but the median turnout by jurisdiction in the U.S. is under 3000 voters. Given an accurate model of voter behavior, the number of tests required is still larger than the turnout in a typical U.S. jurisdiction. Under optimistic assumptions, passive testing that has a 99% chance of detecting a 1% change to the margin with a 1% false alarm rate is impossible in jurisdictions with fewer than about 1 million voters, even if the \"normal\" spoiled ballot rate were known exactly and did not vary from election to election and place to place.",
    "lastUpdated": "2020-07-30T22:46:29Z",
    "categories": [
      "stat.AP",
      "cs.CR",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1908.08144v2"
  },
  {
    "title": "Deep Bayesian Reward Learning from Preferences",
    "authors": [
      "Daniel S. Brown",
      "Scott Niekum"
    ],
    "abstract": "Bayesian inverse reinforcement learning (IRL) methods are ideal for safe imitation learning, as they allow a learning agent to reason about reward uncertainty and the safety of a learned policy. However, Bayesian IRL is computationally intractable for high-dimensional problems because each sample from the posterior requires solving an entire Markov Decision Process (MDP). While there exist non-Bayesian deep IRL methods, these methods typically infer point estimates of reward functions, precluding rigorous safety and uncertainty analysis. We propose Bayesian Reward Extrapolation (B-REX), a highly efficient, preference-based Bayesian reward learning algorithm that scales to high-dimensional, visual control tasks. Our approach uses successor feature representations and preferences over demonstrations to efficiently generate samples from the posterior distribution over the demonstrator's reward function without requiring an MDP solver. Using samples from the posterior, we demonstrate how to calculate high-confidence bounds on policy performance in the imitation learning setting, in which the ground-truth reward function is unknown. We evaluate our proposed approach on the task of learning to play Atari games via imitation learning from pixel inputs, with no access to the game score. We demonstrate that B-REX learns imitation policies that are competitive with a state-of-the-art deep imitation learning method that only learns a point estimate of the reward function. Furthermore, we demonstrate that samples from the posterior generated via B-REX can be used to compute high-confidence performance bounds for a variety of evaluation policies. We show that high-confidence performance bounds are useful for accurately ranking different evaluation policies when the reward function is unknown. We also demonstrate that high-confidence performance bounds may be useful for detecting reward hacking.",
    "lastUpdated": "2019-12-10T03:29:51Z",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1912.04472v1"
  },
  {
    "title": "Secondary Use of Electronic Health Record: Opportunities and Challenges",
    "authors": [
      "Shahid Munir Shah",
      "Rizwan Ahmed Khan"
    ],
    "abstract": "In present technological era, healthcare providers generate huge amount of clinical data on daily basis. Generated clinical data is stored digitally in the form of Electronic Health Records (EHR) as a central data repository of hospitals. Data contained in EHR is not only used for the patients' primary care but also for various secondary purposes such as clinical research, automated disease surveillance and clinical audits for quality enhancement. Using EHR data for secondary purposes without consent or in some cases even with consent creates privacy issues for individuals. Secondly, EHR data is also made accessible to various stake holders including different government agencies at various geographical sites through wired or wireless networks. Sharing of EHR across multiples agencies makes it vulnerable to cyber attacks and also makes it difficult to implement strict privacy laws as in some cases data is shared with organization that is governed by specific regional law. Privacy of an individual could be severely affected when their sensitive private information contained in EHR is leaked or exposed to public. Data leak can cause financial losses or an individuals may encounter social boycott if their medical condition is exposed in public. To protect patients personal data from such threats, there exists different privacy regulations such as GDPR, HIPAA and MHR. However, continually evolving state-of-the-art techniques in machine learning, data analytics and hacking are making it even more difficult to completely protect individual's / patient's privacy. In this article, we have systematically examined various secondary uses of EHR with the aim to highlight how these secondary uses effect patients' privacy. Secondly, we have critically analyzed GDPR and highlighted possible areas of improvement, considering escalating use of technology and different secondary uses of EHR.",
    "lastUpdated": "2020-01-26T16:22:53Z",
    "categories": [
      "cs.CY",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/2001.09479v1"
  },
  {
    "title": "DeepRacing: Parameterized Trajectories for Autonomous Racing",
    "authors": [
      "Trent Weiss",
      "Madhur Behl"
    ],
    "abstract": "We consider the challenging problem of high speed autonomous racing in a realistic Formula One environment. DeepRacing is a novel end-to-end framework, and a virtual testbed for training and evaluating algorithms for autonomous racing. The virtual testbed is implemented using the realistic F1 series of video games, developed by Codemasters, which many Formula One drivers use for training. This virtual testbed is released under an open-source license both as a standalone C++ API and as a binding to the popular Robot Operating System 2 (ROS2) framework. This open-source API allows anyone to use the high fidelity physics and photo-realistic capabilities of the F1 game as a simulator, and without hacking any game engine code. We use this framework to evaluate several neural network methodologies for autonomous racing. Specifically, we consider several fully end-to-end models that directly predict steering and acceleration commands for an autonomous race car as well as a model that predicts a list of waypoints to follow in the car's local coordinate system, with the task of selecting a steering/throttle angle left to a classical control algorithm. We also present a novel method of autonomous racing by training a deep neural network to predict a parameterized representation of a trajectory rather than a list of waypoints. We evaluate these models performance in our open-source simulator and show that trajectory prediction far outperforms end-to-end driving. Additionally, we show that open-loop performance for an end-to-end model, i.e. root-mean-square error for a model's predicted control values, does not necessarily correlate with increased driving performance in the closed-loop sense, i.e. actual ability to race around a track. Finally, we show that our proposed model of parameterized trajectory prediction outperforms both end-to-end control and waypoint prediction.",
    "lastUpdated": "2020-05-06T21:35:48Z",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2005.05178v1"
  },
  {
    "title": "Light Can Hack Your Face! Black-box Backdoor Attack on Face Recognition Systems",
    "authors": [
      "Haoliang Li",
      "Yufei Wang",
      "Xiaofei Xie",
      "Yang Liu",
      "Shiqi Wang",
      "Renjie Wan",
      "Lap-Pui Chau",
      "Alex C. Kot"
    ],
    "abstract": "Deep neural networks (DNN) have shown great success in many computer vision applications. However, they are also known to be susceptible to backdoor attacks. When conducting backdoor attacks, most of the existing approaches assume that the targeted DNN is always available, and an attacker can always inject a specific pattern to the training data to further fine-tune the DNN model. However, in practice, such attack may not be feasible as the DNN model is encrypted and only available to the secure enclave. In this paper, we propose a novel black-box backdoor attack technique on face recognition systems, which can be conducted without the knowledge of the targeted DNN model. To be specific, we propose a backdoor attack with a novel color stripe pattern trigger, which can be generated by modulating LED in a specialized waveform. We also use an evolutionary computing strategy to optimize the waveform for backdoor attack. Our backdoor attack can be conducted in a very mild condition: 1) the adversary cannot manipulate the input in an unnatural way (e.g., injecting adversarial noise); 2) the adversary cannot access the training database; 3) the adversary has no knowledge of the training model as well as the training set used by the victim party. We show that the backdoor trigger can be quite effective, where the attack success rate can be up to $88\\%$ based on our simulation study and up to $40\\%$ based on our physical-domain study by considering the task of face recognition and verification based on at most three-time attempts during authentication. Finally, we evaluate several state-of-the-art potential defenses towards backdoor attacks, and find that our attack can still be effective. We highlight that our study revealed a new physical backdoor attack, which calls for the attention of the security issue of the existing face recognition/verification techniques.",
    "lastUpdated": "2020-09-15T11:50:29Z",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2009.06996v1"
  },
  {
    "title": "Learning about the reduction of food waste using Blockchain technology",
    "authors": [
      "Monica-Paula Marin",
      "Iuliana Marin",
      "Livia Vidu"
    ],
    "abstract": "Farmers need to be efficient and dedicate a lot of time in order to sustain the quality of their animals which are in their care. The most convenient and good quality - price ratio should be chosen for the feed of animals. Blockchain is used in a virtual space to store and share information over a network of users. This is done using the open source Hyperledger Fabric platform. The transactions can be viewed by all the other users in real time. These transactions are stored as JSONs inside CouchDB NoSQL database which supports queries on a large volume of data. When using this technology, the farmer can know with whom the supplier for animal feed collaborated with. The history of the transactions are not saved in just one place. In this way, it is more difficult to hack and provide implausible information. An e-learning platform was created where the farm's user can post information, respectively new blocks about the animal's birth, vaccinations, medicines, including the location of the livestock. The same e-learning platform is accessible from the mobile phone. By using the blockchain technology, anyone, including the client from the shop can know a lot about the origin of the products. Fake origins of food are much more difficult to hide. Fraud is also limited. The system monitored the traceability of dairy products inside a Romanian farm. Data about fodder provider and quality, cow productive performances and health and dairy products process were obtained and analyzed by students who will become specialists at all the levels of the food chain. Blockchain is the technology which in case of a dairy products contamination, the origin of the farm is traced in just a couple of seconds. In this way just a batch of dairy products is removed from distribution, leading to the reduction of food waste.",
    "lastUpdated": "2021-01-03T10:19:10Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2101.02026v1"
  },
  {
    "title": "On reducing Terrorism Power: A Hint from Physics",
    "authors": [
      "Serge Galam",
      "Alain Mauger"
    ],
    "abstract": "The September 11 attack on the US has revealed an unprecedented terrorism worldwide range of destruction. Recently, it has been related to the percolation of worldwide spread passive supporters. This scheme puts the suppression of the percolation effect as the major strategic issue in the fight against terrorism. Accordingly the world density of passive supporters should be reduced below the percolation threshold. In terms of solid policy, it means to neutralize millions of random passive supporters, which is contrary to ethics and out of any sound practical scheme. Given this impossibility we suggest instead a new strategic scheme to act directly on the value of the terrorism percolation threshold itself without harming the passive supporters. Accordingly we identify the space hosting the percolation phenomenon to be a multi-dimensional virtual social space which extends the ground earth surface to include the various independent terrorist-fighting goals. The associated percolating cluster is then found to create long-range ground connections to terrorism activity. We are thus able to modify the percolation threshold pc in the virtual space to reach p<pc by decreasing the social space dimension, leaving the density p unchanged. At once that would break down the associated world terrorism network to a family of unconnected finite size clusters. The current world terrorism threat would thus shrink immediately and spontaneously to a local geographic problem. There, military action would become limited and efficient.",
    "lastUpdated": "2003-01-17T11:35:03Z",
    "categories": [
      "cond-mat.dis-nn"
    ],
    "url": "http://arxiv.org/abs/cond-mat/0301317v1"
  },
  {
    "title": "The Dynamics of Crowd Disasters: An Empirical Study",
    "authors": [
      "Dirk Helbing",
      "Anders Johansson",
      "Habib Zein Al-Abideen"
    ],
    "abstract": "Many observations in the dynamics of pedestrian crowds, including various self-organization phenomena, have been successfully described by simple many-particle models. For ethical reasons, however, there is a serious lack of experimental data regarding crowd panic. Therefore, we have analyzed video recordings of the crowd disaster in Mina/Makkah during the Hajj in 1426H on January 12, 2006. They reveal two subsequent, sudden transitions from laminar to stop-and-go and ``turbulent'' flows, which question many previous simulation models. While the transition from laminar to stop-and-go flows supports a recent model of bottleneck flows [D. Helbing et al., Phys. Rev. Lett. 97, 168001 (2006)], the subsequent transition to turbulent flow is not yet well understood. It is responsible for sudden eruptions of pressure release comparable to earthquakes, which cause sudden displacements and the falling and trampling of people. The insights of this study into the reasons for critical crowd conditions are important for the organization of safer mass events. In particularly, they allow one to understand where and when crowd accidents tend to occur. They have also led to organizational changes, which have ensured a safe Hajj in 1427H.",
    "lastUpdated": "2007-02-12T11:22:00Z",
    "categories": [
      "physics.soc-ph"
    ],
    "url": "http://arxiv.org/abs/physics/0701203v2"
  },
  {
    "title": "Ecosystems in the Mind: Fuzzy Cognitive Maps of the Kizilirmak Delta Wetlands in Turkey",
    "authors": [
      "Uygar Ozesmi"
    ],
    "abstract": "Sustainability of ecosystems & ecosystem management are increasingly accepted societal goals. Can conservation programs be improved by incorporating local people's understanding of ecosystems? The Kizilirmak Delta is one of Turkey's most important wetland complexes. It is also one of the most productive agricultural deltas in Turkey. We obtained 31 cognitive models of the social & ecological system. These models were converted to adjacency matrices, analyzed using graph theoretical methods, & augmented into social cognitive maps. Causal \"What-if\" scenarios were run to determine the trajectory of the ecosystem based on models defined by stakeholders. Villagers had significantly larger numbers of variables, more complex maps, a broader understanding of all the variables that affect the Kizilirmak Delta, & mentioned more variables that control the ecosystem than did NGO and government officials. Villagers adapting to changing ecological & social conditions actively changed & challenged conditions through the political process. Villagers were faced with many important forcing functions that they could not control. Most of the variables defined by villagers were related to agriculture and animal husbandry. Conservation policies & ecosystem management must encompass larger environmental issues & villagers' cognitive maps must be reconciled with that of NGOs & government officials. Cognitive maps can serve as a basis for discussion when policies & management options are formulated. A villager-centered cognitive mapping approach is not only necessary because villagers resist conservation projects, or because top down projects that do not take local knowledge systems into account fail, but because it is the ethical and responsible way of doing ecosystem management.",
    "lastUpdated": "2006-03-19T05:25:37Z",
    "categories": [
      "q-bio.NC",
      "q-bio.OT"
    ],
    "url": "http://arxiv.org/abs/q-bio/0603022v1"
  },
  {
    "title": "What Do Family Caregivers of Alzheimer's Disease Patients Desire in Smart Home Technologies?",
    "authors": [
      "Vincent Rialle",
      "Catherine Ollivet",
      "Carole Guigui",
      "Christian Hervé"
    ],
    "abstract": "Objectives - The authors' aim was to investigate the representations, wishes, and fears of family caregivers (FCs) regarding 14 innovative technologies (IT) for care aiding and burden alleviation, given the severe physical and psychological stress induced by dementia care, and the very slow uptake of these technologies in our society. Methods - A cluster sample survey based on a self-administered questionnaire was carried out on data collected from 270 families of patients with Alzheimer's disease or related disorders, located in the greater Paris area. Multiple Correspondence Analysis was used in addition to usual statistical tests to identify homogenous FCs clusters concerning the appreciation or rejection of the considered technologies. Results - Two opposite clusters were clearly defined: FCs in favor of a substantial use of technology, and those rather or totally hostile. Furthermore the distributions of almost all the answers of appreciations were U shaped. Significant relations were demonstrated between IT appreciation and FC's family or gender statuses (e.g., female FCs appreciated more than male FCs a tracking device for quick recovering of wandering patients: p=0.0025, N=195). Conclusions - The study provides further evidence of the contrasted perception of technology in dementia care at home, and suggests the development of public debates based on rigorous assessment of practices and a strict ethical aim to protect against misuse.",
    "lastUpdated": "2009-04-02T18:16:47Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/0904.0437v1"
  },
  {
    "title": "Knowledge Management Concepts For Training By Project An observation of the case of project management education",
    "authors": [
      "Christine Michel",
      "Patrick Prevot"
    ],
    "abstract": "Project management education programmes are often proposed in higher education to give students competences in project planning (Gantt's chart), project organizing, human and technical resource management, quality control and also social competences (collaboration, communication), emotional ones (empathy, consideration of the other, humour, ethics), and organizational ones (leadership, political vision, and so on). This training is often given according a training-by-project type of learning with case studies. This article presents one course characterized by a pedagogical organization based upon Knowledge Management (KM) concepts: knowledge transfer and construction throughout a learning circle and social interactions. The course is supported by a rich and complex tutor organization. We have observed this course by using another KM method inspired from KADS with various return of experience formalized into cards and charts. Our intention is, according to the model of Argyris and Sch\\\"on (Smith, 2001), to gain feedback information about local and global processes and about actors' experience in order to improve the course. This paper describes precisely the course (pedagogical method and tutor activity) and the KM observation method permitting to identify problem to solve. In our case, we observe problem of pedacogical coordination and skills acquisition. We propose to design a metacognitive tool for tutors and students, usable for improving knowledge construction and learning process organisation",
    "lastUpdated": "2009-11-02T10:52:28Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/0911.0285v1"
  },
  {
    "title": "Traveling the Silk Road: A measurement analysis of a large anonymous online marketplace",
    "authors": [
      "Nicolas Christin"
    ],
    "abstract": "We perform a comprehensive measurement analysis of Silk Road, an anonymous, international online marketplace that operates as a Tor hidden service and uses Bitcoin as its exchange currency. We gather and analyze data over eight months between the end of 2011 and 2012, including daily crawls of the marketplace for nearly six months in 2012. We obtain a detailed picture of the type of goods being sold on Silk Road, and of the revenues made both by sellers and Silk Road operators. Through examining over 24,400 separate items sold on the site, we show that Silk Road is overwhelmingly used as a market for controlled substances and narcotics, and that most items sold are available for less than three weeks. The majority of sellers disappears within roughly three months of their arrival, but a core of 112 sellers has been present throughout our measurement interval. We evaluate the total revenue made by all sellers, from public listings, to slightly over USD 1.2 million per month; this corresponds to about USD 92,000 per month in commissions for the Silk Road operators. We further show that the marketplace has been operating steadily, with daily sales and number of sellers overall increasing over our measurement interval. We discuss economic and policy implications of our analysis and results, including ethical considerations for future research in this area.",
    "lastUpdated": "2012-11-28T23:01:33Z",
    "categories": [
      "cs.CY",
      "cs.CR",
      "K.4.1"
    ],
    "url": "http://arxiv.org/abs/1207.7139v2"
  },
  {
    "title": "Economic decision making: application of the theory of complex systems",
    "authors": [
      "Robert Kitt"
    ],
    "abstract": "In this chapter the complex systems are discussed in the context of economic and business policy and decision making. It will be showed and motivated that social systems are typically chaotic, non-linear and/or non-equilibrium and therefore complex systems. It is discussed that the rapid change in global consumer behaviour is underway, that further increases the complexity in business and management. For policy making under complexity, following principles are offered: openness and international competition, tolerance and variety of ideas, self-reliability and low dependence on external help. The chapter contains four applications that build on the theoretical motivation of complexity in social systems. The first application demonstrates that small economies have good prospects to gain from the global processes underway, if they can demonstrate production flexibility, reliable business ethics and good risk management. The second application elaborates on and discusses the opportunities and challenges in decision making under complexity from macro and micro economic perspective. In this environment, the challenges for corporate management are being also permanently changed: the balance between short term noise and long term chaos whose attractor includes customers, shareholders and employees must be found. The emergence of chaos in economic relationships is demonstrated by a simple system of differential equations that relate the stakeholders described above. The chapter concludes with two financial applications: about debt and risk management. The non-equilibrium economic establishment leads to additional problems by using excessive borrowing; unexpected downturns in economy can more easily kill companies. Finally, the demand for quantitative improvements in risk management is postulated.",
    "lastUpdated": "2013-04-13T17:52:06Z",
    "categories": [
      "q-fin.GN",
      "physics.soc-ph"
    ],
    "url": "http://arxiv.org/abs/1208.1277v2"
  },
  {
    "title": "Using Neural Generative Models to Release Synthetic Twitter Corpora with Reduced Stylometric Identifiability of Users",
    "authors": [
      "Alexander G. Ororbia II",
      "Fridolin Linder",
      "Joshua Snoke"
    ],
    "abstract": "We present a method for generating synthetic versions of Twitter data using neural generative models. The goal is protecting individuals in the source data from stylometric re-identification attacks while still releasing data that carries research value. Specifically, we generate tweet corpora that maintain user-level word distributions by augmenting the neural language models with user-specific components. We compare our approach to two standard text data protection methods: redaction and iterative translation. We evaluate the three methods on measures of risk and utility. We define risk following the stylometric models of re-identification, and we define utility based on two general word distribution measures and two common text analysis research tasks. We find that neural models are able to significantly lower risk over previous methods with little cost to utility. We also demonstrate that the neural models allow data providers to actively control the risk-utility trade-off through model tuning parameters. This work presents promising results for a new tool addressing the problem of privacy for free text and sharing social media data in a way that respects privacy and is ethically responsible.",
    "lastUpdated": "2018-05-30T14:12:39Z",
    "categories": [
      "cs.CL"
    ],
    "url": "http://arxiv.org/abs/1606.01151v4"
  },
  {
    "title": "Juxtaposition of System Dynamics and Agent-based Simulation for a Case Study in Immunosenescence",
    "authors": [
      "Grazziela P. Figueredo",
      "Peer-Olaf Siebers",
      "Uwe Aickelin",
      "Amanda Whitbrook",
      "Jonathan M. Garibaldi"
    ],
    "abstract": "Advances in healthcare and in the quality of life significantly increase human life expectancy. With the ageing of populations, new un-faced challenges are brought to science. The human body is naturally selected to be well-functioning until the age of reproduction to keep the species alive. However, as the lifespan extends, unseen problems due to the body deterioration emerge. There are several age-related diseases with no appropriate treatment; therefore, the complex ageing phenomena needs further understanding. Immunosenescence, the ageing of the immune system, is highly correlated to the negative effects of ageing, such as the increase of auto-inflammatory diseases and decrease in responsiveness to new diseases. Besides clinical and mathematical tools, we believe there is opportunity to further exploit simulation tools to understand immunosenescence. Compared to real-world experimentation, benefits include time and cost effectiveness due to the laborious, resource-intensiveness of the biological environment and the possibility of conducting experiments without ethic restrictions. Contrasted with mathematical models, simulation modelling is more suitable for representing complex systems and emergence. In addition, there is the belief that simulation models are easier to communicate in interdisciplinary contexts. Our work investigates the usefulness of simulations to understand immunosenescence by employing two different simulation methods, agent-based and system dynamics simulation, to a case study of immune cells depletion with age.",
    "lastUpdated": "2016-07-20T09:47:31Z",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "url": "http://arxiv.org/abs/1607.05888v1"
  },
  {
    "title": "The fallacy of evidence based policy",
    "authors": [
      "Andrea Saltelli",
      "Mario Giampietro"
    ],
    "abstract": "The use of science for policy is at the core of a perfect storm generated by the insurgence of several concurrent crises: of science, of trust, of sustainability. The modern positivistic model of science for policy, known as evidence based policy, is based on dramatic simplifications and compressions of available perceptions of the state of affairs and possible explanations (hypocognition). This model can result in flawed prescriptions. The flaws become more evident when dealing with complex issues characterized by concomitant uncertainties in the normative, descriptive and ethical domains. In this situation evidence-based policy may concur to the fragility of the social system. Science plays an important role in reducing the feeling of vulnerability of humans by projecting a promise of protection against uncertainties. In many applications quantitative science is used to remove uncertainty by transforming it into probability, so that mathematical modelling can play the ritual role of haruspices. This epistemic governance arrangement is today in crisis. The primacy of science to adjudicate political issues must pass through an assessment of the level of maturity and effectiveness of the various disciplines deployed. The solution implies abandoning dreams of prediction, control and optimization obtained by relying on a limited set of simplified narratives to define the problem and moving instead to an open exploration of a broader set of plausible and relevant stories. Evidence based policy has to be replaced by robust policy, where robustness is tested with respect to feasibility (compatibility with processes outside human control); viability (compatibility with processes under human control, in relation to both the economic and technical dimensions), and desirability domain (compatibility with a plurality of normative considerations relevant to a plurality of actors).",
    "lastUpdated": "2015-05-25T07:46:14Z",
    "categories": [
      "q-fin.EC",
      "physics.soc-ph",
      "I.6.0"
    ],
    "url": "http://arxiv.org/abs/1607.07398v1"
  },
  {
    "title": "Societal impacts of big data: challenges and opportunities in Europe",
    "authors": [
      "Martí Cuquet",
      "Guillermo Vega-Gorgojo",
      "Hans Lammerant",
      "Rachel Finn",
      "Umair ul Hassan"
    ],
    "abstract": "This paper presents the risks and opportunities of big data and the potential social benefits it can bring. The research is based on an analysis of the societal impacts observed in a set of six case studies across different European sectors. These impacts are divided into economic, social and ethical, legal and political impacts, and affect areas such as improved efficiency, innovation and decision making, changing business models, dependency on public funding, participation, equality, discrimination and trust, data protection and intellectual property rights, private and public tensions and losing control to actors abroad. A special focus is given to the risks and opportunities coming from the legal framework and how to counter the negative impacts of big data. Recommendations are presented for four specific legal frameworks: copyright and database protection, protection of trade secrets, privacy and data protection and anti-discrimination. In addition, the potential social benefits of big data are exemplified in six domains: improved decision making and event detection; data-driven innovations and new business models; direct social, environmental and other citizen benefits; citizen participation, transparency and public trust; privacy-aware data practices; and big data for identifying discrimination. Several best practices are suggested to capture these benefits.",
    "lastUpdated": "2017-04-11T15:34:24Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1704.03361v1"
  },
  {
    "title": "Stereotypical escape behavior in Caenorhabditis elegans allows quantification of nociceptive stimuli levels",
    "authors": [
      "Kawai Leung",
      "Aylia Mohammadi",
      "William S. Ryu",
      "Ilya Nemenman"
    ],
    "abstract": "Experiments of pain with human subjects are difficult, subjective, and ethically constrained. Since the molecular mechanisms of pain transduction are reasonably conserved among different species, these problems are partially solved by the use of animal models. However, animals cannot easily communicate to us their own pain levels. Thus progress depends crucially on our ability to quantitatively and objectively infer the perceived level of noxious stimuli from the behavior of animals. Here we develop a quantitative model to infer the perceived level of thermal nociception from the stereotyped nociceptive response of individual nematodes Caenorhabditis elegans stimulated by an IR laser. The model provides a method for quantification of analgesic effects of chemical stimuli or genetic mutations in C. elegans. We test the nociception of ibuprofen-treated worms and a TRPV (transient receptor potential) mutant, and we show that the perception of thermal nociception for the ibuprofen treated worms is lower than the wild-type. At the same time, our model shows that the mutant changes the worm's behavior beyond affecting nociception. Finally, we determine the stimulus level that best distinguishes the analgesic effects and the minimum number of worms that allow for a statistically significant identification of these effects.",
    "lastUpdated": "2016-01-18T20:41:23Z",
    "categories": [
      "q-bio.QM",
      "q-bio.NC"
    ],
    "url": "http://arxiv.org/abs/1601.04685v1"
  },
  {
    "title": "Assessing the Reach and Impact of Game-Based Learning Approaches to Cultural Competency and Behavioural Change",
    "authors": [
      "Ian Dunwell",
      "Panagiotis Petridis",
      "Petros Lameras",
      "Maurice Hendrix",
      "Stella Doukianou",
      "Mark Gaved"
    ],
    "abstract": "As digital games continue to be explored as solutions to educational and behavioural challenges, the need for evaluation methodologies which support both the unique nature of the format and the need for comparison with other approaches continues to increase. In this workshop paper, a range of challenges are described related specifically to the case of cultural learning using digital games, in terms of how it may best be assessed, understood, and sustained through an iterative process supported by research. An evaluation framework is proposed, identifying metrics for reach and impact and their associated challenges, as well as presenting ethical considerations and the means to utilize evaluation outcomes within an iterative cycle, and to provide feedback to learners. Presenting as a case study a serious game from the Mobile Assistance for Social Inclusion and Empowerment of Immigrants with Persuasive Learning Technologies and Social Networks (MASELTOV) project, the use of the framework in the context of an integrative project is discussed, with emphasis on the need to view game-based learning as a blended component of the cultural learning process, rather than a standalone solution. The particular case of mobile gaming is also considered within this case study, providing a platform by which to deliver and update content in response to evaluation outcomes. Discussion reflects upon the general challenges related to the assessment of cultural learning, and behavioural change in more general terms, suggesting future work should address the need to provide sustainable, research-driven platforms for game-based learning content.",
    "lastUpdated": "2014-02-20T15:37:23Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1402.5037v1"
  },
  {
    "title": "Speculative Physics: the Ontology of Theory and Experiment in High Energy Particle Physics and Science Fiction",
    "authors": [
      "Clarissa Ai Ling Lee"
    ],
    "abstract": "The dissertation brings together approaches across the fields of physics, critical theory, literary studies, philosophy of physics, sociology of science, and history of science to synthesize a hybrid approach for instigating more rigorous and intense cross-disciplinary interrogations between the sciences and the humanities. There are two levels of conversations going on in the dissertation; at the first level, the discussion is centered on a critical historiography and philosophical implications of the discovery Higgs boson in relation to its position at the intersection of old (current) and the potential for new possibilities in quantum physics; I then position my findings on the Higgs boson in connection to the double-slit experiment that represents foundational inquiries into quantum physics, to demonstrate the bridge between fundamental physics and high energy particle physics. The conceptualization of the variants of the double-slit experiment informs the aforementioned critical comparisons. At the second level of the conversation, theories are produced from a close study of the physics objects as speculative engine for new knowledge generation that are then reconceptualized and re-articulated for extrapolation into the speculative ontology of hard science fiction, particularly the hard science fiction written with the double intent of speaking to the science while producing imaginative and socially conscious science through the literary affordances of science fiction. The works of science fiction examined here demonstrate the tension between the internal values of physics in the practice of theory and experiment and questions on ethics, culture, and morality.",
    "lastUpdated": "2014-06-21T17:10:25Z",
    "categories": [
      "physics.hist-ph",
      "hep-ex",
      "hep-ph",
      "physics.soc-ph",
      "quant-ph"
    ],
    "url": "http://arxiv.org/abs/1406.5636v1"
  },
  {
    "title": "Measuring Emotional Contagion in Social Media",
    "authors": [
      "Emilio Ferrara",
      "Zeyao Yang"
    ],
    "abstract": "Social media are used as main discussion channels by millions of individuals every day. The content individuals produce in daily social-media-based micro-communications, and the emotions therein expressed, may impact the emotional states of others. A recent experiment performed on Facebook hypothesized that emotions spread online, even in absence of non-verbal cues typical of in-person interactions, and that individuals are more likely to adopt positive or negative emotions if these are over-expressed in their social network. Experiments of this type, however, raise ethical concerns, as they require massive-scale content manipulation with unknown consequences for the individuals therein involved. Here, we study the dynamics of emotional contagion using Twitter. Rather than manipulating content, we devise a null model that discounts some confounding factors (including the effect of emotional contagion). We measure the emotional valence of content the users are exposed to before posting their own tweets. We determine that on average a negative post follows an over-exposure to 4.34% more negative content than baseline, while positive posts occur after an average over-exposure to 4.50% more positive contents. We highlight the presence of a linear relationship between the average emotional valence of the stimuli users are exposed to, and that of the responses they produce. We also identify two different classes of individuals: highly and scarcely susceptible to emotional contagion. Highly susceptible users are significantly less inclined to adopt negative emotions than the scarcely susceptible ones, but equally likely to adopt positive emotions. In general, the likelihood of adopting positive emotions is much greater than that of negative emotions.",
    "lastUpdated": "2015-06-19T14:29:24Z",
    "categories": [
      "cs.SI",
      "cs.LG",
      "physics.soc-ph"
    ],
    "url": "http://arxiv.org/abs/1506.06021v1"
  },
  {
    "title": "Ab Initio Calculation of stressed Cesium Iodide lattices and resulting Surface Plasmon Resonance Peak shifts",
    "authors": [
      "Kuldeep Kumar",
      "P. Arun",
      "S. V. Syrotyuk"
    ],
    "abstract": "Alkali halides like Cesium Iodide have received renewed attention as a material with potential application as detector coating due to the appearance of Surface Plasmon Resonance absorption peak in their UV-visible absorption spectrum. The formation of Surface Plasmon Resonance peak has been traced to the formation of Cesium metal clusters due to the aglomeration of color centers embedded in Cesium Iodide background. This paper, based on experimental observation that cubic Cesium Iodide experiences stress due to color centers forming in the neighborhood and take up tetragonal lattice structure, investigates the tetragonal Cesium Iodide's band structure and dielectric constant using ab initio calculations. Both, the band-gap and dielectric constant of Cesium Iodide, show a systematic variation with changing lattice constant. While the band-gap is seen to strongly depend on the lattice parameter `c', the dielectric constant's variation along `a' direction (${\\rm 0.2~nm^{-1}}$) was found to be stronger than that along the `c' direction (${\\rm -2.5~nm^{-1}}$). The calculated dielectric constants were used as input parameter for Gan model calculations of the extinction coefficient and evaluation of Surface Plasmon Resonance peak position (${\\rm \\lambda_{max}}$). A red-shift in ${\\rm \\lambda_{max}}$ was seen with increasing dielectric constant that appears with stress acting on Cesium Iodide's lattice.",
    "lastUpdated": "2017-05-30T15:07:49Z",
    "categories": [
      "cond-mat.mtrl-sci"
    ],
    "url": "http://arxiv.org/abs/1610.04890v2"
  },
  {
    "title": "The societal impact of big data: A research roadmap for Europe",
    "authors": [
      "Martí Cuquet",
      "Anna Fensel"
    ],
    "abstract": "With its rapid growth and increasing adoption, big data is producing a substantial impact in society. Its usage is opening both opportunities such as new business models and economic gains and risks such as privacy violations and discrimination. Europe is in need of a comprehensive strategy to optimise the use of data for a societal benefit and increase the innovation and competitiveness of its productive activities. In this paper, we contribute to the definition of this strategy with a research roadmap to capture the economic, social and ethical, legal and political benefits associated with the use of big data in Europe. The present roadmap considers the positive and negative externalities associated with big data, maps research and innovation topics in the areas of data management, processing, analytics, protection, visualisation, as well as non-technical topics, to the externalities they can tackle, and provides a time frame to address these topics in order to deliver social impact, skills development and standardisation. Finally, it also identifies what sectors will be most benefited by each of the research efforts. The goal of the roadmap is to guide European research efforts to develop a socially responsible big data economy, and to allow stakeholders to identify and meet big data challenges and proceed with a shared understanding of the societal impact, positive and negative externalities and concrete problems worth investigating in future programmes.",
    "lastUpdated": "2018-03-26T19:07:46Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1610.06766v2"
  },
  {
    "title": "A studentized permutation test for three-arm trials in the 'gold standard' design",
    "authors": [
      "Tobias Mütze",
      "Frank Konietschke",
      "Axel Munk",
      "Tim Friede"
    ],
    "abstract": "The 'gold standard' design for three-arm trials refers to trials with an active control and a placebo control in addition to the experimental treatment group. This trial design is recommended when being ethically justifiable and it allows the simultaneous comparison of experimental treatment, active control, and placebo. Parametric testing methods have been studied plentifully over the past years. However, these methods often tend to be liberal or conservative when distributional assumptions are not met particularly with small sample sizes. In this article, we introduce a studentized permutation test for testing non-inferiority and superiority of the experimental treatment compared to the active control in three-arm trials in the `gold standard' design. The performance of the studentized permutation test for finite sample sizes is assessed in a Monte-Carlo simulation study under various parameter constellations. Emphasis is put on whether the studentized permutation test meets the target significance level. For comparison purposes, commonly used Wald-type tests are included in the simulation study. The simulation study shows that the presented studentized permutation test for assessing non-inferiority in three-arm trials in the 'gold standard' design outperforms its competitors for count data. The methods discussed in this paper are implemented in the R package ThreeArmedTrials which is available on the comprehensive R archive network (CRAN).",
    "lastUpdated": "2016-10-28T20:13:40Z",
    "categories": [
      "stat.AP"
    ],
    "url": "http://arxiv.org/abs/1610.09388v1"
  },
  {
    "title": "Response adaptive designs for binary responses: how to offer patient benefit while being robust to time trends?",
    "authors": [
      "Sofia S. Villar",
      "Jack Bowden",
      "James Wason"
    ],
    "abstract": "Response-adaptive randomisation (RAR) can considerably improve the chances of a successful treatment outcome for patients in a clinical trial by skewing the allocation probability towards better performing treatments as data accumulates. There is considerable interest in using RAR designs in drug development for rare diseases, where traditional designs are not feasible or ethically objectionable. In this paper we discuss and address a major criticism of RAR: the undesirable type I error inflation due to unknown time trends in the trial. Time trends can appear because of changes in the characteristics of recruited patients - so-called \"patient drift\". Patient drift is a realistic concern for clinical trials in rare diseases because these typically recruit patients over a very long period of time. We compute by simulations how large the type I error inflation is as a function of the time trend magnitude in order to determine in which contexts a potentially costly correction is actually necessary. We then assess the ability of different correction methods to preserve type I error in this context and their performance in terms of other operating characteristics, including patient benefit and power. We make recommendations of which correction methods are most suitable in the rare disease context for several RAR rules, differentiating between the two-armed and the multi-armed case. We further propose a RAR design for multi-armed clinical trials, which is computationally cheap and robust to several time trends considered.",
    "lastUpdated": "2017-03-13T11:31:42Z",
    "categories": [
      "stat.AP"
    ],
    "url": "http://arxiv.org/abs/1703.04341v1"
  },
  {
    "title": "Like trainer, like bot? Inheritance of bias in algorithmic content moderation",
    "authors": [
      "Reuben Binns",
      "Michael Veale",
      "Max Van Kleek",
      "Nigel Shadbolt"
    ],
    "abstract": "The internet has become a central medium through which `networked publics' express their opinions and engage in debate. Offensive comments and personal attacks can inhibit participation in these spaces. Automated content moderation aims to overcome this problem using machine learning classifiers trained on large corpora of texts manually annotated for offence. While such systems could help encourage more civil debate, they must navigate inherently normatively contestable boundaries, and are subject to the idiosyncratic norms of the human raters who provide the training data. An important objective for platforms implementing such measures might be to ensure that they are not unduly biased towards or against particular norms of offence. This paper provides some exploratory methods by which the normative biases of algorithmic content moderation systems can be measured, by way of a case study using an existing dataset of comments labelled for offence. We train classifiers on comments labelled by different demographic subsets (men and women) to understand how differences in conceptions of offence between these groups might affect the performance of the resulting models on various test sets. We conclude by discussing some of the ethical choices facing the implementers of algorithmic moderation systems, given various desired levels of diversity of viewpoints amongst discussion participants.",
    "lastUpdated": "2017-07-05T17:19:45Z",
    "categories": [
      "cs.CY",
      "cs.CL",
      "cs.LG",
      "H.1.2; I.2.6; I.2.1; J.7; J.4; K.4.1; K.4.3; K.5.2; I.2.7; K.4.2"
    ],
    "url": "http://arxiv.org/abs/1707.01477v1"
  },
  {
    "title": "leave a trace - A People Tracking System Meets Anomaly Detection",
    "authors": [
      "Dominik Rueß",
      "Konstantinos Amplianitis",
      "Niklas Deckers",
      "Michele Adduci",
      "Kristian Manthey",
      "Ralf Reulke"
    ],
    "abstract": "Video surveillance always had a negative connotation, among others because of the loss of privacy and because it may not automatically increase public safety. If it was able to detect atypical (i.e. dangerous) situations in real time, autonomously and anonymously, this could change. A prerequisite for this is a reliable automatic detection of possibly dangerous situations from video data. This is done classically by object extraction and tracking. From the derived trajectories, we then want to determine dangerous situations by detecting atypical trajectories. However, due to ethical considerations it is better to develop such a system on data without people being threatened or even harmed, plus with having them know that there is such a tracking system installed. Another important point is that these situations do not occur very often in real, public CCTV areas and may be captured properly even less. In the artistic project leave a trace the tracked objects, people in an atrium of a institutional building, become actor and thus part of the installation. Visualisation in real-time allows interaction by these actors, which in turn creates many atypical interaction situations on which we can develop our situation detection. The data set has evolved over three years and hence, is huge. In this article we describe the tracking system and several approaches for the detection of atypical trajectories.",
    "lastUpdated": "2017-07-20T15:03:11Z",
    "categories": [
      "cs.CV",
      "cs.MM"
    ],
    "url": "http://arxiv.org/abs/1707.06557v1"
  },
  {
    "title": "Institutionally Distributed Deep Learning Networks",
    "authors": [
      "Ken Chang",
      "Niranjan Balachandar",
      "Carson K Lam",
      "Darvin Yi",
      "James M Brown",
      "Andrew Beers",
      "Bruce R Rosen",
      "Daniel L Rubin",
      "Jayashree Kalpathy-Cramer"
    ],
    "abstract": "Deep learning has become a promising approach for automated medical diagnoses. When medical data samples are limited, collaboration among multiple institutions is necessary to achieve high algorithm performance. However, sharing patient data often has limitations due to technical, legal, or ethical concerns. In such cases, sharing a deep learning model is a more attractive alternative. The best method of performing such a task is unclear, however. In this study, we simulate the dissemination of learning deep learning network models across four institutions using various heuristics and compare the results with a deep learning model trained on centrally hosted patient data. The heuristics investigated include ensembling single institution models, single weight transfer, and cyclical weight transfer. We evaluated these approaches for image classification in three independent image collections (retinal fundus photos, mammography, and ImageNet). We find that cyclical weight transfer resulted in a performance (testing accuracy = 77.3%) that was closest to that of centrally hosted patient data (testing accuracy = 78.7%). We also found that there is an improvement in the performance of cyclical weight transfer heuristic with high frequency of weight transfer.",
    "lastUpdated": "2017-09-10T15:36:17Z",
    "categories": [
      "cs.CV",
      "cs.LG",
      "physics.med-ph"
    ],
    "url": "http://arxiv.org/abs/1709.05929v1"
  },
  {
    "title": "Dynamic modelling of hepatitis C virus transmission among people who inject drugs: a methodological review",
    "authors": [
      "Anthony Cousien",
      "Viet Chi Tran",
      "Sylvie Deuffic-Burban",
      "Marie Jauffret-Roustide",
      "Jean-Stephane Dhersin",
      "Yazdan Yazdanpanah"
    ],
    "abstract": "Equipment sharing among people who inject drugs (PWID) is a key risk factor in infection by hepatitis C virus (HCV). Both the effectiveness and cost-effectiveness of interventions aimed at reducing HCV transmission in this population (such as opioid substitution therapy, needle exchange programs or improved treatment) are difficult to evaluate using field surveys. Ethical issues and complicated access to the PWID population make it difficult to gather epidemiological data. In this context, mathematical modelling of HCV transmission is a useful alternative for comparing the cost and effectiveness of various interventions. Several models have been developed in the past few years. They are often based on strong hypotheses concerning the population structure. This review presents compartmental and individual-based models in order to underline their strengths and limits in the context of HCV infection among PWID. The final section discusses the main results of the papers.",
    "lastUpdated": "2015-02-09T20:02:34Z",
    "categories": [
      "stat.AP",
      "math.DS",
      "q-bio.QM"
    ],
    "url": "http://arxiv.org/abs/1312.6220v2"
  },
  {
    "title": "Some Results on Ethnic Conflicts Based on Evolutionary Game Simulation",
    "authors": [
      "Jun Qin",
      "Yunfei Yi",
      "Hongrun Wu",
      "Yuhang Liu",
      "Xiaonian Tong",
      "Bojin Zheng"
    ],
    "abstract": "The force of the ethnic separatism, essentially origining from negative effect of ethnic identity, is damaging the stability and harmony of multiethnic countries. In order to eliminate the foundation of the ethnic separatism and set up a harmonious ethnic relationship, some scholars have proposed a viewpoint: ethnic harmony could be promoted by popularizing civic identity. However, this viewpoint is discussed only from a philosophical prospective and still lack supports of scientific evidences. Because ethic group and ethnic identity are products of evolution and ethnic identity is the parochialism strategy under the perspective of game theory, this paper proposes an evolutionary game simulation model to study the relationship between civic identity and ethnic conflict based on evolutionary game theory. The simulation results indicate that: 1) the ratio of individuals with civic identity has a positive association with the frequency of ethnic conflicts; 2) ethnic conflict will not die out by killing all ethnic members once for all, and it also cannot be reduced by a forcible pressure, i.e., increasing the ratio of individuals with civic identity; 3) the average frequencies of conflicts can stay in a low level by promoting civic identity periodically and persistently.",
    "lastUpdated": "2013-12-29T06:33:51Z",
    "categories": [
      "physics.soc-ph"
    ],
    "url": "http://arxiv.org/abs/1405.3614v1"
  },
  {
    "title": "Signalling Paediatric Side Effects using an Ensemble of Simple Study Designs",
    "authors": [
      "Jenna M. Reps",
      "Jonathan M. Garibaldi",
      "Uwe Aickelin",
      "Daniele Soria",
      "Jack E. Gibson",
      "Richard B. Hubbard"
    ],
    "abstract": "Background: Children are frequently prescribed medication off-label, meaning there has not been sufficient testing of the medication to determine its safety or effectiveness. The main reason this safety knowledge is lacking is due to ethical restrictions that prevent children from being included in the majority of clinical trials. Objective: The objective of this paper is to investigate whether an ensemble of simple study designs can be implemented to signal acutely occurring side effects effectively within the paediatric population by using historical longitudinal data. The majority of pharmacovigilance techniques are unsupervised, but this research presents a supervised framework. Methods: Multiple measures of association are calculated for each drug and medical event pair and these are used as features that are fed into a classiffier to determine the likelihood of the drug and medical event pair corresponding to an adverse drug reaction. The classiffier is trained using known adverse drug reactions or known non-adverse drug reaction relationships. Results: The novel ensemble framework obtained a false positive rate of 0:149, a sensitivity of 0:547 and a specificity of 0:851 when implemented on a reference set of drug and medical event pairs. The novel framework consistently outperformed each individual simple study design. Conclusion: This research shows that it is possible to exploit the mechanism of causality and presents a framework for signalling adverse drug reactions effectively.",
    "lastUpdated": "2014-09-02T16:17:25Z",
    "categories": [
      "cs.LG",
      "cs.CE"
    ],
    "url": "http://arxiv.org/abs/1409.0772v1"
  },
  {
    "title": "Computational Beauty: Aesthetic Judgment at the Intersection of Art and Science",
    "authors": [
      "Emily L. Spratt",
      "Ahmed Elgammal"
    ],
    "abstract": "In part one of the Critique of Judgment, Immanuel Kant wrote that \"the judgment of taste...is not a cognitive judgment, and so not logical, but is aesthetic.\"\\cite{Kant} While the condition of aesthetic discernment has long been the subject of philosophical discourse, the role of the arbiters of that judgment has more often been assumed than questioned. The art historian, critic, connoisseur, and curator have long held the esteemed position of the aesthetic judge, their training, instinct, and eye part of the inimitable subjective processes that Kant described as occurring upon artistic evaluation. Although the concept of intangible knowledge in regard to aesthetic theory has been much explored, little discussion has arisen in response to the development of new types of artificial intelligence as a challenge to the seemingly ineffable abilities of the human observer. This paper examines the developments in the field of computer vision analysis of paintings from canonical movements with the history of Western art and the reaction of art historians to the application of this technology in the field. Through an investigation of the ethical consequences of this innovative technology, the unquestioned authority of the art expert is challenged and the subjective nature of aesthetic judgment is brought to philosophical scrutiny once again.",
    "lastUpdated": "2014-09-30T01:31:58Z",
    "categories": [
      "cs.CV",
      "physics.hist-ph"
    ],
    "url": "http://arxiv.org/abs/1410.2488v1"
  },
  {
    "title": "Two-Party Privacy Games: How Users Perturb When Learners Preempt",
    "authors": [
      "Jeffrey Pawlick",
      "Quanyan Zhu"
    ],
    "abstract": "Internet tracking technologies and wearable electronics provide a vast amount of data to machine learning algorithms. This stock of data stands to increase with the developments of the internet of things and cyber-physical systems. Clearly, these technologies promise benefits. But they also raise the risk of sensitive information disclosure. To mitigate this risk, machine learning algorithms can add noise to outputs according to the formulations provided by differential privacy. At the same time, users can fight for privacy by injecting noise into the data that they report. In this paper, we conceptualize the interactions between privacy and accuracy and between user (input) perturbation and learner (output) perturbation in machine learning, using the frameworks of empirical risk minimization, differential privacy, and Stackelberg games. In particular, we solve for the Stackelberg equilibrium for the case of an averaging query. We find that, in equilibrium, either the users perturb their data before submission or the learner perturbs the machine learning output, but never both. Specifically, the learner perturbs if and only if the number of users is greater than a threshold which increases with the degree to which incentives are misaligned. Provoked by these conclusions - and by some observations from privacy ethics - we also suggest future directions. While other work in this area has studied privacy markets and mechanism design for truthful reporting of user information, we take a different viewpoint by considering both user and learner perturbation. We hope that this effort will open the door to future work in the area of differential privacy games.",
    "lastUpdated": "2016-08-10T17:10:28Z",
    "categories": [
      "cs.CR",
      "cs.GT",
      "cs.SY"
    ],
    "url": "http://arxiv.org/abs/1603.03081v2"
  },
  {
    "title": "Transdisciplinarity seen through Information, Communication, Computation, (Inter-)Action and Cognition",
    "authors": [
      "Gordana Dodig-Crnkovic",
      "Daniel Kade",
      "Markus Wallmyr",
      "Tobias Holstein",
      "Alexander Almér"
    ],
    "abstract": "Similar to oil that acted as a basic raw material and key driving force of industrial society, information acts as a raw material and principal mover of knowledge society in the knowledge production, propagation and application. New developments in information processing and information communication technologies allow increasingly complex and accurate descriptions, representations and models, which are often multi-parameter, multi-perspective, multi-level and multidimensional. This leads to the necessity of collaborative work between different domains with corresponding specialist competences, sciences and research traditions. We present several major transdisciplinary unification projects for information and knowledge, which proceed on the descriptive, logical and the level of generative mechanisms. Parallel process of boundary crossing and transdisciplinary activity is going on in the applied domains. Technological artifacts are becoming increasingly complex and their design is strongly user-centered, which brings in not only the function and various technological qualities but also other aspects including esthetic, user experience, ethics and sustainability with social and environmental dimensions. When integrating knowledge from a variety of fields, with contributions from different groups of stakeholders, numerous challenges are met in establishing common view and common course of action. In this context, information is our environment, and informational ecology determines both epistemology and spaces for action. We present some insights into the current state of the art of transdisciplinary theory and practice of information studies and informatics. We depict different facets of transdisciplinarity as we see it from our different research fields that include information studies, computability, human-computer interaction, multi-operating-systems environments and philosophy.",
    "lastUpdated": "2016-04-16T08:41:57Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1604.04711v1"
  },
  {
    "title": "Information and Communications Technologies (ICT) and Pre-Service Education Professionals: A Case Study of Motivation and Knowledge",
    "authors": [
      "Maria Isabel Ponce-Escudero",
      "Jose Gomez-Galan"
    ],
    "abstract": "The importance of knowing ICT training and motivation -so relevant in today's society- which currently offers the first year college students, mostly in degrees in Education, focuses the object of interest in this study. The following targets have been proposed: [1] knowing what basic skills regarding initial instrumental knowledge presents the prospective teacher (aptitudes) and [2] knowing their motivation for the educational use of ICT in the classroom (attitudes). For this purpose a non-experimental descriptive quantitative methodology has been used, with a sample of subjects (N=282) of the Autonomous Region of Extremadura (Spain). The results show that new degree college students possess a basic knowledge of ICT alongside a highly positive motivation towards the use of these. However, it is worrying that they only show an instrumental and technical knowledge of computing and telematic tools implied in social environments, but not pedagogical ones. Also they are unfamiliar with the true power of social, economic, political, ethical, influence as well as the effects and problems that their misuse can generate in their future students (addictions, manipulation, consumerism, etc.). Dimensions therefore for which they are urged to be trained at University for a proper performance as future professionals in education.",
    "lastUpdated": "2016-05-21T15:27:12Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1605.06659v1"
  },
  {
    "title": "Software startuppers took the medias paycheck Medias fightback happens through startup culture and abstraction shifts",
    "authors": [
      "Outi Alapekkala",
      "Juhani Risku"
    ],
    "abstract": "The collapse of old print media and journalism happened when the Internet, its solutions, services and communities became mature and mobile devices reached the market. The reader abandoned printed dailies for free and mobile access to information. The business of core industries of the early Internet and mobile communication, the mobile network manufacturers and operators are also in stagnation and decline. Therefore these industries may have similar interests to improve or even restructure their own businesses as well as to establish totally new business models by going into media and journalism. This paper analyses, first, the production flows and business models of the old and present media species. Second, it analyses the current market positioning of the network manufacturers and operators. Third, the paper suggests two avenues for media and journalism and the network manufacturers and operators, the Trio, to join their forces to update journalism and make all three stagnating industries great again. Last, we propose further research, development and discussion on the topic and envision possible futures for journalism, if the three would engage in cooperation. We see that the discussion should consist of ethical, societal and philosophical subjects because the development of the Internet solutions are based on 'technology first' actions. We find and outline a tremendous opportunity to create a new industry with new actors through combining the interests of the network manufacturers, network operators and journalism in a systemic solution through a strategic alliance and collaboration Fig. 1. Software startuppers with their applications and communities will be the drivers for this abstraction shift in media and journalism.",
    "lastUpdated": "2016-05-31T13:37:09Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1605.09626v1"
  },
  {
    "title": "The Peaks of Eternal Light: a Near-term Property Issue on the Moon",
    "authors": [
      "Martin Elvis",
      "Tony Milligan",
      "Alanna Krolikowski"
    ],
    "abstract": "The Outer Space Treaty makes it clear that the Moon is the province of all mankind, with the latter ordinarily understood to exclude state or private appropriation of any portion of its surface. However, there are indeterminacies in the Treaty and in space law generally over the issue of appropriation. These indeterminacies might permit a close approximation to a property claim or some manner of quasi-property. The recently revealed highly inhomogeneous distribution of lunar resources changes the context of these issues. We illustrate this altered situation by considering the Peaks of Eternal Light. They occupy about one square kilometer of the lunar surface. We consider a thought experiment in which a Solar telescope is placed on one of the Peaks of Eternal Light at the lunar South pole for scientific research. Its operation would require nondisturbance, and hence that the Peak remain unvisited by others, effectively establishing a claim of protective exclusion and de facto appropriation. Such a telescope would be relatively easy to emplace with todays technology and so poses a near-term property issue on the Moon. While effective appropriation of a Peak might proceed without raising some of the familiar problems associated with commercial development (especially lunar mining), the possibility of such appropriation nonetheless raises some significant issues concerning justice and the safeguarding of scientific practice on the lunar surface. We consider this issue from scientific, technical, ethical and policy viewpoints.",
    "lastUpdated": "2016-08-02T20:52:04Z",
    "categories": [
      "physics.pop-ph",
      "astro-ph.EP",
      "astro-ph.IM"
    ],
    "url": "http://arxiv.org/abs/1608.01989v1"
  },
  {
    "title": "Developing Ecospheres on Transiently Habitable Planets: The Genesis Project",
    "authors": [
      "Claudius Gros"
    ],
    "abstract": "It is often presumed, that life evolves relatively fast on planets with clement conditions, at least in its basic forms, and that extended periods of habitability are subsequently needed for the evolution of higher life forms. Many planets are however expected to be only transiently habitable. On a large set of otherwise suitable planets life will therefore just not have the time to develop on its own to a complexity level as it did arise on earth with the cambrian explosion. The equivalent of a cambrian explosion may however have the chance to unfold on transiently habitable planets if it would be possible to fast forward evolution by 3-4 billion years (with respect to terrestrial timescales). We argue here, that this is indeed possible when seeding the candidate planet with the microbial lifeforms, bacteria and unicellular eukaryotes alike, characterizing earth before the cambrian explosion. An interstellar mission of this kind, denoted the `Genesis project', could be carried out by a relatively low-cost robotic microcraft equipped with a on-board gene laboratory for the in situ synthesis of the microbes. We review here our current understanding of the processes determining the timescales shaping the geo-evolution of an earth-like planet, the prospect of finding Genesis candidate planets and selected issues regarding the mission layout. Discussing the ethical aspects connected with a Genesis mission, which would be expressively not for human benefit, we will also touch the risk that a biosphere incompatibility may arise in the wake of an eventual manned exploration of a second earth.",
    "lastUpdated": "2016-09-01T12:25:55Z",
    "categories": [
      "astro-ph.EP",
      "physics.space-ph",
      "q-bio.PE"
    ],
    "url": "http://arxiv.org/abs/1608.06087v2"
  },
  {
    "title": "Reducing energy consumption of network infrastructure using spectral approach",
    "authors": [
      "Mohammad Habibullah Khan",
      "Eric Rondeau",
      "Jean-Philippe Georges"
    ],
    "abstract": "The energy consumption by ICT (Information and Communication Technology) equipment is rapidly increasing which causes a significant economic and environmental problem. At present, the network infrastructure is becoming a large portion of the energy footprint in ICT. Thus, the concept of energy efficient or green networking has been introduced. Now one of the main concerns of network industry is to minimize energy consumption of network infrastructure because of the potential economic benefits, ethical responsibility, and its environmental impact. In this paper, the energy management strategies to reduce the energy consumed by network switches in LAN (Local Area Network) have been developed. According to the life-cycle assessment of network switches, the highest amount of energy is consumed during usage phase. The study considers bandwidth, link load and traffic matrices as input parameters which have the highest contribution to energy footprints of network switches during usage phase and energy consumption as output. Then with the objective of reducing energy usage of network infrastructure, the feasibility of putting Ethernet switches hibernate or sleep mode was investigated. After that, the network topology was reorganized using clustering method based on the spectral approach for putting network switches to hibernate or switched off mode considering the time and communications among them. Experimental results show the interest in this approach in terms of energy consumption. .",
    "lastUpdated": "2016-09-19T13:18:47Z",
    "categories": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1609.05708v1"
  },
  {
    "title": "Prerequisites for International Exchanges of Health Information: Comparison of Australian, Austrian, Finnish, Swiss, and US Privacy Policies",
    "authors": [
      "Hanna Suominen",
      "Henning Müller",
      "Lucila Ohno-Machado",
      "Sanna Salanterä",
      "Günter Schreier",
      "Leif Hanlen"
    ],
    "abstract": "Capabilities to exchange health information are critical to accelerate discovery and its diffusion to healthcare practice. However, the same ethical and legal policies that protect privacy hinder these data exchanges, and the issues accumulate if moving data across geographical or organizational borders. This can be seen as one of the reasons why many health technologies and research findings are limited to very narrow domains. In this paper, we compare how using and disclosing personal data for research purposes is addressed in Australian, Austrian, Finnish, Swiss, and US policies with a focus on text data analytics. Our goal is to identify approaches and issues that enable or hinder international health information exchanges. As expected, the policies within each country are not as diverse as across countries. Most policies apply the principles of accountability and/or adequacy and are thereby fundamentally similar. Their following requirements create complications with re-using and re-disclosing data and even secondary data: 1) informing data subjects about the purposes of data collection and use, before the dataset is collected; 2) assurance that the subjects are no longer identifiable; and 3) destruction of data when the research activities are finished. Using storage and compute cloud services as well as other exchange technologies on the Internet without proper permissions is technically not allowed if the data are stored in another country. Both legislation and technologies are available as vehicles for overcoming these barriers. The resulting richness in information variety will contribute to the development and evaluation of new clinical hypotheses and technologies.",
    "lastUpdated": "2016-12-15T01:28:25Z",
    "categories": [
      "cs.CY",
      "cs.DL"
    ],
    "url": "http://arxiv.org/abs/1612.04902v1"
  },
  {
    "title": "Partial Bridging of Vaccine Efficacy to New Populations",
    "authors": [
      "Alexander R. Luedtke",
      "Peter B. Gilbert"
    ],
    "abstract": "Suppose one has data from one or more completed vaccine efficacy trials and wishes to estimate the efficacy in a new setting. Often logistical or ethical considerations make running another efficacy trial impossible. Fortunately, if there is a biomarker that is the primary modifier of efficacy, then the biomarker-conditional efficacy may be identical in the completed trials and the new setting, or at least informative enough to meaningfully bound this quantity. Given a sample of this biomarker from the new population, we might hope we can bridge the results of the completed trials to estimate the vaccine efficacy in this new population. Unfortunately, even knowing the true conditional efficacy in the new population fails to identify the marginal efficacy due to the unknown conditional unvaccinated risk. We define a curve that partially identifies (lower bounds) the marginal efficacy in the new population as a function of the population's marginal unvaccinated risk, under the assumption that one can identify bounds on the conditional unvaccinated risk in the new population. Interpreting the curve only requires identifying plausible regions of the marginal unvaccinated risk in the new population. We present a nonparametric estimator of this curve and develop valid lower confidence bounds that concentrate at a parametric rate. We use vaccine terminology throughout, but the results apply to general binary interventions and bounded outcomes.",
    "lastUpdated": "2017-01-24T06:03:00Z",
    "categories": [
      "stat.ME"
    ],
    "url": "http://arxiv.org/abs/1701.06739v1"
  },
  {
    "title": "How well can machine learning predict demographics of social media users?",
    "authors": [
      "Nina Cesare",
      "Christan Grant",
      "Quynh Nguyen",
      "Hedwig Lee",
      "Elaine O. Nsoesie"
    ],
    "abstract": "The wide use of social media sites and other digital technologies have resulted in an unprecedented availability of digital data that are being used to study human behavior across research domains. Although unsolicited opinions and sentiments are available on these platforms, demographic details are usually missing. Demographic information is pertinent in fields such as demography and public health, where significant differences can exist across sex, racial and socioeconomic groups. In an attempt to address this shortcoming, a number of academic studies have proposed methods for inferring the demographics of social media users using details such as names, usernames, and network characteristics. Gender is the easiest trait to accurately infer, with measures of accuracy higher than 90 percent in some studies. Race, ethnicity and age tend to be more challenging to predict for a variety of reasons including the novelty of social media to certain age groups and a lack of significant deviations in user details across racial and ethnic groups. Although the endeavor to predict user demographics is plagued with ethical questions regarding privacy and data ownership, knowing the demographics in a data sample can aid in addressing issues of bias and population representation, so that existing societal inequalities are not exacerbated.",
    "lastUpdated": "2018-05-30T19:06:49Z",
    "categories": [
      "cs.SI",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1702.01807v2"
  },
  {
    "title": "Human decisions in moral dilemmas are largely described by Utilitarianism: virtual car driving study provides guidelines for ADVs",
    "authors": [
      "Maximilian Alexander Wächter",
      "Anja Faulhaber",
      "Felix Blind",
      "Silja Timm",
      "Anke Dittmer",
      "Leon René Sütfeld",
      "Achim Stephan",
      "Gordon Pipa",
      "Peter König"
    ],
    "abstract": "Ethical thought experiments such as the trolley dilemma have been investigated extensively in the past, showing that humans act in a utilitarian way, trying to cause as little overall damage as possible. These trolley dilemmas have gained renewed attention over the past years; especially due to the necessity of implementing moral decisions in autonomous driving vehicles. We conducted a set of experiments in which participants experienced modified trolley dilemmas as the driver in a virtual reality environment. Participants had to make decisionsbetween two discrete options: driving on one of two lanes where different obstacles came into view. Obstacles included a variety of human-like avatars of different ages and group sizes. Furthermore, we tested the influence of a sidewalk as a potential safe harbor and a condition implicating a self-sacrifice. Results showed that subjects, in general, decided in a utilitarian manner, sparing the highest number of avatars possible with a limited influence of the other variables. Our findings support that human behavior is in line with the utilitarian approach to moral decision making. This may serve as a guideline for the implementation of moral decisions in ADVs.",
    "lastUpdated": "2017-06-23T14:12:37Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1706.07332v2"
  },
  {
    "title": "A Framework for Inferring Causality from Multi-Relational Observational Data using Conditional Independence",
    "authors": [
      "Sudeepa Roy",
      "Babak Salimi"
    ],
    "abstract": "The study of causality or causal inference - how much a given treatment causally affects a given outcome in a population - goes way beyond correlation or association analysis of variables, and is critical in making sound data driven decisions and policies in a multitude of applications. The gold standard in causal inference is performing \"controlled experiments\", which often is not possible due to logistical or ethical reasons. As an alternative, inferring causality on \"observational data\" based on the \"Neyman-Rubin potential outcome model\" has been extensively used in statistics, economics, and social sciences over several decades. In this paper, we present a formal framework for sound causal analysis on observational datasets that are given as multiple relations and where the population under study is obtained by joining these base relations. We study a crucial condition for inferring causality from observational data, called the \"strong ignorability assumption\" (the treatment and outcome variables should be independent in the joined relation given the observed covariates), using known conditional independences that hold in the base relations. We also discuss how the structure of the conditional independences in base relations given as graphical models help infer new conditional independences in the joined relation. The proposed framework combines concepts from databases, statistics, and graphical models, and aims to initiate new research directions spanning these fields to facilitate powerful data-driven decisions in today's big data world.",
    "lastUpdated": "2017-08-08T15:56:18Z",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1708.02536v1"
  },
  {
    "title": "An Architecture for Establishing Legal Semantic Workflows in the Context of Integrated Law Enforcement",
    "authors": [
      "Markus Stumptner",
      "Wolfgang Mayer",
      "Georg Grossmann",
      "Jixue Liu",
      "Wenhao Li",
      "Pompeu Casanovas",
      "Louis De Koker",
      "Danuta Mendelson",
      "David Watts",
      "Bridget Bainbridge"
    ],
    "abstract": "Traditionally the integration of data from multiple sources is done on an ad-hoc basis for each analysis scenario and application. This is a solution that is inflexible, incurs in high costs, leads to \"silos\" that prevent sharing data across different agencies or tasks, and is unable to cope with the modern environment, where workflows, tasks, and priorities frequently change. Operating within the Data to Decision Cooperative Research Centre (D2D CRC), the authors are currently involved in the Integrated Law Enforcement Project, which has the goal of developing a federated data platform that will enable the execution of integrated analytics on data accessed from different external and internal sources, thereby providing effective support to an investigator or analyst working to evaluate evidence and manage lines of inquiries in the investigation. Technical solutions should also operate ethically, in compliance with the law, and subject to good governance principles.",
    "lastUpdated": "2017-08-22T13:54:54Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1708.06613v1"
  },
  {
    "title": "Fair Kernel Learning",
    "authors": [
      "Adrián Pérez-Suay",
      "Valero Laparra",
      "Gonzalo Mateo-García",
      "Jordi Muñoz-Marí",
      "Luis Gómez-Chova",
      "Gustau Camps-Valls"
    ],
    "abstract": "New social and economic activities massively exploit big data and machine learning algorithms to do inference on people's lives. Applications include automatic curricula evaluation, wage determination, and risk assessment for credits and loans. Recently, many governments and institutions have raised concerns about the lack of fairness, equity and ethics in machine learning to treat these problems. It has been shown that not including sensitive features that bias fairness, such as gender or race, is not enough to mitigate the discrimination when other related features are included. Instead, including fairness in the objective function has been shown to be more efficient. We present novel fair regression and dimensionality reduction methods built on a previously proposed fair classification framework. Both methods rely on using the Hilbert Schmidt independence criterion as the fairness term. Unlike previous approaches, this allows us to simplify the problem and to use multiple sensitive variables simultaneously. Replacing the linear formulation by kernel functions allows the methods to deal with nonlinear problems. For both linear and nonlinear formulations the solution reduces to solving simple matrix inversions or generalized eigenvalue problems. This simplifies the evaluation of the solutions for different trade-off values between the predictive error and fairness terms. We illustrate the usefulness of the proposed methods in toy examples, and evaluate their performance on real world datasets to predict income using gender and/or race discrimination as sensitive variables, and contraceptive method prediction under demographic and socio-economic sensitive descriptors.",
    "lastUpdated": "2017-10-16T09:19:56Z",
    "categories": [
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1710.05578v1"
  },
  {
    "title": "Discussion Paper: Should statistics rescue mathematical modelling?",
    "authors": [
      "Andrea Saltelli"
    ],
    "abstract": "Statistics experiences a storm around the perceived misuse and possible abuse of its methods in the context of the so-called reproducibility crisis. The methods and styles of quantification practiced in mathematical modelling rarely make it to the headlines, though modelling practitioners writing in disciplinary journals flag a host of problems in the field. Technical, cultural and ethical dimensions are simultaneously at play in the current predicaments of both statistics and mathematical modelling. Since mathematical modelling is not a discipline like statistics, its shortcomings risk remaining untreated longer. We suggest that the tools of statistics and its disciplinary organisation might offer a remedial contribution to mathematical modelling, standardising methodologies and disseminating good practices. Statistics could provide scientists and engineers from all disciplines with a point of anchorage for sound modelling work. This is a vast and long-term undertaking. A step in the proposed direction is offered here by focusing on the use of statistical tools for quality assurance of mathematical models. By way of illustration, techniques for uncertainty quantification, sensitivity analysis and sensitivity auditing are suggested for incorporation in statistical syllabuses and practices.",
    "lastUpdated": "2019-08-17T08:59:59Z",
    "categories": [
      "stat.ME",
      "62A01, 97M10, 97M50, 97M60, 97M70"
    ],
    "url": "http://arxiv.org/abs/1712.06457v4"
  },
  {
    "title": "Demographics and discussion influence views on algorithmic fairness",
    "authors": [
      "Emma Pierson"
    ],
    "abstract": "The field of algorithmic fairness has highlighted ethical questions which may not have purely technical answers. For example, different algorithmic fairness constraints are often impossible to satisfy simultaneously, and choosing between them requires value judgments about which people may disagree. Achieving consensus on algorithmic fairness will be difficult unless we understand why people disagree in the first place. Here we use a series of surveys to investigate how two factors affect disagreement: demographics and discussion. First, we study whether disagreement on algorithmic fairness questions is caused partially by differences in demographic backgrounds. This is a question of interest because computer science is demographically non-representative. If beliefs about algorithmic fairness correlate with demographics, and algorithm designers are demographically non-representative, decisions made about algorithmic fairness may not reflect the will of the population as a whole. We show, using surveys of three separate populations, that there are gender differences in beliefs about algorithmic fairness. For example, women are less likely to favor including gender as a feature in an algorithm which recommends courses to students if doing so would make female students less likely to be recommended science courses. Second, we investigate whether people's views on algorithmic fairness can be changed by discussion and show, using longitudinal surveys of students in two computer science classes, that they can.",
    "lastUpdated": "2018-03-05T01:35:04Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1712.09124v2"
  },
  {
    "title": "\"23andMe confirms: I'm super white\" -- Analyzing Twitter Discourse On Genetic Testing",
    "authors": [
      "Alexandros Mittos",
      "Jeremy Blackburn",
      "Emiliano De Cristofaro"
    ],
    "abstract": "Recent progress in genomics is bringing genetic testing to the masses. Participatory public initiatives are underway to sequence the genome of millions of volunteers, and a new market is booming with a number of companies like 23andMe and AncestryDNA offering affordable tests directly to consumers. Consequently, news, experiences, and views on genetic testing are increasingly shared and discussed online and on social networks like Twitter. In this paper, we present a large-scale analysis of Twitter discourse on genetic testing. We collect 302K tweets from 113K users, posted over 2.5 years, by using thirteen keywords related to genetic testing companies and public initiatives as search keywords. We study both the tweets and the users posting them along several axes, aiming to understand who tweets about genetic testing, what they talk about, and how they use Twitter for that. Among other things, we find that tweets about genetic testing originate from accounts that overall appear to be interested in digital health and technology. Also, marketing efforts as well as announcements, such as the FDA's suspension of 23andMe's health reports, influence the type and the nature of user engagement.Finally, we report on users who share screenshots of their results, and raise a few ethical and societal questions as we find evidence of groups associating genetic testing to racist ideologies.",
    "lastUpdated": "2018-04-20T10:48:17Z",
    "categories": [
      "cs.SI",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1801.09946v2"
  },
  {
    "title": "A Survey Of Methods For Explaining Black Box Models",
    "authors": [
      "Riccardo Guidotti",
      "Anna Monreale",
      "Salvatore Ruggieri",
      "Franco Turini",
      "Dino Pedreschi",
      "Fosca Giannotti"
    ],
    "abstract": "In the last years many accurate decision support systems have been constructed as black boxes, that is as systems that hide their internal logic to the user. This lack of explanation constitutes both a practical and an ethical issue. The literature reports many approaches aimed at overcoming this crucial weakness sometimes at the cost of scarifying accuracy for interpretability. The applications in which black box decision systems can be used are various, and each approach is typically developed to provide a solution for a specific problem and, as a consequence, delineating explicitly or implicitly its own definition of interpretability and explanation. The aim of this paper is to provide a classification of the main problems addressed in the literature with respect to the notion of explanation and the type of black box system. Given a problem definition, a black box type, and a desired explanation this survey should help the researcher to find the proposals more useful for his own work. The proposed classification of approaches to open black box models should also be useful for putting the many research open questions in perspective.",
    "lastUpdated": "2018-06-21T08:15:38Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1802.01933v3"
  },
  {
    "title": "Implementation of a geometrically and energetically constrained mesoscale eddy parameterization in an ocean circulation model",
    "authors": [
      "Julian Mak",
      "James R. Maddison",
      "David P. Marshall",
      "David R. Munday"
    ],
    "abstract": "The global stratification and circulation of the ocean and their sensitivities to changes in forcing depend crucially on the representation of the mesoscale eddy field. Here, a geometrically informed and energetically constrained parameterization framework for mesoscale eddies --- termed GEOMETRIC --- is proposed and implemented in three-dimensional primitive equation channel and sector models. The GEOMETRIC framework closes mesoscale eddy fluxes according to the standard Gent--McWilliams scheme, but with the eddy transfer coefficient constrained by the depth-integrated eddy energy field, provided through a prognostic eddy energy budget evolving with the mean state. It is found that coarse resolution calculations employing GEOMETRIC broadly reproduce model sensitivities of the eddy permitting reference calculations in the emergent circumpolar transport, meridional overturning circulation profile and the depth-integrated eddy energy signature; in particular, eddy saturation emerges in the sector configuration. Some differences arise, attributed here to the simple prognostic eddy energy budget employed, to be improved upon in future investigations. The GEOMETRIC framework thus proposes a shift in paradigm, from a focus on how to close for eddy fluxes, to focusing on the representation of eddy energetics.",
    "lastUpdated": "2018-02-08T11:57:50Z",
    "categories": [
      "physics.ao-ph",
      "physics.flu-dyn"
    ],
    "url": "http://arxiv.org/abs/1802.02816v1"
  },
  {
    "title": "A first look at browser-based Cryptojacking",
    "authors": [
      "Shayan Eskandari",
      "Andreas Leoutsarakos",
      "Troy Mursch",
      "Jeremy Clark"
    ],
    "abstract": "In this paper, we examine the recent trend towards in-browser mining of cryptocurrencies; in particular, the mining of Monero through Coinhive and similar code- bases. In this model, a user visiting a website will download a JavaScript code that executes client-side in her browser, mines a cryptocurrency, typically without her consent or knowledge, and pays out the seigniorage to the website. Websites may consciously employ this as an alternative or to supplement advertisement revenue, may offer premium content in exchange for mining, or may be unwittingly serving the code as a result of a breach (in which case the seigniorage is collected by the attacker). The cryptocurrency Monero is preferred seemingly for its unfriendliness to large-scale ASIC mining that would drive browser-based efforts out of the market, as well as for its purported privacy features. In this paper, we survey this landscape, conduct some measurements to establish its prevalence and profitability, outline an ethical framework for considering whether it should be classified as an attack or business opportunity, and make suggestions for the detection, mitigation and/or prevention of browser-based mining for non- consenting users.",
    "lastUpdated": "2018-03-07T21:50:37Z",
    "categories": [
      "cs.CR",
      "cs.CY",
      "cs.HC",
      "econ.EM"
    ],
    "url": "http://arxiv.org/abs/1803.02887v1"
  },
  {
    "title": "An information-theoretic Phase I/II design for molecularly targeted agents that does not require an assumption of monotonicity",
    "authors": [
      "Pavel Mozgunov",
      "Thomas Jaki"
    ],
    "abstract": "For many years Phase I and Phase II clinical trials were conducted separately, but there was a recent shift to combine these Phases. While a variety of Phase~I/II model-based designs for cytotoxic agents were proposed in the literature, methods for molecularly targeted agents (TA) are just starting to develop. The main challenge of the TA setting is the unknown dose-efficacy relation that can have either an increasing, plateau or umbrella shape. To capture these, approaches with more parameters are needed to model the dose-efficacy relationship or, alternatively, more orderings of the dose-efficacy relationship are required to account for the uncertainty in the curve shape. As a result, designs for more complex clinical trials, for example, trials looking at schedules of a combination treatment involving TA, have not been extensively studied yet. We propose a novel regimen-finding design which is based on a derived efficacy-toxicity trade-off function. Due to its special properties, an accurate regimen selection can be achieved without any parametric or monotonicity assumptions. We illustrate how this design can be applied in the context of a complex combination-schedule clinical trial. We discuss practical and ethical issues such as coherence, delayed and missing efficacy responses, safety and futility constraints.",
    "lastUpdated": "2018-06-18T09:56:16Z",
    "categories": [
      "stat.ME"
    ],
    "url": "http://arxiv.org/abs/1803.04397v2"
  },
  {
    "title": "TYDR - Track Your Daily Routine. Android App for Tracking Smartphone Sensor and Usage Data",
    "authors": [
      "Felix Beierle",
      "Vinh Thuy Tran",
      "Mathias Allemand",
      "Patrick Neff",
      "Winfried Schlee",
      "Thomas Probst",
      "Rüdiger Pryss",
      "Johannes Zimmermann"
    ],
    "abstract": "We present the Android app TYDR (Track Your Daily Routine) which tracks smartphone sensor and usage data and utilizes standardized psychometric personality questionnaires. With the app, we aim at collecting data for researching correlations between the tracked smartphone data and the user's personality in order to predict personality from smartphone data. In this paper, we highlight our approaches in addressing the challenges in developing such an app. We optimize the tracking of sensor data by assessing the trade-off of size of data and battery consumption and granularity of the stored information. Our user interface is designed to incentivize users to install the app and fill out questionnaires. TYDR processes and visualizes the tracked sensor and usage data as well as the results of the personality questionnaires. When developing an app that will be used in psychological studies, requirements posed by ethics commissions / institutional review boards and data protection officials have to be met. We detail our approaches concerning those requirements regarding the anonymized storing of user data, informing the users about the data collection, and enabling an opt-out option. We present our process for anonymized data storing while still being able to identify individual users who successfully completed a psychological study with the app.",
    "lastUpdated": "2018-03-18T19:24:56Z",
    "categories": [
      "cs.CY",
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/1803.06720v1"
  },
  {
    "title": "On Analyzing Self-Driving Networks: A Systems Thinking Approach",
    "authors": [
      "Touseef Yaqoob",
      "Muhammad Usama",
      "Junaid Qadir",
      "Gareth Tyson"
    ],
    "abstract": "The networking field has recently started to incorporate artificial intelligence (AI), machine learning (ML), big data analytics combined with advances in networking (such as software-defined networks, network functions virtualization, and programmable data planes) in a bid to construct highly optimized self-driving and self-organizing networks. It is worth remembering that the modern Internet that interconnects millions of networks is a `complex adaptive social system', in which interventions not only cause effects but the effects have further knock-on effects (not all of which are desirable or anticipated). We believe that self-driving networks will likely raise new unanticipated challenges (particularly in the human-facing domains of ethics, privacy, and security). In this paper, we propose the use of insights and tools from the field of \"systems thinking\"---a rich discipline developing for more than half a century, which encompasses qualitative and quantitative nonlinear models of complex social systems---and highlight their relevance for studying the long-term effects of network architectural interventions, particularly for self-driving networks. We show that these tools complement existing simulation and modeling tools and provide new insights and capabilities. To the best of our knowledge, this is the first study that has considered the relevance of formal systems thinking tools for the analysis of self-driving networks.",
    "lastUpdated": "2018-04-09T17:29:44Z",
    "categories": [
      "cs.CY",
      "cs.SI"
    ],
    "url": "http://arxiv.org/abs/1804.03116v1"
  },
  {
    "title": "Bribery Games on Interdependent Complex Networks",
    "authors": [
      "Prateek Verma",
      "Anjan K. Nandi",
      "Supratim Sengupta"
    ],
    "abstract": "Bribe demands present a social conflict scenario where decisions have wide-ranging economic and ethical consequences. Nevertheless, such incidents occur daily in many countries across the globe. Harassment bribery constitute a significant sub-set of such bribery incidents where a government official demands a bribe for providing a service to a citizen legally entitled to it. We employ an evolutionary game-theoretic framework to analyse the evolution of corrupt and honest strategies in structured populations characterized by an interdependent complex network. The effects of changing network topology, average number of links and asymmetry in size of the citizen and officer population on the proliferation of incidents of bribery are explored. A complex network topology is found to be beneficial for the dominance of corrupt strategies over a larger region of phase space when compared with the outcome for a regular network, for equal citizen and officer population sizes. However, the extent of the advantage depends critically on the network degree and topology. A different trend is observed when there is a difference between the citizen and officer population sizes. Under those circumstances, increasing randomness of the underlying citizen network can be beneficial to the fixation of honest officers up to a certain value of the network degree. Our analysis reveals how the interplay between network topology, connectivity and strategy update rules can affect population level outcomes in such asymmetric games.",
    "lastUpdated": "2018-04-25T10:59:02Z",
    "categories": [
      "physics.soc-ph",
      "cs.SI"
    ],
    "url": "http://arxiv.org/abs/1804.09477v1"
  },
  {
    "title": "Distributed Weight Consolidation: A Brain Segmentation Case Study",
    "authors": [
      "Patrick McClure",
      "Charles Y. Zheng",
      "Jakub R. Kaczmarzyk",
      "John A. Lee",
      "Satrajit S. Ghosh",
      "Dylan Nielson",
      "Peter Bandettini",
      "Francisco Pereira"
    ],
    "abstract": "Collecting the large datasets needed to train deep neural networks can be very difficult, particularly for the many applications for which sharing and pooling data is complicated by practical, ethical, or legal concerns. However, it may be the case that derivative datasets or predictive models developed within individual sites can be shared and combined with fewer restrictions. Training on distributed data and combining the resulting networks is often viewed as continual learning, but these methods require networks to be trained sequentially. In this paper, we introduce distributed weight consolidation (DWC), a continual learning method to consolidate the weights of separate neural networks, each trained on an independent dataset. We evaluated DWC with a brain segmentation case study, where we consolidated dilated convolutional neural networks trained on independent structural magnetic resonance imaging (sMRI) datasets from different sites. We found that DWC led to increased performance on test sets from the different sites, while maintaining generalization performance for a very large and completely independent multi-site dataset, compared to an ensemble baseline.",
    "lastUpdated": "2019-01-16T11:37:26Z",
    "categories": [
      "cs.LG",
      "cs.CV",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1805.10863v9"
  },
  {
    "title": "Active Learning for Segmentation by Optimizing Content Information for Maximal Entropy",
    "authors": [
      "Firat Ozdemir",
      "Zixuan Peng",
      "Christine Tanner",
      "Philipp Fuernstahl",
      "Orcun Goksel"
    ],
    "abstract": "Segmentation is essential for medical image analysis tasks such as intervention planning, therapy guidance, diagnosis, treatment decisions. Deep learning is becoming increasingly prominent for segmentation, where the lack of annotations, however, often becomes the main limitation. Due to privacy concerns and ethical considerations, most medical datasets are created, curated, and allow access only locally. Furthermore, current deep learning methods are often suboptimal in translating anatomical knowledge between different medical imaging modalities. Active learning can be used to select an informed set of image samples to request for manual annotation, in order to best utilize the limited annotation time of clinical experts for optimal outcomes, which we focus on in this work. Our contributions herein are two fold: (1) we enforce domain-representativeness of selected samples using a proposed penalization scheme to maximize information at the network abstraction layer, and (2) we propose a Borda-count based sample querying scheme for selecting samples for segmentation. Comparative experiments with baseline approaches show that the samples queried with our proposed method, where both above contributions are combined, result in significantly improved segmentation performance for this active learning task.",
    "lastUpdated": "2018-07-18T14:24:39Z",
    "categories": [
      "cs.CV",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1807.06962v1"
  },
  {
    "title": "Controllability of Social Networks and the Strategic Use of Random Information",
    "authors": [
      "Marco Cremonini",
      "Francesca Casamassima"
    ],
    "abstract": "This work is aimed at studying realistic social control strategies for social networks based on the introduction of random information into the state of selected driver agents. Deliberately exposing selected agents to random information is a technique already experimented in recommender systems or search engines, and represents one of the few options for influencing the behavior of a social context that could be accepted as ethical, could be fully disclosed to members, and does not involve the use of force or of deception. Our research is based on a model of knowledge diffusion applied to a time-varying adaptive network, and considers two well-known strategies for influencing social contexts. One is the selection of few influencers for manipulating their actions in order to drive the whole network to a certain behavior; the other, instead, drives the network behavior acting on the state of a large subset of ordinary, scarcely influencing users. The two approaches have been studied in terms of network and diffusion effects. The network effect is analyzed through the changes induced on network average degree and clustering coefficient, while the diffusion effect is based on two ad-hoc metrics defined to measure the degree of knowledge diffusion and skill level, as well as the polarization of agent interests. The results, obtained through simulations on synthetic networks, show a rich dynamics and strong effects on the communication structure and on the distribution of knowledge and skills, supporting our hypothesis that the strategic use of random information could represent a realistic approach to social network controllability, and that with both strategies, in principle, the control effect could be remarkable.",
    "lastUpdated": "2018-07-20T09:47:35Z",
    "categories": [
      "cs.SI",
      "physics.soc-ph"
    ],
    "url": "http://arxiv.org/abs/1807.07761v1"
  },
  {
    "title": "Decentralized Search on Decentralized Web",
    "authors": [
      "Ziliang Lai",
      "Chris Liu",
      "Eric Lo",
      "Ben Kao",
      "Siu-Ming Yiu"
    ],
    "abstract": "Decentralized Web, or DWeb, is envisioned as a promising future of the Web. Being decentralized, there are no dedicated web servers in DWeb; Devices that retrieve web contents also serve their cached data to peer devices with straight privacy-preserving mechanisms. The fact that contents in DWeb are distributed, replicated, and decentralized lead to a number of key advantages over the conventional web. These include better resiliency against network partitioning and distributed-denial-of-service attacks (DDoS), and better browsing experiences in terms of shorter latency and higher throughput. Moreover, DWeb provides tamper-proof contents because each content piece is uniquely identified by a cryptographic hash. DWeb also clicks well with future Internet architectures, such as Named Data Networking (NDN).Search engines have been an inseparable element of the Web. Contemporary (\"Web 2.0\") search engines, however, provide centralized services. They are thus subject to DDoS attacks, insider threat, and ethical issues like search bias and censorship. As the web moves from being centralized to being decentralized, search engines ought to follow. We propose QueenBee, a decentralized search engine for DWeb. QueenBee is so named because worker bees and honeycomb are a common metaphor for distributed architectures, with the queen being the one that holds the colony together. QueenBee aims to revolutionize the search engine business model by offering incentives to both content providers and peers that participate in QueenBee's page indexing and ranking operations.",
    "lastUpdated": "2018-08-18T15:32:26Z",
    "categories": [
      "cs.IR",
      "cs.CR",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1809.00939v1"
  },
  {
    "title": "Incorporating Behavioral Constraints in Online AI Systems",
    "authors": [
      "Avinash Balakrishnan",
      "Djallel Bouneffouf",
      "Nicholas Mattei",
      "Francesca Rossi"
    ],
    "abstract": "AI systems that learn through reward feedback about the actions they take are increasingly deployed in domains that have significant impact on our daily life. However, in many cases the online rewards should not be the only guiding criteria, as there are additional constraints and/or priorities imposed by regulations, values, preferences, or ethical principles. We detail a novel online agent that learns a set of behavioral constraints by observation and uses these learned constraints as a guide when making decisions in an online setting while still being reactive to reward feedback. To define this agent, we propose to adopt a novel extension to the classical contextual multi-armed bandit setting and we provide a new algorithm called Behavior Constrained Thompson Sampling (BCTS) that allows for online learning while obeying exogenous constraints. Our agent learns a constrained policy that implements the observed behavioral constraints demonstrated by a teacher agent, and then uses this constrained policy to guide the reward-based online exploration and exploitation. We characterize the upper bound on the expected regret of the contextual bandit algorithm that underlies our agent and provide a case study with real world data in two application domains. Our experiments show that the designed agent is able to act within the set of behavior constraints without significantly degrading its overall reward performance.",
    "lastUpdated": "2018-09-15T14:24:37Z",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1809.05720v1"
  },
  {
    "title": "Transparency and Explanation in Deep Reinforcement Learning Neural Networks",
    "authors": [
      "Rahul Iyer",
      "Yuezhang Li",
      "Huao Li",
      "Michael Lewis",
      "Ramitha Sundar",
      "Katia Sycara"
    ],
    "abstract": "Autonomous AI systems will be entering human society in the near future to provide services and work alongside humans. For those systems to be accepted and trusted, the users should be able to understand the reasoning process of the system, i.e. the system should be transparent. System transparency enables humans to form coherent explanations of the system's decisions and actions. Transparency is important not only for user trust, but also for software debugging and certification. In recent years, Deep Neural Networks have made great advances in multiple application areas. However, deep neural networks are opaque. In this paper, we report on work in transparency in Deep Reinforcement Learning Networks (DRLN). Such networks have been extremely successful in accurately learning action control in image input domains, such as Atari games. In this paper, we propose a novel and general method that (a) incorporates explicit object recognition processing into deep reinforcement learning models, (b) forms the basis for the development of \"object saliency maps\", to provide visualization of internal states of DRLNs, thus enabling the formation of explanations and (c) can be incorporated in any existing deep reinforcement learning framework. We present computational results and human experiments to evaluate our approach.",
    "lastUpdated": "2018-09-17T07:56:35Z",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1809.06061v1"
  },
  {
    "title": "Can high-density human collective motion be forecasted by spatiotemporal fluctuations?",
    "authors": [
      "Arianna Bottinelli",
      "Jesse L. Silverberg"
    ],
    "abstract": "Concerts, protests, and sporting events are occurring with increasing frequency and magnitude. The extreme physical conditions common to these events are known to cause injuries and loss-of-life due to the emergence of collective motion such as crowd crush, turbulence, and density waves. Mathematical models of human crowds aimed at enhancing crowd safety by understanding these phenomena are developed with input from a variety of disciplines. However, model validation is challenged by a lack of high-quality empirical data and ethical constraints surrounding human crowd research. Consequently, generalized model-based approach for real-time monitoring/risk-assessment of crowd collective motion remains an open problem. Here, we take a model-free approach to crowd analysis and show that emergent collective motion can be forecasted directly from video data. We use mode analysis methods from material science and concepts from non-equilibrium physics to study footage of a human crowd at an Oasis rock concert. We analyze the attendees positional fluctuations during a period of crowd turbulence to predict the spatial patterns of an emergent human density wave. In addition to predicting spatial patterns of collective motion, we also identify and measure temporal patterns that precede the density wave and forecast its appearance by 1~s. Looking ahead, widening this forecasting window beyond 1~s will enable new computer vision technologies for real-time risk-assessment of emergent human collective motion.",
    "lastUpdated": "2018-09-24T14:17:00Z",
    "categories": [
      "physics.soc-ph"
    ],
    "url": "http://arxiv.org/abs/1809.07875v2"
  },
  {
    "title": "Teaching Social Behavior through Human Reinforcement for Ad hoc Teamwork -The STAR Framework",
    "authors": [
      "Shani Alkoby",
      "Avilash Rath",
      "Peter Stone"
    ],
    "abstract": "As AI technology continues to develop, more and more agents will become capable of long term autonomy alongside people. Thus, a recent line of research has studied the problem of teaching autonomous agents the concept of ethics and human social norms. Most existing work considers the case of an individual agent attempting to learn a predefined set of rules. In reality, however, social norms are not always pre-defined and are very difficult to represent algorithmically. Moreover, the basic idea behind the social norms concept is ensuring that one's actions do not negatively influence others' utilities, which is inherently a multiagent concept. Thus, here we investigate a way to teach agents, as a team, how to act according to human social norms. In this research, we introduce the STAR framework used to teach an ad hoc team of agents to act in accordance with human social norms. Using a hybrid team (agents and people), when taking an action considered to be socially unacceptable, the agents receive negative feedback from the human teammate(s) who has(have) an awareness of the team's norms. We view STAR as an important step towards teaching agents to act more consistently with respect to human morality.",
    "lastUpdated": "2019-05-02T15:24:56Z",
    "categories": [
      "cs.CY",
      "68T"
    ],
    "url": "http://arxiv.org/abs/1809.07880v3"
  },
  {
    "title": "Measuring the effect of node aggregation on community detection",
    "authors": [
      "Yérali Gandica",
      "Adeline Decuyper",
      "Christophe Cloquet",
      "Isabelle Thomas",
      "Jean-Charles Delvenne"
    ],
    "abstract": "Many times the nodes of a complex network, whether deliberately or not, are aggregated for technical, ethical, legal limitations or privacy reasons. A common example is the geographic position: one may uncover communities in a network of places, or of individuals identified with their typical geographical position, and then aggregate these places into larger entities, such as municipalities, thus obtaining another network. The communities found in the networks obtained at various levels of aggregation may exhibit various degrees of similarity, from full alignment to perfect independence. This is akin to the problem of ecological and atomic fallacies in statistics, or to the Modified Areal Unit Problem in geography. We identify the class of community detection algorithms most suitable to cope with node aggregation, and develop an index for aggregability, capturing to which extent the aggregation preserves the community structure. We illustrate its relevance on real-world examples (mobile phone and Twitter reply-to networks). Our main message is that any node-partitioning analysis performed on aggregated networks should be interpreted with caution, as the outcome may be strongly influenced by the level of the aggregation.",
    "lastUpdated": "2020-03-28T11:52:47Z",
    "categories": [
      "physics.soc-ph",
      "cs.SI"
    ],
    "url": "http://arxiv.org/abs/1809.08855v2"
  },
  {
    "title": "Instantly Deployable Expert Knowledge - Networks of Knowledge Engines",
    "authors": [
      "Bernhard Bergmair",
      "Thomas Buchegger",
      "Johann Hoffelner",
      "Gerald Schatz",
      "Siegfried Silber",
      "Johannes Klinglmayr"
    ],
    "abstract": "Knowledge and information are becoming the primary resources of the emerging information society. To exploit the potential of available expert knowledge, comprehension and application skills (i.e. expert competences) are necessary. The ability to acquire these skills is limited for any individual human. Consequently, the capacities to solve problems based on human knowledge in a manual (i.e. mental) way are strongly limited. We envision a new systemic approach to enable scalable knowledge deployment without expert competences. Eventually, the system is meant to instantly deploy humanity's total knowledge in full depth for every individual challenge. To this end, we propose a socio-technical framework that transforms expert knowledge into a solution creation system. Knowledge is represented by automated algorithms (knowledge engines). Executable compositions of knowledge engines (networks of knowledge engines) generate requested individual information at runtime. We outline how these knowledge representations could yield legal, ethical and social challenges and nurture new business and remuneration models on knowledge. We identify major technological and economic concepts that are already pushing the boundaries in knowledge utilisation: e.g. in artificial intelligence, knowledge bases, ontologies, advanced search tools, automation of knowledge work, the API economy. We indicate impacts on society, economy and labour. Existing developments are linked, including a specific use case in engineering design.",
    "lastUpdated": "2018-11-07T16:30:08Z",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1811.02964v1"
  },
  {
    "title": "The ASCCR Frame for Learning Essential Collaboration Skills",
    "authors": [
      "Eric A. Vance",
      "Heather S. Smith"
    ],
    "abstract": "Statistics and data science are especially collaborative disciplines that typically require practitioners to interact with many different people or groups. Consequently, interdisciplinary collaboration skills are part of the personal and professional skills essential for success as an applied statistician or data scientist. These skills are learnable and teachable, and learning and improving collaboration skills provides a way to enhance one's practice of statistics and data science. To help individuals learn these skills and organizations to teach them, we have developed a framework covering five essential components of statistical collaboration: Attitude, Structure, Content, Communication, and Relationship. We call this the ASCCR Frame. This framework can be incorporated into formal training programs in the classroom or on the job and can also be used by individuals through self-study. We show how this framework can be applied specifically to statisticians and data scientists to improve their collaboration skills and their interdisciplinary impact. We believe that the ASCCR Frame can help organize and stimulate research and teaching in interdisciplinary collaboration and call on individuals and organizations to begin generating evidence regarding its effectiveness.",
    "lastUpdated": "2019-08-30T17:16:05Z",
    "categories": [
      "stat.OT"
    ],
    "url": "http://arxiv.org/abs/1811.03578v5"
  },
  {
    "title": "On Human Predictions with Explanations and Predictions of Machine Learning Models: A Case Study on Deception Detection",
    "authors": [
      "Vivian Lai",
      "Chenhao Tan"
    ],
    "abstract": "Humans are the final decision makers in critical tasks that involve ethical and legal concerns, ranging from recidivism prediction, to medical diagnosis, to fighting against fake news. Although machine learning models can sometimes achieve impressive performance in these tasks, these tasks are not amenable to full automation. To realize the potential of machine learning for improving human decisions, it is important to understand how assistance from machine learning models affects human performance and human agency. In this paper, we use deception detection as a testbed and investigate how we can harness explanations and predictions of machine learning models to improve human performance while retaining human agency. We propose a spectrum between full human agency and full automation, and develop varying levels of machine assistance along the spectrum that gradually increase the influence of machine predictions. We find that without showing predicted labels, explanations alone slightly improve human performance in the end task. In comparison, human performance is greatly improved by showing predicted labels (>20% relative improvement) and can be further improved by explicitly suggesting strong machine performance. Interestingly, when predicted labels are shown, explanations of machine predictions induce a similar level of accuracy as an explicit statement of strong machine performance. Our results demonstrate a tradeoff between human performance and human agency and show that explanations of machine predictions can moderate this tradeoff.",
    "lastUpdated": "2019-01-08T21:15:07Z",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "physics.soc-ph",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1811.07901v4"
  },
  {
    "title": "Large-scale analysis of user exposure to online advertising in Facebook",
    "authors": [
      "Aritz Arrate",
      "José González Cabañas",
      "Ángel Cuevas",
      "María Calderón",
      "Rubén Cuevas"
    ],
    "abstract": "Online advertising is the major source of income for a large portion of Internet Services. There exists a body of literature aiming at optimizing ads engagement, understanding the privacy and ethical implications of online advertising, etc. However, to the best of our knowledge, no previous work analyses at large scale the exposure of real users to online advertising. This paper performs a comprehensive analysis of the exposure of users to ads and advertisers using a dataset including more than 7M ads from 140K unique advertisers delivered to more than 5K users that was collected between October 2016 and May 2018. The study focuses on Facebook, which is the second largest advertising platform only to Google in terms of revenue, and accounts for more than 2.2B monthly active users. Our analysis reveals that Facebook users are exposed (in median) to 70 ads per week, which come from 12 advertisers. Ads represent between 10% and 15% of all the information received in users' newsfeed. A small increment of 1% in the portion of ads in the newsfeed could roughly represent a revenue increase of 8.17M USD per week for Facebook. Finally, we also reveal that Facebook users are overprofiled since in the best case only 22.76% of the interests Facebook assigns to users for advertising purpose are actually related to the ads those users receive.",
    "lastUpdated": "2018-12-26T12:04:17Z",
    "categories": [
      "cs.SI",
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/1811.10921v3"
  },
  {
    "title": "The validity of RFID badges measuring face-to-face interactions",
    "authors": [
      "Timon Elmer",
      "Krishna Chaitanya",
      "Prateek Purwar",
      "Christoph Stadtfeld"
    ],
    "abstract": "Face-to-face interactions are important for a variety of individual behaviors and outcomes. In recent years a number of human sensor technologies have been proposed to incorporate direct observations in behavioral studies of face-to-face interactions. One of the most promising emerging technologies are active Radio Frequency Identification (RFID) badges. They are increasingly applied in behavioral studies because of their low costs, straightforward applicability, and moderate ethical concerns. However, despite the attention that RFID badges have recently received, there is a lack of systematic tests on how valid RFID badges are in measuring face-to-face interaction. With two studies we aim to fill this gap. Study 1 (N = 11) compares how data assessed with RFID badges correspond with video data of the same interactions (construct validity) and how this fit can be improved using straightforward data processing strategies. The analyses show that the RFID badges have a sensitivity of 50% that can be enhanced to 65% when flickering signals with gaps of less than 75 seconds are interpolated. The specificity is relatively less affected by this interpolation process (before interpolation 97%, after interpolation 94.7%) - resulting in an improved accuracy of the measurement. In Study 2 (N = 73) we show that self-report data of social interactions correspond highly with data gathered with the RFID badges (criterion validity).",
    "lastUpdated": "2019-04-18T14:41:42Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1811.12189v2"
  },
  {
    "title": "What are the biases in my word embedding?",
    "authors": [
      "Nathaniel Swinger",
      "Maria De-Arteaga",
      "Neil Thomas Heffernan IV",
      "Mark DM Leiserson",
      "Adam Tauman Kalai"
    ],
    "abstract": "This paper presents an algorithm for enumerating biases in word embeddings. The algorithm exposes a large number of offensive associations related to sensitive features such as race and gender on publicly available embeddings, including a supposedly \"debiased\" embedding. These biases are concerning in light of the widespread use of word embeddings. The associations are identified by geometric patterns in word embeddings that run parallel between people's names and common lower-case tokens. The algorithm is highly unsupervised: it does not even require the sensitive features to be pre-specified. This is desirable because: (a) many forms of discrimination--such as racial discrimination--are linked to social constructs that may vary depending on the context, rather than to categories with fixed definitions; and (b) it makes it easier to identify biases against intersectional groups, which depend on combinations of sensitive features. The inputs to our algorithm are a list of target tokens, e.g. names, and a word embedding. It outputs a number of Word Embedding Association Tests (WEATs) that capture various biases present in the data. We illustrate the utility of our approach on publicly available word embeddings and lists of names, and evaluate its output using crowdsourcing. We also show how removing names may not remove potential proxy bias.",
    "lastUpdated": "2019-06-19T19:52:15Z",
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1812.08769v4"
  },
  {
    "title": "Human-AI Learning Performance in Multi-Armed Bandits",
    "authors": [
      "Ravi Pandya",
      "Sandy H. Huang",
      "Dylan Hadfield-Menell",
      "Anca D. Dragan"
    ],
    "abstract": "People frequently face challenging decision-making problems in which outcomes are uncertain or unknown. Artificial intelligence (AI) algorithms exist that can outperform humans at learning such tasks. Thus, there is an opportunity for AI agents to assist people in learning these tasks more effectively. In this work, we use a multi-armed bandit as a controlled setting in which to explore this direction. We pair humans with a selection of agents and observe how well each human-agent team performs. We find that team performance can beat both human and agent performance in isolation. Interestingly, we also find that an agent's performance in isolation does not necessarily correlate with the human-agent team's performance. A drop in agent performance can lead to a disproportionately large drop in team performance, or in some settings can even improve team performance. Pairing a human with an agent that performs slightly better than them can make them perform much better, while pairing them with an agent that performs the same can make them them perform much worse. Further, our results suggest that people have different exploration strategies and might perform better with agents that match their strategy. Overall, optimizing human-agent team performance requires going beyond optimizing agent performance, to understanding how the agent's suggestions will influence human decision-making.",
    "lastUpdated": "2018-12-21T21:28:11Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1812.09376v1"
  },
  {
    "title": "Impossibility and Uncertainty Theorems in AI Value Alignment (or why your AGI should not have a utility function)",
    "authors": [
      "Peter Eckersley"
    ],
    "abstract": "Utility functions or their equivalents (value functions, objective functions, loss functions, reward functions, preference orderings) are a central tool in most current machine learning systems. These mechanisms for defining goals and guiding optimization run into practical and conceptual difficulty when there are independent, multi-dimensional objectives that need to be pursued simultaneously and cannot be reduced to each other. Ethicists have proved several impossibility theorems that stem from this origin; those results appear to show that there is no way of formally specifying what it means for an outcome to be good for a population without violating strong human ethical intuitions (in such cases, the objective function is a social welfare function). We argue that this is a practical problem for any machine learning system (such as medical decision support systems or autonomous weapons) or rigidly rule-based bureaucracy that will make high stakes decisions about human lives: such systems should not use objective functions in the strict mathematical sense. We explore the alternative of using uncertain objectives, represented for instance as partially ordered preferences, or as probability distributions over total orders. We show that previously known impossibility theorems can be transformed into uncertainty theorems in both of those settings, and prove lower bounds on how much uncertainty is implied by the impossibility results. We close by proposing two conjectures about the relationship between uncertainty in objectives and severe unintended consequences from AI systems.",
    "lastUpdated": "2019-03-05T03:12:49Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1901.00064v3"
  },
  {
    "title": "Why planetary and exoplanetary protection differ: The case of long duration Genesis missions to habitable but sterile M-dwarf oxygen planets",
    "authors": [
      "Claudius Gros"
    ],
    "abstract": "Time is arguably the key limiting factor for interstellar exploration. At high speeds, flyby missions to nearby stars by laser propelled wafersats taking 50-100 years would be feasible. Directed energy launch systems could accelerate on the other side also crafts weighing several tons to cruising speeds of the order of 1000\\,km/s (c/300). At these speeds, superconducting magnetic sails would be able to decelerate the craft by transferring kinetic energy to the protons of the interstellar medium. A tantalizing perspective, which would allow interstellar probes to stop whenever time is not a limiting factor. Prime candidates are in this respect Genesis probes, that is missions aiming to offer terrestrial life new evolutionary pathways on potentially habitable but hitherto barren exoplanets. Genesis missions raise important ethical issues, in particular with regard to planetary protection. Here we argue that exoplanetary and planetary protection differ qualitatively as a result of the vastly different cruising times for payload delivering probes, which are of the order of millennia for interstellar probes, but only of years for solar system bodies. Furthermore we point out that our galaxy may harbor a large number of habitable exoplanets, M-dwarf planets, which could be sterile due to the presence of massive primordial oxygen atmospheres. We believe that the prospect terrestrial life has in our galaxy would shift on a fundamental level in case that the existence of this type of habitable but sterile oxygen planets will be corroborated by future research. It may also explain why our sun is not a M dwarf, the most common star type, but a medium-sized G-class star.",
    "lastUpdated": "2019-01-08T12:46:16Z",
    "categories": [
      "physics.pop-ph",
      "astro-ph.EP",
      "physics.space-ph",
      "q-bio.PE"
    ],
    "url": "http://arxiv.org/abs/1901.02286v1"
  },
  {
    "title": "Problem Formulation and Fairness",
    "authors": [
      "Samir Passi",
      "Solon Barocas"
    ],
    "abstract": "Formulating data science problems is an uncertain and difficult process. It requires various forms of discretionary work to translate high-level objectives or strategic goals into tractable problems, necessitating, among other things, the identification of appropriate target variables and proxies. While these choices are rarely self-evident, normative assessments of data science projects often take them for granted, even though different translations can raise profoundly different ethical concerns. Whether we consider a data science project fair often has as much to do with the formulation of the problem as any property of the resulting model. Building on six months of ethnographic fieldwork with a corporate data science team---and channeling ideas from sociology and history of science, critical data studies, and early writing on knowledge discovery in databases---we describe the complex set of actors and activities involved in problem formulation. Our research demonstrates that the specification and operationalization of the problem are always negotiated and elastic, and rarely worked out with explicit normative considerations in mind. In so doing, we show that careful accounts of everyday data science work can help us better understand how and why data science problems are posed in certain ways---and why specific formulations prevail in practice, even in the face of what might seem like normatively preferable alternatives. We conclude by discussing the implications of our findings, arguing that effective normative interventions will require attending to the practical work of problem formulation.",
    "lastUpdated": "2019-01-08T22:56:45Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1901.02547v1"
  },
  {
    "title": "Fairwashing: the risk of rationalization",
    "authors": [
      "Ulrich Aïvodji",
      "Hiromi Arai",
      "Olivier Fortineau",
      "Sébastien Gambs",
      "Satoshi Hara",
      "Alain Tapp"
    ],
    "abstract": "Black-box explanation is the problem of explaining how a machine learning model -- whose internal logic is hidden to the auditor and generally complex -- produces its outcomes. Current approaches for solving this problem include model explanation, outcome explanation as well as model inspection. While these techniques can be beneficial by providing interpretability, they can be used in a negative manner to perform fairwashing, which we define as promoting the false perception that a machine learning model respects some ethical values. In particular, we demonstrate that it is possible to systematically rationalize decisions taken by an unfair black-box model using the model explanation as well as the outcome explanation approaches with a given fairness metric. Our solution, LaundryML, is based on a regularized rule list enumeration algorithm whose objective is to search for fair rule lists approximating an unfair black-box model. We empirically evaluate our rationalization technique on black-box models trained on real-world datasets and show that one can obtain rule lists with high fidelity to the black-box model while being considerably less unfair at the same time.",
    "lastUpdated": "2019-05-15T15:12:03Z",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1901.09749v3"
  },
  {
    "title": "Toward Controlling Discrimination in Online Ad Auctions",
    "authors": [
      "L. Elisa Celis",
      "Anay Mehrotra",
      "Nisheeth K. Vishnoi"
    ],
    "abstract": "Online advertising platforms are thriving due to the customizable audiences they offer advertisers. However, recent studies show that advertisements can be discriminatory with respect to the gender or race of the audience that sees the ad, and may inadvertently cross ethical and/or legal boundaries. To prevent this, we propose a constrained ad auction framework that maximizes the platform's revenue conditioned on ensuring that the audience seeing an advertiser's ad is distributed appropriately across sensitive types such as gender or race. Building upon Myerson's classic work, we first present an optimal auction mechanism for a large class of fairness constraints. Finding the parameters of this optimal auction, however, turns out to be a non-convex problem. We show that this non-convex problem can be reformulated as a more structured non-convex problem with no saddle points or local-maxima; this allows us to develop a gradient-descent-based algorithm to solve it. Our empirical results on the A1 Yahoo! dataset demonstrate that our algorithm can obtain uniform coverage across different user types for each advertiser at a minor loss to the revenue of the platform, and a small change to the size of the audience each advertiser reaches.",
    "lastUpdated": "2019-05-22T02:53:08Z",
    "categories": [
      "cs.GT",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1901.10450v2"
  },
  {
    "title": "Seasonality Effects on Consumers Preferences Over Quality Attributes of Different Beef Products",
    "authors": [
      "Ali Ardeshiri",
      "Spring Sampson",
      "Joffre Swait"
    ],
    "abstract": "Using discrete choice modelling, the study investigates 946 American consumers willingness-to-pay and preferences for diverse beef products. A novel experiment was used to elicit the number of beef products that each consumer would purchase. The range of products explored in this study included ground, diced, roast, and six cuts of steaks (sirloin, tenderloin, flank, flap, New York and cowboy or rib-eye). The outcome of the study suggests that US consumers vary in their preferences for beef products by season. The presence of a USDA certification logo is by far the most important factor affecting consumers willingness to pay for all beef cuts, which is also heavily dependent on season. In relation to packaging, US consumers have mixed preference for different beef products by season. The results from a scaled adjusted ordered logit model showed that after price, safety-related attributes such as certification logos, types of packaging, and antibiotic free and organic products are a stronger influence on American consumers choice. Furthermore, US consumers on average purchase diced and roast products more often in winter slow cooking season, than in summer, whereas New York strip and flank steak are more popular in the summer grilling season. This study provides valuable insights for businesses as well as policymakers to make inform decisions while considering how consumers relatively value among different labelling and product attributes by season and better address any ethical, safety and aesthetic concerns that consumers might have.",
    "lastUpdated": "2019-02-06T22:35:43Z",
    "categories": [
      "econ.GN",
      "q-fin.EC"
    ],
    "url": "http://arxiv.org/abs/1902.02419v1"
  },
  {
    "title": "Optimal disclosure risk assessment",
    "authors": [
      "Federico Camerlenghi",
      "Stefano Favaro",
      "Zacharie Naulet",
      "Francesca Panero"
    ],
    "abstract": "Protection against disclosure is a legal and ethical obligation for agencies releasing microdata files for public use. Consider a microdata sample of size $n$ from a finite population of size $\\bar{n}=n+\\lambda n$, with $\\lambda>0$, such that each record contains two disjoint types of information: identifying categorical information and sensitive information. Any decision about releasing data is supported by the estimation of measures of disclosure risk, which are functionals of the number of sample records with a unique combination of values of identifying variables. The most common measure is arguably the number $\\tau_{1}$ of sample unique records that are population uniques. In this paper, we first study nonparametric estimation of $\\tau_{1}$ under the Poisson abundance model for sample records. We introduce a class of linear estimators of $\\tau_{1}$ that are simple, computationally efficient and scalable to massive datasets, and we give uniform theoretical guarantees for them. In particular, we show that they provably estimate $\\tau_{1}$ all of the way up to the sampling fraction $(\\lambda+1)^{-1}\\propto (\\log n)^{-1}$, with vanishing normalized mean-square error (NMSE) for large $n$. We then establish a lower bound for the minimax NMSE for the estimation of $\\tau_{1}$, which allows us to show that: i) $(\\lambda+1)^{-1}\\propto (\\log n)^{-1}$ is the smallest possible sampling fraction; ii) estimators' NMSE is near optimal, in the sense of matching the minimax lower bound, for large $n$. This is the main result of our paper, and it provides a precise answer to an open question about the feasibility of nonparametric estimation of $\\tau_{1}$ under the Poisson abundance model and for a sampling fraction $(\\lambda+1)^{-1}<1/2$.",
    "lastUpdated": "2019-02-14T13:53:43Z",
    "categories": [
      "math.ST",
      "stat.TH",
      "62G05, 62C20"
    ],
    "url": "http://arxiv.org/abs/1902.05354v1"
  },
  {
    "title": "Estimating Network Effects Using Naturally Occurring Peer Notification Queue Counterfactuals",
    "authors": [
      "Craig Tutterow",
      "Guillaume Saint-Jacques"
    ],
    "abstract": "Randomized experiments, or A/B tests are used to estimate the causal impact of a feature on the behavior of users by creating two parallel universes in which members are simultaneously assigned to treatment and control. However, in social network settings, members interact, such that the impact of a feature is not always contained within the treatment group. Researchers have developed a number of experimental designs to estimate network effects in social settings. Alternatively, naturally occurring exogenous variation, or 'natural experiments,' allow researchers to recover causal estimates of peer effects from observational data in the absence of experimental manipulation. Natural experiments trade off the engineering costs and some of the ethical concerns associated with network randomization with the search costs of finding situations with natural exogenous variation. To mitigate the search costs associated with discovering natural counterfactuals, we identify a common engineering requirement used to scale massive online systems, in which natural exogenous variation is likely to exist: notification queueing. We identify two natural experiments on the LinkedIn platform based on the order of notification queues to estimate the causal impact of a received message on the engagement of a recipient. We show that receiving a message from another member significantly increases a member's engagement, but that some popular observational specifications, such as fixed-effects estimators, overestimate this effect by as much as 2.7x. We then apply the estimated network effect coefficients to a large body of past experiments to quantify the extent to which it changes our interpretation of experimental results. The study points to the benefits of using messaging queues to discover naturally occurring counterfactuals for the estimation of causal effects without experimenter intervention.",
    "lastUpdated": "2019-02-19T16:44:08Z",
    "categories": [
      "cs.SI",
      "cs.CY",
      "econ.EM",
      "stat.AP",
      "91D30, 91G70, 62P20, 62P25",
      "J.4; G.3"
    ],
    "url": "http://arxiv.org/abs/1902.07133v1"
  },
  {
    "title": "The Prosumer Economy -- Being Like a Forest",
    "authors": [
      "Uygar Ozesmi"
    ],
    "abstract": "Planetary life support systems are collapsing due to climate change and the biodiversity crisis. The root cause is the existing consumer economy, coupled with profit maximisation based on ecological and social externalities. Trends can be reversed, civilisation may be saved by transforming the profit maximising consumer economy into an ecologically and socially just economy, which we call the prosumer economy. Prosumer economy is a macro scale circular economy with minimum negative or positive ecological and social impact, an ecosystem of producers and prosumers, who have synergistic and circular relationships with deepened circular supply chains, networks, where leakage of wealth out of the system is minimised. In a prosumer economy there is no waste, no lasting negative impacts on the ecology and no social exploitation. The prosumer economy is like a lake or a forest, an economic ecosystem that is productive and supportive of the planet. We are already planting this forest through Good4Trust.org, started in Turkey. Good4Trust is a community platform bringing together ecologically and socially just producers and prosumers. Prosumers come together around a basic ethical tenet the golden rule and share on the platform their good deeds. The relationship are already deepening and circularity is forming to create a prosumer economy. The platforms software to structure the economy is open source, and is available to be licenced to start Good4Trust anywhere on the planet. Complexity theory tells us that if enough agents in a given system adopt simple rules which they all follow, the system may shift. The shift from a consumer economy to a prosumer economy has already started, the future is either ecologically and socially just or bust.",
    "lastUpdated": "2019-03-16T12:56:19Z",
    "categories": [
      "econ.GN",
      "q-fin.EC"
    ],
    "url": "http://arxiv.org/abs/1903.07615v1"
  },
  {
    "title": "Evolving Academia/Industry Relations in Computing Research",
    "authors": [
      "Greg Morrisett",
      "Shwetak Patel",
      "Jennifer Rexford",
      "Benjamin Zorn"
    ],
    "abstract": "In 2015, the CCC co-sponsored an industry round table that produced the document \"The Future of Computing Research: Industry-Academic Collaborations\". Since then, several important trends in computing research have emerged, and this document considers how those trends impact the interaction between academia and industry in computing fields. We reach the following conclusions: - In certain computing disciplines, such as currently artificial intelligence, we observe significant increases in the level of interaction between professors and companies, which take the form of extended joint appointments. - Increasingly, companies are highly motivated to engage both professors and graduate students working in specific technical areas because companies view computing research and technical talent as a core aspect of their business success. - There is also the further potential for principles and values from the academy (e.g., ethics, human-centered approaches, etc.) informing products and R&D roadmaps in new ways through these unique joint arrangements. - This increasing connection between faculty, students, and companies has the potential to change (either positively or negatively) numerous things, including: the academic culture in computing research universities, the research topics that faculty and students pursue, the ability of universities to train undergraduate and graduate students, etc. This report is the first step in engaging the broader computing research community, raising awareness of the opportunities, complexities and challenges of this trend but further work is required. We recommend follow-up to measure the degree and impact of this trend and to establish best practices that are shared widely among computing research institutions.",
    "lastUpdated": "2019-10-08T18:48:13Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1903.10375v2"
  },
  {
    "title": "Learning Optimal and Fair Decision Trees for Non-Discriminative Decision-Making",
    "authors": [
      "Sina Aghaei",
      "Mohammad Javad Azizi",
      "Phebe Vayanos"
    ],
    "abstract": "In recent years, automated data-driven decision-making systems have enjoyed a tremendous success in a variety of fields (e.g., to make product recommendations, or to guide the production of entertainment). More recently, these algorithms are increasingly being used to assist socially sensitive decision-making (e.g., to decide who to admit into a degree program or to prioritize individuals for public housing). Yet, these automated tools may result in discriminative decision-making in the sense that they may treat individuals unfairly or unequally based on membership to a category or a minority, resulting in disparate treatment or disparate impact and violating both moral and ethical standards. This may happen when the training dataset is itself biased (e.g., if individuals belonging to a particular group have historically been discriminated upon). However, it may also happen when the training dataset is unbiased, if the errors made by the system affect individuals belonging to a category or minority differently (e.g., if misclassification rates for Blacks are higher than for Whites). In this paper, we unify the definitions of unfairness across classification and regression. We propose a versatile mixed-integer optimization framework for learning optimal and fair decision trees and variants thereof to prevent disparate treatment and/or disparate impact as appropriate. This translates to a flexible schema for designing fair and interpretable policies suitable for socially sensitive decision-making. We conduct extensive computational studies that show that our framework improves the state-of-the-art in the field (which typically relies on heuristics) to yield non-discriminative decisions at lower cost to overall accuracy.",
    "lastUpdated": "2019-03-25T21:16:39Z",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1903.10598v1"
  },
  {
    "title": "Dataset of an EEG-based BCI experiment in Virtual Reality and on a Personal Computer",
    "authors": [
      "Grégoire Cattan",
      "A. Andreev",
      "P. Rodrigues",
      "M. Congedo"
    ],
    "abstract": "We describe the experimental procedures for a dataset that we have made publicly available at https://doi.org/10.5281/zenodo.2605204 in mat (Mathworks, Natick, USA) and csv formats. This dataset contains electroencephalographic recordings on 21 subjects doing a visual P300 experiment on PC (personal computer) and VR (virtual reality). The visual P300 is an event-related potential elicited by a visual stimulation, peaking 240-600 ms after stimulus onset. The experiment was designed in order to compare the use of a P300-based brain-computer interface on a PC and with a virtual reality headset, concerning the physiological, subjective and performance aspects. The brain-computer interface is based on electroencephalography (EEG). EEG were recorded thanks to 16 electrodes. The virtual reality headset consisted of a passive head-mounted display, that is, a head-mounted display which does not include any electronics at the exception of a smartphone. This experiment was carried out at GIPSA-lab (University of Grenoble Alpes, CNRS, Grenoble-INP) in 2018, and promoted by the IHMTEK Company (Interaction Homme-Machine Technologie). The study was approved by the Ethical Committee of the University of Grenoble Alpes (Comit{\\'e} d'Ethique pour la Recherche Non-Interventionnelle). Python code for manipulating the data is available at https://github.com/plcrodrigues/py.VR.EEG.2018-GIPSA. The ID of this dataset is VR.EEG.2018-GIPSA.",
    "lastUpdated": "2019-03-27T08:58:02Z",
    "categories": [
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/1903.11297v1"
  },
  {
    "title": "Big Data Analytics and AI in Mental Healthcare",
    "authors": [
      "Ariel Rosenfeld",
      "David Benrimoh",
      "Caitrin Armstrong",
      "Nykan Mirchi",
      "Timothe Langlois-Therrien",
      "Colleen Rollins",
      "Myriam Tanguay-Sela",
      "Joseph Mehltretter",
      "Robert Fratila",
      "Sonia Israel",
      "Emily Snook",
      "Kelly Perlman",
      "Akiva Kleinerman",
      "Bechara Saab",
      "Mark Thoburn",
      "Cheryl Gabbay",
      "Amit Yaniv-Rosenfeld"
    ],
    "abstract": "Mental health conditions cause a great deal of distress or impairment; depression alone will affect 11% of the world's population. The application of Artificial Intelligence (AI) and big-data technologies to mental health has great potential for personalizing treatment selection, prognosticating, monitoring for relapse, detecting and helping to prevent mental health conditions before they reach clinical-level symptomatology, and even delivering some treatments. However, unlike similar applications in other fields of medicine, there are several unique challenges in mental health applications which currently pose barriers towards the implementation of these technologies. Specifically, there are very few widely used or validated biomarkers in mental health, leading to a heavy reliance on patient and clinician derived questionnaire data as well as interpretation of new signals such as digital phenotyping. In addition, diagnosis also lacks the same objective 'gold standard' as in other conditions such as oncology, where clinicians and researchers can often rely on pathological analysis for confirmation of diagnosis. In this chapter we discuss the major opportunities, limitations and techniques used for improving mental healthcare through AI and big-data. We explore both the computational, clinical and ethical considerations and best practices as well as lay out the major researcher directions for the near future.",
    "lastUpdated": "2019-03-12T20:47:29Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1903.12071v1"
  },
  {
    "title": "Dynamically optimal treatment allocation using Reinforcement Learning",
    "authors": [
      "Karun Adusumilli",
      "Friedrich Geiecke",
      "Claudio Schilter"
    ],
    "abstract": "Devising guidance on how to assign individuals to treatment is an important goal in empirical research. In practice, individuals often arrive sequentially, and the planner faces various constraints such as limited budget/capacity, or borrowing constraints, or the need to place people in a queue. For instance, a governmental body may receive a budget outlay at the beginning of a year, and it may need to decide how best to allocate resources within the year to individuals who arrive sequentially. In this and other examples involving inter-temporal trade-offs, previous work on devising optimal policy rules in a static context is either not applicable, or sub-optimal. Here we show how one can use offline observational data to estimate an optimal policy rule that maximizes expected welfare in this dynamic context. We allow the class of policy rules to be restricted for legal, ethical or incentive compatibility reasons. The problem is equivalent to one of optimal control under a constrained policy class, and we exploit recent developments in Reinforcement Learning (RL) to propose an algorithm to solve this. The algorithm is easily implementable with speedups achieved through multiple RL agents learning in parallel processes. We also characterize the statistical regret from using our estimated policy rule by casting the evolution of the value function under each policy in a Partial Differential Equation (PDE) form and using the theory of viscosity solutions to PDEs. We find that the policy regret decays at a $n^{-1/2}$ rate in most examples; this is the same rate as in the static case.",
    "lastUpdated": "2020-08-31T03:30:30Z",
    "categories": [
      "econ.EM",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1904.01047v3"
  },
  {
    "title": "Learning Analytics Made in France: The METALproject",
    "authors": [
      "Armelle Brun",
      "Geoffray Bonnin",
      "Sylvain Castagnos",
      "Azim Roussanaly",
      "Anne Boyer"
    ],
    "abstract": "This paper presents the METAL project, an ongoing French open Learning Analytics (LA) project for secondary school, that aims at improving the quality of the learning process. The originality of METAL is that it relies on research through exploratory activities and focuses on all the aspects of a Learning Analytics implementation. This large-scale project includes many concerns, divided into 4 main actions. (1) data management: multi-source data identification, collection and storage, selection and promotion of standards, and design and development of an open-source Learning Record Store (LRS); (2) data visualization: learner and teacher dashboards, with a design that relies on the co-conception with final users, including trust and usability concerns; (3) data exploitation: study of the link between gaze and memory of learners, design of explainable multi-source data-mining algorithms, including ethics and privacy concerns. An additional key of originality lies in the global dissemination of LA at an institution level or at a broader level such as a territory, at the opposite on many projects that focus on a specific school or a school curriculum. Each of these aspects is a hot topic in the literature. Taking into account all of them in a holistic view of education is an additional added value of the project.",
    "lastUpdated": "2019-04-04T13:07:42Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1904.02528v1"
  },
  {
    "title": "HARK Side of Deep Learning -- From Grad Student Descent to Automated Machine Learning",
    "authors": [
      "Oguzhan Gencoglu",
      "Mark van Gils",
      "Esin Guldogan",
      "Chamin Morikawa",
      "Mehmet Süzen",
      "Mathias Gruber",
      "Jussi Leinonen",
      "Heikki Huttunen"
    ],
    "abstract": "Recent advancements in machine learning research, i.e., deep learning, introduced methods that excel conventional algorithms as well as humans in several complex tasks, ranging from detection of objects in images and speech recognition to playing difficult strategic games. However, the current methodology of machine learning research and consequently, implementations of the real-world applications of such algorithms, seems to have a recurring HARKing (Hypothesizing After the Results are Known) issue. In this work, we elaborate on the algorithmic, economic and social reasons and consequences of this phenomenon. We present examples from current common practices of conducting machine learning research (e.g. avoidance of reporting negative results) and failure of generalization ability of the proposed algorithms and datasets in actual real-life usage. Furthermore, a potential future trajectory of machine learning research and development from the perspective of accountable, unbiased, ethical and privacy-aware algorithmic decision making is discussed. We would like to emphasize that with this discussion we neither claim to provide an exhaustive argumentation nor blame any specific institution or individual on the raised issues. This is simply a discussion put forth by us, insiders of the machine learning field, reflecting on us.",
    "lastUpdated": "2019-04-16T13:02:01Z",
    "categories": [
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1904.07633v1"
  },
  {
    "title": "Erasing Data from Blockchain Nodes",
    "authors": [
      "Martin Florian",
      "Sophie Beaucamp",
      "Sebastian Henningsen",
      "Björn Scheuermann"
    ],
    "abstract": "It is a common narrative that blockchains are immutable and so it is technically impossible to erase data stored on them. For legal and ethical reasons, however, individuals and organizations might be compelled to erase locally stored data, be it encoded on a blockchain or not. The common assumption for blockchain networks like Bitcoin is that forcing nodes to erase data contained on the blockchain is equal to permanently restricting them from participating in the system in a full-node role. Challenging this belief, in this paper, we propose and demonstrate a pragmatic approach towards functionality-preserving local erasure (FPLE). FPLE enables full nodes to erase infringing or undesirable data while continuing to store and validate most of the blockchain. We describe a general FPLE approach for UTXO-based (i.e., Bitcoin-like) cryptocurrencies and present a lightweight proof-of-concept tool for safely erasing transaction data from the local storage of Bitcoin Core nodes. Erasing nodes continue to operate in tune with the network even when erased transaction outputs become relevant for validating subsequent blocks. Using only our basic proof-of-concept implementation, we are already able to safely comply with a significantly larger range of erasure requests than, to the best of our knowledge, any other full node operator so far.",
    "lastUpdated": "2019-04-18T17:24:50Z",
    "categories": [
      "cs.CR",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1904.08901v1"
  },
  {
    "title": "The role of artificial intelligence in achieving the Sustainable Development Goals",
    "authors": [
      "Ricardo Vinuesa",
      "Hossein Azizpour",
      "Iolanda Leite",
      "Madeline Balaam",
      "Virginia Dignum",
      "Sami Domisch",
      "Anna Felländer",
      "Simone Langhans",
      "Max Tegmark",
      "Francesco Fuso Nerini"
    ],
    "abstract": "The emergence of artificial intelligence (AI) and its progressively wider impact on many sectors across the society requires an assessment of its effect on sustainable development. Here we analyze published evidence of positive or negative impacts of AI on the achievement of each of the 17 goals and 169 targets of the 2030 Agenda for Sustainable Development. We find that AI can support the achievement of 128 targets across all SDGs, but it may also inhibit 58 targets. Notably, AI enables new technologies that improve efficiency and productivity, but it may also lead to increased inequalities among and within countries, thus hindering the achievement of the 2030 Agenda. The fast development of AI needs to be supported by appropriate policy and regulation. Otherwise, it would lead to gaps in transparency, accountability, safety and ethical standards of AI-based technology, which could be detrimental towards the development and sustainable use of AI. Finally, there is a lack of research assessing the medium- and long-term impacts of AI. It is therefore essential to reinforce the global debate regarding the use of AI and to develop the necessary regulatory insight and oversight for AI-based technologies.",
    "lastUpdated": "2019-04-30T08:43:50Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1905.00501v1"
  },
  {
    "title": "Auditing ImageNet: Towards a Model-driven Framework for Annotating Demographic Attributes of Large-Scale Image Datasets",
    "authors": [
      "Chris Dulhanty",
      "Alexander Wong"
    ],
    "abstract": "The ImageNet dataset ushered in a flood of academic and industry interest in deep learning for computer vision applications. Despite its significant impact, there has not been a comprehensive investigation into the demographic attributes of images contained within the dataset. Such a study could lead to new insights on inherent biases within ImageNet, particularly important given it is frequently used to pretrain models for a wide variety of computer vision tasks. In this work, we introduce a model-driven framework for the automatic annotation of apparent age and gender attributes in large-scale image datasets. Using this framework, we conduct the first demographic audit of the 2012 ImageNet Large Scale Visual Recognition Challenge (ILSVRC) subset of ImageNet and the \"person\" hierarchical category of ImageNet. We find that 41.62% of faces in ILSVRC appear as female, 1.71% appear as individuals above the age of 60, and males aged 15 to 29 account for the largest subgroup with 27.11%. We note that the presented model-driven framework is not fair for all intersectional groups, so annotation are subject to bias. We present this work as the starting point for future development of unbiased annotation models and for the study of downstream effects of imbalances in the demographics of ImageNet. Code and annotations are available at: http://bit.ly/ImageNetDemoAudit",
    "lastUpdated": "2019-06-04T18:32:34Z",
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1905.01347v2"
  },
  {
    "title": "The tradeoff between the utility and risk of location data and implications for public good",
    "authors": [
      "Dan Calacci",
      "Alex Berke",
      "Kent Larson",
      "Alex",
      "Pentland"
    ],
    "abstract": "High-resolution individual geolocation data passively collected from mobile phones is increasingly sold in private markets and shared with researchers. This data poses significant security, privacy, and ethical risks: it's been shown that users can be re-identified in such datasets, and its collection rarely involves their full consent or knowledge. This data is valuable to private firms (e.g. targeted marketing) but also presents clear value as a public good. Recent public interest research has demonstrated that high-resolution location data can more accurately measure segregation in cities and provide inexpensive transit modeling. But as data is aggregated to mitigate its re-identifiability risk, its value as a good diminishes. How do we rectify the clear security and safety risks of this data, its high market value, and its potential as a resource for public good? We extend the recently proposed concept of a tradeoff curve that illustrates the relationship between dataset utility and privacy. We then hypothesize how this tradeoff differs between private market use and its potential use for public good. We further provide real-world examples of how high resolution location data, aggregated to varying degrees of privacy protection, can be used in the public sphere and how it is currently used by private firms.",
    "lastUpdated": "2019-12-09T19:21:32Z",
    "categories": [
      "cs.CY",
      "cs.IT",
      "math.IT"
    ],
    "url": "http://arxiv.org/abs/1905.09350v2"
  },
  {
    "title": "On Measuring Gender Bias in Translation of Gender-neutral Pronouns",
    "authors": [
      "Won Ik Cho",
      "Ji Won Kim",
      "Seok Min Kim",
      "Nam Soo Kim"
    ],
    "abstract": "Ethics regarding social bias has recently thrown striking issues in natural language processing. Especially for gender-related topics, the need for a system that reduces the model bias has grown in areas such as image captioning, content recommendation, and automated employment. However, detection and evaluation of gender bias in the machine translation systems are not yet thoroughly investigated, for the task being cross-lingual and challenging to define. In this paper, we propose a scheme for making up a test set that evaluates the gender bias in a machine translation system, with Korean, a language with gender-neutral pronouns. Three word/phrase sets are primarily constructed, each incorporating positive/negative expressions or occupations; all the terms are gender-independent or at least not biased to one side severely. Then, additional sentence lists are constructed concerning formality of the pronouns and politeness of the sentences. With the generated sentence set of size 4,236 in total, we evaluate gender bias in conventional machine translation systems utilizing the proposed measure, which is termed here as translation gender bias index (TGBI). The corpus and the code for evaluation is available on-line.",
    "lastUpdated": "2019-05-28T08:46:56Z",
    "categories": [
      "cs.CL"
    ],
    "url": "http://arxiv.org/abs/1905.11684v1"
  },
  {
    "title": "Defending Against Neural Fake News",
    "authors": [
      "Rowan Zellers",
      "Ari Holtzman",
      "Hannah Rashkin",
      "Yonatan Bisk",
      "Ali Farhadi",
      "Franziska Roesner",
      "Yejin Choi"
    ],
    "abstract": "Recent progress in natural language generation has raised dual-use concerns. While applications like summarization and translation are positive, the underlying technology also might enable adversaries to generate neural fake news: targeted propaganda that closely mimics the style of real news. Modern computer security relies on careful threat modeling: identifying potential threats and vulnerabilities from an adversary's point of view, and exploring potential mitigations to these threats. Likewise, developing robust defenses against neural fake news requires us first to carefully investigate and characterize the risks of these models. We thus present a model for controllable text generation called Grover. Given a headline like `Link Found Between Vaccines and Autism,' Grover can generate the rest of the article; humans find these generations to be more trustworthy than human-written disinformation. Developing robust verification techniques against generators like Grover is critical. We find that best current discriminators can classify neural fake news from real, human-written, news with 73% accuracy, assuming access to a moderate level of training data. Counterintuitively, the best defense against Grover turns out to be Grover itself, with 92% accuracy, demonstrating the importance of public release of strong generators. We investigate these results further, showing that exposure bias -- and sampling strategies that alleviate its effects -- both leave artifacts that similar discriminators can pick up on. We conclude by discussing ethical issues regarding the technology, and plan to release Grover publicly, helping pave the way for better detection of neural fake news.",
    "lastUpdated": "2020-12-11T16:17:17Z",
    "categories": [
      "cs.CL",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1905.12616v3"
  },
  {
    "title": "FairSearch: A Tool For Fairness in Ranked Search Results",
    "authors": [
      "Meike Zehlike",
      "Tom Sühr",
      "Carlos Castillo",
      "Ivan Kitanovski"
    ],
    "abstract": "Ranked search results and recommendations have become the main mechanism by which we find content, products, places, and people online. With hiring, selecting, purchasing, and dating being increasingly mediated by algorithms, rankings may determine career and business opportunities, educational placement, access to benefits, and even social and reproductive success. It is therefore of societal and ethical importance to ask whether search results can demote, marginalize, or exclude individuals of unprivileged groups or promote products with undesired features. In this paper we present FairSearch, the first fair open source search API to provide fairness notions in ranked search results. We implement two algorithms from the fair ranking literature, namely FA*IR (Zehlike et al., 2017) and DELTR (Zehlike and Castillo, 2018) and provide them as stand-alone libraries in Python and Java. Additionally we implement interfaces to Elasticsearch for both algorithms, that use the aforementioned Java libraries and are then provided as Elasticsearch plugins. Elasticsearch is a well-known search engine API based on Apache Lucene. With our plugins we enable search engine developers who wish to ensure fair search results of different styles to easily integrate DELTR and FA*IR into their existing Elasticsearch environment.",
    "lastUpdated": "2020-04-23T08:52:55Z",
    "categories": [
      "cs.IR",
      "H.3.3"
    ],
    "url": "http://arxiv.org/abs/1905.13134v2"
  },
  {
    "title": "Artificial Intelligence and Big Data in Entrepreneurship: A New Era Has Begun",
    "authors": [
      "Martin Obschonka",
      "David B. Audretsch"
    ],
    "abstract": "While the disruptive potential of artificial intelligence (AI) and Big Data has been receiving growing attention and concern in a variety of research and application fields over the last few years, it has not received much scrutiny in contemporary entrepreneurship research so far. Here we present some reflections and a collection of papers on the role of AI and Big Data for this emerging area in the study and application of entrepreneurship research. While being mindful of the potentially overwhelming nature of the rapid progress in machine intelligence and other Big Data technologies for contemporary structures in entrepreneurship research, we put an emphasis on the reciprocity of the co-evolving fields of entrepreneurship research and practice. How can AI and Big Data contribute to a productive transformation of the research field and the real-world phenomena (e.g., 'smart entrepreneurship')? We also discuss, however, ethical issues as well as challenges around a potential contradiction between entrepreneurial uncertainty and rule-driven AI rationality. The editorial gives researchers and practitioners orientation and showcases avenues and examples for concrete research in this field. At the same time, however, it is not unlikely that we will encounter unforeseeable and currently inexplicable developments in the field soon. We call on entrepreneurship scholars, educators, and practitioners to proactively prepare for future scenarios.",
    "lastUpdated": "2019-06-03T03:52:47Z",
    "categories": [
      "econ.GN",
      "q-fin.EC"
    ],
    "url": "http://arxiv.org/abs/1906.00553v1"
  },
  {
    "title": "Analyzing the Role of Model Uncertainty for Electronic Health Records",
    "authors": [
      "Michael W. Dusenberry",
      "Dustin Tran",
      "Edward Choi",
      "Jonas Kemp",
      "Jeremy Nixon",
      "Ghassen Jerfel",
      "Katherine Heller",
      "Andrew M. Dai"
    ],
    "abstract": "In medicine, both ethical and monetary costs of incorrect predictions can be significant, and the complexity of the problems often necessitates increasingly complex models. Recent work has shown that changing just the random seed is enough for otherwise well-tuned deep neural networks to vary in their individual predicted probabilities. In light of this, we investigate the role of model uncertainty methods in the medical domain. Using RNN ensembles and various Bayesian RNNs, we show that population-level metrics, such as AUC-PR, AUC-ROC, log-likelihood, and calibration error, do not capture model uncertainty. Meanwhile, the presence of significant variability in patient-specific predictions and optimal decisions motivates the need for capturing model uncertainty. Understanding the uncertainty for individual patients is an area with clear clinical impact, such as determining when a model decision is likely to be brittle. We further show that RNNs with only Bayesian embeddings can be a more efficient way to capture model uncertainty compared to ensembles, and we analyze how model uncertainty is impacted across individual input features and patient subgroups.",
    "lastUpdated": "2020-03-25T22:38:20Z",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1906.03842v3"
  },
  {
    "title": "Persuasion for Good: Towards a Personalized Persuasive Dialogue System for Social Good",
    "authors": [
      "Xuewei Wang",
      "Weiyan Shi",
      "Richard Kim",
      "Yoojung Oh",
      "Sijia Yang",
      "Jingwen Zhang",
      "Zhou Yu"
    ],
    "abstract": "Developing intelligent persuasive conversational agents to change people's opinions and actions for social good is the frontier in advancing the ethical development of automated dialogue systems. To do so, the first step is to understand the intricate organization of strategic disclosures and appeals employed in human persuasion conversations. We designed an online persuasion task where one participant was asked to persuade the other to donate to a specific charity. We collected a large dataset with 1,017 dialogues and annotated emerging persuasion strategies from a subset. Based on the annotation, we built a baseline classifier with context information and sentence-level features to predict the 10 persuasion strategies used in the corpus. Furthermore, to develop an understanding of personalized persuasion processes, we analyzed the relationships between individuals' demographic and psychological backgrounds including personality, morality, value systems, and their willingness for donation. Then, we analyzed which types of persuasion strategies led to a greater amount of donation depending on the individuals' personal backgrounds. This work lays the ground for developing a personalized persuasive dialogue system.",
    "lastUpdated": "2020-01-13T04:17:44Z",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1906.06725v2"
  },
  {
    "title": "Adversarial training approach for local data debiasing",
    "authors": [
      "Ulrich Aïvodji",
      "François Bidet",
      "Sébastien Gambs",
      "Rosin Claude Ngueveu",
      "Alain Tapp"
    ],
    "abstract": "The widespread use of automated decision processes in many areas of our society raises serious ethical issues concerning the fairness of the process and the possible resulting discriminations. In this work, we propose a novel approach called GANsan whose objective is to prevent the possibility of any discrimination i.e., direct and indirect) based on a sensitive attribute by removing the attribute itself as well as the existing correlations with the remaining attributes. Our sanitization algorithm GANsan is partially inspired by the powerful framework of generative adversarial networks (in particular the Cycle-GANs), which offers a flexible way to learn a distribution empirically or to translate between two different distributions. In contrast to prior work, one of the strengths of our approach is that the sanitization is performed in the same space as the original data by only modifying the other attributes as little as possible and thus preserving the interpretability of the sanitized data. As a consequence, once the sanitizer is trained, it can be applied to new data, such as for instance, locally by an individual on his profile before releasing it. Finally, experiments on a real dataset demonstrate the effectiveness of the proposed approach as well as the achievable trade-off between fairness and utility.",
    "lastUpdated": "2020-09-03T17:54:53Z",
    "categories": [
      "cs.LG",
      "cs.CR",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1906.07858v3"
  },
  {
    "title": "Considerations for the Interpretation of Bias Measures of Word Embeddings",
    "authors": [
      "Inom Mirzaev",
      "Anthony Schulte",
      "Michael Conover",
      "Sam Shah"
    ],
    "abstract": "Word embedding spaces are powerful tools for capturing latent semantic relationships between terms in corpora, and have become widely popular for building state-of-the-art natural language processing algorithms. However, studies have shown that societal biases present in text corpora may be incorporated into the word embedding spaces learned from them. Thus, there is an ethical concern that human-like biases contained in the corpora and their derived embedding spaces might be propagated, or even amplified with the usage of the biased embedding spaces in downstream applications. In an attempt to quantify these biases so that they may be better understood and studied, several bias metrics have been proposed. We explore the statistical properties of these proposed measures in the context of their cited applications as well as their supposed utilities. We find that there are caveats to the simple interpretation of these metrics as proposed. We find that the bias metric proposed by Bolukbasi et al. 2016 is highly sensitive to embedding hyper-parameter selection, and that in many cases, the variance due to the selection of some hyper-parameters is greater than the variance in the metric due to corpus selection, while in fewer cases the bias rankings of corpora vary with hyper-parameter selection. In light of these observations, it may be the case that bias estimates should not be thought to directly measure the properties of the underlying corpus, but rather the properties of the specific embedding spaces in question, particularly in the context of hyper-parameter selections used to generate them. Hence, bias metrics of spaces generated with differing hyper-parameters should be compared only with explicit consideration of the embedding-learning algorithms particular configurations.",
    "lastUpdated": "2019-06-19T21:56:25Z",
    "categories": [
      "cs.CL"
    ],
    "url": "http://arxiv.org/abs/1906.08379v1"
  },
  {
    "title": "Re-annotation of cough events in the AMI corpus",
    "authors": [
      "Paul Leamy",
      "Ted Burke",
      "Damon Berry",
      "David Dorran"
    ],
    "abstract": "Cough sounds act as an important indicator of an individual's physical health, often used by medical professionals in diagnosing a patient's ailments. In recent years progress has been made in the area of automatically detecting cough events and, in certain cases, automatically identifying the ailment associated with a particular cough sound. Ethical and sensitivity issues associated with audio recordings of coughs makes it more difficult for this data to be made publicly available. However, without the public availability of a reliable database of cough sounds, developments in the area of audio event detection are likely to be hampered. The purpose of this paper is to spread awareness of a database containing a large amount of naturally occurring cough sounds that can be used for the implementation, evaluation, and comparison of new machine learning algorithms that allow for audio event detection associated with cough sounds. Using a purpose built GUI designed in MATLAB, the re-annotation procedure followed a reusable methodology that allowed for quick and efficient importing and marking of audio signals, resulting in a re-annotated version of the Augmented Multi-party Interaction (AMI) corpus' cough location annotations, with 1369 individual cough events. All cough annotations and the re-annotation tool are made available for download and public use.",
    "lastUpdated": "2019-06-27T09:05:10Z",
    "categories": [
      "eess.AS",
      "eess.SP"
    ],
    "url": "http://arxiv.org/abs/1906.11509v1"
  },
  {
    "title": "P-hacking in clinical trials and how incentives shape the distribution of results across phases",
    "authors": [
      "Jérôme Adda",
      "Christian Decker",
      "Marco Ottaviani"
    ],
    "abstract": "Clinical research should conform to high standards of ethical and scientific integrity, given that human lives are at stake. However, economic incentives can generate conflicts of interest for investigators, who may be inclined to withhold unfavorable results or even tamper with data in order to achieve desired outcomes. To shed light on the integrity of clinical trial results, this paper systematically analyzes the distribution of p-values of primary outcomes for phase II and phase III drug trials reported to the ClinicalTrials.gov registry. First, we detect no bunching of results just above the classical 5% threshold for statistical significance. Second, a density discontinuity test reveals an upward jump at the 5% threshold for phase III results by small industry sponsors. Third, we document a larger fraction of significant results in phase III compared to phase II. Linking trials across phases, we find that early favorable results increase the likelihood of continuing into the next phase. Once we take into account this selective continuation, we can explain almost completely the excess of significant results in phase III for trials conducted by large industry sponsors. For small industry sponsors, instead, part of the excess remains unexplained.",
    "lastUpdated": "2020-03-19T23:51:24Z",
    "categories": [
      "econ.GN",
      "q-fin.EC"
    ],
    "url": "http://arxiv.org/abs/1907.00185v3"
  },
  {
    "title": "The Sensitivity of Counterfactual Fairness to Unmeasured Confounding",
    "authors": [
      "Niki Kilbertus",
      "Philip J. Ball",
      "Matt J. Kusner",
      "Adrian Weller",
      "Ricardo Silva"
    ],
    "abstract": "Causal approaches to fairness have seen substantial recent interest, both from the machine learning community and from wider parties interested in ethical prediction algorithms. In no small part, this has been due to the fact that causal models allow one to simultaneously leverage data and expert knowledge to remove discriminatory effects from predictions. However, one of the primary assumptions in causal modeling is that you know the causal graph. This introduces a new opportunity for bias, caused by misspecifying the causal model. One common way for misspecification to occur is via unmeasured confounding: the true causal effect between variables is partially described by unobserved quantities. In this work we design tools to assess the sensitivity of fairness measures to this confounding for the popular class of non-linear additive noise models (ANMs). Specifically, we give a procedure for computing the maximum difference between two counterfactually fair predictors, where one has become biased due to confounding. For the case of bivariate confounding our technique can be swiftly computed via a sequence of closed-form updates. For multivariate confounding we give an algorithm that can be efficiently solved via automatic differentiation. We demonstrate our new sensitivity analysis tools in real-world fairness scenarios to assess the bias arising from confounding.",
    "lastUpdated": "2019-07-01T19:47:40Z",
    "categories": [
      "cs.LG",
      "cs.CY",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1907.01040v1"
  },
  {
    "title": "Norms for Beneficial A.I.: A Computational Analysis of the Societal Value Alignment Problem",
    "authors": [
      "Pedro Fernandes",
      "Francisco C. Santos",
      "Manuel Lopes"
    ],
    "abstract": "The rise of artificial intelligence (A.I.) based systems is already offering substantial benefits to the society as a whole. However, these systems may also enclose potential conflicts and unintended consequences. Notably, people will tend to adopt an A.I. system if it confers them an advantage, at which point non-adopters might push for a strong regulation if that advantage for adopters is at a cost for them. Here we propose an agent-based game-theoretical model for these conflicts, where agents may decide to resort to A.I. to use and acquire additional information on the payoffs of a stochastic game, striving to bring insights from simulation to what has been, hitherto, a mostly philosophical discussion. We frame our results under the current discussion on ethical A.I. and the conflict between individual and societal gains: the societal value alignment problem. We test the arising equilibria in the adoption of A.I. technology under different norms followed by artificial agents, their ensuing benefits, and the emergent levels of wealth inequality. We show that without any regulation, purely selfish A.I. systems will have the strongest advantage, even when a utilitarian A.I. provides significant benefits for the individual and the society. Nevertheless, we show that it is possible to develop A.I. systems following human conscious policies that, when introduced in society, lead to an equilibrium where the gains for the adopters are not at a cost for non-adopters, thus increasing the overall wealth of the population and lowering inequality. However, as shown, a self-organised adoption of such policies would require external regulation.",
    "lastUpdated": "2020-12-22T18:11:35Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1907.03843v2"
  },
  {
    "title": "Dataset Growth in Medical Image Analysis Research",
    "authors": [
      "Yuval Landau",
      "Nahum Kiryati"
    ],
    "abstract": "Medical image analysis studies usually require medical image datasets for training, testing and validation of algorithms. The need is underscored by the deep learning revolution and the dominance of machine learning in recent medical image analysis research. Nevertheless, due to ethical and legal constraints, commercial conflicts and the dependence on busy medical professionals, medical image analysis researchers have been described as \"data starved\". Due to the lack of objective criteria for sufficiency of dataset size, the research community implicitly sets ad-hoc standards by means of the peer review process. We hypothesize that peer review requires researchers to report the use of ever-increasing datasets as one condition for acceptance of their work to reputable publication venues. To test this hypothesis, we scanned the proceedings of the eminent MICCAI (Medical Image Computing and Computer-Assisted Intervention) conferences from 2011 to 2018. From a total of 2136 articles, we focused on 907 papers involving human datasets of MRI (Magnetic Resonance Imaging), CT (Computed Tomography) and fMRI (functional MRI) images. For each modality, for each of the years 2011-2018 we calculated the average, geometric mean and median number of human subjects used in that year's MICCAI articles. The results corroborate the dataset growth hypothesis. Specifically, the annual median dataset size in MICCAI articles has grown roughly 3-10 times from 2011 to 2018, depending on the imaging modality. Statistical analysis further supports the dataset growth hypothesis and reveals exponential growth of the geometric mean dataset size, with annual growth of about 21% for MRI, 24% for CT and 31% for fMRI. In slight analogy to Moore's law, the results can provide guidance about trends in the expectations of the medical image analysis community regarding dataset size.",
    "lastUpdated": "2019-08-21T09:34:29Z",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1908.07765v1"
  },
  {
    "title": "On the top-dimensional $\\ell^2$-Betti numbers",
    "authors": [
      "Damien Gaboriau",
      "Camille Noûs"
    ],
    "abstract": "The purpose of this note is to introduce a trick which relates the (non)-vanishing of the top-dimensional $\\ell$ 2-Betti numbers of actions with that of sub-actions. We provide three different types of applications: we prove that the $\\ell$ 2-Betti numbers of Aut($F_n$) and Out($F_n$) (and of their Torelli subgroups) do not vanish in degree equal to their virtual cohomological dimension, we prove that the subgroups of the 3-manifold groups have vanishing $\\ell$ 2-Betti numbers in degree 3 and 2 and we prove for instance that $F_2^d \\times Z$ has ergodic dimension $d + 1$.",
    "lastUpdated": "2020-07-21T07:14:28Z",
    "categories": [
      "math.GR"
    ],
    "url": "http://arxiv.org/abs/1909.01633v3"
  },
  {
    "title": "Machine learning in healthcare -- a system's perspective",
    "authors": [
      "Awais Ashfaq",
      "Slawomir Nowaczyk"
    ],
    "abstract": "A consequence of the fragmented and siloed healthcare landscape is that patient care (and data) is split along multitude of different facilities and computer systems and enabling interoperability between these systems is hard. The lack interoperability not only hinders continuity of care and burdens providers, but also hinders effective application of Machine Learning (ML) algorithms. Thus, most current ML algorithms, designed to understand patient care and facilitate clinical decision-support, are trained on limited datasets. This approach is analogous to the Newtonian paradigm of Reductionism in which a system is broken down into elementary components and a description of the whole is formed by understanding those components individually. A key limitation of the reductionist approach is that it ignores the component-component interactions and dynamics within the system which are often of prime significance in understanding the overall behaviour of complex adaptive systems (CAS). Healthcare is a CAS. Though the application of ML on health data have shown incremental improvements for clinical decision support, ML has a much a broader potential to restructure care delivery as a whole and maximize care value. However, this ML potential remains largely untapped: primarily due to functional limitations of Electronic Health Records (EHR) and the inability to see the healthcare system as a whole. This viewpoint (i) articulates the healthcare as a complex system which has a biological and an organizational perspective, (ii) motivates with examples, the need of a system's approach when addressing healthcare challenges via ML and, (iii) emphasizes to unleash EHR functionality - while duly respecting all ethical and legal concerns - to reap full benefits of ML.",
    "lastUpdated": "2020-01-19T21:50:27Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1909.07370v2"
  },
  {
    "title": "FACE: Feasible and Actionable Counterfactual Explanations",
    "authors": [
      "Rafael Poyiadzi",
      "Kacper Sokol",
      "Raul Santos-Rodriguez",
      "Tijl De Bie",
      "Peter Flach"
    ],
    "abstract": "Work in Counterfactual Explanations tends to focus on the principle of \"the closest possible world\" that identifies small changes leading to the desired outcome. In this paper we argue that while this approach might initially seem intuitively appealing it exhibits shortcomings not addressed in the current literature. First, a counterfactual example generated by the state-of-the-art systems is not necessarily representative of the underlying data distribution, and may therefore prescribe unachievable goals(e.g., an unsuccessful life insurance applicant with severe disability may be advised to do more sports). Secondly, the counterfactuals may not be based on a \"feasible path\" between the current state of the subject and the suggested one, making actionable recourse infeasible (e.g., low-skilled unsuccessful mortgage applicants may be told to double their salary, which may be hard without first increasing their skill level). These two shortcomings may render counterfactual explanations impractical and sometimes outright offensive. To address these two major flaws, first of all, we propose a new line of Counterfactual Explanations research aimed at providing actionable and feasible paths to transform a selected instance into one that meets a certain goal. Secondly, we propose FACE: an algorithmically sound way of uncovering these \"feasible paths\" based on the shortest path distances defined via density-weighted metrics. Our approach generates counterfactuals that are coherent with the underlying data distribution and supported by the \"feasible paths\" of change, which are achievable and can be tailored to the problem at hand.",
    "lastUpdated": "2020-02-24T15:39:07Z",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1909.09369v2"
  },
  {
    "title": "Mathematical decisions and non-causal elements of explainable AI",
    "authors": [
      "Atoosa Kasirzadeh"
    ],
    "abstract": "The social implications of algorithmic decision-making in sensitive contexts have generated lively debates among multiple stakeholders, such as moral and political philosophers, computer scientists, and the public. Yet, the lack of a common language and a conceptual framework for an appropriate bridging of the moral, technical, and political aspects of the debate prevents the discussion to be as effective as it can be. Social scientists and psychologists are contributing to this debate by gathering a wealth of empirical data, yet a philosophical analysis of the social implications of algorithmic decision-making remains comparatively impoverished. In attempting to address this lacuna, this paper argues that a hierarchy of different types of explanations for why and how an algorithmic decision outcome is achieved can establish the relevant connection between the moral and technical aspects of algorithmic decision-making. In particular, I offer a multi-faceted conceptual framework for the explanations and the interpretations of algorithmic decisions, and I claim that this framework can lay the groundwork for a focused discussion among multiple stakeholders about the social implications of algorithmic decision-making, as well as AI governance and ethics more generally.",
    "lastUpdated": "2019-12-12T07:08:33Z",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.HC",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1910.13607v2"
  },
  {
    "title": "Fair Allocation through Selective Information Acquisition",
    "authors": [
      "William Cai",
      "Johann Gaebler",
      "Nikhil Garg",
      "Sharad Goel"
    ],
    "abstract": "Public and private institutions must often allocate scare resources under uncertainty. Banks, for example, extend credit to loan applicants based in part on their estimated likelihood of repaying a loan. But when the quality of information differs across candidates (e.g., if some applicants lack traditional credit histories), common lending strategies can lead to disparities across groups. Here we consider a setting in which decision makers -- before allocating resources -- can choose to spend some of their limited budget further screening select individuals. We present a computationally efficient algorithm for deciding whom to screen that maximizes a standard measure of social welfare. Intuitively, decision makers should screen candidates on the margin, for whom the additional information could plausibly alter the allocation. We formalize this idea by showing the problem can be reduced to solving a series of linear programs. Both on synthetic and real-world datasets, this strategy improves utility, illustrating the value of targeted information acquisition in such decisions. Further, when there is social value for distributing resources to groups for whom we have a priori poor information -- like those without credit scores -- our approach can substantially improve the allocation of limited assets.",
    "lastUpdated": "2020-09-30T03:05:05Z",
    "categories": [
      "cs.CY",
      "cs.GT"
    ],
    "url": "http://arxiv.org/abs/1911.02715v3"
  },
  {
    "title": "Kernel Dependence Regularizers and Gaussian Processes with Applications to Algorithmic Fairness",
    "authors": [
      "Zhu Li",
      "Adrian Perez-Suay",
      "Gustau Camps-Valls",
      "Dino Sejdinovic"
    ],
    "abstract": "Current adoption of machine learning in industrial, societal and economical activities has raised concerns about the fairness, equity and ethics of automated decisions. Predictive models are often developed using biased datasets and thus retain or even exacerbate biases in their decisions and recommendations. Removing the sensitive covariates, such as gender or race, is insufficient to remedy this issue since the biases may be retained due to other related covariates. We present a regularization approach to this problem that trades off predictive accuracy of the learned models (with respect to biased labels) for the fairness in terms of statistical parity, i.e. independence of the decisions from the sensitive covariates. In particular, we consider a general framework of regularized empirical risk minimization over reproducing kernel Hilbert spaces and impose an additional regularizer of dependence between predictors and sensitive covariates using kernel-based measures of dependence, namely the Hilbert-Schmidt Independence Criterion (HSIC) and its normalized version. This approach leads to a closed-form solution in the case of squared loss, i.e. ridge regression. Moreover, we show that the dependence regularizer has an interpretation as modifying the corresponding Gaussian process (GP) prior. As a consequence, a GP model with a prior that encourages fairness to sensitive variables can be derived, allowing principled hyperparameter selection and studying of the relative relevance of covariates under fairness constraints. Experimental results in synthetic examples and in real problems of income and crime prediction illustrate the potential of the approach to improve fairness of automated decisions.",
    "lastUpdated": "2019-11-11T15:09:32Z",
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1911.04322v1"
  },
  {
    "title": "A Biologically Plausible Benchmark for Contextual Bandit Algorithms in Precision Oncology Using in vitro Data",
    "authors": [
      "Niklas T. Rindtorff",
      "MingYu Lu",
      "Nisarg A. Patel",
      "Huahua Zheng",
      "Alexander D'Amour"
    ],
    "abstract": "Precision oncology, the genetic sequencing of tumors to identify druggable targets, has emerged as the standard of care in the treatment of many cancers. Nonetheless, due to the pace of therapy development and variability in patient information, designing effective protocols for individual treatment assignment in a sample-efficient way remains a major challenge. One promising approach to this problem is to frame precision oncology treatment as a contextual bandit problem and to apply sequential decision-making algorithms designed to minimize regret in this setting. However, a clear prerequisite for considering this methodology in high-stakes clinical decisions is careful benchmarking to understand realistic costs and benefits. Here, we propose a benchmark dataset to evaluate contextual bandit algorithms based on real in vitro drug response of approximately 900 cancer cell lines. Specifically, we curated a dataset of complete treatment responses for a subset of 7 treatments from prior in vitro studies. This allows us to compute the regret of proposed decision policies using biologically plausible counterfactuals. We ran a suite of Bayesian bandit algorithms on our benchmark, and found that the methods accumulate less regret over a sequence of treatment assignment tasks than a rule-based baseline derived from current clinical practice. This effect was more pronounced when genomic information was included as context. We expect this work to be a starting point for evaluation of both the unique structural requirements and ethical implications for real-world testing of bandit based clinical decision support.",
    "lastUpdated": "2019-11-11T16:59:11Z",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1911.04389v1"
  },
  {
    "title": "On the Side Effects of Automation in IoT: Complacency and Comfort vs. Relapse and Distrust",
    "authors": [
      "D. Casado-Mansilla",
      "P. Garaizar",
      "A. Irizar-Arrieta",
      "D. López-de-Ipiña"
    ],
    "abstract": "Automation through IoT brings with it a whole new set of philosophical and ethical implications that we barely began to address. However, it is widely considered by many scholars as the panacea to overcoming the majority of societal issues. The case of energy efficiency as an action for tackling climate change is not different: demand-response proposals or occupancy-driven energy management systems crowd the current research agenda on energy efficiency. However, there are still very few studies that have reported the effects of automation in the mid or long term beyond energy reduction (e.g. emotional feelings derived to interact with automation, complacency to the devices or perceived value of the automation throughout the time). In this workshop article, we report scientific evidence of a study conducted in ten workplaces during more than one year where we found that automating some electronic devices of common use (i.e. moving away or preventing subjects from the control of these devices) in favour of comfort and energy efficiency, is associated with a reduction of the users' confidence in science and technology as a mean to solve all environmental current problems and reduce the willingness of people to act in favor of the environment.",
    "lastUpdated": "2019-06-18T13:12:00Z",
    "categories": [
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/1911.08657v1"
  },
  {
    "title": "FairPrep: Promoting Data to a First-Class Citizen in Studies on Fairness-Enhancing Interventions",
    "authors": [
      "Sebastian Schelter",
      "Yuxuan He",
      "Jatin Khilnani",
      "Julia Stoyanovich"
    ],
    "abstract": "The importance of incorporating ethics and legal compliance into machine-assisted decision-making is broadly recognized. Further, several lines of recent work have argued that critical opportunities for improving data quality and representativeness, controlling for bias, and allowing humans to oversee and impact computational processes are missed if we do not consider the lifecycle stages upstream from model training and deployment. Yet, very little has been done to date to provide system-level support to data scientists who wish to develop and deploy responsible machine learning methods. We aim to fill this gap and present FairPrep, a design and evaluation framework for fairness-enhancing interventions. FairPrep is based on a developer-centered design, and helps data scientists follow best practices in software engineering and machine learning. As part of our contribution, we identify shortcomings in existing empirical studies for analyzing fairness-enhancing interventions. We then show how FairPrep can be used to measure the impact of sound best practices, such as hyperparameter tuning and feature scaling. In particular, our results suggest that the high variability of the outcomes of fairness-enhancing interventions observed in previous studies is often an artifact of a lack of hyperparameter tuning. Further, we show that the choice of a data cleaning method can impact the effectiveness of fairness-enhancing interventions.",
    "lastUpdated": "2019-11-28T08:28:46Z",
    "categories": [
      "cs.LG",
      "cs.CY",
      "cs.DB",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1911.12587v1"
  },
  {
    "title": "Online information of vaccines: information quality is an ethical responsibility of search engines",
    "authors": [
      "Pietro Ghezzi",
      "Peter G Bannister",
      "Gonzalo Casino",
      "Alessia Catalani",
      "Michel Goldman",
      "Jessica Morley",
      "Marie Neunez",
      "Andreu Prados",
      "Mariarosaria Taddeo",
      "Tania Vanzolini",
      "Luciano Floridi"
    ],
    "abstract": "The fact that internet companies may record our personal data and track our online behavior for commercial or political purpose has emphasized aspects related to online privacy. This has also led to the development of search engines that promise no tracking and privacy. Search engines also have a major role in spreading low-quality health information such as that of anti-vaccine websites. This study investigates the relationship between search engines' approach to privacy and the scientific quality of the information they return. We analyzed the first 30 webpages returned searching 'vaccines autism' in English, Spanish, Italian and French. The results show that alternative search engines (Duckduckgo, Ecosia, Qwant, Swisscows and Mojeek) may return more anti-vaccine pages (10 to 53 percent) than Google.com (zero). Some localized versions of Google, however, returned more anti-vaccine webpages (up to 10 percent) than Google.com. Our study suggests that designing a search engine that is privacy savvy and avoids issues with filter bubbles that can result from user tracking is necessary but insufficient; instead, mechanisms should be developed to test search engines from the perspective of information quality (particularly for health-related webpages), before they can be deemed trustworthy providers of public health information.",
    "lastUpdated": "2019-12-02T16:24:40Z",
    "categories": [
      "cs.SI",
      "cs.IR"
    ],
    "url": "http://arxiv.org/abs/1912.00898v1"
  },
  {
    "title": "When Autonomous Intelligent Goodware will Fight Autonomous Intelligent Malware: A Possible Future of Cyber Defense",
    "authors": [
      "Paul Théron",
      "Alexander Kott"
    ],
    "abstract": "In the coming years, the future of military combat will include, on one hand, artificial intelligence-optimized complex command, control, communications, computers, intelligence, surveillance and reconnaissance (C4ISR) and networks and, on the other hand, autonomous intelligent Things fighting autonomous intelligent Things at a fast pace. Under this perspective, enemy forces will seek to disable or disturb our autonomous Things and our complex infrastructures and systems. Autonomy, scale and complexity in our defense systems will trigger new cyber-attack strategies, and autonomous intelligent malware (AIM) will be part of the picture. Should these cyber-attacks succeed while human operators remain unaware or unable to react fast enough due to the speed, scale or complexity of the mission, systems or attacks, missions would fail, our networks and C4ISR would be heavily disrupted, and command and control would be disabled. New cyber-defense doctrines and technologies are therefore required. Autonomous cyber defense (ACyD) is a new field of research and technology driven by the defense sector in anticipation of such threats to future military infrastructures, systems and operations. It will be implemented via swarms of autonomous intelligent cyber-defense agents (AICAs) that will fight AIM within our networks and systems. This paper presents this cyber-defense technology of the future, the current state of the art in this field and its main challenges. First, we review the rationale of the ACyD concept and its associated AICA technology. Then, we present the current research results from NATO's IST-152 Research Task Group on the AICA Reference Architecture. We then develop the 12 main technological challenges that must be resolved in the coming years, besides ethical and political issues.",
    "lastUpdated": "2019-11-25T20:36:48Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1912.01959v1"
  },
  {
    "title": "Monotone Submodular Diversity functions for Categorical Vectors with Application to Diversification of Seeds for Targeted Influence Maximization",
    "authors": [
      "Antonio Caliò",
      "Andrea Tagarelli"
    ],
    "abstract": "Embedding diversity into knowledge discovery tasks is of crucial importance to enhance the meaningfulness of the mined patterns with high-impact aspects related to novelty, serendipity, and ethics. Surprisingly, in the classic problem of influence maximization in social networks, relatively little study has been devoted to diversity and its integration into the objective function of an influence maximization method. In this work, we propose the integration of a side-information-based notion of seed diversity into the objective function of a targeted influence maximization problem. Starting from the assumption that side-information is available at node level in the general form of categorical attribute values, we design a class of monotone submodular functions specifically conceived for determining the diversity within a set of categorical profiles associated with the seeds to be discovered. This allows us to develop an efficient scalable approximate method, with a constant-factor guarantee of optimality. More precisely, we formulate the attribute-based diversity-sensitive targeted influence maximization problem under the state-of-the-art reverse influence sampling framework, and we develop a method, dubbed ADITUM, that ensures a (1-1/e-\\epsilon)-approximate solution under the general triggering diffusion model. We experimentally evaluated ADITUM on five real-world networks, including comparison with methods that exploit numerical-attribute-based diversity and topology-driven diversity in influence maximization.",
    "lastUpdated": "2019-12-08T17:59:07Z",
    "categories": [
      "cs.SI",
      "cs.DS",
      "physics.soc-ph"
    ],
    "url": "http://arxiv.org/abs/1912.03727v1"
  },
  {
    "title": "Judge, Jury & Encryptioner: Exceptional Device Access with a Social Cost",
    "authors": [
      "Sacha Servan-Schreiber",
      "Archer Wheeler"
    ],
    "abstract": "We present Judge, Jury and Encryptioner (JJE) an exceptional access scheme for unlocking devices that does not give unilateral power to any single authority. JJE achieves this by placing final approval to unlock a device in the hands of peer devices. JJE distributes maintenance of the protocol across a network of \"custodians\" such as courts, government agencies, civil rights watchdogs, and academic institutions. Unlock requests, however, can only be approved by a randomly selected set of recently active peer devices that must be physically located by law enforcement in order to gain access to the locked device. This requires that law enforcement expend both human and monetary resources and pay a \"social cost\" in order to find and request the participation of random device owners in the unlock process. Compared to other proposed exceptional access schemes, we believe that JJE mitigates the risk of mass surveillance, law enforcement abuse, and vulnerability to unlawful attackers. While we propose a concrete construction, our primary goal with JJE is to spur discussion on ethical exceptional access schemes that balance privacy of individuals and the desires for law enforcement. JJE transparently reveals the use of exceptional access to the public and enforces a fixed social cost that, we believe, can be an effective deterrent to mass surveillance and abuse.",
    "lastUpdated": "2020-03-06T15:44:54Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1912.05620v3"
  },
  {
    "title": "Industrial robot ransomware: Akerbeltz",
    "authors": [
      "Víctor Mayoral-Vilches",
      "Lander Usategui San Juan",
      "Unai Ayucar Carbajo",
      "Rubén Campo",
      "Xabier Sáez de Cámara",
      "Oxel Urzelai",
      "Nuria García",
      "Endika Gil-Uriarte"
    ],
    "abstract": "Cybersecurity lessons have not been learnt from the dawn of other technological industries. In robotics, the existing insecurity landscape needs to be addressed immediately. Several manufacturers profiting from the lack of general awareness are systematically ignoring their responsibilities by claiming their insecure (open) systems facilitate system integration, disregarding the safety, privacy and ethical consequences that their (lack of) actions have. In an attempt to raise awareness and illustrate the \"insecurity by design in robotics\" we have created Akerbeltz, the first known instance of industrial robot ransomware. Our malware is demonstrated using a leading brand for industrial collaborative robots, Universal Robots. We describe the rationale behind our target and discuss the general flow of the attack including the initial cyber-intrusion, lateral movement and later control phase. We urge security researchers to adopt some sort of disclosure policy that forces manufacturers to react promptly. We advocate against security by obscurity and encourage the release of similar actions once vulnerability reports fall into a dead-end. Actions are now to be taken to abide a future free of zero-days for robotics.",
    "lastUpdated": "2019-12-16T21:39:16Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1912.07714v1"
  },
  {
    "title": "Counterfactual thinking in cooperation dynamics",
    "authors": [
      "Luis Moniz Pereira",
      "Francisco C. Santos"
    ],
    "abstract": "Counterfactual Thinking is a human cognitive ability studied in a wide variety of domains. It captures the process of reasoning about a past event that did not occur, namely what would have happened had this event occurred, or, otherwise, to reason about an event that did occur but what would ensue had it not. Given the wide cognitive empowerment of counterfactual reasoning in the human individual, the question arises of how the presence of individuals with this capability may improve cooperation in populations of self-regarding individuals. Here we propose a mathematical model, grounded on Evolutionary Game Theory, to examine the population dynamics emerging from the interplay between counterfactual thinking and social learning (i.e., individuals that learn from the actions and success of others) whenever the individuals in the population face a collective dilemma. Our results suggest that counterfactual reasoning fosters coordination in collective action problems occurring in large populations, and has a limited impact on cooperation dilemmas in which coordination is not required. Moreover, we show that a small prevalence of individuals resorting to counterfactual thinking is enough to nudge an entire population towards highly cooperative standards.",
    "lastUpdated": "2019-12-18T23:38:34Z",
    "categories": [
      "cs.AI",
      "cs.MA",
      "I.6, J.5, J.6",
      "I.6; J.5; J.6"
    ],
    "url": "http://arxiv.org/abs/1912.08946v1"
  },
  {
    "title": "Where Are We? Using Scopus to Map the Literature at the Intersection Between Artificial Intelligence and Research on Crime",
    "authors": [
      "Gian Maria Campedelli"
    ],
    "abstract": "Research on Artificial Intelligence (AI) applications has spread over many scientific disciplines. Scientists have tested the power of intelligent algorithms developed to predict (or learn from) natural, physical and social phenomena. This also applies to crime-related research problems. Nonetheless, studies that map the current state of the art at the intersection between AI and crime are lacking. What are the current research trends in terms of topics in this area? What is the structure of scientific collaboration when considering works investigating criminal issues using machine learning, deep learning, and AI in general? What are the most active countries in this specific scientific sphere? Using data retrieved from the Scopus database, this work quantitatively analyzes 692 published works at the intersection between AI and crime employing network science to respond to these questions. Results show that researchers are mainly focusing on cyber-related criminal topics and that relevant themes such as algorithmic discrimination, fairness, and ethics are considerably overlooked. Furthermore, data highlight the extremely disconnected structure of co-authorship networks. Such disconnectedness may represent a substantial obstacle to a more solid community of scientists interested in these topics. Additionally, the graph of scientific collaboration indicates that countries that are more prone to engage in international partnerships are generally less central in the network. This means that scholars working in highly productive countries (e.g. the United States, China) tend to mostly collaborate domestically. Finally, current issues and future developments within this scientific area are also discussed.",
    "lastUpdated": "2020-08-06T23:23:57Z",
    "categories": [
      "cs.DL",
      "cs.CY",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1912.11084v2"
  },
  {
    "title": "The Windfall Clause: Distributing the Benefits of AI for the Common Good",
    "authors": [
      "Cullen O'Keefe",
      "Peter Cihon",
      "Ben Garfinkel",
      "Carrick Flynn",
      "Jade Leung",
      "Allan Dafoe"
    ],
    "abstract": "As the transformative potential of AI has become increasingly salient as a matter of public and political interest, there has been growing discussion about the need to ensure that AI broadly benefits humanity. This in turn has spurred debate on the social responsibilities of large technology companies to serve the interests of society at large. In response, ethical principles and codes of conduct have been proposed to meet the escalating demand for this responsibility to be taken seriously. As yet, however, few institutional innovations have been suggested to translate this responsibility into legal commitments which apply to companies positioned to reap large financial gains from the development and use of AI. This paper offers one potentially attractive tool for addressing such issues: the Windfall Clause, which is an ex ante commitment by AI firms to donate a significant amount of any eventual extremely large profits. By this we mean an early commitment that profits that a firm could not earn without achieving fundamental, economically transformative breakthroughs in AI capabilities will be donated to benefit humanity broadly, with particular attention towards mitigating any downsides from deployment of windfall-generating AI.",
    "lastUpdated": "2020-01-24T18:43:43Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1912.11595v2"
  },
  {
    "title": "Mining Disinformation and Fake News: Concepts, Methods, and Recent Advancements",
    "authors": [
      "Kai Shu",
      "Suhang Wang",
      "Dongwon Lee",
      "Huan Liu"
    ],
    "abstract": "In recent years, disinformation including fake news, has became a global phenomenon due to its explosive growth, particularly on social media. The wide spread of disinformation and fake news can cause detrimental societal effects. Despite the recent progress in detecting disinformation and fake news, it is still non-trivial due to its complexity, diversity, multi-modality, and costs of fact-checking or annotation. The goal of this chapter is to pave the way for appreciating the challenges and advancements via: (1) introducing the types of information disorder on social media and examine their differences and connections; (2) describing important and emerging tasks to combat disinformation for characterization, detection and attribution; and (3) discussing a weak supervision approach to detect disinformation with limited labeled data. We then provide an overview of the chapters in this book that represent the recent advancements in three related parts: (1) user engagements in the dissemination of information disorder; (2) techniques on detecting and mitigating disinformation; and (3) trending issues such as ethics, blockchain, clickbaits, etc. We hope this book to be a convenient entry point for researchers, practitioners, and students to understand the problems and challenges, learn state-of-the-art solutions for their specific needs, and quickly identify new research problems in their domains.",
    "lastUpdated": "2020-01-02T21:01:02Z",
    "categories": [
      "cs.SI",
      "cs.CL",
      "H.2.8",
      "H.2.8"
    ],
    "url": "http://arxiv.org/abs/2001.00623v1"
  },
  {
    "title": "Big Data Architecture in Czech Republic Healthcare Service: Requirements, TPC-H Benchmarks and Vertica",
    "authors": [
      "Martin Štufi",
      "Boris Bačić",
      "Leonid Stoimenov"
    ],
    "abstract": "Big data in healthcare has made a positive difference in advancing analytical capabilities and lowering the costs of medical care. In addition to providing analytical capabilities on platforms supporting current and near-future AI with machine-learning and data-mining algorithms, there is also a need for ethical considerations mandating new ways to preserve privacy, all of which are preconditioned by the growing body of regulations and expectations. The purpose of this study is to improve existing clinical care by implementing a big data platform for the Czech Republic National Health Service. Based on the achieved performance and its compliance with mandatory guidelines, the reported big-data platform was selected as the winning solution from the Czech Republic national tender (Tender Id. VZ0036628, No. Z2017-035520). The platform, based on analytical Vertica NoSQL database for massive data processing, complies with the TPC-H1 for decision support benchmark, the European Union (EU) and the Czech Republic requirements, well-exceeding defined system performance thresholds. The reported artefacts and concepts are transferrable to healthcare systems in other countries and are intended to provide personalised autonomous assessment from big data in a cost-effective, scalable and high-performance manner. The implemented platform allows: (1) scalability; (2) further implementations of newly-developed machine learning algorithms for classification and predictive analytics; (3) security improvements related to Electronic Health Records (EHR) by using automated functions for data encryption and decryption; and (4) the use of big data to allow strategic planning in healthcare.",
    "lastUpdated": "2020-01-05T08:51:33Z",
    "categories": [
      "cs.DC",
      "B.8, C.3, C.4, C.5, E.2, H.0, H.2, H.3, H.4, I.2, I.7, J.3, K.4, K.6",
      "B.8; C.3; C.4; C.5; E.2; H.0; H.2; H.3; H.4; I.2; I.7; J.3; K.4; K.6"
    ],
    "url": "http://arxiv.org/abs/2001.01192v1"
  },
  {
    "title": "Investigating the Impact of Inclusion in Face Recognition Training Data on Individual Face Identification",
    "authors": [
      "Chris Dulhanty",
      "Alexander Wong"
    ],
    "abstract": "Modern face recognition systems leverage datasets containing images of hundreds of thousands of specific individuals' faces to train deep convolutional neural networks to learn an embedding space that maps an arbitrary individual's face to a vector representation of their identity. The performance of a face recognition system in face verification (1:1) and face identification (1:N) tasks is directly related to the ability of an embedding space to discriminate between identities. Recently, there has been significant public scrutiny into the source and privacy implications of large-scale face recognition training datasets such as MS-Celeb-1M and MegaFace, as many people are uncomfortable with their face being used to train dual-use technologies that can enable mass surveillance. However, the impact of an individual's inclusion in training data on a derived system's ability to recognize them has not previously been studied. In this work, we audit ArcFace, a state-of-the-art, open source face recognition system, in a large-scale face identification experiment with more than one million distractor images. We find a Rank-1 face identification accuracy of 79.71% for individuals present in the model's training data and an accuracy of 75.73% for those not present. This modest difference in accuracy demonstrates that face recognition systems using deep learning work better for individuals they are trained on, which has serious privacy implications when one considers all major open source face recognition training datasets do not obtain informed consent from individuals during their collection.",
    "lastUpdated": "2020-01-10T21:17:59Z",
    "categories": [
      "cs.CY",
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2001.03071v2"
  },
  {
    "title": "Security Vetting Process of Smart-home Assistant Applications: A First Look and Case Studies",
    "authors": [
      "Hang Hu",
      "Limin Yang",
      "Shihan Lin",
      "Gang Wang"
    ],
    "abstract": "The popularity of smart-home assistant systems such as Amazon Alexa and Google Home leads to a booming third-party application market (over 70,000 applications across the two stores). While existing works have revealed security issues in these systems, it is not well understood how to help application developers to enforce security requirements. In this paper, we perform a preliminary case study to examine the security vetting mechanisms adopted by Amazon Alexa and Google Home app stores. With a focus on the authentication mechanisms between Alexa/Google cloud and third-party application servers (i.e. endpoints), we show the current security vetting is insufficient as developer mistakes can not be effectively detected and notified. A weak authentication would allow attackers to spoof the cloud to insert/retrieve data into/from the application endpoints. We validate the attack through ethical proof-of-concept experiments. To confirm vulnerable applications have indeed passed the security vetting and entered the markets, we develop a heuristic-based searching method. We find 219 real-world Alexa endpoints that carry the vulnerability, many of which are related to critical applications that control smart home devices and electronic cars. We have notified Amazon and Google about our findings and offered our suggestions to mitigate the issue.",
    "lastUpdated": "2020-01-13T20:03:14Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/2001.04520v1"
  },
  {
    "title": "Expecting the Unexpected: Developing Autonomous-System Design Principles for Reacting to Unpredicted Events and Conditions",
    "authors": [
      "Assaf Marron",
      "Lior Limonad",
      "Sarah Pollack",
      "David Harel"
    ],
    "abstract": "When developing autonomous systems, engineers and other stakeholders make great effort to prepare the system for all foreseeable events and conditions. However, these systems are still bound to encounter events and conditions that were not considered at design time. For reasons like safety, cost, or ethics, it is often highly desired that these new situations be handled correctly upon first encounter. In this paper we first justify our position that there will always exist unpredicted events and conditions, driven among others by: new inventions in the real world; the diversity of world-wide system deployments and uses; and, the non-negligible probability that multiple seemingly unlikely events, which may be neglected at design time, will not only occur, but occur together. We then argue that despite this unpredictability property, handling these events and conditions is indeed possible. Hence, we offer and exemplify design principles that when applied in advance, can enable systems to deal, in the future, with unpredicted circumstances. We conclude with a discussion of how this work and a broader theoretical study of the unexpected can contribute toward a foundation of engineering principles for developing trustworthy next-generation autonomous systems.",
    "lastUpdated": "2020-01-25T13:39:32Z",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "cs.RO"
    ],
    "url": "http://arxiv.org/abs/2001.06047v3"
  },
  {
    "title": "Fairness Measures for Regression via Probabilistic Classification",
    "authors": [
      "Daniel Steinberg",
      "Alistair Reid",
      "Simon O'Callaghan"
    ],
    "abstract": "Algorithmic fairness involves expressing notions such as equity, or reasonable treatment, as quantifiable measures that a machine learning algorithm can optimise. Most work in the literature to date has focused on classification problems where the prediction is categorical, such as accepting or rejecting a loan application. This is in part because classification fairness measures are easily computed by comparing the rates of outcomes, leading to behaviours such as ensuring that the same fraction of eligible men are selected as eligible women. But such measures are computationally difficult to generalise to the continuous regression setting for problems such as pricing, or allocating payments. The difficulty arises from estimating conditional densities (such as the probability density that a system will over-charge by a certain amount). For the regression setting we introduce tractable approximations of the independence, separation and sufficiency criteria by observing that they factorise as ratios of different conditional probabilities of the protected attributes. We introduce and train machine learning classifiers, distinct from the predictor, as a mechanism to estimate these probabilities from the data. This naturally leads to model agnostic, tractable approximations of the criteria, which we explore experimentally.",
    "lastUpdated": "2020-03-05T03:46:01Z",
    "categories": [
      "cs.LG",
      "cs.CY",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2001.06089v2"
  },
  {
    "title": "Monitoring Misuse for Accountable 'Artificial Intelligence as a Service'",
    "authors": [
      "Seyyed Ahmad Javadi",
      "Richard Cloete",
      "Jennifer Cobbe",
      "Michelle Seng Ah Lee",
      "Jatinder Singh"
    ],
    "abstract": "AI is increasingly being offered 'as a service' (AIaaS). This entails service providers offering customers access to pre-built AI models and services, for tasks such as object recognition, text translation, text-to-voice conversion, and facial recognition, to name a few. The offerings enable customers to easily integrate a range of powerful AI-driven capabilities into their applications. Customers access these models through the provider's APIs, sending particular data to which models are applied, the results of which returned. However, there are many situations in which the use of AI can be problematic. AIaaS services typically represent generic functionality, available 'at a click'. Providers may therefore, for reasons of reputation or responsibility, seek to ensure that the AIaaS services they offer are being used by customers for 'appropriate' purposes. This paper introduces and explores the concept whereby AIaaS providers uncover situations of possible service misuse by their customers. Illustrated through topical examples, we consider the technical usage patterns that could signal situations warranting scrutiny, and raise some of the legal and technical challenges of monitoring for misuse. In all, by introducing this concept, we indicate a potential area for further inquiry from a range of perspectives.",
    "lastUpdated": "2020-01-14T18:14:33Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2001.09723v1"
  },
  {
    "title": "Bias in Data-driven AI Systems -- An Introductory Survey",
    "authors": [
      "Eirini Ntoutsi",
      "Pavlos Fafalios",
      "Ujwal Gadiraju",
      "Vasileios Iosifidis",
      "Wolfgang Nejdl",
      "Maria-Esther Vidal",
      "Salvatore Ruggieri",
      "Franco Turini",
      "Symeon Papadopoulos",
      "Emmanouil Krasanakis",
      "Ioannis Kompatsiaris",
      "Katharina Kinder-Kurlanda",
      "Claudia Wagner",
      "Fariba Karimi",
      "Miriam Fernandez",
      "Harith Alani",
      "Bettina Berendt",
      "Tina Kruegel",
      "Christian Heinze",
      "Klaus Broelemann",
      "Gjergji Kasneci",
      "Thanassis Tiropanis",
      "Steffen Staab"
    ],
    "abstract": "AI-based systems are widely employed nowadays to make decisions that have far-reaching impacts on individuals and society. Their decisions might affect everyone, everywhere and anytime, entailing concerns about potential human rights issues. Therefore, it is necessary to move beyond traditional AI algorithms optimized for predictive performance and embed ethical and legal principles in their design, training and deployment to ensure social good while still benefiting from the huge potential of the AI technology. The goal of this survey is to provide a broad multi-disciplinary overview of the area of bias in AI systems, focusing on technical challenges and solutions as well as to suggest new research directions towards approaches well-grounded in a legal frame. In this survey, we focus on data-driven AI, as a large part of AI is powered nowadays by (big) data and powerful Machine Learning (ML) algorithms. If otherwise not specified, we use the general term bias to describe problems related to the gathering or processing of data that might result in prejudiced decisions on the bases of demographic features like race, sex, etc.",
    "lastUpdated": "2020-01-14T09:39:09Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2001.09762v1"
  },
  {
    "title": "Visuohaptic augmented feedback for enhancing motor skills acquisition",
    "authors": [
      "Ali Asadipour",
      "Kurt Debattista",
      "Alan Chalmers"
    ],
    "abstract": "Serious games are accepted as an effective approach to deliver augmented feedback in motor (re-) learning processes. The multi-modal nature of the conventional computer games (e.g. audiovisual representation) plus the ability to interact via haptic-enabled inputs provides a more immersive experience. Thus, particular disciplines such as medical education in which frequent hands on rehearsals play a key role in learning core motor skills (e.g. physical palpations) may benefit from this technique. Challenges such as the impracticality of verbalising palpation experience by tutors and ethical considerations may prevent the medical students from correctly learning core palpation skills. This work presents a new data glove, built from off-the-shelf components which captures pressure sensitivity designed to provide feedback for palpation tasks. In this work the data glove is used to control a serious game adapted from the infinite runner genre to improve motor skill acquisition. A comparative evaluation on usability and effectiveness of the method using multimodal visualisations, as part of a larger study to enhance pressure sensitivity, is presented. Thirty participants divided into a game-playing group (n = 15) and a control group (n = 15) were invited to perform a simple palpation task. The game-playing group significantly outperformed the control group in which abstract visualisation of force was provided to the users in a blind-folded transfer test. The game-based training approach was positively described by the game-playing group as enjoyable and engaging.",
    "lastUpdated": "2020-01-30T15:31:52Z",
    "categories": [
      "cs.HC",
      "eess.SP",
      "H.5.2; D.2.2; H.1.2; I.3.6"
    ],
    "url": "http://arxiv.org/abs/2001.11401v1"
  },
  {
    "title": "Quality Assessment of Online Automated Privacy Policy Generators: An Empirical Study",
    "authors": [
      "Ruoxi Sun",
      "Minhui Xue"
    ],
    "abstract": "Online Automated Privacy Policy Generators (APPGs) are tools used by app developers to quickly create app privacy policies which are required by privacy regulations to be incorporated to each mobile app. The creation of these tools brings convenience to app developers; however, the quality of these tools puts developers and stakeholders at legal risk. In this paper, we conduct an empirical study to assess the quality of online APPGs. We analyze the completeness of privacy policies, determine what categories and items should be covered in a complete privacy policy, and conduct APPG assessment with boilerplate apps. The results of assessment show that due to the lack of static or dynamic analysis of app's behavior, developers may encounter two types of issues caused by APPGs. First, the generated policies could be incomplete because they do not cover all the essential items required by a privacy policy. Second, some generated privacy policies contain unnecessary personal information collection or arbitrary commitments inconsistent with user input. Ultimately, the defects of APPGs may potentially lead to serious legal issues. We hope that the results and insights developed in this paper can motivate the healthy and ethical development of APPGs towards generating a more complete, accurate, and robust privacy policy.",
    "lastUpdated": "2020-02-13T04:34:57Z",
    "categories": [
      "cs.CR",
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/2002.05341v1"
  },
  {
    "title": "Steps Towards Value-Aligned Systems",
    "authors": [
      "Osonde A. Osoba",
      "Benjamin Boudreaux",
      "Douglas Yeung"
    ],
    "abstract": "Algorithmic (including AI/ML) decision-making artifacts are an established and growing part of our decision-making ecosystem. They are indispensable tools for managing the flood of information needed to make effective decisions in a complex world. The current literature is full of examples of how individual artifacts violate societal norms and expectations (e.g. violations of fairness, privacy, or safety norms). Against this backdrop, this discussion highlights an under-emphasized perspective in the literature on assessing value misalignment in AI-equipped sociotechnical systems. The research on value misalignment has a strong focus on the behavior of individual tech artifacts. This discussion argues for a more structured systems-level approach for assessing value-alignment in sociotechnical systems. We rely primarily on the research on fairness to make our arguments more concrete. And we use the opportunity to highlight how adopting a system perspective improves our ability to explain and address value misalignments better. Our discussion ends with an exploration of priority questions that demand attention if we are to assure the value alignment of whole systems, not just individual artifacts.",
    "lastUpdated": "2020-11-09T21:27:12Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2002.05672v2"
  },
  {
    "title": "The Value of Big Data for Credit Scoring: Enhancing Financial Inclusion using Mobile Phone Data and Social Network Analytics",
    "authors": [
      "María Óskarsdóttir",
      "Cristián Bravo",
      "Carlos Sarraute",
      "Jan Vanthienen",
      "Bart Baesens"
    ],
    "abstract": "Credit scoring is without a doubt one of the oldest applications of analytics. In recent years, a multitude of sophisticated classification techniques have been developed to improve the statistical performance of credit scoring models. Instead of focusing on the techniques themselves, this paper leverages alternative data sources to enhance both statistical and economic model performance. The study demonstrates how including call networks, in the context of positive credit information, as a new Big Data source has added value in terms of profit by applying a profit measure and profit-based feature selection. A unique combination of datasets, including call-detail records, credit and debit account information of customers is used to create scorecards for credit card applicants. Call-detail records are used to build call networks and advanced social network analytics techniques are applied to propagate influence from prior defaulters throughout the network to produce influence scores. The results show that combining call-detail records with traditional data in credit scoring models significantly increases their performance when measured in AUC. In terms of profit, the best model is the one built with only calling behavior features. In addition, the calling behavior features are the most predictive in other models, both in terms of statistical and economic performance. The results have an impact in terms of ethical use of call-detail records, regulatory implications, financial inclusion, as well as data sharing and privacy.",
    "lastUpdated": "2020-02-23T16:13:56Z",
    "categories": [
      "cs.SI",
      "cs.CY",
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2002.09931v1"
  },
  {
    "title": "Migration Networks: Applications of Network Analysis to Macroscale Migration Patterns",
    "authors": [
      "Valentin Danchev",
      "Mason A. Porter"
    ],
    "abstract": "An emerging area of research is the study of macroscale migration patterns as a network of nodes that represent places (e.g., countries, cities, and rural areas) and edges that encode migration ties that connect those places. In this chapter, we first review advances in the study of migration networks and recent work that has employed network analysis to examine such networks at different geographical scales. In our discussion, we focus in particular on global scale migration networks. We then propose ways to leverage network analysis in concert with digital technologies and online geolocated data to examine the structure and dynamics of migration networks. The implementation of such approaches for studying migration networks faces many challenges, including ethical ones, methodological ones, socio-technological ones (e.g., data availability and reuse), and research reproducibility. We detail these challenges, and we then consider possible ways of linking digital geolocated data to administrative and survey data as a way of harnessing new technologies to construct increasingly realistic migration networks (e.g., using multiplex networks). We also briefly discuss new methods (e.g., multilayer network analysis) in network analysis and adjacent fields (e.g., machine learning) that can help advance understanding of macroscale patterns of migration.",
    "lastUpdated": "2020-05-26T22:51:51Z",
    "categories": [
      "cs.SI",
      "nlin.AO",
      "physics.soc-ph"
    ],
    "url": "http://arxiv.org/abs/2002.10992v2"
  },
  {
    "title": "\"Do the Right Thing\" for Whom? An Experiment on Ingroup Favouritism, Group Assorting and Moral Suasion",
    "authors": [
      "Ennio Bilancini",
      "Leonardo Boncinelli",
      "Valerio Capraro",
      "Tatiana Celadin",
      "Roberto Di Paolo"
    ],
    "abstract": "In this paper we investigate the effect of moral suasion on ingroup favouritism. We report a well-powered, pre-registered, two-stage 2x2 mixed-design experiment. In the first stage, groups are formed on the basis of how participants answer to a set of questions, concerning non-morally relevant issues in one treatment (assorting on non-moral preferences), and morally relevant issues in another treatment (assorting on moral preferences). In the second stage, participants choose how to split a given amount of money between participants of their own group and participants of the other group, first in the baseline setting and then in a setting where they are told to do what they believe to be morally right (moral suasion). Our main results are: (i) in the baseline, participants tend to favour their own group to a greater extent when groups are assorted according to moral preferences, compared to when they are assorted according to non-moral preferences; (ii) the net effect of moral suasion is to decrease ingroup favouritism, but there is also a non-negligible proportion of participants for whom moral suasion increases ingroup favouritism; (iii) the effect of moral suasion is substantially stable across group assorting and four pre-registered individual characteristics (gender, political orientation, religiosity, pro-life vs pro-choice ethical convictions).",
    "lastUpdated": "2020-02-27T22:02:58Z",
    "categories": [
      "physics.soc-ph",
      "cs.GT",
      "cs.SI",
      "q-bio.PE"
    ],
    "url": "http://arxiv.org/abs/2002.12464v1"
  },
  {
    "title": "Getting Fairness Right: Towards a Toolbox for Practitioners",
    "authors": [
      "Boris Ruf",
      "Chaouki Boutharouite",
      "Marcin Detyniecki"
    ],
    "abstract": "The potential risk of AI systems unintentionally embedding and reproducing bias has attracted the attention of machine learning practitioners and society at large. As policy makers are willing to set the standards of algorithms and AI techniques, the issue on how to refine existing regulation, in order to enforce that decisions made by automated systems are fair and non-discriminatory, is again critical. Meanwhile, researchers have demonstrated that the various existing metrics for fairness are statistically mutually exclusive and the right choice mostly depends on the use case and the definition of fairness. Recognizing that the solutions for implementing fair AI are not purely mathematical but require the commitments of the stakeholders to define the desired nature of fairness, this paper proposes to draft a toolbox which helps practitioners to ensure fair AI practices. Based on the nature of the application and the available training data, but also on legal requirements and ethical, philosophical and cultural dimensions, the toolbox aims to identify the most appropriate fairness objective. This approach attempts to structure the complex landscape of fairness metrics and, therefore, makes the different available options more accessible to non-technical people. In the proven absence of a silver bullet solution for fair AI, this toolbox intends to produce the fairest AI systems possible with respect to their local context.",
    "lastUpdated": "2020-03-15T20:53:50Z",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/2003.06920v1"
  },
  {
    "title": "Lifespan Age Transformation Synthesis",
    "authors": [
      "Roy Or-El",
      "Soumyadip Sengupta",
      "Ohad Fried",
      "Eli Shechtman",
      "Ira Kemelmacher-Shlizerman"
    ],
    "abstract": "We address the problem of single photo age progression and regression-the prediction of how a person might look in the future, or how they looked in the past. Most existing aging methods are limited to changing the texture, overlooking transformations in head shape that occur during the human aging and growth process. This limits the applicability of previous methods to aging of adults to slightly older adults, and application of those methods to photos of children does not produce quality results. We propose a novel multi-domain image-to-image generative adversarial network architecture, whose learned latent space models a continuous bi-directional aging process. The network is trained on the FFHQ dataset, which we labeled for ages, gender, and semantic segmentation. Fixed age classes are used as anchors to approximate continuous age transformation. Our framework can predict a full head portrait for ages 0-70 from a single photo, modifying both texture and shape of the head. We demonstrate results on a wide variety of photos and datasets, and show significant improvement over the state of the art.",
    "lastUpdated": "2020-07-24T12:08:55Z",
    "categories": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2003.09764v2"
  },
  {
    "title": "Word2Vec: Optimal Hyper-Parameters and Their Impact on NLP Downstream Tasks",
    "authors": [
      "Tosin P. Adewumi",
      "Foteini Liwicki",
      "Marcus Liwicki"
    ],
    "abstract": "Word2Vec is a prominent model for natural language processing (NLP) tasks. Similar inspiration is found in distributed embeddings for new state-of-the-art (SotA) deep neural networks. However, wrong combination of hyper-parameters can produce poor quality vectors. The objective of this work is to empirically show optimal combination of hyper-parameters exists and evaluate various combinations. We compare them with the released, pre-trained original word2vec model. Both intrinsic and extrinsic (downstream) evaluations, including named entity recognition (NER) and sentiment analysis (SA) were carried out. The downstream tasks reveal that the best model is usually task-specific, high analogy scores don't necessarily correlate positively with F1 scores and the same applies to focus on data alone. Increasing vector dimension size after a point leads to poor quality or performance. If ethical considerations to save time, energy and the environment are made, then reasonably smaller corpora may do just as well or even better in some cases. Besides, using a small corpus, we obtain better human-assigned WordSim scores, corresponding Spearman correlation and better downstream performances (with significance tests) compared to the original model, trained on 100 billion-word corpus.",
    "lastUpdated": "2020-05-12T10:09:22Z",
    "categories": [
      "cs.CL",
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2003.11645v2"
  },
  {
    "title": "Face Quality Estimation and Its Correlation to Demographic and Non-Demographic Bias in Face Recognition",
    "authors": [
      "Philipp Terhörst",
      "Jan Niklas Kolf",
      "Naser Damer",
      "Florian Kirchbuchner",
      "Arjan Kuijper"
    ],
    "abstract": "Face quality assessment aims at estimating the utility of a face image for the purpose of recognition. It is a key factor to achieve high face recognition performances. Currently, the high performance of these face recognition systems come with the cost of a strong bias against demographic and non-demographic sub-groups. Recent work has shown that face quality assessment algorithms should adapt to the deployed face recognition system, in order to achieve highly accurate and robust quality estimations. However, this could lead to a bias transfer towards the face quality assessment leading to discriminatory effects e.g. during enrolment. In this work, we present an in-depth analysis of the correlation between bias in face recognition and face quality assessment. Experiments were conducted on two publicly available datasets captured under controlled and uncontrolled circumstances with two popular face embeddings. We evaluated four state-of-the-art solutions for face quality assessment towards biases to pose, ethnicity, and age. The experiments showed that the face quality assessment solutions assign significantly lower quality values towards subgroups affected by the recognition bias demonstrating that these approaches are biased as well. This raises ethical questions towards fairness and discrimination which future works have to address.",
    "lastUpdated": "2020-07-10T11:24:37Z",
    "categories": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2004.01019v3"
  },
  {
    "title": "Improving Confidence in the Estimation of Values and Norms",
    "authors": [
      "Luciano Cavalcante Siebert",
      "Rijk Mercuur",
      "Virginia Dignum",
      "Jeroen van den Hoven",
      "Catholijn Jonker"
    ],
    "abstract": "Autonomous agents (AA) will increasingly be interacting with us in our daily lives. While we want the benefits attached to AAs, it is essential that their behavior is aligned with our values and norms. Hence, an AA will need to estimate the values and norms of the humans it interacts with, which is not a straightforward task when solely observing an agent's behavior. This paper analyses to what extent an AA is able to estimate the values and norms of a simulated human agent (SHA) based on its actions in the ultimatum game. We present two methods to reduce ambiguity in profiling the SHAs: one based on search space exploration and another based on counterfactual analysis. We found that both methods are able to increase the confidence in estimating human values and norms, but differ in their applicability, the latter being more efficient when the number of interactions with the agent is to be minimized. These insights are useful to improve the alignment of AAs with human values and norms.",
    "lastUpdated": "2020-04-02T15:03:03Z",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "url": "http://arxiv.org/abs/2004.01056v1"
  },
  {
    "title": "A Norm Emergence Framework for Normative MAS -- Position Paper",
    "authors": [
      "Andreasa Morris-Martin",
      "Marina De Vos",
      "Julian Padget"
    ],
    "abstract": "Norm emergence is typically studied in the context of multiagent systems (MAS) where norms are implicit, and participating agents use simplistic decision-making mechanisms. These implicit norms are usually unconsciously shared and adopted through agent interaction. A norm is deemed to have emerged when a threshold or predetermined percentage of agents follow the \"norm\". Conversely, in normative MAS, norms are typically explicit and agents deliberately share norms through communication or are informed about norms by an authority, following which an agent decides whether to adopt the norm or not. The decision to adopt a norm by the agent can happen immediately after recognition or when an applicable situation arises. In this paper, we make the case that, similarly, a norm has emerged in a normative MAS when a percentage of agents adopt the norm. Furthermore, we posit that agents themselves can and should be involved in norm synthesis, and hence influence the norms governing the MAS, in line with Ostrom's eight principles. Consequently, we put forward a framework for the emergence of norms within a normative MAS, that allows participating agents to propose/request changes to the normative system, while special-purpose synthesizer agents formulate new norms or revisions in response to these requests. Synthesizers must collectively agree that the new norm or norm revision should proceed, and then finally be approved by an \"Oracle\". The normative system is then modified to incorporate the norm.",
    "lastUpdated": "2020-04-06T11:42:01Z",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2004.02575v1"
  },
  {
    "title": "How Do You Act? An Empirical Study to Understand Behavior of Deep Reinforcement Learning Agents",
    "authors": [
      "Richard Meyes",
      "Moritz Schneider",
      "Tobias Meisen"
    ],
    "abstract": "The demand for more transparency of decision-making processes of deep reinforcement learning agents is greater than ever, due to their increased use in safety critical and ethically challenging domains such as autonomous driving. In this empirical study, we address this lack of transparency following an idea that is inspired by research in the field of neuroscience. We characterize the learned representations of an agent's policy network through its activation space and perform partial network ablations to compare the representations of the healthy and the intentionally damaged networks. We show that the healthy agent's behavior is characterized by a distinct correlation pattern between the network's layer activation and the performed actions during an episode and that network ablations, which cause a strong change of this pattern, lead to the agent failing its trained control task. Furthermore, the learned representation of the healthy agent is characterized by a distinct pattern in its activation space reflecting its different behavioral stages during an episode, which again, when distorted by network ablations, leads to the agent failing its trained control task. Concludingly, we argue in favor of a new perspective on artificial neural networks as objects of empirical investigations, just as biological neural systems in neuroscientific studies, paving the way towards a new standard of scientific falsifiability with respect to research on transparency and interpretability of artificial neural networks.",
    "lastUpdated": "2020-04-07T10:08:55Z",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "url": "http://arxiv.org/abs/2004.03237v1"
  },
  {
    "title": "Causal Relational Learning",
    "authors": [
      "Babak Salimi",
      "Harsh Parikh",
      "Moe Kayali",
      "Sudeepa Roy",
      "Lise Getoor",
      "Dan Suciu"
    ],
    "abstract": "Causal inference is at the heart of empirical research in natural and social sciences and is critical for scientific discovery and informed decision making. The gold standard in causal inference is performing randomized controlled trials; unfortunately these are not always feasible due to ethical, legal, or cost constraints. As an alternative, methodologies for causal inference from observational data have been developed in statistical studies and social sciences. However, existing methods critically rely on restrictive assumptions such as the study population consisting of homogeneous elements that can be represented in a single flat table, where each row is referred to as a unit. In contrast, in many real-world settings, the study domain naturally consists of heterogeneous elements with complex relational structure, where the data is naturally represented in multiple related tables. In this paper, we present a formal framework for causal inference from such relational data. We propose a declarative language called CaRL for capturing causal background knowledge and assumptions and specifying causal queries using simple Datalog-like rules.CaRL provides a foundation for inferring causality and reasoning about the effect of complex interventions in relational domains. We present an extensive experimental evaluation on real relational data to illustrate the applicability of CaRL in social sciences and healthcare.",
    "lastUpdated": "2020-04-07T18:33:05Z",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2004.03644v1"
  },
  {
    "title": "Care Robots with Sexual Assistance Functions",
    "authors": [
      "Oliver Bendel"
    ],
    "abstract": "Residents in retirement and nursing homes have sexual needs just like other people. However, the semi-public situation makes it difficult for them to satisfy these existential concerns. In addition, they may not be able to meet a suitable partner or find it difficult to have a relationship for mental or physical reasons. People who live or are cared for at home can also be affected by this problem. Perhaps they can host someone more easily and discreetly than the residents of a health facility, but some elderly and disabled people may be restricted in some ways. This article examines the opportunities and risks that arise with regard to care robots with sexual assistance functions. First of all, it deals with sexual well-being. Then it presents robotic systems ranging from sex robots to care robots. Finally, the focus is on care robots, with the author exploring technical and design issues. A brief ethical discussion completes the article. The result is that care robots with sexual assistance functions could be an enrichment of the everyday life of people in need of care, but that we also have to consider some technical, design and moral aspects.",
    "lastUpdated": "2020-04-09T09:02:27Z",
    "categories": [
      "cs.RO",
      "cs.CY",
      "cs.HC",
      "I.2.9"
    ],
    "url": "http://arxiv.org/abs/2004.04428v1"
  },
  {
    "title": "Online Social Deception and Its Countermeasures for Trustworthy Cyberspace: A Survey",
    "authors": [
      "Zhen Guo",
      "Jin-Hee Cho",
      "Ing-Ray Chen",
      "Srijan Sengupta",
      "Michin Hong",
      "Tanushree Mitra"
    ],
    "abstract": "We are living in an era when online communication over social network services (SNSs) have become an indispensable part of people's everyday lives. As a consequence, online social deception (OSD) in SNSs has emerged as a serious threat in cyberspace, particularly for users vulnerable to such cyberattacks. Cyber attackers have exploited the sophisticated features of SNSs to carry out harmful OSD activities, such as financial fraud, privacy threat, or sexual/labor exploitation. Therefore, it is critical to understand OSD and develop effective countermeasures against OSD for building a trustworthy SNSs. In this paper, we conducted an extensive survey, covering (i) the multidisciplinary concepts of social deception; (ii) types of OSD attacks and their unique characteristics compared to other social network attacks and cybercrimes; (iii) comprehensive defense mechanisms embracing prevention, detection, and response (or mitigation) against OSD attacks along with their pros and cons; (iv) datasets/metrics used for validation and verification; and (v) legal and ethical concerns related to OSD research. Based on this survey, we provide insights into the effectiveness of countermeasures and the lessons from existing literature. We conclude this survey paper with an in-depth discussions on the limitations of the state-of-the-art and recommend future research directions in this area.",
    "lastUpdated": "2020-04-16T14:28:21Z",
    "categories": [
      "cs.CR",
      "cs.SI"
    ],
    "url": "http://arxiv.org/abs/2004.07678v1"
  },
  {
    "title": "COVID-19 and the difficulty of inferring epidemiological parameters from clinical data",
    "authors": [
      "Simon N. Wood",
      "Ernst C. Wit",
      "Matteo Fasiolo",
      "Peter J. Green"
    ],
    "abstract": "Knowing the infection fatality ratio (IFR) is of crucial importance for evidence-based epidemic management: for immediate planning; for balancing the life years saved against the life years lost due to the consequences of management; and for evaluating the ethical issues associated with the tacit willingness to pay substantially more for life years lost to the epidemic, than for those to other diseases. Against this background Verity et al. (2020, Lancet Infections Diseases) have rapidly assembled case data and used statistical modelling to infer the IFR for COVID-19. We have attempted an in-depth statistical review of their approach, to identify to what extent the data are sufficiently informative about the IFR to play a greater role than the modelling assumptions, and have tried to identify those assumptions that appear to play a key role. Given the difficulties with other data sources, we provide a crude alternative analysis based on the Diamond Princess Cruise ship data and case data from China, and argue that, given the data problems, modelling of clinical data to obtain the IFR can only be a stop-gap measure. What is needed is near direct measurement of epidemic size by PCR and/or antibody testing of random samples of the at risk population.",
    "lastUpdated": "2020-05-05T12:43:30Z",
    "categories": [
      "q-bio.QM",
      "q-bio.PE"
    ],
    "url": "http://arxiv.org/abs/2004.14482v2"
  },
  {
    "title": "How average is average? Temporal patterns in human behaviour as measured by mobile phone data -- or why chose Thursdays",
    "authors": [
      "Marina Toger",
      "Ian Shuttleworth",
      "John Östh"
    ],
    "abstract": "Mobile phone data -- with file sizes scaling into terabytes -- easily overwhelm the computational capacity available to some researchers. Moreover, for ethical reasons, data access is often granted only to particular subsets, restricting analyses to cover single days, weeks, or geographical areas. Consequently, it is frequently impossible to set a particular analysis or event in its context and know how typical it is, compared to other days, weeks or months. This is important for academic referees questioning research on mobile phone data and for the analysts in deciding how to sample, how much data to process, and which events are anomalous. All these issues require an understanding of variability in Big Data to answer the question of how average is average? This paper provides a method, using a large mobile phone dataset, to answer these basic but necessary questions. We show that file size is a robust proxy for the activity level of phone users by profiling the temporal variability of the data at an hourly, daily and monthly level. We then apply time-series analysis to isolate temporal periodicity. Finally, we discuss confidence limits to anomalous events in the data. We recommend an analytical approach to mobile phone data selection which suggests that ideally data should be sampled across days, across working weeks, and across the year, to obtain a representative average. However, where this is impossible, the temporal variability is such that specific weekdays' data can provide a fair picture of other days in their general structure.",
    "lastUpdated": "2020-04-30T23:06:15Z",
    "categories": [
      "econ.GN",
      "q-fin.EC",
      "stat.AP"
    ],
    "url": "http://arxiv.org/abs/2005.00137v1"
  },
  {
    "title": "The Visual Social Distancing Problem",
    "authors": [
      "Marco Cristani",
      "Alessio Del Bue",
      "Vittorio Murino",
      "Francesco Setti",
      "Alessandro Vinciarelli"
    ],
    "abstract": "One of the main and most effective measures to contain the recent viral outbreak is the maintenance of the so-called Social Distancing (SD). To comply with this constraint, workplaces, public institutions, transports and schools will likely adopt restrictions over the minimum inter-personal distance between people. Given this actual scenario, it is crucial to massively measure the compliance to such physical constraint in our life, in order to figure out the reasons of the possible breaks of such distance limitations, and understand if this implies a possible threat given the scene context. All of this, complying with privacy policies and making the measurement acceptable. To this end, we introduce the Visual Social Distancing (VSD) problem, defined as the automatic estimation of the inter-personal distance from an image, and the characterization of the related people aggregations. VSD is pivotal for a non-invasive analysis to whether people comply with the SD restriction, and to provide statistics about the level of safety of specific areas whenever this constraint is violated. We then discuss how VSD relates with previous literature in Social Signal Processing and indicate which existing Computer Vision methods can be used to manage such problem. We conclude with future challenges related to the effectiveness of VSD systems, ethical implications and future application scenarios.",
    "lastUpdated": "2020-05-11T00:04:34Z",
    "categories": [
      "cs.CV",
      "cs.LG",
      "eess.IV"
    ],
    "url": "http://arxiv.org/abs/2005.04813v1"
  },
  {
    "title": "Designing for Human Rights in AI",
    "authors": [
      "Evgeni Aizenberg",
      "Jeroen van den Hoven"
    ],
    "abstract": "In the age of big data, companies and governments are increasingly using algorithms to inform hiring decisions, employee management, policing, credit scoring, insurance pricing, and many more aspects of our lives. AI systems can help us make evidence-driven, efficient decisions, but can also confront us with unjustified, discriminatory decisions wrongly assumed to be accurate because they are made automatically and quantitatively. It is becoming evident that these technological developments are consequential to people's fundamental human rights. Despite increasing attention to these urgent challenges in recent years, technical solutions to these complex socio-ethical problems are often developed without empirical study of societal context and the critical input of societal stakeholders who are impacted by the technology. On the other hand, calls for more ethically- and socially-aware AI often fail to provide answers for how to proceed beyond stressing the importance of transparency, explainability, and fairness. Bridging these socio-technical gaps and the deep divide between abstract value language and design requirements is essential to facilitate nuanced, context-dependent design choices that will support moral and social values. In this paper, we bridge this divide through the framework of Design for Values, drawing on methodologies of Value Sensitive Design and Participatory Design to present a roadmap for proactively engaging societal stakeholders to translate fundamental human rights into context-dependent design requirements through a structured, inclusive, and transparent process.",
    "lastUpdated": "2020-07-06T17:00:46Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2005.04949v2"
  },
  {
    "title": "IEEE 7010: A New Standard for Assessing the Well-being Implications of Artificial Intelligence",
    "authors": [
      "Daniel S. Schiff",
      "Aladdin Ayesh",
      "Laura Musikanski",
      "John C. Havens"
    ],
    "abstract": "Artificial intelligence (AI) enabled products and services are becoming a staple of everyday life. While governments and businesses are eager to enjoy the benefits of AI innovations, the mixed impact of these autonomous and intelligent systems on human well-being has become a pressing issue. This article introduces one of the first international standards focused on the social and ethical implications of AI: The Institute of Electrical and Electronics Engineering (IEEE) Standard (Std) 7010-2020 Recommended Practice for Assessing the Impact of Autonomous and Intelligent Systems on Human Well-being. Incorporating well-being factors throughout the lifecycle of AI is both challenging and urgent and IEEE 7010 provides key guidance for those who design, deploy, and procure these technologies. We begin by articulating the benefits of an approach for AI centered around well-being and the measurement of well-being data. Next, we provide an overview of IEEE 7010, including its key principles and how the standard relates to approaches and perspectives in place in the AI community. Finally, we indicate where future efforts are needed.",
    "lastUpdated": "2020-12-17T19:30:00Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2005.06620v3"
  },
  {
    "title": "Avoiding Improper Treatment of Persons with Dementia by Care Robots",
    "authors": [
      "Martin Cooney",
      "Sepideh Pashami",
      "Eric Järpe",
      "Awais Ashfaq"
    ],
    "abstract": "The phrase \"most cruel and revolting crimes\" has been used to describe some poor historical treatment of vulnerable impaired persons by precisely those who should have had the responsibility of protecting and helping them. We believe we might be poised to see history repeat itself, as increasingly human-like aware robots become capable of engaging in behavior which we would consider immoral in a human--either unknowingly or deliberately. In the current paper we focus in particular on exploring some potential dangers affecting persons with dementia (PWD), which could arise from insufficient software or external factors, and describe a proposed solution involving rich causal models and accountability measures: Specifically, the Consequences of Needs-driven Dementia-compromised Behaviour model (C-NDB) could be adapted to be used with conversation topic detection, causal networks and multi-criteria decision making, alongside reports, audits, and deterrents. Our aim is that the considerations raised could help inform the design of care robots intended to support well-being in PWD.",
    "lastUpdated": "2020-05-08T14:34:13Z",
    "categories": [
      "cs.CY",
      "cs.RO"
    ],
    "url": "http://arxiv.org/abs/2005.06622v1"
  },
  {
    "title": "Ethical Adversaries: Towards Mitigating Unfairness with Adversarial Machine Learning",
    "authors": [
      "Pieter Delobelle",
      "Paul Temple",
      "Gilles Perrouin",
      "Benoît Frénay",
      "Patrick Heymans",
      "Bettina Berendt"
    ],
    "abstract": "Machine learning is being integrated into a growing number of critical systems with far-reaching impacts on society. Unexpected behaviour and unfair decision processes are coming under increasing scrutiny due to this widespread use and its theoretical considerations. Individuals, as well as organisations, notice, test, and criticize unfair results to hold model designers and deployers accountable. We offer a framework that assists these groups in mitigating unfair representations stemming from the training datasets. Our framework relies on two inter-operating adversaries to improve fairness. First, a model is trained with the goal of preventing the guessing of protected attributes' values while limiting utility losses. This first step optimizes the model's parameters for fairness. Second, the framework leverages evasion attacks from adversarial machine learning to generate new examples that will be misclassified. These new examples are then used to retrain and improve the model in the first step. These two steps are iteratively applied until a significant improvement in fairness is obtained. We evaluated our framework on well-studied datasets in the fairness literature -- including COMPAS -- where it can surpass other approaches concerning demographic parity, equality of opportunity and also the model's utility. We also illustrate our findings on the subtle difficulties when mitigating unfairness and highlight how our framework can assist model designers.",
    "lastUpdated": "2020-09-01T16:47:17Z",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2005.06852v2"
  },
  {
    "title": "Equality of Learning Opportunity via Individual Fairness in Personalized Recommendations",
    "authors": [
      "Mirko Marras",
      "Ludovico Boratto",
      "Guilherme Ramos",
      "Gianni Fenu"
    ],
    "abstract": "Online educational platforms are playing a primary role in mediating the success of individuals' careers. Therefore, while building overlying content recommendation services, it becomes essential to guarantee that learners are provided with equal recommended learning opportunities, according to the platform values, context, and pedagogy. Though the importance of ensuring equality of learning opportunities has been well investigated in traditional institutions, how this equality can be operationalized in online learning ecosystems through recommender systems is still under-explored. In this paper, we formalize educational principles that model recommendations' learning properties, and a novel fairness metric that combines them in order to monitor the equality of recommended learning opportunities among learners. Then, we envision a scenario wherein an educational platform should be arranged in such a way that the generated recommendations meet each principle to a certain degree for all learners, constrained to their individual preferences. Under this view, we explore the learning opportunities provided by recommender systems in a large-scale course platform, uncovering systematic inequalities. To reduce this effect, we propose a novel post-processing approach that balances personalization and equality of recommended opportunities. Experiments show that our approach leads to higher equality, with a negligible loss in personalization. Our study moves a step forward in operationalizing the ethics of human learning in recommendations, a core unit of intelligent educational systems.",
    "lastUpdated": "2020-10-27T01:45:18Z",
    "categories": [
      "cs.IR"
    ],
    "url": "http://arxiv.org/abs/2006.04282v2"
  },
  {
    "title": "SECure: A Social and Environmental Certificate for AI Systems",
    "authors": [
      "Abhishek Gupta",
      "Camylle Lanteigne",
      "Sara Kingsley"
    ],
    "abstract": "In a world increasingly dominated by AI applications, an understudied aspect is the carbon and social footprint of these power-hungry algorithms that require copious computation and a trove of data for training and prediction. While profitable in the short-term, these practices are unsustainable and socially extractive from both a data-use and energy-use perspective. This work proposes an ESG-inspired framework combining socio-technical measures to build eco-socially responsible AI systems. The framework has four pillars: compute-efficient machine learning, federated learning, data sovereignty, and a LEEDesque certificate. Compute-efficient machine learning is the use of compressed network architectures that show marginal decreases in accuracy. Federated learning augments the first pillar's impact through the use of techniques that distribute computational loads across idle capacity on devices. This is paired with the third pillar of data sovereignty to ensure the privacy of user data via techniques like use-based privacy and differential privacy. The final pillar ties all these factors together and certifies products and services in a standardized manner on their environmental and social impacts, allowing consumers to align their purchase with their values.",
    "lastUpdated": "2020-07-19T12:39:45Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG",
      "econ.GN",
      "q-fin.EC"
    ],
    "url": "http://arxiv.org/abs/2006.06217v2"
  },
  {
    "title": "Group-Fair Online Allocation in Continuous Time",
    "authors": [
      "Semih Cayci",
      "Swati Gupta",
      "Atilla Eryilmaz"
    ],
    "abstract": "The theory of discrete-time online learning has been successfully applied in many problems that involve sequential decision-making under uncertainty. However, in many applications including contractual hiring in online freelancing platforms and server allocation in cloud computing systems, the outcome of each action is observed only after a random and action-dependent time. Furthermore, as a consequence of certain ethical and economic concerns, the controller may impose deadlines on the completion of each task, and require fairness across different groups in the allocation of total time budget $B$. In order to address these applications, we consider continuous-time online learning problem with fairness considerations, and present a novel framework based on continuous-time utility maximization. We show that this formulation recovers reward-maximizing, max-min fair and proportionally fair allocation rules across different groups as special cases. We characterize the optimal offline policy, which allocates the total time between different actions in an optimally fair way (as defined by the utility function), and impose deadlines to maximize time-efficiency. In the absence of any statistical knowledge, we propose a novel online learning algorithm based on dual ascent optimization for time averages, and prove that it achieves $\\tilde{O}(B^{-1/2})$ regret bound.",
    "lastUpdated": "2020-07-23T19:07:54Z",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2006.06852v2"
  },
  {
    "title": "The EMV Standard: Break, Fix, Verify",
    "authors": [
      "David Basin",
      "Ralf Sasse",
      "Jorge Toro-Pozo"
    ],
    "abstract": "EMV is the international protocol standard for smartcard payment and is used in over 9 billion cards worldwide. Despite the standard's advertised security, various issues have been previously uncovered, deriving from logical flaws that are hard to spot in EMV's lengthy and complex specification, running over 2,000 pages. We formalize a comprehensive symbolic model of EMV in Tamarin, a state-of-the-art protocol verifier. Our model is the first that supports a fine-grained analysis of all relevant security guarantees that EMV is intended to offer. We use our model to automatically identify flaws that lead to two critical attacks: one that defrauds the cardholder and a second that defrauds the merchant. First, criminals can use a victim's Visa contactless card to make payments for amounts that require cardholder verification, without knowledge of the card's PIN. We built a proof-of-concept Android application and successfully demonstrated this attack on real-world payment terminals. Second, criminals can trick the terminal into accepting an unauthentic offline transaction, which the issuing bank should later decline, after the criminal has walked away with the goods. This attack is possible for implementations following the standard, although we did not test it on actual terminals for ethical reasons. Finally, we propose and verify improvements to the standard that prevent these attacks, as well as any other attacks that violate the considered security properties. The proposed improvements can be easily implemented in the terminals and do not affect the cards in circulation.",
    "lastUpdated": "2020-11-04T13:21:23Z",
    "categories": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/2006.08249v2"
  },
  {
    "title": "ETHOS: an Online Hate Speech Detection Dataset",
    "authors": [
      "Ioannis Mollas",
      "Zoe Chrysopoulou",
      "Stamatis Karlos",
      "Grigorios Tsoumakas"
    ],
    "abstract": "Online hate speech is a newborn problem in our modern society which is growing at a steady rate exploiting weaknesses of the corresponding regimes that characterise several social media platforms. Therefore, this phenomenon is mainly cultivated through such comments, either during users' interaction or on posted multimedia context. Nowadays, giant companies own platforms where many millions of users log in daily. Thus, protection of their users from exposure to similar phenomena for keeping up with the corresponding law, as well as for retaining a high quality of offered services, seems mandatory. Having a robust and reliable mechanism for identifying and preventing the uploading of related material would have a huge effect on our society regarding several aspects of our daily life. On the other hand, its absence would deteriorate heavily the total user experience, while its erroneous operation might raise several ethical issues. In this work, we present a protocol for creating a more suitable dataset, regarding its both informativeness and representativeness aspects, favouring the safer capture of hate speech occurrence, without at the same time restricting its applicability to other classification problems. Moreover, we produce and publish a textual dataset with two variants: binary and multi-label, called `ETHOS', based on YouTube and Reddit comments validated through figure-eight crowdsourcing platform. Our assumption about the production of more compatible datasets is further investigated by applying various classification models and recording their behaviour over several appropriate metrics.",
    "lastUpdated": "2020-06-11T08:59:57Z",
    "categories": [
      "cs.CL",
      "cs.LG",
      "stat.ML",
      "I.2.6; I.2.7; I.5.4; H.2.4"
    ],
    "url": "http://arxiv.org/abs/2006.08328v1"
  },
  {
    "title": "Opportunities and Challenges in Explainable Artificial Intelligence (XAI): A Survey",
    "authors": [
      "Arun Das",
      "Paul Rad"
    ],
    "abstract": "Nowadays, deep neural networks are widely used in mission critical systems such as healthcare, self-driving vehicles, and military which have direct impact on human lives. However, the black-box nature of deep neural networks challenges its use in mission critical applications, raising ethical and judicial concerns inducing lack of trust. Explainable Artificial Intelligence (XAI) is a field of Artificial Intelligence (AI) that promotes a set of tools, techniques, and algorithms that can generate high-quality interpretable, intuitive, human-understandable explanations of AI decisions. In addition to providing a holistic view of the current XAI landscape in deep learning, this paper provides mathematical summaries of seminal work. We start by proposing a taxonomy and categorizing the XAI techniques based on their scope of explanations, methodology behind the algorithms, and explanation level or usage which helps build trustworthy, interpretable, and self-explanatory deep learning models. We then describe the main principles used in XAI research and present the historical timeline for landmark studies in XAI from 2007 to 2020. After explaining each category of algorithms and approaches in detail, we then evaluate the explanation maps generated by eight XAI algorithms on image data, discuss the limitations of this approach, and provide potential future directions to improve XAI evaluation.",
    "lastUpdated": "2020-06-23T01:48:56Z",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2006.11371v2"
  },
  {
    "title": "Adding flexibility to clinical trial designs: an example-based guide to the practical use of adaptive designs",
    "authors": [
      "Thomas Burnett",
      "Pavel Mozgunov",
      "Philip Pallmann",
      "Sofia S. Villar",
      "Graham M. Wheeler",
      "Thomas Jaki"
    ],
    "abstract": "Adaptive designs for clinical trials permit alterations to a study in response to accumulating data in order to make trials more flexible, ethical and efficient. These benefits are achieved while preserving the integrity and validity of the trial, through the pre-specification and proper adjustment for the possible alterations during the course of the trial. Despite much research in the statistical literature highlighting the potential advantages of adaptive designs over traditional fixed designs, the uptake of such methods in clinical research has been slow. One major reason for this is that different adaptations to trial designs, as well as their advantages and limitations, remain unfamiliar to large parts of the clinical community. The aim of this paper is to clarify where adaptive designs can be used to address specific questions of scientific interest; we introduce the main features of adaptive designs and commonly used terminology, highlighting their utility and pitfalls, and illustrate their use through case studies of adaptive trials ranging from early-phase dose escalation to confirmatory Phase III studies.",
    "lastUpdated": "2020-06-23T08:03:48Z",
    "categories": [
      "stat.AP"
    ],
    "url": "http://arxiv.org/abs/2006.12811v1"
  },
  {
    "title": "A Vision-based Social Distancing and Critical Density Detection System for COVID-19",
    "authors": [
      "Dongfang Yang",
      "Ekim Yurtsever",
      "Vishnu Renganathan",
      "Keith A. Redmill",
      "Ümit Özgüner"
    ],
    "abstract": "Social distancing has been proven as an effective measure against the spread of the infectious COronaVIrus Disease 2019 (COVID-19). However, individuals are not used to tracking the required 6-feet (2-meters) distance between themselves and their surroundings. An active surveillance system capable of detecting distances between individuals and warning them can slow down the spread of the deadly disease. Furthermore, measuring social density in a region of interest (ROI) and modulating inflow can decrease social distancing violation occurrence chance. On the other hand, recording data and labeling individuals who do not follow the measures will breach individuals' rights in free-societies. Here we propose an Artificial Intelligence (AI) based real-time social distancing detection and warning system considering four important ethical factors: (1) the system should never record/cache data, (2) the warnings should not target the individuals, (3) no human supervisor should be in the detection/warning loop, and (4) the code should be open-source and accessible to the public. Against this backdrop, we propose using a monocular camera and deep learning-based real-time object detectors to measure social distancing. If a violation is detected, a non-intrusive audio-visual warning signal is emitted without targeting the individual who breached the social distancing measure. Also, if the social density is over a critical value, the system sends a control signal to modulate inflow into the ROI. We tested the proposed method across real-world datasets to measure its generality and performance. The proposed method is ready for deployment, and our code is open-sourced.",
    "lastUpdated": "2020-07-08T22:53:16Z",
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2007.03578v2"
  },
  {
    "title": "Towards causal benchmarking of bias in face analysis algorithms",
    "authors": [
      "Guha Balakrishnan",
      "Yuanjun Xiong",
      "Wei Xia",
      "Pietro Perona"
    ],
    "abstract": "Measuring algorithmic bias is crucial both to assess algorithmic fairness, and to guide the improvement of algorithms. Current methods to measure algorithmic bias in computer vision, which are based on observational datasets, are inadequate for this task because they conflate algorithmic bias with dataset bias. To address this problem we develop an experimental method for measuring algorithmic bias of face analysis algorithms, which manipulates directly the attributes of interest, e.g., gender and skin tone, in order to reveal causal links between attribute variation and performance change. Our proposed method is based on generating synthetic ``transects'' of matched sample images that are designed to differ along specific attributes while leaving other attributes constant. A crucial aspect of our approach is relying on the perception of human observers, both to guide manipulations, and to measure algorithmic bias. Besides allowing the measurement of algorithmic bias, synthetic transects have other advantages with respect to observational datasets: they sample attributes more evenly allowing for more straightforward bias analysis on minority and intersectional groups, they enable prediction of bias in new scenarios, they greatly reduce ethical and legal challenges, and they are economical and fast to obtain, helping make bias testing affordable and widely available. We validate our method by comparing it to a study that employs the traditional observational method for analyzing bias in gender classification algorithms. The two methods reach different conclusions. While the observational method reports gender and skin color biases, the experimental method reveals biases due to gender, hair length, age, and facial hair.",
    "lastUpdated": "2020-07-13T17:10:34Z",
    "categories": [
      "cs.CV",
      "cs.CY",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2007.06570v1"
  },
  {
    "title": "A Bayesian Evaluation Framework for Ground Truth-Free Visual Recognition Tasks",
    "authors": [
      "Derek S. Prijatelj",
      "Mel McCurrie",
      "Walter J. Scheirer"
    ],
    "abstract": "An interesting development in automatic visual recognition has been the emergence of tasks where it is not possible to assign ground truth labels to images, yet still feasible to collect annotations that reflect human judgements about them. Such tasks include subjective visual attribute assignment and the labeling of ambiguous scenes. Machine learning-based predictors for these tasks rely on supervised training that models the behavior of the annotators, e.g., what would the average person's judgement be for an image? A key open question for this type of work, especially for applications where inconsistency with human behavior can lead to ethical lapses, is how to evaluate the uncertainty of trained predictors. Given that the real answer is unknowable, we are left with often noisy judgements from human annotators to work with. In order to account for the uncertainty that is present, we propose a relative Bayesian framework for evaluating predictors trained on such data. The framework specifies how to estimate a predictor's uncertainty due to the human labels by approximating a conditional distribution and producing a credible interval for the predictions and their measures of performance. The framework is successfully applied to four image classification tasks that use subjective human judgements: facial beauty assessment using the SCUT-FBP5500 dataset, social attribute assignment using data from TestMyBrain.org, apparent age estimation using data from the ChaLearn series of challenges, and ambiguous scene labeling using the LabelMe dataset.",
    "lastUpdated": "2020-06-20T18:35:33Z",
    "categories": [
      "cs.CV",
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2007.06711v1"
  },
  {
    "title": "Welcome to Gab Alt Right Discourses",
    "authors": [
      "Nga Than",
      "Maria Y. Rodriguez",
      "Diane Yoong",
      "Friederike Windel"
    ],
    "abstract": "Social media has become an important venue for diverse groups to share information, discuss political issues, and organize social movements. Recent scholarship has shown that the social media ecosystem can affect political thinking and expression. Individuals and groups across the political spectrum have engaged in the use of these platforms extensively, even creating their own forums with varying approaches to content moderation in pursuit of freer standards of speech. The Gab social media platform arose in this context. Gab is a social media platform for the so-called alt right, and much of the popular press has opined about the thematic content of discourses on Gab and platforms like it, but little research has examined the content itself. Using a publicly available dataset of all Gab posts from August 2016 until July 2019, the current paper explores a five percent random sample of this dataset to explore thematic content on the platform. We run multiple structural topic models, using standard procedures to arrive at an optimal k number of topics. The final model specifies 85 topics for 403,469 documents. We include as prevalence variables whether the source account has been flagged as a bot and the number of followers for the source account. Results suggest the most nodal topics in the dataset pertain to the authenticity of the Holocaust, the meaning of red pill, and the journalistic merit of mainstream media. We conclude by discussing the implications of our findings for work in ethical content moderation, online community development, political polarization, and avenues for future research.",
    "lastUpdated": "2020-07-19T15:07:25Z",
    "categories": [
      "cs.SI"
    ],
    "url": "http://arxiv.org/abs/2007.09685v1"
  },
  {
    "title": "A Comprehensive Review of Deep Learning Applications in Hydrology and Water Resources",
    "authors": [
      "Muhammed Sit",
      "Bekir Z. Demiray",
      "Zhongrun Xiang",
      "Gregory J. Ewing",
      "Yusuf Sermet",
      "Ibrahim Demir"
    ],
    "abstract": "The global volume of digital data is expected to reach 175 zettabytes by 2025. The volume, variety, and velocity of water-related data are increasing due to large-scale sensor networks and increased attention to topics such as disaster response, water resources management, and climate change. Combined with the growing availability of computational resources and popularity of deep learning, these data are transformed into actionable and practical knowledge, revolutionizing the water industry. In this article, a systematic review of literature is conducted to identify existing research which incorporates deep learning methods in the water sector, with regard to monitoring, management, governance and communication of water resources. The study provides a comprehensive review of state-of-the-art deep learning approaches used in the water industry for generation, prediction, enhancement, and classification tasks, and serves as a guide for how to utilize available deep learning methods for future water resources challenges. Key issues and challenges in the application of these techniques in the water domain are discussed, including the ethics of these technologies for decision-making in water resources management and governance. Finally, we provide recommendations and future directions for the application of deep learning models in hydrology and water resources.",
    "lastUpdated": "2020-06-17T16:57:17Z",
    "categories": [
      "physics.geo-ph",
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2007.12269v1"
  },
  {
    "title": "A Recommendation and Risk Classification System for Connecting Rough Sleepers to Essential Outreach Services",
    "authors": [
      "Harrison Wilde",
      "Lucia Lushi Chen",
      "Austin Nguyen",
      "Zoe Kimpel",
      "Joshua Sidgwick",
      "Adolfo De Unanue",
      "Davide Veronese",
      "Bilal Mateen",
      "Rayid Ghani",
      "Sebastian Vollmer"
    ],
    "abstract": "Rough sleeping is a chronic problem faced by some of the most disadvantaged people in modern society. This paper describes work carried out in partnership with Homeless Link, a UK-based charity, in developing a data-driven approach to assess the quality of incoming alerts from members of the public aimed at connecting people sleeping rough on the streets with outreach service providers. Alerts are prioritised based on the predicted likelihood of successfully connecting with the rough sleeper, helping to address capacity limitations and to quickly, effectively, and equitably process all of the alerts that they receive. Initial evaluation concludes that our approach increases the rate at which rough sleepers are found following a referral by at least 15\\% based on labelled data, implying a greater overall increase when the alerts with unknown outcomes are considered, and suggesting the benefit in a trial taking place over a longer period to assess the models in practice. The discussion and modelling process is done with careful considerations of ethics, transparency and explainability due to the sensitive nature of the data in this context and the vulnerability of the people that are affected.",
    "lastUpdated": "2020-07-30T09:14:46Z",
    "categories": [
      "stat.AP",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2007.15326v1"
  },
  {
    "title": "Teaching Climate Change in a Physics Classroom: Towards a Transdisciplinary Approach",
    "authors": [
      "Vandana Singh"
    ],
    "abstract": "The climate crisis, along with biodiversity loss and other social-environmental concerns, presents an existential threat to humanity and the biosphere (IPCC 2014, 2018). Apart from scientific and technological aspects, climate change also presents concerns of ethics and justice. All of these call for urgent action, including effective education. Yet the developing field of climate pedagogy is beset with challenges, owing in part to the complex, transdisciplinary nature of the climate crisis, and the structural limitations of the education system. I describe pedagogical experiments conducted in a general physics undergraduate course towards a transdisciplinary reconceptualization of the climate crisis. I identify five barriers to teaching climate change that manifest in the undergraduate college classroom, and formulate four dimensions of an effective climate pedagogy: the scientific-technological, the transdisciplinary, the onto-epistemological, and the psychosocial action dimensions. I identify and align essential climate science concepts with standard topics in a general physics course, and foreground justice issues as a pathway to exploring how the climate crisis is connected to other disciplines and other social-ecological crises. Within the context of a collaborative classroom culture informed by transformational learning, I describe the use of a meta-conceptual framework that, along with the issue of climate justice, embraces all four dimensions of an effective climate pedagogy.",
    "lastUpdated": "2020-08-01T15:19:26Z",
    "categories": [
      "physics.ed-ph"
    ],
    "url": "http://arxiv.org/abs/2008.00281v1"
  },
  {
    "title": "Hierarchical Reinforcement Learning in StarCraft II with Human Expertise in Subgoals Selection",
    "authors": [
      "Xinyi Xu",
      "Tiancheng Huang",
      "Pengfei Wei",
      "Akshay Narayan",
      "Tze-Yun Leong"
    ],
    "abstract": "This work is inspired by recent advances in hierarchical reinforcement learning (HRL) (Barto and Mahadevan 2003; Hengst 2010), and improvements in learning efficiency from heuristic-based subgoal selection, experience replay (Lin 1993; Andrychowicz et al. 2017), and task-based curriculum learning (Bengio et al. 2009; Zaremba and Sutskever 2014). We propose a new method to integrate HRL, experience replay and effective subgoal selection through an implicit curriculum design based on human expertise to support sample-efficient learning and enhance interpretability of the agent's behavior. Human expertise remains indispensable in many areas such as medicine (Buch, Ahmed, and Maruthappu 2018) and law (Cath 2018), where interpretability, explainability and transparency are crucial in the decision making process, for ethical and legal reasons. Our method simplifies the complex task sets for achieving the overall objectives by decomposing them into subgoals at different levels of abstraction. Incorporating relevant subjective knowledge also significantly reduces the computational resources spent in exploration for RL, especially in high speed, changing, and complex environments where the transition dynamics cannot be effectively learned and modelled in a short time. Experimental results in two StarCraft II (SC2) (Vinyals et al. 2017) minigames demonstrate that our method can achieve better sample efficiency than flat and end-to-end RL methods, and provides an effective method for explaining the agent's performance.",
    "lastUpdated": "2020-09-29T01:15:05Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2008.03444v3"
  },
  {
    "title": "Comprehensiveness of Archives: A Modern AI-enabled Approach to Build Comprehensive Shared Cultural Heritage",
    "authors": [
      "Abhishek Gupta",
      "Nikitasha Kapoor"
    ],
    "abstract": "Archives play a crucial role in the construction and advancement of society. Humans place a great deal of trust in archives and depend on them to craft public policies and to preserve languages, cultures, self-identity, views and values. Yet, there are certain voices and viewpoints that remain elusive in the current processes deployed in the classification and discoverability of records and archives. In this paper, we explore the ramifications and effects of centralized, due process archival systems on marginalized communities. There is strong evidence to prove the need for progressive design and technological innovation while in the pursuit of comprehensiveness, equity and justice. Intentionality and comprehensiveness is our greatest opportunity when it comes to improving archival practices and for the advancement and thrive-ability of societies at large today. Intentionality and comprehensiveness is achievable with the support of technology and the Information Age we live in today. Reopening, questioning and/or purposefully including others voices in archival processes is the intention we present in our paper. We provide examples of marginalized communities who continue to lead \"community archive\" movements in efforts to reclaim and protect their cultural identity, knowledge, views and futures. In conclusion, we offer design and AI-dominant technological considerations worth further investigation in efforts to bridge systemic gaps and build robust archival processes.",
    "lastUpdated": "2020-08-11T06:35:23Z",
    "categories": [
      "cs.CY",
      "cs.DL",
      "cs.SI"
    ],
    "url": "http://arxiv.org/abs/2008.04541v1"
  },
  {
    "title": "Explainability in Deep Reinforcement Learning",
    "authors": [
      "Alexandre Heuillet",
      "Fabien Couthouis",
      "Natalia Díaz-Rodríguez"
    ],
    "abstract": "A large set of the explainable Artificial Intelligence (XAI) literature is emerging on feature relevance techniques to explain a deep neural network (DNN) output or explaining models that ingest image source data. However, assessing how XAI techniques can help understand models beyond classification tasks, e.g. for reinforcement learning (RL), has not been extensively studied. We review recent works in the direction to attain Explainable Reinforcement Learning (XRL), a relatively new subfield of Explainable Artificial Intelligence, intended to be used in general public applications, with diverse audiences, requiring ethical, responsible and trustable algorithms. In critical situations where it is essential to justify and explain the agent's behaviour, better explainability and interpretability of RL models could help gain scientific insight on the inner workings of what is still considered a black box. We evaluate mainly studies directly linking explainability to RL, and split these into two categories according to the way the explanations are generated: transparent algorithms and post-hoc explainaility. We also review the most prominent XAI works from the lenses of how they could potentially enlighten the further deployment of the latest advances in RL, in the demanding present and future of everyday problems.",
    "lastUpdated": "2020-12-18T10:08:51Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2008.06693v4"
  },
  {
    "title": "Tackling COVID-19 through Responsible AI Innovation: Five Steps in the Right Direction",
    "authors": [
      "David Leslie"
    ],
    "abstract": "Innovations in data science and AI/ML have a central role to play in supporting global efforts to combat COVID-19. The versatility of AI/ML technologies enables scientists and technologists to address an impressively broad range of biomedical, epidemiological, and socioeconomic challenges. This wide-reaching scientific capacity, however, also raises a diverse array of ethical challenges. The need for researchers to act quickly and globally in tackling SARS-CoV-2 demands unprecedented practices of open research and responsible data sharing at a time when innovation ecosystems are hobbled by proprietary protectionism, inequality, and a lack of public trust. Moreover, societally impactful interventions like digital contact tracing are raising fears of surveillance creep and are challenging widely held commitments to privacy, autonomy, and civil liberties. Prepandemic concerns that data-driven innovations may function to reinforce entrenched dynamics of societal inequity have likewise intensified given the disparate impact of the virus on vulnerable social groups and the life-and-death consequences of biased and discriminatory public health outcomes. To address these concerns, I offer five steps that need to be taken to encourage responsible research and innovation. These provide a practice-based path to responsible AI/ML design and discovery centered on open, accountable, equitable, and democratically governed processes and products. When taken from the start, these steps will not only enhance the capacity of innovators to tackle COVID-19 responsibly, they will, more broadly, help to better equip the data science and AI/ML community to cope with future pandemics and to support a more humane, rational, and just society.",
    "lastUpdated": "2020-08-15T17:26:48Z",
    "categories": [
      "cs.CY",
      "cs.LG",
      "stat.OT"
    ],
    "url": "http://arxiv.org/abs/2008.06755v1"
  },
  {
    "title": "Intelligence Primer",
    "authors": [
      "Karl Fezer",
      "Andrew Sloss"
    ],
    "abstract": "This primer explores the exciting subject of intelligence. Intelligence is a fundamental component of all living things, as well as Artificial Intelligence(AI). Artificial Intelligence has the potential to affect all of our lives and a new era for modern humans. This paper is an attempt to explore the ideas associated with intelligence, and by doing so understand the implications, constraints, and potentially the capabilities of future Artificial Intelligence. As an exploration, we journey into different parts of intelligence that appear essential. We hope that people find this useful in determining where Artificial Intelligence may be headed. Also, during the exploration, we hope to create new thought-provoking questions. Intelligence is not a single weighable quantity but a subject that spans Biology, Physics, Philosophy, Cognitive Science, Neuroscience, Psychology, and Computer Science. Historian Yuval Noah Harari pointed out that engineers and scientists in the future will have to broaden their understandings to include disciplines such as Psychology, Philosophy, and Ethics. Fiction writers have long portrayed engineers and scientists as deficient in these areas. Today, modern society, the emergence of Artificial Intelligence, and legal requirements all act as forcing functions to push these broader subjects into the foreground. We start with an introduction to intelligence and move quickly onto more profound thoughts and ideas. We call this a Life, the Universe and Everything primer, after the famous science fiction book by Douglas Adams. Forty-two may very well be the right answer, but what are the questions?",
    "lastUpdated": "2020-08-18T17:04:46Z",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2008.07324v2"
  },
  {
    "title": "CalciumGAN: A Generative Adversarial Network Model for Synthesising Realistic Calcium Imaging Data of Neuronal Populations",
    "authors": [
      "Bryan M. Li",
      "Theoklitos Amvrosiadis",
      "Nathalie Rochefort",
      "Arno Onken"
    ],
    "abstract": "Calcium imaging has become a powerful and popular technique to monitor the activity of large populations of neurons in vivo. However, for ethical considerations and despite recent technical developments, recordings are still constrained to a limited number of trials and animals. This limits the amount of data available from individual experiments and hinders the development of analysis techniques and models for more realistic size of neuronal populations. The ability to artificially synthesize realistic neuronal calcium signals could greatly alleviate this problem by scaling up the number of trials. Here we propose a Generative Adversarial Network (GAN) model to generate realistic calcium signals as seen in neuronal somata with calcium imaging. To this end, we adapt the WaveGAN architecture and train it with the Wasserstein distance. We test the model on artificial data with known ground-truth and show that the distribution of the generated signals closely resembles the underlying data distribution. Then, we train the model on real calcium signals recorded from the primary visual cortex of behaving mice and confirm that the deconvolved spike trains match the statistics of the recorded data. Together, these results demonstrate that our model can successfully generate realistic calcium imaging data, thereby providing the means to augment existing datasets of neuronal activity for enhanced data exploration and modeling.",
    "lastUpdated": "2020-09-08T03:58:43Z",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2009.02707v2"
  },
  {
    "title": "Justifications for Goal-Directed Constraint Answer Set Programming",
    "authors": [
      "Joaquín Arias",
      "Manuel Carro",
      "Zhuo Chen",
      "Gopal Gupta"
    ],
    "abstract": "Ethical and legal concerns make it necessary for programs that may directly influence the life of people (via, e.g., legal or health counseling) to justify in human-understandable terms the advice given. Answer Set Programming has a rich semantics that makes it possible to very concisely express complex knowledge. However, justifying why an answer is a consequence from an ASP program may be non-trivial -- even more so when the user is an expert in a given domain, but not necessarily knowledgeable in ASP. Most ASP systems generate answers using SAT-solving procedures on ground rules that do not match how humans perceive reasoning. We propose using s(CASP), a query-driven, top-down execution model for predicate ASP with constraints to generate justification trees of (constrained) answer sets. The operational semantics of s(CASP) relies on backward chaining, which is intuitive to follow and lends itself to generating explanations that are easier to translate into natural language. We show how s(CASP) provides minimal justifications for, among others, relevant examples proposed in the literature, both as search trees but, more importantly, as explanations in natural language. We validate our design with real ASP applications and evaluate the cost of generating s(CASP) justification trees.",
    "lastUpdated": "2020-09-22T00:48:05Z",
    "categories": [
      "cs.LO",
      "cs.PL"
    ],
    "url": "http://arxiv.org/abs/2009.10238v1"
  },
  {
    "title": "The Role of Isomorphism Classes in Multi-Relational Datasets",
    "authors": [
      "Vijja Wichitwechkarn",
      "Ben Day",
      "Cristian Bodnar",
      "Matthew Wales",
      "Pietro Liò"
    ],
    "abstract": "Multi-interaction systems abound in nature, from colloidal suspensions to gene regulatory circuits. These systems can produce complex dynamics and graph neural networks have been proposed as a method to extract underlying interactions and predict how systems will evolve. The current training and evaluation procedures for these models through the use of synthetic multi-relational datasets however are agnostic to interaction network isomorphism classes, which produce identical dynamics up to initial conditions. We extensively analyse how isomorphism class awareness affects these models, focusing on neural relational inference (NRI) models, which are unique in explicitly inferring interactions to predict dynamics in the unsupervised setting. Specifically, we demonstrate that isomorphism leakage overestimates performance in multi-relational inference and that sampling biases present in the multi-interaction network generation process can impair generalisation. To remedy this, we propose isomorphism-aware synthetic benchmarks for model evaluation. We use these benchmarks to test generalisation abilities and demonstrate the existence of a threshold sampling frequency of isomorphism classes for successful learning. In addition, we demonstrate that isomorphism classes can be utilised through a simple prioritisation scheme to improve model performance, stability during training and reduce training time.",
    "lastUpdated": "2020-09-30T12:15:24Z",
    "categories": [
      "cs.LG",
      "cs.SI",
      "physics.soc-ph",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2009.14593v1"
  },
  {
    "title": "Metadata-Based Detection of Child Sexual Abuse Material",
    "authors": [
      "Mayana Pereira",
      "Rahul Dodhia",
      "Richard Brown"
    ],
    "abstract": "In the last decade, the scale of creation and distribution of child sexual abuse medias (CSAM) has exponentially increased. Technologies that aid law enforcement agencies worldwide to identify such crimes rapidly can potentially result in the mitigation of child victimization, and the apprehending of offenders. Machine learning presents the potential to help law enforcement rapidly identify such material, and even block such content from being distributed digitally. However, collecting and storing CSAM files to train machine learning models has many ethical and legal constraints, creating a barrier to the development of accurate computer vision-based models. With such restrictions in place, the development of accurate machine learning classifiers for CSAM identification based on file metadata becomes crucial. In this work, we propose a system for CSAM identification on file storage systems based solely on metadata - file paths. Our aim is to provide a tool that is material type agnostic (image, video, PDF), and can potentially scans thousands of file storage systems in a short time. Our approach uses convolutional neural networks, and achieves an accuracy of 97% and recall of 94%. Additionally, we address the potential problem of offenders trying to evade detection by this model by evaluating the robustness of our model against adversarial modifications in the file paths.",
    "lastUpdated": "2020-10-05T23:10:21Z",
    "categories": [
      "cs.LG",
      "cs.CR",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2010.02387v1"
  },
  {
    "title": "FaiR-N: Fair and Robust Neural Networks for Structured Data",
    "authors": [
      "Shubham Sharma",
      "Alan H. Gee",
      "David Paydarfar",
      "Joydeep Ghosh"
    ],
    "abstract": "Fairness in machine learning is crucial when individuals are subject to automated decisions made by models in high-stake domains. Organizations that employ these models may also need to satisfy regulations that promote responsible and ethical A.I. While fairness metrics relying on comparing model error rates across subpopulations have been widely investigated for the detection and mitigation of bias, fairness in terms of the equalized ability to achieve recourse for different protected attribute groups has been relatively unexplored. We present a novel formulation for training neural networks that considers the distance of data points to the decision boundary such that the new objective: (1) reduces the average distance to the decision boundary between two groups for individuals subject to a negative outcome in each group, i.e. the network is more fair with respect to the ability to obtain recourse, and (2) increases the average distance of data points to the boundary to promote adversarial robustness. We demonstrate that training with this loss yields more fair and robust neural networks with similar accuracies to models trained without it. Moreover, we qualitatively motivate and empirically show that reducing recourse disparity across groups also improves fairness measures that rely on error rates. To the best of our knowledge, this is the first time that recourse capabilities across groups are considered to train fairer neural networks, and a relation between error rates based fairness and recourse based fairness is investigated.",
    "lastUpdated": "2020-10-13T01:53:15Z",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2010.06113v1"
  },
  {
    "title": "Understanding bias in facial recognition technologies",
    "authors": [
      "David Leslie"
    ],
    "abstract": "Over the past couple of years, the growing debate around automated facial recognition has reached a boiling point. As developers have continued to swiftly expand the scope of these kinds of technologies into an almost unbounded range of applications, an increasingly strident chorus of critical voices has sounded concerns about the injurious effects of the proliferation of such systems. Opponents argue that the irresponsible design and use of facial detection and recognition technologies (FDRTs) threatens to violate civil liberties, infringe on basic human rights and further entrench structural racism and systemic marginalisation. They also caution that the gradual creep of face surveillance infrastructures into every domain of lived experience may eventually eradicate the modern democratic forms of life that have long provided cherished means to individual flourishing, social solidarity and human self-creation. Defenders, by contrast, emphasise the gains in public safety, security and efficiency that digitally streamlined capacities for facial identification, identity verification and trait characterisation may bring. In this explainer, I focus on one central aspect of this debate: the role that dynamics of bias and discrimination play in the development and deployment of FDRTs. I examine how historical patterns of discrimination have made inroads into the design and implementation of FDRTs from their very earliest moments. And, I explain the ways in which the use of biased FDRTs can lead distributional and recognitional injustices. The explainer concludes with an exploration of broader ethical questions around the potential proliferation of pervasive face-based surveillance infrastructures and makes some recommendations for cultivating more responsible approaches to the development and governance of these technologies.",
    "lastUpdated": "2020-10-05T20:45:46Z",
    "categories": [
      "cs.CY",
      "cs.CV",
      "cs.DB"
    ],
    "url": "http://arxiv.org/abs/2010.07023v1"
  },
  {
    "title": "Monitoring Trust in Human-Machine Interactions for Public Sector Applications",
    "authors": [
      "Farhana Faruqe",
      "Ryan Watkins",
      "Larry Medsker"
    ],
    "abstract": "The work reported here addresses the capacity of psychophysiological sensors and measures using Electroencephalogram (EEG) and Galvanic Skin Response (GSR) to detect levels of trust for humans using AI-supported Human-Machine Interaction (HMI). Improvements to the analysis of EEG and GSR data may create models that perform as well, or better than, traditional tools. A challenge to analyzing the EEG and GSR data is the large amount of training data required due to a large number of variables in the measurements. Researchers have routinely used standard machine-learning classifiers like artificial neural networks (ANN), support vector machines (SVM), and K-nearest neighbors (KNN). Traditionally, these have provided few insights into which features of the EEG and GSR data facilitate the more and least accurate predictions - thus making it harder to improve the HMI and human-machine trust relationship. A key ingredient to applying trust-sensor research results to practical situations and monitoring trust in work environments is the understanding of which key features are contributing to trust and then reducing the amount of data needed for practical applications. We used the Local Interpretable Model-agnostic Explanations (LIME) model as a process to reduce the volume of data required to monitor and enhance trust in HMI systems - a technology that could be valuable for governmental and public sector applications. Explainable AI can make HMI systems transparent and promote trust. From customer service in government agencies and community-level non-profit public service organizations to national military and cybersecurity institutions, many public sector organizations are increasingly concerned to have effective and ethical HMI with services that are trustworthy, unbiased, and free of unintended negative consequences.",
    "lastUpdated": "2020-10-16T03:59:28Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2010.08140v1"
  },
  {
    "title": "Value Cards: An Educational Toolkit for Teaching Social Impacts of Machine Learning through Deliberation",
    "authors": [
      "Hong Shen",
      "Hanwen Wesley Deng",
      "Aditi Chattopadhyay",
      "Zhiwei Steven Wu",
      "Xu Wang",
      "Haiyi Zhu"
    ],
    "abstract": "Recently, there have been increasing calls for computer science curricula to complement existing technical training with topics related to Fairness, Accountability, Transparency, and Ethics. In this paper, we present Value Card, an educational toolkit to inform students and practitioners of the social impacts of different machine learning models via deliberation. This paper presents an early use of our approach in a college-level computer science course. Through an in-class activity, we report empirical data for the initial effectiveness of our approach. Our results suggest that the use of the Value Cards toolkit can improve students' understanding of both the technical definitions and trade-offs of performance metrics and apply them in real-world contexts, help them recognize the significance of considering diverse social values in the development of deployment of algorithmic systems, and enable them to communicate, negotiate and synthesize the perspectives of diverse stakeholders. Our study also demonstrates a number of caveats we need to consider when using the different variants of the Value Cards toolkit. Finally, we discuss the challenges as well as future applications of our approach.",
    "lastUpdated": "2020-11-21T08:45:37Z",
    "categories": [
      "cs.CY",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2010.11411v2"
  },
  {
    "title": "Revolutionizing Medical Data Sharing Using Advanced Privacy Enhancing Technologies: Technical, Legal and Ethical Synthesis",
    "authors": [
      "James Scheibner",
      "Jean Louis Raisaro",
      "Juan Ramón Troncoso-Pastoriza",
      "Marcello Ienca",
      "Jacques Fellay",
      "Effy Vayena",
      "Jean-Pierre Hubaux"
    ],
    "abstract": "Multisite medical data sharing is critical in modern clinical practice and medical research. The challenge is to conduct data sharing that preserves individual privacy and data usability. The shortcomings of traditional privacy-enhancing technologies mean that institutions rely on bespoke data sharing contracts. These contracts increase the inefficiency of data sharing and may disincentivize important clinical treatment and medical research. This paper provides a synthesis between two novel advanced privacy enhancing technologies (PETs): Homomorphic Encryption and Secure Multiparty Computation (defined together as Multiparty Homomorphic Encryption or MHE). These PETs provide a mathematical guarantee of privacy, with MHE providing a performance advantage over separately using HE or SMC. We argue MHE fulfills legal requirements for medical data sharing under the General Data Protection Regulation (GDPR) which has set a global benchmark for data protection. Specifically, the data processed and shared using MHE can be considered anonymized data. We explain how MHE can reduce the reliance on customized contractual measures between institutions. The proposed approach can accelerate the pace of medical research whilst offering additional incentives for healthcare and research institutes to employ common data interoperability standards.",
    "lastUpdated": "2020-10-27T17:03:28Z",
    "categories": [
      "cs.CR",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2010.14445v1"
  },
  {
    "title": "Behavioral Use Licensing for Responsible AI",
    "authors": [
      "Danish Contractor",
      "Daniel McDuff",
      "Julia Haines",
      "Jenny Lee",
      "Christopher Hines",
      "Brent Hecht"
    ],
    "abstract": "Scientific research and development relies on the sharing of ideas and artifacts. With the growing reliance on artificial intelligence (AI) for many different applications, the sharing of code, data, and models is important to ensure the ability to replicate methods and the democratization of scientific knowledge. Many high-profile journals and conferences expect code to be submitted and released with papers. Furthermore, developers often want to release code and models to encourage development of technology that leverages their frameworks and services. However, AI algorithms are becoming increasingly powerful and generalized. Ultimately, the context in which an algorithm is applied can be far removed from that which the developers had intended. A number of organizations have expressed concerns about inappropriate or irresponsible use of AI and have proposed AI ethical guidelines and responsible AI initiatives. While such guidelines are useful and help shape policy, they are not easily enforceable. Governments have taken note of the risks associated with certain types of AI applications and have passed legislation. While these are enforceable, they require prolonged scientific and political deliberation. In this paper we advocate the use of licensing to enable legally enforceable behavioral use conditions on software and data. We argue that licenses serve as a useful tool for enforcement in situations where it is difficult or time-consuming to legislate AI usage. Furthermore, by using such licenses, AI developers provide a signal to the AI community, as well as governmental bodies, that they are taking responsibility for their technologies and are encouraging responsible use by downstream users.",
    "lastUpdated": "2020-11-04T09:23:28Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2011.03116v1"
  },
  {
    "title": "Deep Convolutional Neural Networks: A survey of the foundations, selected improvements, and some current applications",
    "authors": [
      "Lars Lien Ankile",
      "Morgan Feet Heggland",
      "Kjartan Krange"
    ],
    "abstract": "Within the world of machine learning there exists a wide range of different methods with respective advantages and applications. This paper seeks to present and discuss one such method, namely Convolutional Neural Networks (CNNs). CNNs are deep neural networks that use a special linear operation called convolution. This operation represents a key and distinctive element of CNNs, and will therefore be the focus of this method paper. The discussion starts with the theoretical foundations that underlie convolutions and CNNs. Then, the discussion proceeds to discuss some improvements and augmentations that can be made to adapt the method to estimate a wider set of function classes. The paper mainly investigates two ways of improving the method: by using locally connected layers, which can make the network less invariant to translation, and tiled convolution, which allows for the learning of more complex invariances than standard convolution. Furthermore, the use of the Fast Fourier Transform can improve the computational efficiency of convolution. Subsequently, this paper discusses two applications of convolution that have proven to be very effective in practice. First, the YOLO architecture is a state of the art neural network for image object classification, which accurately predicts bounding boxes around objects in images. Second, tumor detection in mammography may be performed using CNNs, accomplishing 7.2% higher specificity than actual doctors with only .3% less sensitivity. Finally, the invention of technology that outperforms humans in different fields also raises certain ethical and regulatory questions that are briefly discussed.",
    "lastUpdated": "2020-11-25T19:03:23Z",
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2011.12960v1"
  },
  {
    "title": "Achievements and Challenges in Explaining Deep Learning based Computer-Aided Diagnosis Systems",
    "authors": [
      "Adriano Lucieri",
      "Muhammad Naseer Bajwa",
      "Andreas Dengel",
      "Sheraz Ahmed"
    ],
    "abstract": "Remarkable success of modern image-based AI methods and the resulting interest in their applications in critical decision-making processes has led to a surge in efforts to make such intelligent systems transparent and explainable. The need for explainable AI does not stem only from ethical and moral grounds but also from stricter legislation around the world mandating clear and justifiable explanations of any decision taken or assisted by AI. Especially in the medical context where Computer-Aided Diagnosis can have a direct influence on the treatment and well-being of patients, transparency is of utmost importance for safe transition from lab research to real world clinical practice. This paper provides a comprehensive overview of current state-of-the-art in explaining and interpreting Deep Learning based algorithms in applications of medical research and diagnosis of diseases. We discuss early achievements in development of explainable AI for validation of known disease criteria, exploration of new potential biomarkers, as well as methods for the subsequent correction of AI models. Various explanation methods like visual, textual, post-hoc, ante-hoc, local and global have been thoroughly and critically analyzed. Subsequently, we also highlight some of the remaining challenges that stand in the way of practical applications of AI as a clinical decision support tool and provide recommendations for the direction of future research.",
    "lastUpdated": "2020-11-26T08:08:19Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2011.13169v1"
  },
  {
    "title": "Transdisciplinary AI Observatory -- Retrospective Analyses and Future-Oriented Contradistinctions",
    "authors": [
      "Nadisha-Marie Aliman",
      "Leon Kester",
      "Roman Yampolskiy"
    ],
    "abstract": "In the last years, AI safety gained international recognition in the light of heterogeneous safety-critical and ethical issues that risk overshadowing the broad beneficial impacts of AI. In this context, the implementation of AI observatory endeavors represents one key research direction. This paper motivates the need for an inherently transdisciplinary AI observatory approach integrating diverse retrospective and counterfactual views. We delineate aims and limitations while providing hands-on-advice utilizing concrete practical examples. Distinguishing between unintentionally and intentionally triggered AI risks with diverse socio-psycho-technological impacts, we exemplify a retrospective descriptive analysis followed by a retrospective counterfactual risk analysis. Building on these AI observatory tools, we present near-term transdisciplinary guidelines for AI safety. As further contribution, we discuss differentiated and tailored long-term directions through the lens of two disparate modern AI safety paradigms. For simplicity, we refer to these two different paradigms with the terms artificial stupidity (AS) and eternal creativity (EC) respectively. While both AS and EC acknowledge the need for a hybrid cognitive-affective approach to AI safety and overlap with regard to many short-term considerations, they differ fundamentally in the nature of multiple envisaged long-term solution patterns. By compiling relevant underlying contradistinctions, we aim to provide future-oriented incentives for constructive dialectics in practical and theoretical AI safety research.",
    "lastUpdated": "2020-12-07T02:23:13Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2012.02592v2"
  },
  {
    "title": "Brain Co-Processors: Using AI to Restore and Augment Brain Function",
    "authors": [
      "Rajesh P. N. Rao"
    ],
    "abstract": "Brain-computer interfaces (BCIs) use decoding algorithms to control prosthetic devices based on brain signals for restoration of lost function. Computer-brain interfaces (CBIs), on the other hand, use encoding algorithms to transform external sensory signals into neural stimulation patterns for restoring sensation or providing sensory feedback for closed-loop prosthetic control. In this article, we introduce brain co-processors, devices that combine decoding and encoding in a unified framework using artificial intelligence (AI) to supplement or augment brain function. Brain co-processors can be used for a range of applications, from inducing Hebbian plasticity for rehabilitation after brain injury to reanimating paralyzed limbs and enhancing memory. A key challenge is simultaneous multi-channel neural decoding and encoding for optimization of external behavioral or task-related goals. We describe a new framework for developing brain co-processors based on artificial neural networks, deep learning and reinforcement learning. These \"neural co-processors\" allow joint optimization of cost functions with the nervous system to achieve desired behaviors. By coupling artificial neural networks with their biological counterparts, neural co-processors offer a new way of restoring and augmenting the brain, as well as a new scientific tool for brain research. We conclude by discussing the potential applications and ethical implications of brain co-processors.",
    "lastUpdated": "2020-12-06T21:06:28Z",
    "categories": [
      "cs.AI",
      "cs.NE",
      "nlin.AO",
      "q-bio.NC"
    ],
    "url": "http://arxiv.org/abs/2012.03378v1"
  },
  {
    "title": "Digital Contact Tracing: Technologies, Shortcomings, and the Path Forward",
    "authors": [
      "Amee Trivedi",
      "Deepak Vasisht"
    ],
    "abstract": "Since the start of the COVID-19 pandemic, technology enthusiasts have pushed for digital contact tracing as a critical tool for breaking the COVID-19 transmission chains. Motivated by this push, many countries and companies have created apps that enable digital contact tracing with the goal to identify the chain of transmission from an infected individual to others and enable early quarantine. Digital contact tracing applications like AarogyaSetu in India, TraceTogether in Singapore, SwissCovid in Switzerland, and others have been downloaded hundreds of millions of times. Yet, this technology hasn't seen the impact that we envisioned at the start of the pandemic. Some countries have rolled back their apps, while others have seen low adoption. Therefore, it is prudent to ask what the technology landscape of contact-tracing looks like and what are the missing pieces. We attempt to undertake this task in this paper. We present a high-level review of technologies underlying digital contact tracing, a set of metrics that are important while evaluating different contact tracing technologies, and evaluate where the different technologies stand today on this set of metrics. Our hope is two-fold: (a) Future designers of contact tracing applications can use this review paper to understand the technology landscape, and (b) Researchers can identify and solve the missing pieces of this puzzle so that we are ready to face the rest of the COVID-19 pandemic and any future pandemics. A majority of this discussion is focused on the ability to identify contact between individuals. The questions of ethics, privacy, and security of such contact tracing are briefly mentioned but not discussed in detail.",
    "lastUpdated": "2020-12-11T16:36:34Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2012.06466v1"
  },
  {
    "title": "Tutorial: Introduction to computational causal inference using reproducible Stata, R and Python code",
    "authors": [
      "Matthew J. Smith",
      "Camille Maringe",
      "Bernard Rachet",
      "Mohammad A. Mansournia",
      "Paul N. Zivich",
      "Stephen R. Cole",
      "Miguel Angel Luque-Fernandez"
    ],
    "abstract": "The purpose of many health studies is to estimate the effect of an exposure on an outcome. It is not always ethical to assign an exposure to individuals in randomised controlled trials, instead observational data and appropriate study design must be used. There are major challenges with observational studies, one of which is confounding that can lead to biased estimates of the causal effects. Controlling for confounding is commonly performed by simple adjustment for measured confounders; although, often this is not enough. Recent advances in the field of causal inference have dealt with confounding by building on classical standardisation methods. However, these recent advances have progressed quickly with a relative paucity of computational-oriented applied tutorials contributing to some confusion in the use of these methods among applied researchers. In this tutorial, we show the computational implementation of different causal inference estimators from a historical perspective where different estimators were developed to overcome the limitations of the previous one. Furthermore, we also briefly introduce the potential outcomes framework, illustrate the use of different methods using an illustration from the health care setting, and most importantly, we provide reproducible and commented code in Stata, R and Python for researchers to apply in their own observational study. The code can be accessed at https://github.com/migariane/TutorialCausalInferenceEstimators",
    "lastUpdated": "2020-12-21T17:01:06Z",
    "categories": [
      "stat.ME",
      "stat.CO"
    ],
    "url": "http://arxiv.org/abs/2012.09920v2"
  },
  {
    "title": "BENN: Bias Estimation Using Deep Neural Network",
    "authors": [
      "Amit Giloni",
      "Edita Grolman",
      "Tanja Hagemann",
      "Ronald Fromm",
      "Sebastian Fischer",
      "Yuval Elovici",
      "Asaf Shabtai"
    ],
    "abstract": "The need to detect bias in machine learning (ML) models has led to the development of multiple bias detection methods, yet utilizing them is challenging since each method: i) explores a different ethical aspect of bias, which may result in contradictory output among the different methods, ii) provides an output of a different range/scale and therefore, can't be compared with other methods, and iii) requires different input, and therefore a human expert needs to be involved to adjust each method according to the examined model. In this paper, we present BENN -- a novel bias estimation method that uses a pretrained unsupervised deep neural network. Given a ML model and data samples, BENN provides a bias estimation for every feature based on the model's predictions. We evaluated BENN using three benchmark datasets and one proprietary churn prediction model used by a European Telco and compared it with an ensemble of 21 existing bias estimation methods. Evaluation results highlight the significant advantages of BENN over the ensemble, as it is generic (i.e., can be applied to any ML model) and there is no need for a domain expert, yet it provides bias estimations that are aligned with those of the ensemble.",
    "lastUpdated": "2020-12-23T08:25:35Z",
    "categories": [
      "cs.LG",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2012.12537v1"
  },
  {
    "title": "AI Development Race Can Be Mediated on Heterogeneous Networks",
    "authors": [
      "Theodor Cimpeanu",
      "Francisco C. Santos",
      "Luis Moniz Pereira",
      "Tom Lenaerts",
      "The Anh Han"
    ],
    "abstract": "The field of Artificial Intelligence (AI) has been introducing a certain level of anxiety in research, business and also policy. Tensions are further heightened by an AI race narrative which makes many stakeholders fear that they might be missing out. Whether real or not, a belief in this narrative may be detrimental as some stakeholders will feel obliged to cut corners on safety precautions or ignore societal consequences. Starting from a game-theoretical model describing an idealised technology race in a well-mixed world, here we investigate how different interaction structures among race participants can alter collective choices and requirements for regulatory actions. Our findings indicate that, when participants portray a strong diversity in terms of connections and peer-influence (e.g., when scale-free networks shape interactions among parties), the conflicts that exist in homogeneous settings are significantly reduced, thereby lessening the need for regulatory actions. Furthermore, our results suggest that technology governance and regulation may profit from the world's patent heterogeneity and inequality among firms and nations to design and implement meticulous interventions on a minority of participants capable of influencing an entire population towards an ethical and sustainable use of AI.",
    "lastUpdated": "2020-12-30T17:23:18Z",
    "categories": [
      "cs.AI",
      "cs.GT"
    ],
    "url": "http://arxiv.org/abs/2012.15234v1"
  },
  {
    "title": "Fairness in Machine Learning",
    "authors": [
      "Luca Oneto",
      "Silvia Chiappa"
    ],
    "abstract": "Machine learning based systems are reaching society at large and in many aspects of everyday life. This phenomenon has been accompanied by concerns about the ethical issues that may arise from the adoption of these technologies. ML fairness is a recently established area of machine learning that studies how to ensure that biases in the data and model inaccuracies do not lead to models that treat individuals unfavorably on the basis of characteristics such as e.g. race, gender, disabilities, and sexual or political orientation. In this manuscript, we discuss some of the limitations present in the current reasoning about fairness and in methods that deal with it, and describe some work done by the authors to address them. More specifically, we show how causal Bayesian networks can play an important role to reason about and deal with fairness, especially in complex unfairness scenarios. We describe how optimal transport theory can be used to develop methods that impose constraints on the full shapes of distributions corresponding to different sensitive attributes, overcoming the limitation of most approaches that approximate fairness desiderata by imposing constraints on the lower order moments or other functions of those distributions. We present a unified framework that encompasses methods that can deal with different settings and fairness criteria, and that enjoys strong theoretical guarantees. We introduce an approach to learn fair representations that can generalize to unseen tasks. Finally, we describe a technique that accounts for legal restrictions about the use of sensitive attributes.",
    "lastUpdated": "2020-12-31T18:38:58Z",
    "categories": [
      "cs.LG",
      "cs.CY",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2012.15816v1"
  },
  {
    "title": "From Learning to Relearning: A Framework for Diminishing Bias in Social Robot Navigation",
    "authors": [
      "Juana Valeria Hurtado",
      "Laura Londoño",
      "Abhinav Valada"
    ],
    "abstract": "The exponentially increasing advances in robotics and machine learning are facilitating the transition of robots from being confined to controlled industrial spaces to performing novel everyday tasks in domestic and urban environments. In order to make the presence of robots safe as well as comfortable for humans, and to facilitate their acceptance in public environments, they are often equipped with social abilities for navigation and interaction. Socially compliant robot navigation is increasingly being learned from human observations or demonstrations. We argue that these techniques that typically aim to mimic human behavior do not guarantee fair behavior. As a consequence, social navigation models can replicate, promote, and amplify societal unfairness such as discrimination and segregation. In this work, we investigate a framework for diminishing bias in social robot navigation models so that robots are equipped with the capability to plan as well as adapt their paths based on both physical and social demands. Our proposed framework consists of two components: learning which incorporates social context into the learning process to account for safety and comfort, and relearning to detect and correct potentially harmful outcomes before the onset. We provide both technological and sociological analysis using three diverse case studies in different social scenarios of interaction. Moreover, we present ethical implications of deploying robots in social environments and propose potential solutions. Through this study, we highlight the importance and advocate for fairness in human-robot interactions in order to promote more equitable social relationships, roles, and dynamics and consequently positively influence our society.",
    "lastUpdated": "2021-01-07T17:42:35Z",
    "categories": [
      "cs.RO",
      "cs.CV",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2101.02647v1"
  },
  {
    "title": "Estimating the Causal Effects of Marketing Interventions Using Propensity Score Methodology",
    "authors": [
      "Donald B. Rubin",
      "Richard P. Waterman"
    ],
    "abstract": "Propensity score methods were proposed by Rosenbaum and Rubin [Biometrika 70 (1983) 41--55] as central tools to help assess the causal effects of interventions. Since their introduction more than two decades ago, they have found wide application in a variety of areas, including medical research, economics, epidemiology and education, especially in those situations where randomized experiments are either difficult to perform, or raise ethical questions, or would require extensive delays before answers could be obtained. In the past few years, the number of published applications using propensity score methods to evaluate medical and epidemiological interventions has increased dramatically. Nevertheless, thus far, we believe that there have been few applications of propensity score methods to evaluate marketing interventions (e.g., advertising, promotions), where the tradition is to use generally inappropriate techniques, which focus on the prediction of an outcome from background characteristics and an indicator for the intervention using statistical tools such as least-squares regression, data mining, and so on. With these techniques, an estimated parameter in the model is used to estimate some global ``causal'' effect. This practice can generate grossly incorrect answers that can be self-perpetuating: polishing the Ferraris rather than the Jeeps ``causes'' them to continue to win more races than the Jeeps $\\Leftrightarrow$ visiting the high-prescribing doctors rather than the low-prescribing doctors ``causes'' them to continue to write more prescriptions. This presentation will take ``causality'' seriously, not just as a casual concept implying some predictive association in a data set, and will illustrate why propensity score methods are generally superior in practice to the standard predictive approaches for estimating causal effects.",
    "lastUpdated": "2006-09-07T10:48:38Z",
    "categories": [
      "math.ST",
      "stat.TH"
    ],
    "url": "http://arxiv.org/abs/math/0609201v1"
  },
  {
    "title": "On the Unfathomableness of Consciousness by Consciousness: Why do physicists widely agree on the assured extent of their professional knowledge, but not so philosophers? An exchange of letters with Carl Friedrich von Weizsaecker",
    "authors": [
      "Klaus Gottstein"
    ],
    "abstract": "On the occasion of Carl Friedrich von Weizsaecker's 81st birthday, a colloquium was held on July 3, 1993. One of the topics was \"The epistemological foundation of physics from Kant to von Weizsaecker\". I took part in the discussion. Afterwards I got the impression that I had not succeeded in making my points clear. Therefore, I wrote an explanatory letter to Prof. von Weizsaecker. This was the beginning of a correspondence on the questions intimated by the title above. In addition, a private discussion between Prof. von Weizsaecker and myself took place. Some readers may be interested in the answers which Carl Friedrich von Weizsaecker has given to the naive questions and views of a physicist with only a rudimentary education in philosophy. The starting point of our discussion was my remark that the conspicuous inability of philosophers to agree on the deepest elements of human existence including the basic questions of ethics, which is tantamount to the occurrence of different schools of philosophy competing with each other, could perhaps be traced back to the fundamental inability of man to attain self-knowledge. Physicists, on the other hand, can reach consent, in an equally remarkable way, on the results of their measurements and on whether or not these results agree with the ideas of theory. They just have to deal with res extensa. Here the yardstick does not intend to measure itself, but objects which are external to it, and this is possible. There remains only the question what consequences can be drawn from this realization. Is philosophy, in as much as it gives statements on the totality of human existence, only an expression of the prevailing social circumstances and views, interesting enough as such, but not a gateway to truth?",
    "lastUpdated": "2006-10-02T14:40:44Z",
    "categories": [
      "physics.soc-ph"
    ],
    "url": "http://arxiv.org/abs/physics/0610011v1"
  },
  {
    "title": "Characterisation of placental malaria in olive baboons (Papio anubis) infected with Plasmodium knowlesi H strain",
    "authors": [
      "Barasa Mustafa",
      "Gicheru Muita MichaeL",
      "Kagasi Ambogo Esther",
      "Ozwara Suba Hastings"
    ],
    "abstract": "Pregnant women have increased susceptibility to malaria infection. In these women, malaria parasites are frequently found sequestered in the placental intervillous spaces, a condition referred to as placental malaria (PM). Placental malaria threatens the health of the mother and the child's life by causing still births and reduction in gestational age. An estimated 24 million pregnant women in Sub-Saharan Africa are at risk. Mechanisms responsible for increased susceptibility in pregnant women are not fully understood. Pregnancy malaria studies have been limited by the lack of a suitable animal model. This research aimed to develop a baboon (Papio anubis) model for studying PM. The pregnancies of three adult female baboons were synchronized and their gestational levels confirmed by ultrasonography. On the 150th day of gestation the pregnant baboons were infected with Plasmodium knowlesi H strain parasites together with four nulligravid control baboons. Parasitaemia was monitored from two days post inoculation until the 159th day of gestation when caesarean section was done on one baboon in order to obtain the placenta. Two baboons aborted their conceptus. Smears prepared from placental blood demonstrated the presence of Plasmodium knowlesi parasites in all the three sampled placentas. These new findings show that P. knowlesi sequesters in the baboon placenta. In addition, this study has characterized haemoglobin, eosinophil, Immunoglobulin G and Immunoglobulin M profiles in this model. Thus a non human primate (baboon) model for studying PM has been established. The established baboon - P. knowlesi model for studying human placental/pregnancy malaria now offers an opportunity for circumventing the obstacles experienced during human studies like having inadequate tissue for analysis, inaccurate estimation of gestational age, moral, ethical and financial limitations.",
    "lastUpdated": "2012-04-17T08:10:37Z",
    "categories": [
      "q-bio.CB"
    ],
    "url": "http://arxiv.org/abs/1204.3126v2"
  },
  {
    "title": "FuturICT",
    "authors": [
      "Dirk Helbing",
      "Steven Bishop",
      "Paul Lukowicz",
      "the FuturICT Consortium"
    ],
    "abstract": "FuturlCT is a FET Flagship project using collective, participatory research, integrated across ICT, the social sciences and complexity science, to design socio-inspired technology and develop a science of global, socially interactive systems. The project will bring together, on a global level, Big Data, new modelling techniques and new forms of interaction, leading to a new understanding of society and its coevolution with technology. It aims to understand, explore and manage our complex, connected world in a more sustainable and resilient way. FuturICT is motivated by the fact that ubiquitous communication and sensing blur the boundaries between the physical and digital worlds, creating unparalleled opportunities for understanding the socio-economic fabric of our world, and for empowering humanity to make informed, responsible decisions for its future. The intimate, complex and dynamic relationship between global, networked ICT systems and human society directly influences the complexity and manageability of both. This also opens up the possibility to fundamentally change the way ICT will be designed, built and operated, to reflect the need for socially interactive, ethically sensitive, trustworthy, self-organised and reliable systems. FuturICT will create a new public resource - value-oriented tools and models to aggregate, access, query and understand vast amounts of data. Information from open sources, real-time devices and mobile sensors will be integrated with multi-scale models of the behaviour of social, technological, environmental and economic systems, which can be interrogated by policy-makers, business people and citizens alike. Together, these will build an eco-system that will lead to new business models, scientific paradigm shifts and more rapid and effective ways to create and disseminate new knowledge and social benefits - thereby forming an innovation accelerator.",
    "lastUpdated": "2012-11-10T10:11:10Z",
    "categories": [
      "nlin.AO",
      "cs.CY",
      "physics.soc-ph"
    ],
    "url": "http://arxiv.org/abs/1211.2313v1"
  },
  {
    "title": "The Beginning and the End: The Meaning of Life in a Cosmological Perspective",
    "authors": [
      "Clement Vidal"
    ],
    "abstract": "Where does it all come from? Where are we going? Are we alone in the universe? What is good and what is evil? The scientific narrative of cosmic evolution demands that we tackle such big questions with a cosmological perspective. I tackle the first question in Chapters 4-6; the second in Chapters 7-8; the third in Chapter 9 and the fourth in Chapter 10. However, where do we start to answer such questions? In Chapters 1-3, I elaborate the concept of worldview and argue that we should aim at constructing comprehensive and coherent worldviews. In Chapter 4, I identify seven fundamental challenges to any ultimate explanation. I conclude that our explanations tend to fall in two cognitive attractors, the point or the cycle. In Chapter 5, I focus on the free parameters issue, while Chapter 6 is a critical analysis of the fine-tuning issue. I conclude that fine-tuning is a conjecture and that we need to further study how typical our universe is. This opens a research endeavor that I call artificial cosmogenesis. In Chapter 7, I show the importance of artificial cosmogenesis from extrapolating the future of scientific simulations. I then analyze two other evolutionary explanations of fine-tuning in Chapter 8: Cosmological Natural Selection and the broader scenario of Cosmological Artificial Selection. In Chapter 9, I inquire into the search for extraterrestrials and conclude that some binary star systems are good candidates. Since those putative beings feed on stars, I call them starivores. The question of their artificiality remains open, but I propose a prize to further continue and motivate the scientific assessment of this hypothesis. In Chapter 10, I explore foundations to build a cosmological ethics and conclude that the ultimate good is the infinite continuation of the evolutionary process. Appendix I summarizes my position and Appendix II provides argumentative maps of the entire thesis.",
    "lastUpdated": "2013-06-05T14:38:13Z",
    "categories": [
      "physics.gen-ph"
    ],
    "url": "http://arxiv.org/abs/1301.1648v2"
  },
  {
    "title": "Small area estimation of general parameters with application to poverty indicators: A hierarchical Bayes approach",
    "authors": [
      "Isabel Molina",
      "Balgobin Nandram",
      "J. N. K. Rao"
    ],
    "abstract": "Poverty maps are used to aid important political decisions such as allocation of development funds by governments and international organizations. Those decisions should be based on the most accurate poverty figures. However, often reliable poverty figures are not available at fine geographical levels or for particular risk population subgroups due to the sample size limitation of current national surveys. These surveys cannot cover adequately all the desired areas or population subgroups and, therefore, models relating the different areas are needed to 'borrow strength\" from area to area. In particular, the Spanish Survey on Income and Living Conditions (SILC) produces national poverty estimates but cannot provide poverty estimates by Spanish provinces due to the poor precision of direct estimates, which use only the province specific data. It also raises the ethical question of whether poverty is more severe for women than for men in a given province. We develop a hierarchical Bayes (HB) approach for poverty mapping in Spanish provinces by gender that overcomes the small province sample size problem of the SILC. The proposed approach has a wide scope of application because it can be used to estimate general nonlinear parameters. We use a Bayesian version of the nested error regression model in which Markov chain Monte Carlo procedures and the convergence monitoring therein are avoided. A simulation study reveals good frequentist properties of the HB approach. The resulting poverty maps indicate that poverty, both in frequency and intensity, is localized mostly in the southern and western provinces and it is more acute for women than for men in most of the provinces.",
    "lastUpdated": "2014-07-31T12:42:00Z",
    "categories": [
      "stat.AP"
    ],
    "url": "http://arxiv.org/abs/1407.8384v1"
  },
  {
    "title": "Case Studies and Challenges in Reproducibility in the Computational Sciences",
    "authors": [
      "Sylwester Arabas",
      "Michael R. Bareford",
      "Lakshitha R. de Silva",
      "Ian P. Gent",
      "Benjamin M. Gorman",
      "Masih Hajiarabderkani",
      "Tristan Henderson",
      "Luke Hutton",
      "Alexander Konovalov",
      "Lars Kotthoff",
      "Ciaran McCreesh",
      "Miguel A. Nacenta",
      "Ruma R. Paul",
      "Karen E. J. Petrie",
      "Abdul Razaq",
      "Daniël Reijsbergen",
      "Kenji Takeda"
    ],
    "abstract": "This paper investigates the reproducibility of computational science research and identifies key challenges facing the community today. It is the result of the First Summer School on Experimental Methodology in Computational Science Research (https://blogs.cs.st-andrews.ac.uk/emcsr2014/). First, we consider how to reproduce experiments that involve human subjects, and in particular how to deal with different ethics requirements at different institutions. Second, we look at whether parallel and distributed computational experiments are more or less reproducible than serial ones. Third, we consider reproducible computational experiments from fields outside computer science. Our final case study looks at whether reproducibility for one researcher is the same as for another, by having an author attempt to have others reproduce their own, reproducible, paper. This paper is open, executable and reproducible: the whole process of writing this paper is captured in the source control repository hosting both the source of the paper, supplementary codes and data; we are providing setup for several experiments on which we were working; finally, we try to describe what we have achieved during the week of the school in a way that others may reproduce (and hopefully improve) our experiments.",
    "lastUpdated": "2014-09-11T22:01:57Z",
    "categories": [
      "cs.CE",
      "cs.DL"
    ],
    "url": "http://arxiv.org/abs/1408.2123v2"
  },
  {
    "title": "Resource Redistribution Method for Short-Term Recovery of Society after Large Scale Disasters",
    "authors": [
      "Vasily Lubashevskiy",
      "Taro Kanno",
      "Kazuo Furuta"
    ],
    "abstract": "Recovery of society after a large scale disaster generally consists of two phases, short- and long-term recoveries. The main goal of the short-term recovery is to bounce the damaged system back to the operating standards enabling residents in damaged cities to survive, and fast supply with vital resources to them is one of its important elements. We propose a general principle by which the required redistribution of vital resources between the affected and neighbouring cities can be efficiently implemented. The short-term recovery is a rescuer operation where uncertainty in evaluating the state of damaged region is highly probable. To allow for such an operation the developed principle involves two basic components. The first one of ethic nature is the triage concept determining the current city priority in the resource delivery. The second one is the minimization of the delivery time subjected to this priority. Finally a certain plan of the resource redistribution is generated according to this principle. Several specific examples are studied numerically. It elucidates, in particular, the effects of system characteristics such as the city limit capacity in resource delivery, the type of initial resource allocation among the cities, the number of cities able to participate in the resource redistribution, and the damage level in the affected cities. As far as the uncertainty in evaluating the state of damaged region is concerned, some specific cases were studied. It assumes the initial communication system has crashed and formation of a new one and the resource redistribution proceed synchronously. The obtained results enable us to consider the resource redistribution plan governed by the proposed method semi-optimal and rather efficient especially under uncertainty.",
    "lastUpdated": "2014-04-29T02:40:48Z",
    "categories": [
      "physics.soc-ph",
      "nlin.AO"
    ],
    "url": "http://arxiv.org/abs/1404.7215v1"
  },
  {
    "title": "Mammalian Value Systems",
    "authors": [
      "Gopal P. Sarma",
      "Nick J. Hay"
    ],
    "abstract": "Characterizing human values is a topic deeply interwoven with the sciences, humanities, art, and many other human endeavors. In recent years, a number of thinkers have argued that accelerating trends in computer science, cognitive science, and related disciplines foreshadow the creation of intelligent machines which meet and ultimately surpass the cognitive abilities of human beings, thereby entangling an understanding of human values with future technological development. Contemporary research accomplishments suggest sophisticated AI systems becoming widespread and responsible for managing many aspects of the modern world, from preemptively planning users' travel schedules and logistics, to fully autonomous vehicles, to domestic robots assisting in daily living. The extrapolation of these trends has been most forcefully described in the context of a hypothetical \"intelligence explosion,\" in which the capabilities of an intelligent software agent would rapidly increase due to the presence of feedback loops unavailable to biological organisms. The possibility of superintelligent agents, or simply the widespread deployment of sophisticated, autonomous AI systems, highlights an important theoretical problem: the need to separate the cognitive and rational capacities of an agent from the fundamental goal structure, or value system, which constrains and guides the agent's actions. The \"value alignment problem\" is to specify a goal structure for autonomous agents compatible with human values. In this brief article, we suggest that recent ideas from affective neuroscience and related disciplines aimed at characterizing neurological and behavioral universals in the mammalian class provide important conceptual foundations relevant to describing human values. We argue that the notion of \"mammalian value systems\" points to a potential avenue for fundamental research in AI safety and AI ethics.",
    "lastUpdated": "2019-01-21T19:29:30Z",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.HC",
      "cs.LG",
      "cs.RO"
    ],
    "url": "http://arxiv.org/abs/1607.08289v4"
  },
  {
    "title": "Systematic reviews in paediatric multiple sclerosis and Creutzfeldt-Jakob disease exemplify shortcomings in methods used to evaluate therapies in rare conditions",
    "authors": [
      "Steffen Unkel",
      "Christian Röver",
      "Nigel Stallard",
      "Norbert Benda",
      "Martin Posch",
      "Sarah Zohar",
      "Tim Friede"
    ],
    "abstract": "BACKGROUND: Randomized controlled trials (RCTs) are the gold standard design of clinical research to assess interventions. However, RCTs cannot always be applied for practical or ethical reasons. To investigate the current practices in rare diseases, we review evaluations of therapeutic interventions in paediatric multiple sclerosis (MS) and Creutzfeldt-Jakob disease (CJD). In particular, we shed light on the endpoints used, the study designs implemented and the statistical methodologies applied. METHODS: We conducted literature searches to identify relevant primary studies. Data on study design, objectives, endpoints, patient characteristics, randomization and masking, type of intervention, control, withdrawals and statistical methodology were extracted from the selected studies. The risk of bias and the quality of the studies were assessed. RESULTS: Twelve (seven) primary studies on paediatric MS (CJD) were included in the qualitative synthesis. No double-blind, randomized placebo-controlled trial for evaluating interventions in paediatric MS has been published yet. Evidence from one open-label RCT is available. The observational studies are before-after studies or controlled studies. Three of the seven selected studies on CJD are RCTs, of which two received the maximum mark on the Oxford Quality Scale. Four trials are controlled observational studies. CONCLUSIONS: Evidence from double-blind RCTs on the efficacy of treatments appears to be variable between rare diseases. With regard to paediatric conditions it remains to be seen what impact regulators will have through e.g., paediatric investigation plans. Overall, there is space for improvement by using innovative trial designs and data analysis techniques.",
    "lastUpdated": "2016-02-21T16:28:58Z",
    "categories": [
      "q-bio.QM",
      "stat.AP"
    ],
    "url": "http://arxiv.org/abs/1602.07207v1"
  },
  {
    "title": "A computational study of the effects of remodelled electrophysiology and mechanics on initiation of ventricular fibrillation in human heart failure",
    "authors": [
      "Nathan Kirk",
      "Alan Benson",
      "Christopher Goodyer",
      "Matthew Hubbard"
    ],
    "abstract": "The study of pathological cardiac conditions such as arrhythmias, a major cause of mortality in heart failure, is becoming increasingly informed by computational simulation, numerically modelling the governing equations. This can provide insight where experimental work is constrained by technical limitations and/or ethical issues. As the models become more realistic, the construction of efficient and accurate computational models becomes increasingly challenging. In particular, recent developments have started to couple the electrophysiology models with mechanical models in order to investigate the effect of tissue deformation on arrhythmogenesis, thus introducing an element of nonlinearity into the mathematical representation. This paper outlines a biophysically-detailed computational model of coupled electromechanical cardiac activity which uses the finite element method to approximate both electrical and mechanical systems on unstructured, deforming, meshes. An ILU preconditioner is applied to improve performance of the solver. This software is used to examine the role of electrophysiology, fibrosis and mechanical deformation on the stability of spiral wave dynamics in human ventricular tissue by applying it to models of both healthy and failing tissue. The latter was simulated by modifying (i) cellular electrophysiological properties, to generate an increased action potential duration and altered intracellular calcium handling, and (ii) tissue-level properties, to simulate the gap junction remodelling, fibrosis and increased tissue stiffness seen in heart failure. The resulting numerical experiments suggest that, for the chosen mathematical models of electrophysiology and mechanical response, introducing tissue level fibrosis can have a destabilising effect on the dynamics, while the net effect of the electrophysiological remodelling stabilises the system.",
    "lastUpdated": "2014-06-06T15:10:04Z",
    "categories": [
      "cs.CE",
      "cs.NA",
      "math.NA",
      "q-bio.TO",
      "35Q74, 35Q92, 65F08, 65M60, 65N30, 92-08, 74H15, 74S05",
      "G.1.0; G.1.3; G.1.8; G.4; J.3"
    ],
    "url": "http://arxiv.org/abs/1406.1701v1"
  },
  {
    "title": "On Automating the Doctrine of Double Effect",
    "authors": [
      "Naveen Sundar Govindarajulu",
      "Selmer Bringsjord"
    ],
    "abstract": "The doctrine of double effect ($\\mathcal{DDE}$) is a long-studied ethical principle that governs when actions that have both positive and negative effects are to be allowed. The goal in this paper is to automate $\\mathcal{DDE}$. We briefly present $\\mathcal{DDE}$, and use a first-order modal logic, the deontic cognitive event calculus, as our framework to formalize the doctrine. We present formalizations of increasingly stronger versions of the principle, including what is known as the doctrine of triple effect. We then use our framework to simulate successfully scenarios that have been used to test for the presence of the principle in human subjects. Our framework can be used in two different modes: One can use it to build $\\mathcal{DDE}$-compliant autonomous systems from scratch, or one can use it to verify that a given AI system is $\\mathcal{DDE}$-compliant, by applying a $\\mathcal{DDE}$ layer on an existing system or model. For the latter mode, the underlying AI system can be built using any architecture (planners, deep neural networks, bayesian networks, knowledge-representation systems, or a hybrid); as long as the system exposes a few parameters in its model, such verification is possible. The role of the $\\mathcal{DDE}$ layer here is akin to a (dynamic or static) software verifier that examines existing software modules. Finally, we end by presenting initial work on how one can apply our $\\mathcal{DDE}$ layer to the STRIPS-style planning model, and to a modified POMDP model.This is preliminary work to illustrate the feasibility of the second mode, and we hope that our initial sketches can be useful for other researchers in incorporating DDE in their own frameworks.",
    "lastUpdated": "2017-07-17T23:12:54Z",
    "categories": [
      "cs.AI",
      "cs.LO",
      "cs.RO"
    ],
    "url": "http://arxiv.org/abs/1703.08922v5"
  },
  {
    "title": "Semantics derived automatically from language corpora contain human-like biases",
    "authors": [
      "Aylin Caliskan",
      "Joanna J. Bryson",
      "Arvind Narayanan"
    ],
    "abstract": "Artificial intelligence and machine learning are in a period of astounding growth. However, there are concerns that these technologies may be used, either with or without intention, to perpetuate the prejudice and unfairness that unfortunately characterizes many human institutions. Here we show for the first time that human-like semantic biases result from the application of standard machine learning to ordinary language---the same sort of language humans are exposed to every day. We replicate a spectrum of standard human biases as exposed by the Implicit Association Test and other well-known psychological studies. We replicate these using a widely used, purely statistical machine-learning model---namely, the GloVe word embedding---trained on a corpus of text from the Web. Our results indicate that language itself contains recoverable and accurate imprints of our historic biases, whether these are morally neutral as towards insects or flowers, problematic as towards race or gender, or even simply veridical, reflecting the {\\em status quo} for the distribution of gender with respect to careers or first names. These regularities are captured by machine learning along with the rest of semantics. In addition to our empirical findings concerning language, we also contribute new methods for evaluating bias in text, the Word Embedding Association Test (WEAT) and the Word Embedding Factual Association Test (WEFAT). Our results have implications not only for AI and machine learning, but also for the fields of psychology, sociology, and human ethics, since they raise the possibility that mere exposure to everyday language can account for the biases we replicate here.",
    "lastUpdated": "2017-05-25T17:50:31Z",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1608.07187v4"
  },
  {
    "title": "Taking Turing by Surprise? Designing Digital Computers for morally-loaded contexts",
    "authors": [
      "Sylvie Delacroix"
    ],
    "abstract": "There is much to learn from what Turing hastily dismissed as Lady Lovelace s objection. Digital computers can indeed surprise us. Just like a piece of art, algorithms can be designed in such a way as to lead us to question our understanding of the world, or our place within it. Some humans do lose the capacity to be surprised in that way. It might be fear, or it might be the comfort of ideological certainties. As lazy normative animals, we do need to be able to rely on authorities to simplify our reasoning: that is ok. Yet the growing sophistication of systems designed to free us from the constraints of normative engagement may take us past a point of no-return. What if, through lack of normative exercise, our moral muscles became so atrophied as to leave us unable to question our social practices? This paper makes two distinct normative claims: 1. Decision-support systems should be designed with a view to regularly jolting us out of our moral torpor. 2. Without the depth of habit to somatically anchor model certainty, a computer s experience of something new is very different from that which in humans gives rise to non-trivial surprises. This asymmetry has key repercussions when it comes to the shape of ethical agency in artificial moral agents. The worry is not just that they would be likely to leap morally ahead of us, unencumbered by habits. The main reason to doubt that the moral trajectories of humans v. autonomous systems might remain compatible stems from the asymmetry in the mechanisms underlying moral change. Whereas in humans surprises will continue to play an important role in waking us to the need for moral change, cognitive processes will rule when it comes to machines. This asymmetry will translate into increasingly different moral outlooks, to the point of likely unintelligibility. The latter prospect is enough to doubt the desirability of autonomous moral agents.",
    "lastUpdated": "2018-03-12T21:51:48Z",
    "categories": [
      "cs.CY",
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/1803.04548v1"
  },
  {
    "title": "Interpretable Multi-Objective Reinforcement Learning through Policy Orchestration",
    "authors": [
      "Ritesh Noothigattu",
      "Djallel Bouneffouf",
      "Nicholas Mattei",
      "Rachita Chandra",
      "Piyush Madan",
      "Kush Varshney",
      "Murray Campbell",
      "Moninder Singh",
      "Francesca Rossi"
    ],
    "abstract": "Autonomous cyber-physical agents and systems play an increasingly large role in our lives. To ensure that agents behave in ways aligned with the values of the societies in which they operate, we must develop techniques that allow these agents to not only maximize their reward in an environment, but also to learn and follow the implicit constraints of society. These constraints and norms can come from any number of sources including regulations, business process guidelines, laws, ethical principles, social norms, and moral values. We detail a novel approach that uses inverse reinforcement learning to learn a set of unspecified constraints from demonstrations of the task, and reinforcement learning to learn to maximize the environment rewards. More precisely, we assume that an agent can observe traces of behavior of members of the society but has no access to the explicit set of constraints that give rise to the observed behavior. Inverse reinforcement learning is used to learn such constraints, that are then combined with a possibly orthogonal value function through the use of a contextual bandit-based orchestrator that picks a contextually-appropriate choice between the two policies (constraint-based and environment reward-based) when taking actions. The contextual bandit orchestrator allows the agent to mix policies in novel ways, taking the best actions from either a reward maximizing or constrained policy. In addition, the orchestrator is transparent on which policy is being employed at each time step. We test our algorithms using a Pac-Man domain and show that the agent is able to learn to act optimally, act within the demonstrated constraints, and mix these two functions in complex ways.",
    "lastUpdated": "2018-09-21T23:38:17Z",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1809.08343v1"
  },
  {
    "title": "A survey of automatic de-identification of longitudinal clinical narratives",
    "authors": [
      "Vithya Yogarajan",
      "Michael Mayo",
      "Bernhard Pfahringer"
    ],
    "abstract": "Use of medical data, also known as electronic health records, in research helps develop and advance medical science. However, protecting patient confidentiality and identity while using medical data for analysis is crucial. Medical data can be in the form of tabular structures (i.e. tables), free-form narratives, and images. This study focuses on medical data in the free form longitudinal text. De-identification of electronic health records provides the opportunity to use such data for research without it affecting patient privacy, and avoids the need for individual patient consent. In recent years there is increasing interest in developing an accurate, robust and adaptable automatic de-identification system for electronic health records. This is mainly due to the dilemma between the availability of an abundance of health data, and the inability to use such data in research due to legal and ethical restrictions. De-identification tracks in competitions such as the 2014 i2b2 UTHealth and the 2016 CEGS N-GRID shared tasks have provided a great platform to advance this area. The primary reasons for this include the open source nature of the dataset and the fact that raw psychiatric data were used for 2016 competitions. This study focuses on noticeable trend changes in the techniques used in the development of automatic de-identification for longitudinal clinical narratives. More specifically, the shift from using conditional random fields (CRF) based systems only or rules (regular expressions, dictionary or combinations) based systems only, to hybrid models (combining CRF and rules), and more recently to deep learning based systems. We review the literature and results that arose from the 2014 and the 2016 competitions and discuss the outcomes of these systems. We also provide a list of research questions that emerged from this survey.",
    "lastUpdated": "2018-10-16T00:26:39Z",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "url": "http://arxiv.org/abs/1810.06765v1"
  },
  {
    "title": "Producing Corpora of Medieval and Premodern Occitan",
    "authors": [
      "Jean-Baptiste Camps",
      "Gilles Guilhem Couffignal"
    ],
    "abstract": "At a time when the quantity of - more or less freely - available data is increasing significantly, thanks to digital corpora, editions or libraries, the development of data mining tools or deep learning methods allows researchers to build a corpus of study tailored for their research, to enrich their data and to exploit them.Open optical character recognition (OCR) tools can be adapted to old prints, incunabula or even manuscripts, with usable results, allowing the rapid creation of textual corpora. The alternation of training and correction phases makes it possible to improve the quality of the results by rapidly accumulating raw text data. These can then be structured, for example in XML/TEI, and enriched.The enrichment of the texts with graphic or linguistic annotations can also be automated. These processes, known to linguists and functional for modern languages, present difficulties for languages such as Medieval Occitan, due in part to the absence of big enough lemmatized corpora. Suggestions for the creation of tools adapted to the considerable spelling variation of ancient languages will be presented, as well as experiments for the lemmatization of Medieval and Premodern Occitan.These techniques open the way for many exploitations. The much desired increase in the amount of available quality texts and data makes it possible to improve digital philology methods, if everyone takes the trouble to make their data freely available online and reusable.By exposing different technical solutions and some micro-analyses as examples, this paper aims to show part of what digital philology can offer to researchers in the Occitan domain, while recalling the ethical issues on which such practices are based.",
    "lastUpdated": "2019-04-26T12:55:03Z",
    "categories": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1904.11815v1"
  },
  {
    "title": "AI-GAs: AI-generating algorithms, an alternate paradigm for producing general artificial intelligence",
    "authors": [
      "Jeff Clune"
    ],
    "abstract": "Perhaps the most ambitious scientific quest in human history is the creation of general artificial intelligence, which roughly means AI that is as smart or smarter than humans. The dominant approach in the machine learning community is to attempt to discover each of the pieces required for intelligence, with the implicit assumption that some future group will complete the Herculean task of figuring out how to combine all of those pieces into a complex thinking machine. I call this the \"manual AI approach\". This paper describes another exciting path that ultimately may be more successful at producing general AI. It is based on the clear trend in machine learning that hand-designed solutions eventually are replaced by more effective, learned solutions. The idea is to create an AI-generating algorithm (AI-GA), which automatically learns how to produce general AI. Three Pillars are essential for the approach: (1) meta-learning architectures, (2) meta-learning the learning algorithms themselves, and (3) generating effective learning environments. I argue that either approach could produce general AI first, and both are scientifically worthwhile irrespective of which is the fastest path. Because both are promising, yet the ML community is currently committed to the manual approach, I argue that our community should increase its research investment in the AI-GA approach. To encourage such research, I describe promising work in each of the Three Pillars. I also discuss AI-GA-specific safety and ethical considerations. Because it it may be the fastest path to general AI and because it is inherently scientifically interesting to understand the conditions in which a simple algorithm can produce general AI (as happened on Earth where Darwinian evolution produced human intelligence), I argue that the pursuit of AI-GAs should be considered a new grand challenge of computer science research.",
    "lastUpdated": "2020-02-01T04:46:25Z",
    "categories": [
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1905.10985v2"
  },
  {
    "title": "Proof of Witness Presence: Blockchain Consensus for Augmented Democracy in Smart Cities",
    "authors": [
      "Evangelos Pournaras"
    ],
    "abstract": "Smart Cities evolve into complex and pervasive urban environments with a citizens' mandate to meet sustainable development goals. Repositioning democratic values of citizens' choices in these complex ecosystems has turned out to be imperative in an era of social media filter bubbles, fake news and opportunities for manipulating electoral results with such means. This paper introduces a new paradigm of augmented democracy that promises actively engaging citizens in a more informed decision-making augmented into public urban space. The proposed concept is inspired by a digital revive of the Ancient Agora of Athens, an arena of public discourse, a Polis where citizens assemble to actively deliberate and collectively decide about public matters. The core contribution of the proposed paradigm is the concept of proving witness presence: making decision-making subject of providing secure evidence and testifying for choices made in the physical space. This paper shows how the challenge of proving witness presence can be tackled with blockchain consensus to empower citizens' trust and overcome security vulnerabilities of GPS localization. Moreover, a novel platform for collective decision-making and crowd-sensing in urban space is introduced: Smart Agora. It is shown how real-time collective measurements over citizens' choices can be made in a fully decentralized and privacy-preserving way. Witness presence is tested by deploying a decentralized system for crowd-sensing the sustainable use of transport means. Furthermore, witness presence of cycling risk is validated using official accident data from public authorities, which are compared against wisdom of the crowd. The paramount role of dynamic consensus, self-governance and ethically aligned artificial intelligence in the augmented democracy paradigm is outlined.",
    "lastUpdated": "2020-07-08T22:48:11Z",
    "categories": [
      "cs.CY",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1907.00498v4"
  },
  {
    "title": "To regulate or not: a social dynamics analysis of the race for AI supremacy",
    "authors": [
      "The Anh Han",
      "Luis Moniz Pereira",
      "Francisco C. Santos",
      "Tom Lenaerts"
    ],
    "abstract": "Rapid technological advancements in AI as well as the growing deployment of intelligent technologies in new application domains are currently driving the competition between businesses, nations and regions. This race for technological supremacy creates a complex ecology of choices that may lead to negative consequences, in particular, when ethical and safety procedures are underestimated or even ignored. As a consequence, different actors are urging to consider both the normative and social impact of these technological advancements. As there is no easy access to data describing this AI race, theoretical models are necessary to understand its dynamics, allowing for the identification of when, how and which procedures need to be put in place to favour outcomes beneficial for all. We show that, next to the risks of setbacks and being reprimanded for unsafe behaviour, the time-scale in which AI supremacy can be achieved plays a crucial role. When this supremacy can be achieved in a short term, those who completely ignore the safety precautions are bound to win the race but at a cost to society, apparently requiring regulatory actions. Our analysis reveals that blindly imposing regulations may not have anticipated effect as only for specific conditions a dilemma arises between what individually preferred and globally beneficial. Similar observations can be made for the long-term development case. Yet different from the short term situation, certain conditions require the promotion of risk-taking as opposed to compliance to safety regulations in order to improve social welfare. These results remain robust when two or several actors are involved in the race and when collective rather than individual setbacks are produced by risk-taking behaviour. When defining codes of conduct and regulatory policies for AI, a clear understanding about the time-scale of the race is required.",
    "lastUpdated": "2020-01-16T16:48:16Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "physics.soc-ph"
    ],
    "url": "http://arxiv.org/abs/1907.12393v2"
  },
  {
    "title": "Astro2020 APC White Paper: Findings and Recommendations from the AAS Committee on the Status of Women in Astronomy: Towards Eliminating Harassment in Astronomy",
    "authors": [
      "Nicolle Zellner",
      "JoEllen McBride",
      "Nancy Morrison",
      "Alice Olmstead",
      "Maria Patterson",
      "Gregory Rudnick",
      "Aparna Venkatesan",
      "Heather Flewelling",
      "David Grinspoon",
      "Jessica D. Mink",
      "Christina Richey",
      "Angela Speck",
      "Cristina A. Thomas",
      "Sarah E. Tuttle"
    ],
    "abstract": "The Committee on the Status of Women in Astronomy (CSWA) is calling on federal science funding agencies, in their role as the largest sources of funding for astronomy in the United States, to take actions that will end harassment, particularly sexual harassment, in astronomical workplaces. Funding agencies can and should lead the charge to end harassment in astronomy by the 2030 Astrophysics Decadal Survey. Anecdotal and quantitative evidence, gathered both by the CSWA and other groups, shows that harassment is prevalent and damaging for women and minority astronomers and those in related fields. Actions recommended herein will increase the rate of reporting of harassment to agencies and improve their ability to investigate and take action against harassers. We also recommend that agencies participate in harassment prevention by creating and implementing the best anti-harassment education possible. Key recommendations are: - Federal agencies should improve their ethics policies by making harassment a form of scientific misconduct. - Federal agencies should mandate that institutions report to them when a funded Principal Investigator (PI) or co-Principal Investigator (co-PI) is found to be a perpetrator of harassment. - Federal funding agencies should provide online guides to help scientists identify harassment and connect them to the right resources for making confidential or official reports. - Federal agencies should create and ensure the implementation of anti-harassment trainings by making them a requirement of receiving grant funding.",
    "lastUpdated": "2019-08-01T19:25:58Z",
    "categories": [
      "astro-ph.IM"
    ],
    "url": "http://arxiv.org/abs/1908.00589v1"
  },
  {
    "title": "Aggregating Votes with Local Differential Privacy: Usefulness, Soundness vs. Indistinguishability",
    "authors": [
      "Shaowei Wang",
      "Jiachun Du",
      "Wei Yang",
      "Xinrong Diao",
      "Zichun Liu",
      "Yiwen Nie",
      "Liusheng Huang",
      "Hongli Xu"
    ],
    "abstract": "Voting plays a central role in bringing crowd wisdom to collective decision making, meanwhile data privacy has been a common ethical/legal issue in eliciting preferences from individuals. This work studies the problem of aggregating individual's voting data under the local differential privacy setting, where usefulness and soundness of the aggregated scores are of major concern. One naive approach to the problem is adding Laplace random noises, however, it makes aggregated scores extremely fragile to new types of strategic behaviors tailored to the local privacy setting: data amplification attack and view disguise attack. The data amplification attack means an attacker's manipulation power is amplified by the privacy-preserving procedure when contributing a fraud vote. The view disguise attack happens when an attacker could disguise malicious data as valid private views to manipulate the voting result. In this work, after theoretically quantifying the estimation error bound and the manipulating risk bound of the Laplace mechanism, we propose two mechanisms improving the usefulness and soundness simultaneously: the weighted sampling mechanism and the additive mechanism. The former one interprets the score vector as probabilistic data. Compared to the Laplace mechanism for Borda voting rule with $d$ candidates, it reduces the mean squared error bound by half and lowers the maximum magnitude risk bound from $+\\infty$ to $O(\\frac{d^3}{n\\epsilon})$. The latter one randomly outputs a subset of candidates according to their total scores. Its mean squared error bound is optimized from $O(\\frac{d^5}{n\\epsilon^2})$ to $O(\\frac{d^4}{n\\epsilon^2})$, and its maximum magnitude risk bound is reduced to $O(\\frac{d^2}{n\\epsilon})$. Experimental results validate that our proposed approaches averagely reduce estimation error by $50\\%$ and are more robust to adversarial attacks.",
    "lastUpdated": "2019-08-14T01:53:48Z",
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1908.04920v1"
  },
  {
    "title": "AnimalWeb: A Large-Scale Hierarchical Dataset of Annotated Animal Faces",
    "authors": [
      "Muhammad Haris Khan",
      "John McDonagh",
      "Salman Khan",
      "Muhammad Shahabuddin",
      "Aditya Arora",
      "Fahad Shahbaz Khan",
      "Ling Shao",
      "Georgios Tzimiropoulos"
    ],
    "abstract": "Being heavily reliant on animals, it is our ethical obligation to improve their well-being by understanding their needs. Several studies show that animal needs are often expressed through their faces. Though remarkable progress has been made towards the automatic understanding of human faces, this has regrettably not been the case with animal faces. There exists significant room and appropriate need to develop automatic systems capable of interpreting animal faces. Among many transformative impacts, such a technology will foster better and cheaper animal healthcare, and further advance animal psychology understanding. We believe the underlying research progress is mainly obstructed by the lack of an adequately annotated dataset of animal faces, covering a wide spectrum of animal species. To this end, we introduce a large-scale, hierarchical annotated dataset of animal faces, featuring 21.9K faces from 334 diverse species and 21 animal orders across biological taxonomy. These faces are captured `in-the-wild' conditions and are consistently annotated with 9 landmarks on key facial features. The proposed dataset is structured and scalable by design; its development underwent four systematic stages involving rigorous, manual annotation effort of over 6K man-hours. We benchmark it for face alignment using the existing art under novel problem settings. Results showcase its challenging nature, unique attributes and present definite prospects for novel, adaptive, and generalized face-oriented CV algorithms. We further benchmark the dataset for face detection and fine-grained recognition tasks, to demonstrate multi-task applications and room for improvement. Experiments indicate that this dataset will push the algorithmic advancements across many related CV tasks and encourage the development of novel systems for animal facial behaviour monitoring. We will make the dataset publicly available.",
    "lastUpdated": "2019-09-11T09:55:56Z",
    "categories": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1909.04951v1"
  },
  {
    "title": "Two Case Studies of Experience Prototyping Machine Learning Systems in the Wild",
    "authors": [
      "Qian Yang"
    ],
    "abstract": "Throughout the course of my Ph.D., I have been designing the user experience (UX) of various machine learning (ML) systems. In this workshop, I share two projects as case studies in which people engage with ML in much more complicated and nuanced ways than the technical HCML work might assume. The first case study describes how cardiology teams in three hospitals used a clinical decision-support system that helps them decide whether and when to implant an artificial heart to a heart failure patient. I demonstrate that physicians cannot draw on their decision-making experience by seeing only patient data on paper. They are also confused by some fundamental premises upon which ML operates. For example, physicians asked: Are ML predictions made based on clinicians' best efforts? Is it ethical to make decisions based on previous patients' collective outcomes? In the second case study, my collaborators and I designed an intelligent text editor, with the goal of improving authors' writing experience with NLP (Natural Language Processing) technologies. We prototyped a number of generative functionalities where the system provides phrase-or-sentence-level writing suggestions upon user request. When writing with the prototype, however, authors shared that they need to \"see where the sentence is going two paragraphs later\" in order to decide whether the suggestion aligns with their writing; Some even considered adopting machine suggestions as plagiarism, therefore \"is simply wrong\". By sharing these unexpected and intriguing responses from these real-world ML users, I hope to start a discussion about such previously-unknown complexities and nuances of -- as the workshop proposal states -- \"putting ML at the service of people in a way that is accessible, useful, and trustworthy to all\".",
    "lastUpdated": "2019-10-21T03:43:12Z",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1910.09137v1"
  },
  {
    "title": "Algorithms and Statistical Models for Scientific Discovery in the Petabyte Era",
    "authors": [
      "Brian Nord",
      "Andrew J. Connolly",
      "Jamie Kinney",
      "Jeremy Kubica",
      "Gautaum Narayan",
      "Joshua E. G. Peek",
      "Chad Schafer",
      "Erik J. Tollerud",
      "Camille Avestruz",
      "G. Jogesh Babu",
      "Simon Birrer",
      "Douglas Burke",
      "João Caldeira",
      "Douglas A. Caldwell",
      "Joleen K. Carlberg",
      "Yen-Chi Chen",
      "Chuanfei Dong",
      "Eric D. Feigelson",
      "V. Zach Golkhou",
      "Vinay Kashyap",
      "T. S. Li",
      "Thomas Loredo",
      "Luisa Lucie-Smith",
      "Kaisey S. Mandel",
      "J. R. Martínez-Galarza",
      "Adam A. Miller",
      "Priyamvada Natarajan",
      "Michelle Ntampaka",
      "Andy Ptak",
      "David Rapetti",
      "Lior Shamir",
      "Aneta Siemiginowska",
      "Brigitta M. Sipőcz",
      "Arfon M. Smith",
      "Nhan Tran",
      "Ricardo Vilalta",
      "Lucianne M. Walkowicz",
      "John ZuHone"
    ],
    "abstract": "The field of astronomy has arrived at a turning point in terms of size and complexity of both datasets and scientific collaboration. Commensurately, algorithms and statistical models have begun to adapt --- e.g., via the onset of artificial intelligence --- which itself presents new challenges and opportunities for growth. This white paper aims to offer guidance and ideas for how we can evolve our technical and collaborative frameworks to promote efficient algorithmic development and take advantage of opportunities for scientific discovery in the petabyte era. We discuss challenges for discovery in large and complex data sets; challenges and requirements for the next stage of development of statistical methodologies and algorithmic tool sets; how we might change our paradigms of collaboration and education; and the ethical implications of scientists' contributions to widely applicable algorithms and computational modeling. We start with six distinct recommendations that are supported by the commentary following them. This white paper is related to a larger corpus of effort that has taken place within and around the Petabytes to Science Workshops (https://petabytestoscience.github.io/).",
    "lastUpdated": "2019-11-05T04:06:32Z",
    "categories": [
      "astro-ph.IM",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1911.02479v1"
  },
  {
    "title": "Privacy-Preserving Generalized Linear Models using Distributed Block Coordinate Descent",
    "authors": [
      "Erik-Jan van Kesteren",
      "Chang Sun",
      "Daniel L. Oberski",
      "Michel Dumontier",
      "Lianne Ippel"
    ],
    "abstract": "Combining data from varied sources has considerable potential for knowledge discovery: collaborating data parties can mine data in an expanded feature space, allowing them to explore a larger range of scientific questions. However, data sharing among different parties is highly restricted by legal conditions, ethical concerns, and / or data volume. Fueled by these concerns, the fields of cryptography and distributed learning have made great progress towards privacy-preserving and distributed data mining. However, practical implementations have been hampered by the limited scope or computational complexity of these methods. In this paper, we greatly extend the range of analyses available for vertically partitioned data, i.e., data collected by separate parties with different features on the same subjects. To this end, we present a novel approach for privacy-preserving generalized linear models, a fundamental and powerful framework underlying many prediction and classification procedures. We base our method on a distributed block coordinate descent algorithm to obtain parameter estimates, and we develop an extension to compute accurate standard errors without additional communication cost. We critically evaluate the information transfer for semi-honest collaborators and show that our protocol is secure against data reconstruction. Through both simulated and real-world examples we illustrate the functionality of our proposed algorithm. Without leaking information, our method performs as well on vertically partitioned data as existing methods on combined data -- all within mere minutes of computation time. We conclude that our method is a viable approach for vertically partitioned data analysis with a wide range of real-world applications.",
    "lastUpdated": "2019-11-08T11:07:07Z",
    "categories": [
      "cs.LG",
      "cs.CR",
      "cs.DC",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1911.03183v1"
  },
  {
    "title": "Response to NITRD, NCO, NSF Request for Information on \"Update to the 2016 National Artificial Intelligence Research and Development Strategic Plan\"",
    "authors": [
      "J. Amundson",
      "J. Annis",
      "C. Avestruz",
      "D. Bowring",
      "J. Caldeira",
      "G. Cerati",
      "C. Chang",
      "S. Dodelson",
      "D. Elvira",
      "A. Farahi",
      "K. Genser",
      "L. Gray",
      "O. Gutsche",
      "P. Harris",
      "J. Kinney",
      "J. B. Kowalkowski",
      "R. Kutschke",
      "S. Mrenna",
      "B. Nord",
      "A. Para",
      "K. Pedro",
      "G. N. Perdue",
      "A. Scheinker",
      "P. Spentzouris",
      "J. St. John",
      "N. Tran",
      "S. Trivedi",
      "L. Trouille",
      "W. L. K. Wu",
      "C. R. Bom"
    ],
    "abstract": "We present a response to the 2018 Request for Information (RFI) from the NITRD, NCO, NSF regarding the \"Update to the 2016 National Artificial Intelligence Research and Development Strategic Plan.\" Through this document, we provide a response to the question of whether and how the National Artificial Intelligence Research and Development Strategic Plan (NAIRDSP) should be updated from the perspective of Fermilab, America's premier national laboratory for High Energy Physics (HEP). We believe the NAIRDSP should be extended in light of the rapid pace of development and innovation in the field of Artificial Intelligence (AI) since 2016, and present our recommendations below. AI has profoundly impacted many areas of human life, promising to dramatically reshape society --- e.g., economy, education, science --- in the coming years. We are still early in this process. It is critical to invest now in this technology to ensure it is safe and deployed ethically. Science and society both have a strong need for accuracy, efficiency, transparency, and accountability in algorithms, making investments in scientific AI particularly valuable. Thus far the US has been a leader in AI technologies, and we believe as a national Laboratory it is crucial to help maintain and extend this leadership. Moreover, investments in AI will be important for maintaining US leadership in the physical sciences.",
    "lastUpdated": "2019-11-05T04:04:25Z",
    "categories": [
      "astro-ph.IM",
      "cs.AI",
      "physics.soc-ph"
    ],
    "url": "http://arxiv.org/abs/1911.05796v1"
  },
  {
    "title": "\"The Human Body is a Black Box\": Supporting Clinical Decision-Making with Deep Learning",
    "authors": [
      "Mark Sendak",
      "Madeleine Elish",
      "Michael Gao",
      "Joseph Futoma",
      "William Ratliff",
      "Marshall Nichols",
      "Armando Bedoya",
      "Suresh Balu",
      "Cara O'Brien"
    ],
    "abstract": "Machine learning technologies are increasingly developed for use in healthcare. While research communities have focused on creating state-of-the-art models, there has been less focus on real world implementation and the associated challenges to accuracy, fairness, accountability, and transparency that come from actual, situated use. Serious questions remain under examined regarding how to ethically build models, interpret and explain model output, recognize and account for biases, and minimize disruptions to professional expertise and work cultures. We address this gap in the literature and provide a detailed case study covering the development, implementation, and evaluation of Sepsis Watch, a machine learning-driven tool that assists hospital clinicians in the early diagnosis and treatment of sepsis. We, the team that developed and evaluated the tool, discuss our conceptualization of the tool not as a model deployed in the world but instead as a socio-technical system requiring integration into existing social and professional contexts. Rather than focusing on model interpretability to ensure a fair and accountable machine learning, we point toward four key values and practices that should be considered when developing machine learning to support clinical decision-making: rigorously define the problem in context, build relationships with stakeholders, respect professional discretion, and create ongoing feedback loops with stakeholders. Our work has significant implications for future research regarding mechanisms of institutional accountability and considerations for designing machine learning systems. Our work underscores the limits of model interpretability as a solution to ensure transparency, accuracy, and accountability in practice. Instead, our work demonstrates other means and goals to achieve FATML values in design and in practice.",
    "lastUpdated": "2019-12-07T03:42:06Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1911.08089v2"
  },
  {
    "title": "Privacy Attacks on Network Embeddings",
    "authors": [
      "Michael Ellers",
      "Michael Cochez",
      "Tobias Schumacher",
      "Markus Strohmaier",
      "Florian Lemmerich"
    ],
    "abstract": "Data ownership and data protection are increasingly important topics with ethical and legal implications, e.g., with the right to erasure established in the European General Data Protection Regulation (GDPR). In this light, we investigate network embeddings, i.e., the representation of network nodes as low-dimensional vectors. We consider a typical social network scenario with nodes representing users and edges relationships between them. We assume that a network embedding of the nodes has been trained. After that, a user demands the removal of his data, requiring the full deletion of the corresponding network information, in particular the corresponding node and incident edges. In that setting, we analyze whether after the removal of the node from the network and the deletion of the vector representation of the respective node in the embedding significant information about the link structure of the removed node is still encoded in the embedding vectors of the remaining nodes. This would require a (potentially computationally expensive) retraining of the embedding. For that purpose, we deploy an attack that leverages information from the remaining network and embedding to recover information about the neighbors of the removed node. The attack is based on (i) measuring distance changes in network embeddings and (ii) a machine learning classifier that is trained on networks that are constructed by removing additional nodes. Our experiments demonstrate that substantial information about the edges of a removed node/user can be retrieved across many different datasets. This implies that to fully protect the privacy of users, node deletion requires complete retraining - or at least a significant modification - of original network embeddings. Our results suggest that deleting the corresponding vector representation from network embeddings alone is not sufficient from a privacy perspective.",
    "lastUpdated": "2019-12-23T17:10:20Z",
    "categories": [
      "cs.LG",
      "cs.CR",
      "cs.SI",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1912.10979v1"
  },
  {
    "title": "Algorithmic Fairness from a Non-ideal Perspective",
    "authors": [
      "Sina Fazelpour",
      "Zachary C. Lipton"
    ],
    "abstract": "Inspired by recent breakthroughs in predictive modeling, practitioners in both industry and government have turned to machine learning with hopes of operationalizing predictions to drive automated decisions. Unfortunately, many social desiderata concerning consequential decisions, such as justice or fairness, have no natural formulation within a purely predictive framework. In efforts to mitigate these problems, researchers have proposed a variety of metrics for quantifying deviations from various statistical parities that we might expect to observe in a fair world and offered a variety of algorithms in attempts to satisfy subsets of these parities or to trade off the degree to which they are satisfied against utility. In this paper, we connect this approach to \\emph{fair machine learning} to the literature on ideal and non-ideal methodological approaches in political philosophy. The ideal approach requires positing the principles according to which a just world would operate. In the most straightforward application of ideal theory, one supports a proposed policy by arguing that it closes a discrepancy between the real and the perfectly just world. However, by failing to account for the mechanisms by which our non-ideal world arose, the responsibilities of various decision-makers, and the impacts of proposed policies, naive applications of ideal thinking can lead to misguided interventions. In this paper, we demonstrate a connection between the fair machine learning literature and the ideal approach in political philosophy, and argue that the increasingly apparent shortcomings of proposed fair machine learning algorithms reflect broader troubles faced by the ideal approach. We conclude with a critical discussion of the harms of misguided solutions, a reinterpretation of impossibility results, and directions for future research.",
    "lastUpdated": "2020-01-08T18:44:41Z",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2001.09773v1"
  },
  {
    "title": "Algorithms for Fair Team Formation in Online Labour Marketplaces",
    "authors": [
      "Giorgio Barnabò",
      "Adriano Fazzone",
      "Stefano Leonardi",
      "Chris Schwiegelshohn"
    ],
    "abstract": "As freelancing work keeps on growing almost everywhere due to a sharp decrease in communication costs and to the widespread of Internet-based labour marketplaces (e.g., guru.com, feelancer.com, mturk.com, upwork.com), many researchers and practitioners have started exploring the benefits of outsourcing and crowdsourcing. Since employers often use these platforms to find a group of workers to complete a specific task, researchers have focused their efforts on the study of team formation and matching algorithms and on the design of effective incentive schemes. Nevertheless, just recently, several concerns have been raised on possibly unfair biases introduced through the algorithms used to carry out these selection and matching procedures. For this reason, researchers have started studying the fairness of algorithms related to these online marketplaces, looking for intelligent ways to overcome the algorithmic bias that frequently arises. Broadly speaking, the aim is to guarantee that, for example, the process of hiring workers through the use of machine learning and algorithmic data analysis tools does not discriminate, even unintentionally, on grounds of nationality or gender. In this short paper, we define the Fair Team Formation problem in the following way: given an online labour marketplace where each worker possesses one or more skills, and where all workers are divided into two or more not overlapping classes (for examples, men and women), we want to design an algorithm that is able to find a team with all the skills needed to complete a given task, and that has the same number of people from all classes. We provide inapproximability results for the Fair Team Formation problem together with four algorithms for the problem itself. We also tested the effectiveness of our algorithmic solutions by performing experiments using real data from an online labor marketplace.",
    "lastUpdated": "2020-02-14T11:33:35Z",
    "categories": [
      "cs.CY",
      "cs.LG",
      "cs.SI",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2002.11621v1"
  },
  {
    "title": "Learning Reinforced Agents with Counterfactual Simulation for Medical Automatic Diagnosis",
    "authors": [
      "Junfan Lin",
      "Ziliang Chen",
      "Xiaodan Liang",
      "Keze Wang",
      "Liang Lin"
    ],
    "abstract": "Medical automatic diagnosis (MAD) aims to learn an agent that mimics the behavior of human doctors, i.e. inquiring symptoms and informing diseases. Due to medical ethics concerns, it is impractical to directly apply reinforcement learning techniques to MAD, e.g., training a reinforced agent with human patients. Developing a patient simulator by using the collected patient-doctor dialogue records has been proposed as a promising workaround to MAD. However, most of these existing works overlook the causal relationship between patient symptoms and diseases. For example, these simulators simply generate the \"not-sure\" response to the symptom inquiry if the symptom was not observed in the dialogue record. Consequently, the MAD agent is usually trained without exploiting the counterfactual reasoning beyond the factual observations. To address this problem, this paper presents a propensity-based patient simulator (PBPS), which is capable of facilitating the training of MAD agents by generating informative counterfactual answers along with the disease diagnosis. Specifically, our PBPS estimates the propensity score of each record with the patient-doctor dialogue reasoning, and can thus generate the counterfactual answers by searching across records. That is, the unrecorded symptom for one patient can be found in the records of other patients according to the propensity score matching. The informative and causal-aware responses from PBPS are beneficial for modeling diagnostic confidence. To this end, we also propose a progressive assurance agent~(P2A) trained with PBPS, which includes two separate yet cooperative branches accounting for the execution of symptom-inquiry and disease-diagnosis actions, respectively.",
    "lastUpdated": "2020-08-04T01:54:26Z",
    "categories": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2003.06534v2"
  },
  {
    "title": "COVID-19 Antibody Test / Vaccination Certification: There's an app for that",
    "authors": [
      "Marc Eisenstadt",
      "Manoharan Ramachandran",
      "Niaz Chowdhury",
      "Allan Third",
      "John Domingue"
    ],
    "abstract": "Goal: As the Coronavirus Pandemic of 2019/2020 unfolds, a COVID-19 'Immunity Passport' has been mooted as a way to enable individuals to return back to work. While the quality of antibody testing, the availability of vaccines, and the likelihood of even attaining COVID-19 immunity continue to be researched, we address the issues involved in providing tamper-proof and privacy-preserving certification for test results and vaccinations. Methods: We developed a prototype mobile phone app and requisite decentralized server architecture that facilitates instant verification of tamper-proof test results. Personally identifiable information is only stored at the user's discretion, and the app allows the end-user selectively to present only the specific test result with no other personal information revealed. The architecture, designed for scalability, relies upon (a) the 2019 World Wide Web Consortium standard called 'Verifiable Credentials', (b) Tim Berners-Lee's decentralized personal data platform 'Solid', and (c) a Consortium Ethereum-based blockchain. Results: Our mobile phone app and decentralized server architecture enable the mixture of verifiability and privacy in a manner derived from public/private key pairs and digital signatures, generalized to avoid restrictive ownership of sensitive digital keys and/or data. Benchmark performance tests show it to scale linearly in the worst case, as significant processing is done locally on each app. For the test certificate Holder, Issuer (e.g. healthcare staff, pharmacy) and Verifier (e.g. employer), it is 'just another app' which takes only minutes to use. Conclusions: The app and decentralized server architecture offer a prototype proof of concept that is readily scalable, applicable generically, and in effect 'waiting in the wings' for the biological issues, plus key ethical issues raised in the discussion section, to be resolved.",
    "lastUpdated": "2020-06-28T18:42:35Z",
    "categories": [
      "cs.CR",
      "cs.CY",
      "cs.NI",
      "cs.SI",
      "J.3; K.4.1; E.2; D.4.3; C.5.5; C.2.2; E.3"
    ],
    "url": "http://arxiv.org/abs/2004.07376v4"
  },
  {
    "title": "6G White paper: Research challenges for Trust, Security and Privacy",
    "authors": [
      "Mika Ylianttila",
      "Raimo Kantola",
      "Andrei Gurtov",
      "Lozenzo Mucchi",
      "Ian Oppermann",
      "Zheng Yan",
      "Tri Hong Nguyen",
      "Fei Liu",
      "Tharaka Hewa",
      "Madhusanka Liyanage",
      "Ahmad Ijaz",
      "Juha Partala",
      "Robert Abbas",
      "Artur Hecker",
      "Sara Jayousi",
      "Alessio Martinelli",
      "Stefano Caputo",
      "Jonathan Bechtold",
      "Ivan Morales",
      "Andrei Stoica",
      "Giuseppe Abreu",
      "Shahriar Shahabuddin",
      "Erdal Panayirci",
      "Harald Haas",
      "Tanesh Kumar",
      "Basak Ozan Ozparlak",
      "Juha Röning"
    ],
    "abstract": "The roles of trust, security and privacy are somewhat interconnected, but different facets of next generation networks. The challenges in creating a trustworthy 6G are multidisciplinary spanning technology, regulation, techno-economics, politics and ethics. This white paper addresses their fundamental research challenges in three key areas. Trust: Under the current \"open internet\" regulation, the telco cloud can be used for trust services only equally for all users. 6G network must support embedded trust for increased level of information security in 6G. Trust modeling, trust policies and trust mechanisms need to be defined. 6G interlinks physical and digital worlds making safety dependent on information security. Therefore, we need trustworthy 6G. Security: In 6G era, the dependence of the economy and societies on IT and the networks will deepen. The role of IT and the networks in national security keeps rising - a continuation of what we see in 5G. The development towards cloud and edge native infrastructures is expected to continue in 6G networks, and we need holistic 6G network security architecture planning. Security automation opens new questions: machine learning can be used to make safer systems, but also more dangerous attacks. Physical layer security techniques can also represent efficient solutions for securing less investigated network segments as first line of defense. Privacy: There is currently no way to unambiguously determine when linked, deidentified datasets cross the threshold to become personally identifiable. Courts in different parts of the world are making decisions about whether privacy is being infringed, while companies are seeking new ways to exploit private data to create new business revenues. As solution alternatives, we may consider blockchain, distributed ledger technologies and differential privacy approaches.",
    "lastUpdated": "2020-04-30T09:09:17Z",
    "categories": [
      "cs.CR",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/2004.11665v2"
  },
  {
    "title": "Explainable Deep Learning: A Field Guide for the Uninitiated",
    "authors": [
      "Ning Xie",
      "Gabrielle Ras",
      "Marcel van Gerven",
      "Derek Doran"
    ],
    "abstract": "Deep neural network (DNN) is an indispensable machine learning tool for achieving human-level performance on many learning tasks. Yet, due to its black-box nature, it is inherently difficult to understand which aspects of the input data drive the decisions of the network. There are various real-world scenarios in which humans need to make actionable decisions based on the output DNNs. Such decision support systems can be found in critical domains, such as legislation, law enforcement, etc. It is important that the humans making high-level decisions can be sure that the DNN decisions are driven by combinations of data features that are appropriate in the context of the deployment of the decision support system and that the decisions made are legally or ethically defensible. Due to the incredible pace at which DNN technology is being developed, the development of new methods and studies on explaining the decision-making process of DNNs has blossomed into an active research field. A practitioner beginning to study explainable deep learning may be intimidated by the plethora of orthogonal directions the field is taking. This complexity is further exacerbated by the general confusion that exists in defining what it means to be able to explain the actions of a deep learning system and to evaluate a system's \"ability to explain\". To alleviate this problem, this article offers a \"field guide\" to deep learning explainability for those uninitiated in the field. The field guide: i) Discusses the traits of a deep learning system that researchers enhance in explainability research, ii) places explainability in the context of other related deep learning research areas, and iii) introduces three simple dimensions defining the space of foundational methods that contribute to explainable deep learning. The guide is designed as an easy-to-digest starting point for those just embarking in the field.",
    "lastUpdated": "2020-04-30T02:09:02Z",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2004.14545v1"
  },
  {
    "title": "RL Unplugged: Benchmarks for Offline Reinforcement Learning",
    "authors": [
      "Caglar Gulcehre",
      "Ziyu Wang",
      "Alexander Novikov",
      "Tom Le Paine",
      "Sergio Gomez Colmenarejo",
      "Konrad Zolna",
      "Rishabh Agarwal",
      "Josh Merel",
      "Daniel Mankowitz",
      "Cosmin Paduraru",
      "Gabriel Dulac-Arnold",
      "Jerry Li",
      "Mohammad Norouzi",
      "Matt Hoffman",
      "Ofir Nachum",
      "George Tucker",
      "Nicolas Heess",
      "Nando de Freitas"
    ],
    "abstract": "Offline methods for reinforcement learning have a potential to help bridge the gap between reinforcement learning research and real-world applications. They make it possible to learn policies from offline datasets, thus overcoming concerns associated with online data collection in the real-world, including cost, safety, or ethical concerns. In this paper, we propose a benchmark called RL Unplugged to evaluate and compare offline RL methods. RL Unplugged includes data from a diverse range of domains including games (e.g., Atari benchmark) and simulated motor control problems (e.g., DM Control Suite). The datasets include domains that are partially or fully observable, use continuous or discrete actions, and have stochastic vs. deterministic dynamics. We propose detailed evaluation protocols for each domain in RL Unplugged and provide an extensive analysis of supervised learning and offline RL methods using these protocols. We will release data for all our tasks and open-source all algorithms presented in this paper. We hope that our suite of benchmarks will increase the reproducibility of experiments and make it possible to study challenging tasks with a limited computational budget, thus making RL research both more systematic and more accessible across the community. Moving forward, we view RL Unplugged as a living benchmark suite that will evolve and grow with datasets contributed by the research community and ourselves. Our project page is available on https://git.io/JJUhd.",
    "lastUpdated": "2020-07-21T17:31:01Z",
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2006.13888v3"
  },
  {
    "title": "Large image datasets: A pyrrhic win for computer vision?",
    "authors": [
      "Vinay Uday Prabhu",
      "Abeba Birhane"
    ],
    "abstract": "In this paper we investigate problematic practices and consequences of large scale vision datasets. We examine broad issues such as the question of consent and justice as well as specific concerns such as the inclusion of verifiably pornographic images in datasets. Taking the ImageNet-ILSVRC-2012 dataset as an example, we perform a cross-sectional model-based quantitative census covering factors such as age, gender, NSFW content scoring, class-wise accuracy, human-cardinality-analysis, and the semanticity of the image class information in order to statistically investigate the extent and subtleties of ethical transgressions. We then use the census to help hand-curate a look-up-table of images in the ImageNet-ILSVRC-2012 dataset that fall into the categories of verifiably pornographic: shot in a non-consensual setting (up-skirt), beach voyeuristic, and exposed private parts. We survey the landscape of harm and threats both society broadly and individuals face due to uncritical and ill-considered dataset curation practices. We then propose possible courses of correction and critique the pros and cons of these. We have duly open-sourced all of the code and the census meta-datasets generated in this endeavor for the computer vision community to build on. By unveiling the severity of the threats, our hope is to motivate the constitution of mandatory Institutional Review Boards (IRB) for large scale dataset curation processes.",
    "lastUpdated": "2020-07-24T02:55:13Z",
    "categories": [
      "cs.CY",
      "stat.AP",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2006.16923v2"
  },
  {
    "title": "An Empirical Characterization of Fair Machine Learning For Clinical Risk Prediction",
    "authors": [
      "Stephen R. Pfohl",
      "Agata Foryciarz",
      "Nigam H. Shah"
    ],
    "abstract": "The use of machine learning to guide clinical decision making has the potential to worsen existing health disparities. Several recent works frame the problem as that of algorithmic fairness, a framework that has attracted considerable attention and criticism. However, the appropriateness of this framework is unclear due to both ethical as well as technical considerations, the latter of which include trade-offs between measures of fairness and model performance that are not well-understood for predictive models of clinical outcomes. To inform the ongoing debate, we conduct an empirical study to characterize the impact of penalizing group fairness violations on an array of measures of model performance and group fairness. We repeat the analyses across multiple observational healthcare databases, clinical outcomes, and sensitive attributes. We find that procedures that penalize differences between the distributions of predictions across groups induce nearly-universal degradation of multiple performance metrics within groups. On examining the secondary impact of these procedures, we observe heterogeneity of the effect of these procedures on measures of fairness in calibration and ranking across experimental conditions. Beyond the reported trade-offs, we emphasize that analyses of algorithmic fairness in healthcare lack the contextual grounding and causal awareness necessary to reason about the mechanisms that lead to health disparities, as well as about the potential of algorithmic fairness methods to counteract those mechanisms. In light of these limitations, we encourage researchers building predictive models for clinical use to step outside the algorithmic fairness frame and engage critically with the broader sociotechnical context surrounding the use of machine learning in healthcare.",
    "lastUpdated": "2020-11-30T19:25:57Z",
    "categories": [
      "stat.ML",
      "cs.CY",
      "cs.LG",
      "stat.AP"
    ],
    "url": "http://arxiv.org/abs/2007.10306v2"
  },
  {
    "title": "Fairness-Aware Online Personalization",
    "authors": [
      "G Roshan Lal",
      "Sahin Cem Geyik",
      "Krishnaram Kenthapadi"
    ],
    "abstract": "Decision making in crucial applications such as lending, hiring, and college admissions has witnessed increasing use of algorithmic models and techniques as a result of a confluence of factors such as ubiquitous connectivity, ability to collect, aggregate, and process large amounts of fine-grained data using cloud computing, and ease of access to applying sophisticated machine learning models. Quite often, such applications are powered by search and recommendation systems, which in turn make use of personalized ranking algorithms. At the same time, there is increasing awareness about the ethical and legal challenges posed by the use of such data-driven systems. Researchers and practitioners from different disciplines have recently highlighted the potential for such systems to discriminate against certain population groups, due to biases in the datasets utilized for learning their underlying recommendation models. We present a study of fairness in online personalization settings involving the ranking of individuals. Starting from a fair warm-start machine-learned model, we first demonstrate that online personalization can cause the model to learn to act in an unfair manner if the user is biased in his/her responses. For this purpose, we construct a stylized model for generating training data with potentially biased features as well as potentially biased labels and quantify the extent of bias that is learned by the model when the user responds in a biased manner as in many real-world scenarios. We then formulate the problem of learning personalized models under fairness constraints and present a regularization based approach for mitigating biases in machine learning. We demonstrate the efficacy of our approach through extensive simulations with different parameter settings. Code: https://github.com/groshanlal/Fairness-Aware-Online-Personalization",
    "lastUpdated": "2020-09-06T10:03:27Z",
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2007.15270v2"
  },
  {
    "title": "Gibbs Sampling with People",
    "authors": [
      "Peter M. C. Harrison",
      "Raja Marjieh",
      "Federico Adolfi",
      "Pol van Rijn",
      "Manuel Anglada-Tort",
      "Ofer Tchernichovski",
      "Pauline Larrouy-Maestri",
      "Nori Jacoby"
    ],
    "abstract": "A core problem in cognitive science and machine learning is to understand how humans derive semantic representations from perceptual objects, such as color from an apple, pleasantness from a musical chord, or seriousness from a face. Markov Chain Monte Carlo with People (MCMCP) is a prominent method for studying such representations, in which participants are presented with binary choice trials constructed such that the decisions follow a Markov Chain Monte Carlo acceptance rule. However, while MCMCP has strong asymptotic properties, its binary choice paradigm generates relatively little information per trial, and its local proposal function makes it slow to explore the parameter space and find the modes of the distribution. Here we therefore generalize MCMCP to a continuous-sampling paradigm, where in each iteration the participant uses a slider to continuously manipulate a single stimulus dimension to optimize a given criterion such as 'pleasantness'. We formulate both methods from a utility-theory perspective, and show that the new method can be interpreted as 'Gibbs Sampling with People' (GSP). Further, we introduce an aggregation parameter to the transition step, and show that this parameter can be manipulated to flexibly shift between Gibbs sampling and deterministic optimization. In an initial study, we show GSP clearly outperforming MCMCP; we then show that GSP provides novel and interpretable results in three other domains, namely musical chords, vocal emotions, and faces. We validate these results through large-scale perceptual rating experiments. The final experiments use GSP to navigate the latent space of a state-of-the-art image synthesis network (StyleGAN), a promising approach for applying GSP to high-dimensional perceptual spaces. We conclude by discussing future cognitive applications and ethical implications.",
    "lastUpdated": "2020-11-02T16:55:40Z",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.CV",
      "stat.AP"
    ],
    "url": "http://arxiv.org/abs/2008.02595v2"
  },
  {
    "title": "A New Screening Method for COVID-19 based on Ocular Feature Recognition by Machine Learning Tools",
    "authors": [
      "Yanwei Fu",
      "Feng Li",
      "Wenxuan Wang",
      "Haicheng Tang",
      "Xuelin Qian",
      "Mengwei Gu",
      "Xiangyang Xue"
    ],
    "abstract": "The Coronavirus disease 2019 (COVID-19) has affected several million people. With the outbreak of the epidemic, many researchers are devoting themselves to the COVID-19 screening system. The standard practices for rapid risk screening of COVID-19 are the CT imaging or RT-PCR (real-time polymerase chain reaction). However, these methods demand professional efforts of the acquisition of CT images and saliva samples, a certain amount of waiting time, and most importantly prohibitive examination fee in some countries. Recently, some literatures have shown that the COVID-19 patients usually accompanied by ocular manifestations consistent with the conjunctivitis, including conjunctival hyperemia, chemosis, epiphora, or increased secretions. After more than four months study, we found that the confirmed cases of COVID-19 present the consistent ocular pathological symbols; and we propose a new screening method of analyzing the eye-region images, captured by common CCD and CMOS cameras, could reliably make a rapid risk screening of COVID-19 with very high accuracy. We believe a system implementing such an algorithm should assist the triage management or the clinical diagnosis. To further evaluate our algorithm and approved by the Ethics Committee of Shanghai public health clinic center of Fudan University, we conduct a study of analyzing the eye-region images of 303 patients (104 COVID-19, 131 pulmonary, and 68 ocular patients), as well as 136 healthy people. Remarkably, our results of COVID-19 patients in testing set consistently present similar ocular pathological symbols; and very high testing results have been achieved in terms of sensitivity and specificity. We hope this study can be inspiring and helpful for encouraging more researches in this topic.",
    "lastUpdated": "2020-09-04T00:50:27Z",
    "categories": [
      "eess.IV",
      "cs.CV",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2009.03184v1"
  },
  {
    "title": "Epidemic mitigation by statistical inference from contact tracing data",
    "authors": [
      "Antoine Baker",
      "Indaco Biazzo",
      "Alfredo Braunstein",
      "Giovanni Catania",
      "Luca Dall'Asta",
      "Alessandro Ingrosso",
      "Florent Krzakala",
      "Fabio Mazza",
      "Marc Mézard",
      "Anna Paola Muntoni",
      "Maria Refinetti",
      "Stefano Sarao Mannelli",
      "Lenka Zdeborová"
    ],
    "abstract": "Contact-tracing is an essential tool in order to mitigate the impact of pandemic such as the COVID-19. In order to achieve efficient and scalable contact-tracing in real time, digital devices can play an important role. While a lot of attention has been paid to analyzing the privacy and ethical risks of the associated mobile applications, so far much less research has been devoted to optimizing their performance and assessing their impact on the mitigation of the epidemic. We develop Bayesian inference methods to estimate the risk that an individual is infected. This inference is based on the list of his recent contacts and their own risk levels, as well as personal information such as results of tests or presence of syndromes. We propose to use probabilistic risk estimation in order to optimize testing and quarantining strategies for the control of an epidemic. Our results show that in some range of epidemic spreading (typically when the manual tracing of all contacts of infected people becomes practically impossible, but before the fraction of infected people reaches the scale where a lock-down becomes unavoidable), this inference of individuals at risk could be an efficient way to mitigate the epidemic. Our approaches translate into fully distributed algorithms that only require communication between individuals who have recently been in contact. Such communication may be encrypted and anonymized and thus compatible with privacy preserving standards. We conclude that probabilistic risk estimation is capable to enhance performance of digital contact tracing and should be considered in the currently developed mobile applications.",
    "lastUpdated": "2020-09-20T12:24:45Z",
    "categories": [
      "q-bio.PE",
      "cond-mat.stat-mech",
      "cs.AI",
      "cs.LG",
      "G.3; G.4; I.2.11; J.3"
    ],
    "url": "http://arxiv.org/abs/2009.09422v1"
  },
  {
    "title": "A narrowing of AI research?",
    "authors": [
      "Joel Klinger",
      "Juan Mateos-Garcia",
      "Konstantinos Stathoulopoulos"
    ],
    "abstract": "Artificial Intelligence (AI) is being hailed as the latest example of a General Purpose Technology that could transform productivity and help tackle important societal challenges. This outcome is however not guaranteed: a myopic focus on short-term benefits could lock AI into technologies that turn out to be sub-optimal in the longer-run. Recent controversies about the dominance of deep learning methods and private labs in AI research suggest that the field may be getting narrower, but the evidence base is lacking. We seek to address this gap with an analysis of the thematic diversity of AI research in arXiv, a widely used pre-prints site. Having identified 110,000 AI papers in this corpus, we use hierarchical topic modelling to estimate the thematic composition of AI research, and this composition to calculate various metrics of research diversity. Our analysis suggests that diversity in AI research has stagnated in recent years, and that AI research involving private sector organisations tends to be less diverse than research in academia. This appears to be driven by a small number of prolific and narrowly-focused technology companies. Diversity in academia is bolstered by smaller institutions and research groups that may have less incentives to race and lower levels of collaboration with the private sector. We also find that private sector AI researchers tend to specialise in data and computationally intensive deep learning methods at the expense of research involving other (symbolic and statistical) AI methods, and of research that considers the societal and ethical implications of AI or applies it in domains like health. Our results suggest that there may be a rationale for policy action to prevent a premature narrowing of AI research that could reduce its societal benefits, but we note the incentive, information and scale hurdles standing in the way of such interventions.",
    "lastUpdated": "2020-11-17T14:59:09Z",
    "categories": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2009.10385v3"
  },
  {
    "title": "Towards a Policy-as-a-Service Framework to Enable Compliant, Trustworthy AI and HRI Systems in the Wild",
    "authors": [
      "Alexis Morris",
      "Hallie Siegel",
      "Jonathan Kelly"
    ],
    "abstract": "Building trustworthy autonomous systems is challenging for many reasons beyond simply trying to engineer agents that 'always do the right thing.' There is a broader context that is often not considered within AI and HRI: that the problem of trustworthiness is inherently socio-technical and ultimately involves a broad set of complex human factors and multidimensional relationships that can arise between agents, humans, organizations, and even governments and legal institutions, each with their own understanding and definitions of trust. This complexity presents a significant barrier to the development of trustworthy AI and HRI systems---while systems developers may desire to have their systems 'always do the right thing,' they generally lack the practical tools and expertise in law, regulation, policy and ethics to ensure this outcome. In this paper, we emphasize the \"fuzzy\" socio-technical aspects of trustworthiness and the need for their careful consideration during both design and deployment. We hope to contribute to the discussion of trustworthy engineering in AI and HRI by i) describing the policy landscape that must be considered when addressing trustworthy computing and the need for usable trust models, ii) highlighting an opportunity for trustworthy-by-design intervention within the systems engineering process, and iii) introducing the concept of a \"policy-as-a-service\" (PaaS) framework that can be readily applied by AI systems engineers to address the fuzzy problem of trust during the development and (eventually) runtime process. We envision that the PaaS approach, which offloads the development of policy design parameters and maintenance of policy standards to policy experts, will enable runtime trust capabilities intelligent systems in the wild.",
    "lastUpdated": "2020-10-06T18:32:31Z",
    "categories": [
      "cs.CY",
      "cs.HC",
      "cs.RO",
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/2010.07022v1"
  },
  {
    "title": "Next Wave Artificial Intelligence: Robust, Explainable, Adaptable, Ethical, and Accountable",
    "authors": [
      "Odest Chadwicke Jenkins",
      "Daniel Lopresti",
      "Melanie Mitchell"
    ],
    "abstract": "The history of AI has included several \"waves\" of ideas. The first wave, from the mid-1950s to the 1980s, focused on logic and symbolic hand-encoded representations of knowledge, the foundations of so-called \"expert systems\". The second wave, starting in the 1990s, focused on statistics and machine learning, in which, instead of hand-programming rules for behavior, programmers constructed \"statistical learning algorithms\" that could be trained on large datasets. In the most recent wave research in AI has largely focused on deep (i.e., many-layered) neural networks, which are loosely inspired by the brain and trained by \"deep learning\" methods. However, while deep neural networks have led to many successes and new capabilities in computer vision, speech recognition, language processing, game-playing, and robotics, their potential for broad application remains limited by several factors. A concerning limitation is that even the most successful of today's AI systems suffer from brittleness-they can fail in unexpected ways when faced with situations that differ sufficiently from ones they have been trained on. This lack of robustness also appears in the vulnerability of AI systems to adversarial attacks, in which an adversary can subtly manipulate data in a way to guarantee a specific wrong answer or action from an AI system. AI systems also can absorb biases-based on gender, race, or other factors-from their training data and further magnify these biases in their subsequent decision-making. Taken together, these various limitations have prevented AI systems such as automatic medical diagnosis or autonomous vehicles from being sufficiently trustworthy for wide deployment. The massive proliferation of AI across society will require radically new ideas to yield technology that will not sacrifice our productivity, our quality of life, or our values.",
    "lastUpdated": "2020-12-11T00:50:09Z",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2012.06058v1"
  },
  {
    "title": "Measuring Recommender System Effects with Simulated Users",
    "authors": [
      "Sirui Yao",
      "Yoni Halpern",
      "Nithum Thain",
      "Xuezhi Wang",
      "Kang Lee",
      "Flavien Prost",
      "Ed H. Chi",
      "Jilin Chen",
      "Alex Beutel"
    ],
    "abstract": "Imagine a food recommender system -- how would we check if it is \\emph{causing} and fostering unhealthy eating habits or merely reflecting users' interests? How much of a user's experience over time with a recommender is caused by the recommender system's choices and biases, and how much is based on the user's preferences and biases? Popularity bias and filter bubbles are two of the most well-studied recommender system biases, but most of the prior research has focused on understanding the system behavior in a single recommendation step. How do these biases interplay with user behavior, and what types of user experiences are created from repeated interactions? In this work, we offer a simulation framework for measuring the impact of a recommender system under different types of user behavior. Using this simulation framework, we can (a) isolate the effect of the recommender system from the user preferences, and (b) examine how the system performs not just on average for an \"average user\" but also the extreme experiences under atypical user behavior. As part of the simulation framework, we propose a set of evaluation metrics over the simulations to understand the recommender system's behavior. Finally, we present two empirical case studies -- one on traditional collaborative filtering in MovieLens and one on a large-scale production recommender system -- to understand how popularity bias manifests over time.",
    "lastUpdated": "2021-01-12T14:51:11Z",
    "categories": [
      "cs.LG",
      "cs.CY",
      "cs.IR"
    ],
    "url": "http://arxiv.org/abs/2101.04526v1"
  },
  {
    "title": "Automated 3D cephalometric landmark identification using computerized tomography",
    "authors": [
      "Hye Sun Yun",
      "Chang Min Hyun",
      "Seong Hyeon Baek",
      "Sang-Hwy Lee",
      "Jin Keun Seo"
    ],
    "abstract": "Identification of 3D cephalometric landmarks that serve as proxy to the shape of human skull is the fundamental step in cephalometric analysis. Since manual landmarking from 3D computed tomography (CT) images is a cumbersome task even for the trained experts, automatic 3D landmark detection system is in a great need. Recently, automatic landmarking of 2D cephalograms using deep learning (DL) has achieved great success, but 3D landmarking for more than 80 landmarks has not yet reached a satisfactory level, because of the factors hindering machine learning such as the high dimensionality of the input data and limited amount of training data due to ethical restrictions on the use of medical data. This paper presents a semi-supervised DL method for 3D landmarking that takes advantage of anonymized landmark dataset with paired CT data being removed. The proposed method first detects a small number of easy-to-find reference landmarks, then uses them to provide a rough estimation of the entire landmarks by utilizing the low dimensional representation learned by variational autoencoder (VAE). Anonymized landmark dataset is used for training the VAE. Finally, coarse-to-fine detection is applied to the small bounding box provided by rough estimation, using separate strategies suitable for mandible and cranium. For mandibular landmarks, patch-based 3D CNN is applied to the segmented image of the mandible (separated from the maxilla), in order to capture 3D morphological features of mandible associated with the landmarks. We detect 6 landmarks around the condyle all at once, instead of one by one, because they are closely related to each other. For cranial landmarks, we again use VAE-based latent representation for more accurate annotation. In our experiment, the proposed method achieved an averaged 3D point-to-point error of 2.91 mm for 90 landmarks only with 15 paired training data.",
    "lastUpdated": "2020-12-16T07:29:32Z",
    "categories": [
      "cs.CV",
      "eess.IV"
    ],
    "url": "http://arxiv.org/abs/2101.05205v1"
  },
  {
    "title": "K-Stacker, an algorithm to hack the orbital parameters of planets hidden in high-contrast imaging. First applications to VLT SPHERE multi-epoch observations",
    "authors": [
      "H. Le Coroller",
      "M. Nowak",
      "P. Delorme",
      "G. Chauvin",
      "R. Gratton",
      "M. Devinat",
      "J. Bec-Canet",
      "A. Schneeberger",
      "D. Estevez",
      "L. Arnold",
      "H. Beust",
      "M. Bonnefoy",
      "A. Boccaletti",
      "C. Desgrange",
      "S. Desidera",
      "R. Galicher",
      "A. M. Lagrange",
      "M. Langlois",
      "A. L. Maire",
      "F. Menard",
      "P. Vernazza",
      "A. Vigan",
      "A. Zurlo",
      "T. Fenouillet",
      "J. C. Lambert",
      "M. Bonavita",
      "A. Cheetham",
      "V. Dorazi",
      "M. Feldt",
      "M. Janson",
      "R. Ligi",
      "D. Mesa",
      "M. Meyer",
      "M. Samland",
      "E. Sissa",
      "J. L. Beuzit",
      "K. Dohlen",
      "T. Fusco",
      "D. Le Mignant",
      "D. Mouillet",
      "J. Ramos",
      "S. Rochat",
      "J. F. Sauvage"
    ],
    "abstract": "Recent high-contrast imaging surveys, looking for planets in young, nearby systems showed evidence of a small number of giant planets at relatively large separation beyond typically 20 au where those surveys are the most sensitive. Access to smaller physical separations between 5 and 20 au is the next step for future planet imagers on 10 m telescopes and ELTs in order to bridge the gap with indirect techniques (radial velocity, transit, astrometry with Gaia). In that context, we recently proposed a new algorithm, Keplerian-Stacker, combining multiple observations acquired at different epochs and taking into account the orbital motion of a potential planet present in the images to boost the ultimate detection limit. We showed that this algorithm is able to find planets in time series of simulated images of SPHERE even when a planet remains undetected at one epoch. Here, we validate the K-Stacker algorithm performances on real SPHERE datasets, to demonstrate its resilience to instrumental speckles and the gain offered in terms of true detection. This will motivate future dedicated multi-epoch observation campaigns in high-contrast imaging to search for planets in emitted and reflected light. Results. We show that K-Stacker achieves high success rate when the SNR of the planet in the stacked image reaches 7. The improvement of the SNR ratio goes as the square root of the total exposure time. During the blind test and the redetection of HD 95086 b, and betaPic b, we highlight the ability of K-Stacker to find orbital solutions consistent with the ones derived by the state of the art MCMC orbital fitting techniques, confirming that in addition to the detection gain, K-Stacker offers the opportunity to characterize the most probable orbital solutions of the exoplanets recovered at low signal to noise.",
    "lastUpdated": "2020-04-27T15:36:07Z",
    "categories": [
      "astro-ph.EP",
      "astro-ph.IM",
      "astro-ph.SR"
    ],
    "url": "http://arxiv.org/abs/2004.12878v1"
  }
]