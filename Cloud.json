[
  {
    "title": "Considerations for Cloud Security Operations",
    "author": [
      "James Cusick"
    ],
    "abstract": "Information Security in Cloud Computing environments is explored. Cloud Computing is presented, security needs are discussed, and mitigation approaches are listed. Topics covered include Information Security, Cloud Computing, Private Cloud, Public Cloud, SaaS, PaaS, IaaS, ISO 27001, OWASP, Secure SDLC.",
    "lastUpdated": "2016-01-23T17:08:22Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1601.06289v1"
  },
  {
    "title": "Security of Cloud FPGAs: A Survey",
    "author": [
      "Chenglu Jin",
      "Vasudev Gohil",
      "Ramesh Karri",
      "Jeyavijayan Rajendran"
    ],
    "abstract": "Integrating Field Programmable Gate Arrays (FPGAs) with cloud computing instances is a rapidly emerging trend on commercial cloud computing platforms such as Amazon Web Services (AWS), Huawei cloud, and Alibaba cloud. Cloud FPGAs allow cloud users to build hardware accelerators to speed up the computation in the cloud. However, since the cloud FPGA technology is still in its infancy, the security implications of this integration of FPGAs in the cloud are not clear. In this paper, we survey the emerging field of cloud FPGA security, providing a comprehensive overview of the security issues related to cloud FPGAs, and highlighting future challenges in this research area.",
    "lastUpdated": "2020-05-11T05:31:15Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/2005.04867v1"
  },
  {
    "title": "Evolution of Cloud Storage as Cloud Computing Infrastructure Service",
    "author": [
      "Arokia Paul Rajan",
      "Shanmugapriyaa"
    ],
    "abstract": "Enterprises are driving towards less cost, more availability, agility, managed risk - all of which is accelerated towards Cloud Computing. Cloud is not a particular product, but a way of delivering IT services that are consumable on demand, elastic to scale up and down as needed, and follow a pay-for-usage model. Out of the three common types of cloud computing service models, Infrastructure as a Service (IaaS) is a service model that provides servers, computing power, network bandwidth and Storage capacity, as a service to their subscribers. Cloud can relate to many things but without the fundamental storage pieces, which is provided as a service namely Cloud Storage, none of the other applications is possible. This paper introduces Cloud Storage, which covers the key technologies in cloud computing and Cloud Storage, management insights about cloud computing, different types of cloud services, driving forces of cloud computing and cloud storage, advantages and challenges of cloud storage and concludes by pinpointing few challenges to be addressed by the cloud storage providers.",
    "lastUpdated": "2013-08-05T06:11:12Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1308.1303v1"
  },
  {
    "title": "Interoperability and Standardization of Intercloud Cloud Computing",
    "author": [
      "Jingxin K. Wang",
      "Jianrui Ding",
      "Tian Niu"
    ],
    "abstract": "Cloud computing is getting mature, and the interoperability and standardization of the clouds is still waiting to be solved. This paper discussed the interoperability among clouds about message transmission, data transmission and virtual machine transfer. Starting from IEEE Pioneering Cloud Computing Initiative, this paper discussed about standardization of the cloud computing, especially intercloud cloud computing. This paper also discussed the standardization from the market-oriented view.",
    "lastUpdated": "2012-12-24T19:24:35Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1212.5956v1"
  },
  {
    "title": "Discussion of various models related to cloud performance",
    "author": [
      "Chaitanya Krishna Kande"
    ],
    "abstract": "This paper discusses the various models related to cloud computing. Knowing the metrics related to infrastructure is very critical to enhance the performance of cloud services. Various metrics related to clouds such as pageview response time, admission control and enforcing elasticity to cloud infrastructure are very crucial in analyzing the characteristics of the cloud to enhance the cloud performance.",
    "lastUpdated": "2015-05-01T18:10:51Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1505.00236v1"
  },
  {
    "title": "Securing the Data in Clouds with Hyperelliptic Curve Cryptography",
    "author": [
      "Debajyoti Mukhopadhyay",
      "Ashay Shirwadkar",
      "Pratik Gaikar",
      "Tanmay Agrawal"
    ],
    "abstract": "In todays world, Cloud computing has attracted research communities as it provides services in reduced cost due to virtualizing all the necessary resources. Even modern business architecture depends upon Cloud computing .As it is a internet based utility, which provides various services over a network, it is prone to network based attacks. Hence security in clouds is the most important in case of cloud computing. Cloud Security concerns the customer to fully rely on storing data on clouds. That is why Cloud security has attracted attention of the research community. This paper will discuss securing the data in clouds by implementing key agreement, encryption and signature verification/generation with hyperelliptic curve cryptography.",
    "lastUpdated": "2014-11-25T08:56:01Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1411.6771v1"
  },
  {
    "title": "A Survey on Cloud Security Issues and Techniques",
    "author": [
      "Shubhanjali Sharma",
      "Garima Gupta",
      "P. R. Laxmi"
    ],
    "abstract": "Today, cloud computing is an emerging way of computing in computer science. Cloud computing is a set of resources and services that are offered by the network or internet. Cloud computing extends various computing techniques like grid computing, distributed computing. Today cloud computing is used in both industrial field and academic field. Cloud facilitates its users by providing virtual resources via internet. As the field of cloud computing is spreading the new techniques are developing. This increase in cloud computing environment also increases security challenges for cloud developers. Users of cloud save their data in the cloud hence the lack of security in cloud can lose the users trust. In this paper we will discuss some of the cloud security issues in various aspects like multi-tenancy, elasticity, availability etc. The paper also discuss existing security techniques and approaches for a secure cloud. This paper will enable researchers and professionals to know about different security threats and models and tools proposed.",
    "lastUpdated": "2014-03-22T08:49:30Z",
    "category": [
      "cs.DC",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1403.5627v1"
  },
  {
    "title": "Framework for cloud computing adoption: A road map for Smes to cloud migration",
    "author": [
      "Nabeel Khan",
      "Adil Al-Yasiri"
    ],
    "abstract": "Small and Medium size Enterprises (SME) are considered as a backbone of many developing and developed economies of the world; they are the driving force to any major economy across the globe. Through Cloud Computing firms outsource their entire information technology (IT) process while concentrating more on their core business. It allows businesses to cut down heavy cost incurred over IT infrastructure without losing focus on customer needs. However, Cloud industry to an extent has struggled to grow among SMEs due to the reluctance and concerns expressed by them. Throughout the course of this study several interviews were conducted and the literature was reviewed to understand how cloud providers offer services and what challenges SMEs are facing. The study identified issues like cloud knowledge, interoperability, security and contractual concerns to be hindering SMEs adoption of cloud services. From the interviews common practices followed by cloud vendors and what concerns SMEs have were identified as a basis for a cloud framework which will bridge gaps between cloud vendors and SMEs. A stepwise framework for cloud adoption is formulated which identifies and provides recommendation to four most predominant challenges which are hurting cloud industry and taking SMEs away from cloud computing, as well as guide SMEs aiding in successful cloud adoption. Moreover, this framework streamlines the cloud adoption process for SMEs by removing ambiguity in regards to fundamentals associated with their organisation and cloud adoption process.",
    "lastUpdated": "2016-01-07T17:21:41Z",
    "category": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1601.01608v1"
  },
  {
    "title": "Towards a Lightweight Multi-Cloud DSL for Elastic and Transferable Cloud-native Applications",
    "author": [
      "Peter-Christian Quint",
      "Nane Kratzke"
    ],
    "abstract": "Cloud-native applications are intentionally designed for the cloud in order to leverage cloud platform features like horizontal scaling and elasticity - benefits coming along with cloud platforms. In addition to classical (and very often static) multi-tier deployment scenarios, cloud-native applications are typically operated on much more complex but elastic infrastructures. Furthermore, there is a trend to use elastic container platforms like Kubernetes, Docker Swarm or Apache Mesos. However, especially multi-cloud use cases are astonishingly complex to handle. In consequence, cloud-native applications are prone to vendor lock-in. Very often TOSCA-based approaches are used to tackle this aspect. But, these application topology defining approaches are limited in supporting multi-cloud adaption of a cloud-native application at runtime. In this paper, we analyzed several approaches to define cloud-native applications being multi-cloud transferable at runtime. We have not found an approach that fully satisfies all of our requirements. Therefore we introduce a solution proposal that separates elastic platform definition from cloud application definition. We present first considerations for a domain specific language for application definition and demonstrate evaluation results on the platform level showing that a cloud-native application can be transferred between different cloud service providers like Azure and Google within minutes and without downtime. The evaluation covers public and private cloud service infrastructures provided by Amazon Web Services, Microsoft Azure, Google Compute Engine and OpenStack.",
    "lastUpdated": "2018-02-10T10:00:04Z",
    "category": [
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/1802.03562v1"
  },
  {
    "title": "soCloud: A service-oriented component-based PaaS for managing portability, provisioning, elasticity, and high availability across multiple clouds",
    "author": [
      "Fawaz Paraiso",
      "Philippe Merle",
      "Lionel Seinturier"
    ],
    "abstract": "Multi-cloud computing is a promising paradigm to support very large scale world wide distributed applications. Multi-cloud computing is the usage of multiple, independent cloud environments, which assumed no priori agreement between cloud providers or third party. However, multi-cloud computing has to face several key challenges such as portability, provisioning, elasticity, and high availability. Developers will not only have to deploy applications to a specific cloud, but will also have to consider application portability from one cloud to another, and to deploy distributed applications spanning multiple clouds. This article presents soCloud a service-oriented component-based Platform as a Service (PaaS) for managing portability, elasticity, provisioning, and high availability across multiple clouds. soCloud is based on the OASIS Service Component Architecture (SCA) standard in order to address portability. soCloud provides services for managing provisioning, elasticity, and high availability across multiple clouds. soCloud has been deployed and evaluated on top of ten existing cloud providers: Windows Azure, DELL KACE, Amazon EC2, CloudBees, OpenShift, dotCloud, Jelastic, Heroku, Appfog, and an Eucalyptus private cloud.",
    "lastUpdated": "2014-07-08T06:20:48Z",
    "category": [
      "cs.SE",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1407.1963v1"
  },
  {
    "title": "Autonomic Cloud Computing: Research Perspective",
    "author": [
      "Sukhpal Singh Gill"
    ],
    "abstract": "Cloud computing is an evolving utility computing mechanism in which cloud consumer can detect, choose and utilize the resources (infrastructure, software and platform) and provide service to user based on pay per use model as computing utilities. Current computing mechanism is effective, particular for medium and small cloud based companies, in which it permits easy and reliable access to cloud services like infrastructure, software and platform. Present cloud computing is almost similar to the existing models: cluster computing and grid computing. The important key technical features of cloud computing which includes autonomic service, rapid elasticity, end-to-end virtualization support, on-demand resource pooling and transparency in cloud billing. Further, non-technical features of cloud computing includes environment friendliness, little maintenance overhead, lower upfront costs, faster time to deployments, Service Level Agreement (SLA) and pay-as-you-go-model. In distributed computing environment, unpredictability of service is a fact, so same possible in cloud also. The success of next-generation Cloud Computing infrastructures will depend on how capably these infrastructures will discover and dynamically tolerate computing platforms, which meet randomly varying resource and service requirements of Cloud costumer applications.",
    "lastUpdated": "2015-12-06T13:40:07Z",
    "category": [
      "cs.DC",
      "97P70",
      "J.7"
    ],
    "url": "http://arxiv.org/abs/1507.01546v2"
  },
  {
    "title": "An Automated Implementation of Hybrid Cloud for Performance Evaluation of Distributed Databases",
    "author": [
      "Yaser Mansouri",
      "Victor Prokhorenko",
      "M. Ali Babar"
    ],
    "abstract": "A Hybrid cloud is an integration of resources between private and public clouds. It enables users to horizontally scale their on-premises infrastructure up to public clouds in order to improve performance and cut up-front investment cost. This model of applications deployment is called cloud bursting that allows data-intensive applications especially distributed database systems to have the benefit of both private and public clouds. In this work, we present an automated implementation of a hybrid cloud using (i) a robust and zero-cost Linux-based VPN to make a secure connection between private and public clouds, and (ii) Terraform as a software tool to deploy infrastructure resources based on the requirements of hybrid cloud. We also explore performance evaluation of cloud bursting for six modern and distributed database systems on the hybrid cloud spanning over local OpenStack and Microsoft Azure. Our results reveal that MongoDB and MySQL Cluster work efficient in terms of throughput and operations latency if they burst into a public cloud to supply their resources. In contrast, the performance of Cassandra, Riak, Redis, and Couchdb reduces if they significantly leverage their required resources via cloud bursting.",
    "lastUpdated": "2020-06-04T13:08:27Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/2006.02833v1"
  },
  {
    "title": "Thick Cloud Removal of Remote Sensing Images Using Temporal Smoothness and Sparsity-Regularized Tensor Optimization",
    "author": [
      "Chenxi Duan",
      "Jun Pan",
      "Rui Li"
    ],
    "abstract": "In remote sensing images, the presence of thick cloud accompanying cloud shadow is a high probability event, which can affect the quality of subsequent processing and limit the scenarios of application. Hence, removing the thick cloud and cloud shadow as well as recovering the cloud-contaminated pixels is indispensable to make good use of remote sensing images. In this paper, a novel thick cloud removal method for remote sensing images based on temporal smoothness and sparsity-regularized tensor optimization (TSSTO) is proposed. The basic idea of TSSTO is that the thick cloud and cloud shadow are not only sparse but also smooth along the horizontal and vertical direction in images while the clean images are smooth along the temporal direction between images. Therefore, the sparsity norm is used to boost the sparsity of the cloud and cloud shadow, and unidirectional total variation (UTV) regularizers are applied to ensure the unidirectional smoothness. This paper utilizes alternation direction method of multipliers to solve the presented model and generate the cloud and cloud shadow element as well as the clean element. The cloud and cloud shadow element is purified to get the cloud area and cloud shadow area. Then, the clean area of the original cloud-contaminated images is replaced to the corresponding area of the clean element. Finally, the reference image is selected to reconstruct details of the cloud area and cloud shadow area using the information cloning method. A series of experiments are conducted both on simulated and real cloud-contaminated images from different sensors and with different resolutions, and the results demonstrate the potential of the proposed TSSTO method for removing cloud and cloud shadow from both qualitative and quantitative viewpoints.",
    "lastUpdated": "2020-09-01T04:28:23Z",
    "category": [
      "eess.IV",
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2008.04529v2"
  },
  {
    "title": "A Survey on Cloud Computing Security",
    "author": [
      "Hero Modares",
      "Rosli Salleh",
      "Amirhosein Moravejosharieh",
      "Hassan Keshavarz",
      "Majid Talebi Shahgoli"
    ],
    "abstract": "Computation encounter the new approach of cloud computing which maybe keeps the world and possibly can prepare all the human's necessities. In other words, cloud computing is the subsequent regular step in the evolution of on-demand information technology services and products. The Cloud is a metaphor for the Internet and is a concept for the covered complicated infrastructure; it also depends on sketching in computer network diagrams. In this paper we will focus on concept of cloud computing, cloud deployment models, cloud security challenges encryption and data protection, privacy and security and data management and movement from grid to cloud.",
    "lastUpdated": "2012-06-24T07:20:46Z",
    "category": [
      "cs.NI",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1206.5468v1"
  },
  {
    "title": "A Comparative Study of Load Balancing Algorithms in Cloud Computing Environment",
    "author": [
      "Mayanka Katyal",
      "Atul Mishra"
    ],
    "abstract": "Cloud Computing is a new trend emerging in IT environment with huge requirements of infrastructure and resources. Load Balancing is an important aspect of cloud computing environment. Efficient load balancing scheme ensures efficient resource utilization by provisioning of resources to cloud users on demand basis in pay as you say manner. Load Balancing may even support prioritizing users by applying appropriate scheduling criteria. This paper presents various load balancing schemes in different cloud environment based on requirements specified in Service Level Agreement (SLA).",
    "lastUpdated": "2014-03-27T05:07:28Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1403.6918v1"
  },
  {
    "title": "Model-Based Cloud Resource Management with TOSCA and OCCI",
    "author": [
      "Stéphanie Challita",
      "Fabian Korte",
      "Johannes Erbel",
      "Faiez Zalila",
      "Jens Grabowski",
      "Philippe Merle"
    ],
    "abstract": "With the advent of cloud computing, different cloud providers with heterogeneous cloud services (compute, storage, network, applications, etc.) and their related Application Programming Interfaces (APIs) have emerged. This heterogeneity complicates the implementation of an interoperable cloud system. Several standards have been proposed to address this challenge and provide a unified interface to cloud resources. The Open Cloud Computing Interface (OCCI) thereby focuses on the standardization of a common API for Infrastructure-as-a-Service (IaaS) providers while the Topology and Orchestration Specification for Cloud Applications (TOSCA) focuses on the standardization of a template language to enable the proper definition of the topology of cloud applications and their orchestrations on top of a cloud system. TOSCA thereby does not define how the application topologies are created on the cloud. Therefore, we analyse the conceptual similarities between the two approaches and we study how we can integrate them to obtain a complete standard-based approach to manage both cloud infrastructure and cloud application layers. We propose an automated extensive mapping between the concepts of the two standards and we provide TOSCA Studio, a model-driven tool chain for TOSCA that conforms to OCCI. TOSCA Studio allows to graphically design cloud applications as well as to deploy and manage them at runtime using a fully model-driven cloud orchestrator based on the two standards. Our contribution is validated by successfully designing and deploying three cloud applications: WordPress, Node Cellar and Multi-Tier.",
    "lastUpdated": "2020-10-05T22:21:05Z",
    "category": [
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/2001.07900v2"
  },
  {
    "title": "I Have the Proof: Providing Proofs of Past Data Possession in Cloud Forensics",
    "author": [
      "Shams Zawoad",
      "Ragib Hasan"
    ],
    "abstract": "Cloud computing has emerged as a popular computing paradigm in recent years. However, today's cloud computing architectures often lack support for computer forensic investigations. A key task of digital forensics is to prove the presence of a particular file in a given storage system. Unfortunately, it is very hard to do so in a cloud given the black-box nature of clouds and the multi-tenant cloud models. In clouds, analyzing the data from a virtual machine instance or data stored in a cloud storage only allows us to investigate the current content of the cloud storage, but not the previous contents. In this paper, we introduce the idea of building proofs of past data possession in the context of a cloud storage service. We present a scheme for creating such proofs and evaluate its performance in a real cloud provider. We also discuss how this proof of past data possession can be used effectively in cloud forensics.",
    "lastUpdated": "2012-11-19T08:16:59Z",
    "category": [
      "cs.CR",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1211.4328v1"
  },
  {
    "title": "SecLaaS: Secure Logging-as-a-Service for Cloud Forensics",
    "author": [
      "Shams Zawoad",
      "Amit Kumar Dutta",
      "Ragib Hasan"
    ],
    "abstract": "Cloud computing has emerged as a popular computing paradigm in recent years. However, today's cloud computing architectures often lack support for computer forensic investigations. Analyzing various logs (e.g., process logs, network logs) plays a vital role in computer forensics. Unfortunately, collecting logs from a cloud is very hard given the black-box nature of clouds and the multi-tenant cloud models, where many users share the same processing and network resources. Researchers have proposed using log API or cloud management console to mitigate the challenges of collecting logs from cloud infrastructure. However, there has been no concrete work, which shows how to provide cloud logs to investigator while preserving users' privacy and integrity of the logs. In this paper, we introduce Secure-Logging-as-a-Service (SecLaaS), which stores virtual machines' logs and provides access to forensic investigators ensuring the confidentiality of the cloud users. Additionally, SeclaaS preserves proofs of past log and thus protects the integrity of the logs from dishonest investigators or cloud providers. Finally, we evaluate the feasibility of the scheme by implementing SecLaaS for network access logs in OpenStack - a popular open source cloud platform.",
    "lastUpdated": "2013-02-25T22:36:06Z",
    "category": [
      "cs.CR",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1302.6267v1"
  },
  {
    "title": "Formal Specification Language Based IaaS Cloud Workload Regression Analysis",
    "author": [
      "Sukhpal Singh",
      "Inderveer Chana"
    ],
    "abstract": "Cloud Computing is an emerging area for accessing computing resources. In general, Cloud service providers offer services that can be clustered into three categories: SaaS, PaaS and IaaS. This paper discusses the Cloud workload analysis. The efficient Cloud workload resource mapping technique is proposed. This paper aims to provide a means of understanding and investigating IaaS Cloud workloads and the resources. In this paper, regression analysis is used to analyze the Cloud workloads and identifies the relationship between Cloud workloads and available resources. The effective organization of dynamic nature resources can be done with the help of Cloud workloads. Till Cloud workload is considered a vital talent, the Cloud resources cannot be consumed in an effective style. The proposed technique has been validated by Z Formal specification language. This approach is effective in minimizing the cost and submission burst time of Cloud workloads.",
    "lastUpdated": "2014-02-13T05:24:37Z",
    "category": [
      "cs.DC",
      "97P70",
      "J.7"
    ],
    "url": "http://arxiv.org/abs/1402.3034v1"
  },
  {
    "title": "Bridging Ecology and Cloud: Transposing Ecological Prespective to Enable Better Cloud Autoscaling",
    "author": [
      "Tao Chen",
      "Rami Bahsoon"
    ],
    "abstract": "Elastic autoscaling is the fundamental mechanism that enables the cloud-based services to continually evolve themselves - through changing the related software configurations and hardware resource provisions - under time-varying workloads. However, given the increasingly complex dynamic, uncertainty and trade-offs related to the runtime QoS and cost/energy of services, cloud autoscaling system is becoming one of the most complex artifacts constructed by human and thus its effectiveness is difficult to be preserved. In this article, we present novel ideas for facilitating cloud autoscaling. Our hypothesis that cloud ecosystem, represented by a collection of cloud-based services, bears many similarities with the natural ecosystem. As such, we in- tend to investigate how ecological view can be adopted to better explain how the cloud-based services evolve, and to explore what are the key factors that drive stable and sustainable cloud-based services in the cloud. To achieve this goal, we aim to transpose ecological principles, theories and models into cloud autoscaling analogues and spontaneously improve long-term stability and sustainability of cloud ecosystem.",
    "lastUpdated": "2016-08-21T12:17:42Z",
    "category": [
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/1608.05926v1"
  },
  {
    "title": "An Analysis of the Cloud Computing Security Problem",
    "author": [
      "Mohamed Almorsy",
      "John Grundy",
      "Ingo Müller"
    ],
    "abstract": "Cloud computing is a new computational paradigm that offers an innovative business model for organizations to adopt IT without upfront investment. Despite the potential gains achieved from the cloud computing, the model security is still questionable which impacts the cloud model adoption. The security problem becomes more complicated under the cloud model as new dimensions have entered into the problem scope related to the model architecture, multi-tenancy, elasticity, and layers dependency stack. In this paper we introduce a detailed analysis of the cloud security problem. We investigated the problem from the cloud architecture perspective, the cloud offered characteristics perspective, the cloud stakeholders' perspective, and the cloud service delivery models perspective. Based on this analysis we derive a detailed specification of the cloud security problem and key features that should be covered by any proposed security solution.",
    "lastUpdated": "2016-09-05T11:31:42Z",
    "category": [
      "cs.SE",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1609.01107v1"
  },
  {
    "title": "Cloud Resource Allocation for Cloud-Based Automotive Applications",
    "author": [
      "Zhaojian Li",
      "Tianshu Chu",
      "Ilya V. Kolmanovsky",
      "Xiang Yin",
      "Xunyuan Yin"
    ],
    "abstract": "There is a rapidly growing interest in the use of cloud computing for automotive vehicles to facilitate computation and data intensive tasks. Efficient utilization of on-demand cloud resources holds a significant potential to improve future vehicle safety, comfort, and fuel economy. In the meanwhile, issues like cyber security and resource allocation pose great challenges. In this paper, we treat the resource allocation problem for cloud-based automotive systems. Both private and public cloud paradigms are considered where a private cloud provides an internal, company-owned internet service dedicated to its own vehicles while a public cloud serves all subscribed vehicles. This paper establishes comprehensive models of cloud resource provisioning for both private and public cloud- based automotive systems. Complications such as stochastic communication delays and task deadlines are explicitly considered. In particular, a centralized resource provisioning model is developed for private cloud and chance constrained optimization is exploited to utilize the cloud resources for best Quality of Services. On the other hand, a decentralized auction-based model is developed for public cloud and reinforcement learning is employed to obtain an optimal bidding policy for a \"selfish\" agent. Numerical examples are presented to illustrate the effectiveness of the developed techniques.",
    "lastUpdated": "2017-01-17T05:48:56Z",
    "category": [
      "cs.SY"
    ],
    "url": "http://arxiv.org/abs/1701.04537v1"
  },
  {
    "title": "Cloud Brokerage: A Systematic Survey",
    "author": [
      "Abdessalam Elhabbash",
      "Faiza Samreen",
      "James Hadley",
      "Yehia Elkhatib"
    ],
    "abstract": "Background: The proliferation of cloud providers and provisioning levels has opened a space for cloud brokerage services. Brokers intermediate between cloud customers and providers to assist the customer in selecting the most suitable cloud service, helping to manage the dimensionality, heterogeneity, and uncertainty associated with cloud services. Objective: This paper identifies and classifies approaches to realise cloud brokerage. By doing so, this paper presents an understanding of the state of the art and a novel taxonomy to characterise cloud brokers. Method: We conducted a systematic literature survey to compile studies related to cloud brokerage and explore how cloud brokers are engineered. We analysed the studies from multiple perspectives, such as motivation, functionality, engineering approach, and evaluation methodology. Results: The survey resulted in a knowledge base of current proposals for realising cloud brokers. The survey identified surprising differences between the studies' implementations, with engineering efforts directed at combinations of market-based solutions, middlewares, toolkits, algorithms, semantic frameworks, and conceptual frameworks. Conclusion: Our comprehensive meta-analysis shows that cloud brokerage is still a formative field. There is no doubt that progress has been achieved in the field but considerable challenges remain to be addressed. This survey identifies such challenges and directions for future research.",
    "lastUpdated": "2018-05-23T09:15:57Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1805.09018v1"
  },
  {
    "title": "Resource Management in Cloud Computing: Classification and Taxonomy",
    "author": [
      "Swapnil M Parikh",
      "Narendra M Patel",
      "Harshadkumar B Prajapati"
    ],
    "abstract": "Cloud Computing is a new era of remote computing / Internet based computing where one can access their personal resources easily from any computer through Internet. Cloud delivers computing as a utility as it is available to the cloud consumers on demand. It is a simple pay-per-use consumer-provider service model. It contains large number of shared resources. So Resource Management is always a major issue in cloud computing like any other computing paradigm. Due to the availability of finite resources it is very challenging for cloud providers to provide all the requested resources. From the cloud providers perspective cloud resources must be allocated in a fair and efficient manner. Research Survey is not available from the perspective of resource management as a process in cloud computing. So this research paper provides a detailed sequential view / steps on resource management in cloud computing. Firstly this research paper classifies various resources in cloud computing. It also gives taxonomy on resource management in cloud computing through which one can do further research. Lastly comparisons on various resource management algorithms has been presented.",
    "lastUpdated": "2017-02-24T11:39:59Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1703.00374v1"
  },
  {
    "title": "Multi-Head Linear Attention Generative Adversarial Network for Thin Cloud Removal",
    "author": [
      "Chenxi Duan",
      "Rui Li"
    ],
    "abstract": "In remote sensing images, the existence of the thin cloud is an inevitable and ubiquitous phenomenon that crucially reduces the quality of imageries and limits the scenarios of application. Therefore, thin cloud removal is an indispensable procedure to enhance the utilization of remote sensing images. Generally, even though contaminated by thin clouds, the pixels still retain more or less surface information. Hence, different from thick cloud removal, thin cloud removal algorithms normally concentrate on inhibiting the cloud influence rather than substituting the cloud-contaminated pixels. Meanwhile, considering the surface features obscured by the cloud are usually similar to adjacent areas, the dependency between each pixel of the input is useful to reconstruct contaminated areas. In this paper, to make full use of the dependencies between pixels of the image, we propose a Multi-Head Linear Attention Generative Adversarial Network (MLAGAN) for Thin Cloud Removal. The MLA-GAN is based on the encoding-decoding framework consisting of multiple attention-based layers and deconvolutional layers. Compared with six deep learning-based thin cloud removal benchmarks, the experimental results on the RICE1 and RICE2 datasets demonstrate that the proposed framework MLA-GAN has dominant advantages in thin cloud removal.",
    "lastUpdated": "2020-12-20T11:50:54Z",
    "category": [
      "cs.CV",
      "eess.IV"
    ],
    "url": "http://arxiv.org/abs/2012.10898v1"
  },
  {
    "title": "An Experimental Study of Load Balancing of OpenNebula Open-Source Cloud Computing Platform",
    "author": [
      "A B M Moniruzzaman",
      "Kawser Wazed Nafi",
      "Syed Akther Hossain"
    ],
    "abstract": "Cloud Computing is becoming a viable computing solution for services oriented computing. Several open-source cloud solutions are available to these supports. Open-source software stacks offer a huge amount of customizability without huge licensing fees. As a result, open source software are widely used for designing cloud, and private clouds are being built increasingly in the open source way. Numerous contributions have been made by the open-source community related to private-IaaS-cloud. OpenNebula - a cloud platform is one of the popular private cloud management software. However, little has been done to systematically investigate the performance evaluation of this open-source cloud solution in the existing literature. The performance evaluation aids new and existing research, industry and international projects when selecting OpenNebula software to their work. The objective of this paper is to evaluate the load-balancing performance of the OpenNebula cloud management software. For the performance evaluation, the OpenNebula cloud management software is installed and configured as a prototype implementation and tested on the DIU Cloud Lab. In this paper, two set of experiments are conducted to identify the load balancing performance of the OpenNebula cloud management platform- (1) Delete and Add Virtual Machine (VM) from OpenNebula cloud platform; (2) Mapping Physical Hosts to Virtual Machines (VMs) in the OpenNebula cloud platform.",
    "lastUpdated": "2014-06-22T20:40:07Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1406.5759v1"
  },
  {
    "title": "FASTCloud: A framework of assessment and selection for trustworthy cloud service based on QoS",
    "author": [
      "Xiang Li"
    ],
    "abstract": "By virtue of technology and benefit advantages, cloud computing has increasingly attracted a large number of potential cloud consumers (PCC) plan to migrate traditional business to the cloud service. However, trust has become one of the most challenging issues that prevent the PCC from adopting cloud services, especially in trustworthy cloud service selection. In addition, due to the diversity and dynamic of quality of service (QoS) in cloud environment, the existing trust assessment methods based on the single constant value of QoS attribute and the subjective weight assignment are not good enough to provides an effective solution for PCCs to identify and select a trustworthy cloud service among a wide range of functionally-equivalent cloud service providers (CSP). To address the challenge, a novel assessment and selection framework for trustworthy cloud service, FASTCloud, is proposed in this study. This framework facilitate PCCs to select a trustworthy cloud service based on their actual QoS requirements. In order to accurately and efficiently assess the trust level of cloud services, a QoS-based trust assessment model is proposed. This model represents a trust level assessment method based on the interval multiple attributes with a objective weight assignment method based on the deviation maximization to adaptively determine the trust level of different cloud services provisioned by candidate CSPs. The advantage of proposed trust level assessment method in time complexity is demonstrated by the performance analysis and comparison.The experimental result of a case study with an open source dataset shows that the trust model is efficient in cloud service trust assessment and the FASTCloud can effectively help PCCs select a trustworthy cloud service.",
    "lastUpdated": "2020-11-02T01:18:05Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/2011.01871v1"
  },
  {
    "title": "Compute and Storage Clouds Using Wide Area High Performance Networks",
    "author": [
      "Robert L. Grossman",
      "Yunhong Gu",
      "Michael Sabala",
      "Wanzhi Zhang"
    ],
    "abstract": "We describe a cloud based infrastructure that we have developed that is optimized for wide area, high performance networks and designed to support data mining applications. The infrastructure consists of a storage cloud called Sector and a compute cloud called Sphere. We describe two applications that we have built using the cloud and some experimental studies.",
    "lastUpdated": "2008-08-13T09:48:37Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/0808.1802v1"
  },
  {
    "title": "Defining Cross-Cloud Systems",
    "author": [
      "Yehia Elkhatib"
    ],
    "abstract": "Recent years have seen an increasing number of cross-cloud architectures, i.e. systems that span across cloud provisioning boundaries. However, the cloud computing world still lacks any standards in terms of programming interfaces, which has a knock-on effect on the costs associated with interoperability and severely limits the flexibility and portability of applications and virtual infrastructures. This paper outlines the different types of cross-cloud systems, and the associated design decisions.",
    "lastUpdated": "2016-02-08T19:13:32Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1602.02698v1"
  },
  {
    "title": "Is Cloud Computing Steganography-proof?",
    "author": [
      "Wojciech Mazurczyk",
      "Krzysztof Szczypiorski"
    ],
    "abstract": "The paper focuses on characterisation of information hiding possibilities in Cloud Computing. After general introduction to cloud computing and its security we move to brief description of steganography. In particular we introduce classification of steganographic communication scenarios in cloud computing which is based on location of the steganograms receiver. These scenarios as well as the threats that steganographic methods can cause must be taken into account when designing secure cloud computing services.",
    "lastUpdated": "2011-07-20T19:18:36Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1107.4077v1"
  },
  {
    "title": "Towards Constraint-based High Performance Cloud System in the Process of Cloud Computing Adoption in an Organization",
    "author": [
      "Mikael Fernandus Simalango",
      "Mun-Young Kang",
      "Sangyoon Oh"
    ],
    "abstract": "Cloud computing is penetrating into various domains and environments, from theoretical computer science to economy, from marketing hype to educational curriculum and from R&D lab to enterprise IT infrastructure. Yet, the currently developing state of cloud computing leaves several issues to address and also affects cloud computing adoption by organizations. In this paper, we explain how the transition into the cloud can occur in an organization and describe the mechanism for transforming legacy infrastructure into a virtual infrastructure-based cloud. We describe the state of the art of infrastructural cloud, which is essential in the decision making on cloud adoption, and highlight the challenges that can limit the scale and speed of the adoption. We then suggest a strategic framework for designing a high performance cloud system. This framework is applicable when transformation cloudbased deployment model collides with some constraints. We give an example of the implementation of the framework in a design of a budget-constrained high availability cloud system.",
    "lastUpdated": "2010-10-24T12:08:12Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1010.4952v1"
  },
  {
    "title": "Platforms for Building and Deploying Applications for Cloud Computing",
    "author": [
      "Rajkumar Buyya",
      "Karthik Sukumar"
    ],
    "abstract": "Cloud computing is rapidly emerging as a new paradigm for delivering IT services as utlity-oriented services on subscription-basis. The rapid development of applications and their deployment in Cloud computing environments in efficient manner is a complex task. In this article, we give a brief introduction to Cloud computing technology and Platform as a Service, we examine the offerings in this category, and provide the basis for helping readers to understand basic application platform opportunities in Cloud by technologies such as Microsoft Azure, Sales Force, Google App, and Aneka for Cloud computing. We demonstrate that Manjrasoft Aneka is a Cloud Application Platform (CAP) leveraging these concepts and allowing an easy development of Cloud ready applications on a Private/Public/Hybrid Cloud. Aneka CAP offers facilities for quickly developing Cloud applications and a modular platform where additional services can be easily integrated to extend the system capabilities, thus being at pace with the rapidly evolution of Cloud computing.",
    "lastUpdated": "2011-04-22T02:51:54Z",
    "category": [
      "cs.DC",
      "C.1.4"
    ],
    "url": "http://arxiv.org/abs/1104.4379v1"
  },
  {
    "title": "Cloud Infrastructure Service Management - A Review",
    "author": [
      "A. Anasuya Threse Innocent"
    ],
    "abstract": "The new era of computing called Cloud Computing allows the user to access the cloud services dynamically over the Internet wherever and whenever needed. Cloud consists of data and resources; and the cloud services include the delivery of software, infrastructure, applications, and storage over the Internet based on user demand through Internet. In short, cloud computing is a business and economic model allowing the users to utilize high-end computing and storage virtually with minimal infrastructure on their end. Cloud has three service models namely, Cloud Software-as-a-Service (SaaS), Cloud Platform-as-a-Service (PaaS), and Cloud Infrastructure-as-a-Service (IaaS). This paper talks in depth of cloud infrastructure service management.",
    "lastUpdated": "2012-05-30T09:45:54Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1206.6016v1"
  },
  {
    "title": "Towards a Taxonomy of Performance Evaluation of Commercial Cloud Services",
    "author": [
      "Zheng Li",
      "Liam O'Brien",
      "Rainbow Cai",
      "He Zhang"
    ],
    "abstract": "Cloud Computing, as one of the most promising computing paradigms, has become increasingly accepted in industry. Numerous commercial providers have started to supply public Cloud services, and corresponding performance evaluation is then inevitably required for Cloud provider selection or cost-benefit analysis. Unfortunately, inaccurate and confusing evaluation implementations can be often seen in the context of commercial Cloud Computing, which could severely interfere and spoil evaluation-related comprehension and communication. This paper introduces a taxonomy to help profile and standardize the details of performance evaluation of commercial Cloud services. Through a systematic literature review, we constructed the taxonomy along two dimensions by arranging the atomic elements of Cloud-related performance evaluation. As such, this proposed taxonomy can be employed both to analyze existing evaluation practices through decomposition into elements and to design new experiments through composing elements for evaluating performance of commercial Cloud services. Moreover, through smooth expansion, we can continually adapt this taxonomy to the more general area of evaluation of Cloud Computing.",
    "lastUpdated": "2013-02-08T07:20:30Z",
    "category": [
      "cs.DC",
      "cs.PF"
    ],
    "url": "http://arxiv.org/abs/1302.1957v1"
  },
  {
    "title": "Cost Minimization in Multiple IaaS Clouds: A Double Auction Approach",
    "author": [
      "Jian Zhao",
      "Chuan Wu",
      "Zongpeng Li"
    ],
    "abstract": "IaaS clouds invest substantial capital in operating their data centers. Reducing the cost of resource provisioning, is their forever pursuing goal. Computing resource trading among multiple IaaS clouds provide a potential for IaaS clouds to utilize cheaper resources to fulfill their jobs, by exploiting the diversities of different clouds' workloads and operational costs. In this paper, we focus on studying the IaaS clouds' cost reduction through computing resource trading among multiple IaaS clouds. We formulate the global cost minimization problem among multiple IaaS clouds under cooperative scenario where each individual cloud's workload and cost information is known. Taking into consideration jobs with disparate lengths, a non-preemptive approximation algorithm for leftover job migration and new job scheduling is designed. Given to the selfishness of individual clouds, we further design a randomized double auction mechanism to elicit clouds' truthful bidding for buying or selling virtual machines. We evaluate our algorithms using trace-driven simulations.",
    "lastUpdated": "2013-12-08T09:15:59Z",
    "category": [
      "cs.NI",
      "cs.GT"
    ],
    "url": "http://arxiv.org/abs/1308.0841v3"
  },
  {
    "title": "Checkpointing as a Service in Heterogeneous Cloud Environments",
    "author": [
      "Jiajun Cao",
      "Matthieu Simonin",
      "Gene Cooperman",
      "Christine Morin"
    ],
    "abstract": "A non-invasive, cloud-agnostic approach is demonstrated for extending existing cloud platforms to include checkpoint-restart capability. Most cloud platforms currently rely on each application to provide its own fault tolerance. A uniform mechanism within the cloud itself serves two purposes: (a) direct support for long-running jobs, which would otherwise require a custom fault-tolerant mechanism for each application; and (b) the administrative capability to manage an over-subscribed cloud by temporarily swapping out jobs when higher priority jobs arrive. An advantage of this uniform approach is that it also supports parallel and distributed computations, over both TCP and InfiniBand, thus allowing traditional HPC applications to take advantage of an existing cloud infrastructure. Additionally, an integrated health-monitoring mechanism detects when long-running jobs either fail or incur exceptionally low performance, perhaps due to resource starvation, and proactively suspends the job. The cloud-agnostic feature is demonstrated by applying the implementation to two very different cloud platforms: Snooze and OpenStack. The use of a cloud-agnostic architecture also enables, for the first time, migration of applications from one cloud platform to another.",
    "lastUpdated": "2015-03-21T01:21:20Z",
    "category": [
      "cs.DC",
      "H.3.4; C.2.4"
    ],
    "url": "http://arxiv.org/abs/1411.1958v2"
  },
  {
    "title": "Usage of Cloud Computing Simulators and Future Systems For Computational Research",
    "author": [
      "Ramkumar Lakshminarayanan",
      "Rajasekar Ramalingam"
    ],
    "abstract": "Cloud Computing is an Internet based computing, whereby shared resources, software and information, are provided to computers and devices on demand, like the electricity grid. Currently, IaaS (Infrastructure as a Service), PaaS (Platform as a Service) and SaaS (Software as a Service) are used as a business model for Cloud Computing. Nowadays, the adoption and deployment of Cloud Computing is increasing in various domains, forcing researchers to conduct research in the area of Cloud Computing globally. Setting up the research environment is critical for the researchers in the developing countries to evaluate the research outputs. Currently, modeling, simulation technology and access of resources from various university data centers has become a useful and powerful tool in cloud computing research. Several cloud simulators have been specifically developed by various universities to carry out Cloud Computing research, including CloudSim, SPECI, Green Cloud and Future Systems (the Indiana University machines India, Bravo, Delta, Echo and Foxtrot) supports leading edge data science research and a broad range of computing-enabled education as well as integration of ideas from cloud and HPC systems. In this paper, the features, suitability, adaptability and the learning curve of the existing Cloud Computing simulators and Future Systems are reviewed and analyzed.",
    "lastUpdated": "2016-04-30T09:30:14Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1605.00085v1"
  },
  {
    "title": "A Cost-Effective Strategy for Storing Scientific Datasets with Multiple Service Providers in the Cloud",
    "author": [
      "Dong Yuan",
      "Lizhen Cui",
      "Xiao Liu",
      "Erjiang Fu",
      "Yun Yang"
    ],
    "abstract": "Cloud computing provides scientists a platform that can deploy computation and data intensive applications without infrastructure investment. With excessive cloud resources and a decision support system, large generated data sets can be flexibly 1 stored locally in the current cloud, 2 deleted and regenerated whenever reused or 3 transferred to cheaper cloud service for storage. However, due to the pay for use model, the total application cost largely depends on the usage of computation, storage and bandwidth resources, hence cutting the cost of cloud based data storage becomes a big concern for deploying scientific applications in the cloud. In this paper, we propose a novel strategy that can cost effectively store large generated data sets with multiple cloud service providers. The strategy is based on a novel algorithm that finds the trade off among computation, storage and bandwidth costs in the cloud, which are three key factors for the cost of data storage. Both general (random) simulations conducted with popular cloud service providers pricing models and three specific case studies on real world scientific applications show that the proposed storage strategy is highly cost effective and practical for run time utilization in the cloud.",
    "lastUpdated": "2016-01-26T14:07:45Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1601.07028v1"
  },
  {
    "title": "Generating the Cloud Motion Winds Field from Satellite Cloud Imagery Using Deep Learning Approach",
    "author": [
      "Chao Tan"
    ],
    "abstract": "Cloud motion winds (CMW) are routinely derived by tracking features in sequential geostationary satellite infrared cloud imagery. In this paper, we explore the cloud motion winds algorithm based on data-driven deep learning approach, and different from conventional hand-craft feature tracking and correlation matching algorithms, we use deep learning model to automatically learn the motion feature representations and directly output the field of cloud motion winds. In addition, we propose a novel large-scale cloud motion winds dataset (CMWD) for training deep learning models. We also try to use a single cloud imagery to predict the cloud motion winds field in a fixed region, which is impossible to achieve using traditional algorithms. The experimental results demonstrate that our algorithm can predict the cloud motion winds field efficiently, and even with a single cloud imagery as input.",
    "lastUpdated": "2020-10-03T05:40:36Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2010.01283v1"
  },
  {
    "title": "A Novel Application Licensing Framework for Mobile Cloud Environment",
    "author": [
      "Atta ur Rehman Khan",
      "Mazliza Othman",
      "Abdul Nasir Khan"
    ],
    "abstract": "Mobile cloud computing is a new technology that enhances smartphone applications capabilities in terms of performance, energy efficiency, and execution support. These features are achieved via computation offloading technique that is supported by specialized mobile cloud application development models. However, the cloud-enabled applications are prone to application piracy issue for which the traditional licensing frameworks are of no use. Therefore, a new licensing framework is required to control application piracy in mobile cloud environment. This paper presents a preliminary design of a novel application licensing framework for mobile cloud environment that restricts execution of applications on unauthenticated smartphones and cloud resources.",
    "lastUpdated": "2013-12-30T21:59:30Z",
    "category": [
      "cs.CY",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1401.0034v1"
  },
  {
    "title": "On Cloud-Based Engineering of Dependable Systems",
    "author": [
      "Sami Alajrami"
    ],
    "abstract": "The cloud computing paradigm is being adopted by many organizations in different application domains as it is cost effective and offers a virtually unlimited pool of resources. Engineering critical systems can benefit from clouds in attaining all dependability means: fault tolerance, fault prevention, fault removal and fault forecasting. Our research aims to investigate the potential of supporting engineering of dependable software systems with cloud computing and proposes an open, extensible, and elastic cloud-based software engineering workflow system which represents and executes software processes to improve collaboration, reliability and quality assurance, and automation in software projects.",
    "lastUpdated": "2014-04-29T20:01:55Z",
    "category": [
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/1404.7509v1"
  },
  {
    "title": "Digital Forensic Investigation of Cloud Storage Services",
    "author": [
      "Hyunji Chung",
      "Jungheum Park",
      "Sangjin Lee",
      "Chulhoon Kang"
    ],
    "abstract": "The demand for cloud computing is increasing because of the popularity of digital devices and the wide use of the Internet. Among cloud computing services, most consumers use cloud storage services that provide mass storage. This is because these services give them various additional functions as well as storage. It is easy to access cloud storage services using smartphones. With increasing utilization, it is possible for malicious users to abuse cloud storage services. Therefore, a study on digital forensic investigation of cloud storage services is necessary. This paper proposes new procedure for investigating and analyzing the artifacts of all accessible devices, such as Windows, Mac, iPhone, and Android smartphone.",
    "lastUpdated": "2017-08-22T19:16:08Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1709.10395v1"
  },
  {
    "title": "Lidar Cloud Detection with Fully Convolutional Networks",
    "author": [
      "Erol Cromwell",
      "Donna Flynn"
    ],
    "abstract": "In this contribution, we present a novel approach for segmenting laser radar (lidar) imagery into geometric time-height cloud locations with a fully convolutional network (FCN). We describe a semi-supervised learning method to train the FCN by: pre-training the classification layers of the FCN with image-level annotations, pre-training the entire FCN with the cloud locations of the MPLCMASK cloud mask algorithm, and fully supervised learning with hand-labeled cloud locations. We show the model achieves higher levels of cloud identification compared to the cloud mask algorithm implementation.",
    "lastUpdated": "2018-07-11T23:39:33Z",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1805.00928v2"
  },
  {
    "title": "Application of Ontologies in Cloud Computing: The State-Of-The-Art",
    "author": [
      "Fahim T. Imam"
    ],
    "abstract": "This paper presents a systematic survey on existing literature and seminal works relevant to the application of ontologies in different aspects of Cloud computing. Our hypothesis is that ontologies along with their reasoning capabilities can have significant impact on improving various aspects of the Cloud computing phenomena. Ontologies can promote intelligent decision support mechanisms for various Cloud based services. They can also provide effective interoperability among the Cloud based systems and resources. This survey can promote a comprehensive understanding on the roles and significance of ontologies within the overall domain of Cloud Computing. Also, this project can potentially form the basis of new research area and possibilities for both ontology and Cloud computing communities.",
    "lastUpdated": "2016-10-06T05:39:37Z",
    "category": [
      "cs.DC",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1610.02333v1"
  },
  {
    "title": "A Slow Read attack Using Cloud",
    "author": [
      "Darine Ameyed",
      "Fehmi Jaafar",
      "Jaouhar Fattahi"
    ],
    "abstract": "Cloud computing relies on sharing computing resources rather than having local servers or personal devices to handle applications. Nowadays, cloud computing has become one of the fastest growing fields in information technology. However, several new security issues of cloud computing have emerged due to its service delivery models. In this paper, we discuss the case of distributed denial-of-service (DDoS) attack using Cloud resources. First, we show how such attack using a cloud platform could not be detected by previous techniques. Then we present a tricky solution based on the cloud as well.",
    "lastUpdated": "2017-12-05T21:41:00Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1712.01939v1"
  },
  {
    "title": "A Preliminary Study On Emerging Cloud Computing Security Challenges",
    "author": [
      "Babin Bhandari",
      "James Zheng"
    ],
    "abstract": "Cloud computing is the internet based provisioning of the computing resources, software, and information on demand. Cloud Computing is referred to as one of most recent emerging paradigms of computing utilities. Since Cloud computing is the dominant infrastructure of the shared services over the internet, it is important to be aware of the security risk and the challenges associated with this emerging computing paradigm. This survey provides a brief introduction to the cloud computing, its major characteristics, and service models. It also explores cloud security threats, lists a few security solutions , and proposes a promsing research direction to deal with the evolving security challenges in Cloud computing.",
    "lastUpdated": "2018-08-13T10:45:38Z",
    "category": [
      "cs.CR",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1808.04143v1"
  },
  {
    "title": "MediaWise - Designing a Smart Media Cloud",
    "author": [
      "Dimitrios Georgakopoulos",
      "Rajiv Ranjan",
      "Karan Mitra",
      "Xiangmin Zhou"
    ],
    "abstract": "The MediaWise project aims to expand the scope of existing media delivery systems with novel cloud, personalization and collaboration capabilities that can serve the needs of more users, communities, and businesses. The project develops a MediaWise Cloud platform that supports do-it-yourself creation, search, management, and consumption of multimedia content. The MediaWise Cloud supports pay-as-you-go models and elasticity that are similar to those offered by commercially available cloud services. However, unlike existing commercial CDN services providers such as Limelight Networks and Akamai the MediaWise Cloud require no ownerships of computing infrastructure and instead rely on the public Internet and public cloud services (e.g., commercial cloud storage to store its content). In addition to integrating such public cloud services into a public cloud-based Content Delivery Network, the MediaWise Cloud also provides advanced Quality of Service (QoS) management as required for the delivery of streamed and interactive high resolution multimedia content. In this paper, we give a brief overview of MediaWise Cloud architecture and present a comprehensive discussion on research objectives related to its service components. Finally, we also compare the features supported by the existing CDN services against the envisioned objectives of MediaWise Cloud.",
    "lastUpdated": "2012-06-18T03:12:37Z",
    "category": [
      "cs.DC",
      "cs.MM",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1206.1943v2"
  },
  {
    "title": "Dynamic Polygon Clouds: Representation and Compression for VR/AR",
    "author": [
      "Philip A. Chou",
      "Eduardo Pavez",
      "Ricardo L. de Queiroz",
      "Antonio Ortega"
    ],
    "abstract": "We introduce the {\\em polygon cloud}, also known as a polygon set or {\\em soup}, as a compressible representation of 3D geometry (including its attributes, such as color texture) intermediate between polygonal meshes and point clouds. Dynamic or time-varying polygon clouds, like dynamic polygonal meshes and dynamic point clouds, can take advantage of temporal redundancy for compression, if certain challenges are addressed. In this paper, we propose methods for compressing both static and dynamic polygon clouds, specifically triangle clouds. We compare triangle clouds to both triangle meshes and point clouds in terms of compression, for live captured dynamic colored geometry. We find that triangle clouds can be compressed nearly as well as triangle meshes, while being far more robust to noise and other structures typically found in live captures, which violate the assumption of a smooth surface manifold, such as lines, points, and ragged boundaries. We also find that triangle clouds can be used to compress point clouds with significantly better performance than previously demonstrated point cloud compression methods. In particular, for intra-frame coding of geometry, our method improves upon octree-based intra-frame coding by a factor of 5-10 in bit rate. Inter-frame coding improves this by another factor of 2-5. Overall, our dynamic triangle cloud compression improves over the previous state-of-the-art in dynamic point cloud compression by 33\\% or more.",
    "lastUpdated": "2017-03-08T06:25:45Z",
    "category": [
      "cs.GR"
    ],
    "url": "http://arxiv.org/abs/1610.00402v2"
  },
  {
    "title": "A novel tree-structured point cloud dataset for skeletonization algorithm evaluation",
    "author": [
      "Yan Lin",
      "Ji Liu",
      "Jianlin Zhou"
    ],
    "abstract": "Curve skeleton extraction from unorganized point cloud is a fundamental task of computer vision and three-dimensional data preprocessing and visualization. A great amount of work has been done to extract skeleton from point cloud. but the lack of standard datasets of point cloud with ground truth skeleton makes it difficult to evaluate these algorithms. In this paper, we construct a brand new tree-structured point cloud dataset, including ground truth skeletons, and point cloud models. In addition, four types of point cloud are built on clean point cloud: point clouds with noise, point clouds with missing data, point clouds with different density, and point clouds with uneven density distribution. We first use tree editor to build the tree skeleton and corresponding mesh model. Since the implicit surface is sufficiently expressive to retain the edges and details of the complex branches model, we use the implicit surface to model the triangular mesh. With the implicit surface, virtual scanner is applied to the sampling of point cloud. Finally, considering the challenges in skeleton extraction, we introduce different methods to build four different types of point cloud models. This dataset can be used as standard dataset for skeleton extraction algorithms. And the evaluation between skeleton extraction algorithms can be performed by comparing the ground truth skeleton with the extracted skeleton.",
    "lastUpdated": "2020-01-09T03:35:57Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2001.02823v1"
  },
  {
    "title": "Research Challenges for Enterprise Cloud Computing",
    "author": [
      "Ali Khajeh-Hosseini",
      "Ian Sommerville",
      "Ilango Sriram"
    ],
    "abstract": "Cloud computing represents a shift away from computing as a product that is purchased, to computing as a service that is delivered to consumers over the internet from large-scale data centers - or \"clouds\". This paper discusses some of the research challenges for cloud computing from an enterprise or organizational perspective, and puts them in context by reviewing the existing body of literature in cloud computing. Various research challenges relating to the following topics are discussed: the organizational changes brought about by cloud computing; the economic and organizational implications of its utility billing model; the security, legal and privacy issues that cloud computing raises. It is important to highlight these research challenges because cloud computing is not simply about a technological improvement of data centers but a fundamental change in how IT is provisioned and used. This type of research has the potential to influence wider adoption of cloud computing in enterprise, and in the consumer market too.",
    "lastUpdated": "2010-01-19T11:39:30Z",
    "category": [
      "cs.DC",
      "cs.CY",
      "C.2.4"
    ],
    "url": "http://arxiv.org/abs/1001.3257v1"
  },
  {
    "title": "Reusability Framework for Cloud Computing",
    "author": [
      "Sukhpal Singh",
      "Rishideep Singh"
    ],
    "abstract": "Cloud based development is a challenging task for several software engineering projects, especially for those which needs development with reusability. Present time of cloud computing is allowing new professional models for using the software development. The expected upcoming trend of computing is assumed to be this cloud computing because of speed of application deployment, shorter time to market, and lower cost of operation. Until Cloud Co mputing Reusability Model is considered a fundamental capability, the speed of developing services is very slow. Th is paper spreads cloud computing with component based development named Cloud Co mputing Reusability Model (CCR) and enable reusability in cloud computing. In this paper Cloud Co mputing Reusability Model has been proposed. The model has been validated by Cloudsim an d experimental result shows that reusability based cloud computing approach is effective in minimizing cost and time to market.",
    "lastUpdated": "2012-10-30T13:57:19Z",
    "category": [
      "cs.SE",
      "68N30",
      "D.2.13"
    ],
    "url": "http://arxiv.org/abs/1210.8011v1"
  },
  {
    "title": "Inter-Cloud Data Security Strategies",
    "author": [
      "Sugata Sanyal",
      "Parthasarathy P. Iyer"
    ],
    "abstract": "Cloud computing is a complex infrastructure of software, hardware, processing, and storage that is available as a service. Cloud computing offers immediate access to large numbers of the world's most sophisticated supercomputers and their corresponding processing power, interconnected at various locations around the world, proffering speed in the tens of trillions of computations per second. Information in databases and software scattered around the Internet. There are many service providers in the internet, we can call each service as a cloud, each cloud service will exchange data with other cloud, so when the data is exchanged between the clouds, there exist the problem of security. Security is an important issue for cloud computing, both in terms of legal compliance and user trust, and needs to be considered at every phase of design. In contrast to traditional solutions, where the IT services are under proper physical, logical and personnel controls, Cloud Computing moves the application software and databases to the large data centers, where the management of the data and services may not be trustworthy. This unique attribute, however, poses many new security challenges. Cloud computing seems to offer some incredible benefits for communicators.",
    "lastUpdated": "2013-03-06T18:36:09Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1303.1417v1"
  },
  {
    "title": "A Cloud Computing Survey: Developments and Future Trends in Infrastructure as a Service Computing",
    "author": [
      "Jonathan Stuart Ward",
      "Adam Barker"
    ],
    "abstract": "Cloud computing is a recent paradigm based around the notion of delivery of resources via a service model over the Internet. Despite being a new paradigm of computation, cloud computing owes its origins to a number of previous paradigms. The term cloud computing is well defined and no longer merits rigorous taxonomies to furnish a definition. Instead this survey paper considers the past, present and future of cloud computing. As an evolution of previous paradigms, we consider the predecessors to cloud computing and what significance they still hold to cloud services. Additionally we examine the technologies which comprise cloud computing and how the challenges and future developments of these technologies will influence the field. Finally we examine the challenges that limit the growth, application and development of cloud computing and suggest directions required to overcome these challenges in order to further the success of cloud computing.",
    "lastUpdated": "2013-06-06T12:41:57Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1306.1394v1"
  },
  {
    "title": "Cache policies for cloud-based systems: To keep or not to keep",
    "author": [
      "Nicolas Le Scouarnec",
      "Christoph Neumann",
      "Gilles Straub"
    ],
    "abstract": "In this paper, we study cache policies for cloud-based caching. Cloud-based caching uses cloud storage services such as Amazon S3 as a cache for data items that would have been recomputed otherwise. Cloud-based caching departs from classical caching: cloud resources are potentially infinite and only paid when used, while classical caching relies on a fixed storage capacity and its main monetary cost comes from the initial investment. To deal with this new context, we design and evaluate a new caching policy that minimizes the overall cost of a cloud-based system. The policy takes into account the frequency of consumption of an item and the cloud cost model. We show that this policy is easier to operate, that it scales with the demand and that it outperforms classical policies managing a fixed capacity.",
    "lastUpdated": "2014-04-24T08:05:14Z",
    "category": [
      "cs.NI",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1312.0499v2"
  },
  {
    "title": "Software Licensing in the Cloud Age",
    "author": [
      "Malcolm McRoberts"
    ],
    "abstract": "Cloud computing represents a major shift in information systems architecture, combining both new deployment models and new business models. Rapid provisioning, elastic scaling, and metered usage are essential characteristics of cloud services, and they require cloud resources with these same characteristics. When cloud services depend on commercial software, the licenses for that software become another resource to be managed by the cloud. This paper examines common licensing models, including open source, and how well they function in a cloud services model. It discusses creative, new, cloud-centric licensing models and how they allow providers to preserve and expand their revenue streams as their partners and customers transition to the cloud. The paper concludes by identifying the next steps to achieve standardized, cloud-friendly licensing models.",
    "lastUpdated": "2014-01-21T15:25:04Z",
    "category": [
      "cs.CY",
      "cs.DC",
      "91B32",
      "K.6.2; K.5.1; C.5.m"
    ],
    "url": "http://arxiv.org/abs/1401.5346v1"
  },
  {
    "title": "Datacenter Changes vs. Employment Rates for Datacenter Managers In the Cloud Computing Era",
    "author": [
      "Timur Mirzoev",
      "Bruce Benson",
      "David Hillhouse",
      "Mickey Lewis"
    ],
    "abstract": "Due to the evolving Cloud Computing paradigm, there is a prevailing concern that in the near future data center managers may be in short supply. Cloud computing, as a whole, is becoming more prevalent into today s computing world. In fact, cloud computing has become so popular that some are now referring to data centers as cloud centers. How does this interest in cloud computing translate into employment rates for data center managers? The popularity of the public and private cloud models are the prevailing force behind answering this question. Therefore, the skill set of the datacenter manager has evolved to harness the on demand self-services, broad network access, resource pooling, rapid elasticity, measured service, and multi tenacity characteristics of cloud computing. Using diverse sources ranging from the Bureau of Labor and Statistics to trade articles, this manuscript takes an in-depth look at these employment rates related to the cloud and the determining factors behind them. Based on the information available, datacenter manager employment rates in the cloud computing era will continue to increase well into 2016.",
    "lastUpdated": "2014-04-08T14:31:35Z",
    "category": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1404.2151v1"
  },
  {
    "title": "The Making of Cloud Applications An Empirical Study on Software Development for the Cloud",
    "author": [
      "Jürgen Cito",
      "Philipp Leitner",
      "Thomas Fritz",
      "Harald C. Gall"
    ],
    "abstract": "Cloud computing is gaining more and more traction as a deployment and provisioning model for software. While a large body of research already covers how to optimally operate a cloud system, we still lack insights into how professional software engineers actually use clouds, and how the cloud impacts development practices. This paper reports on the first systematic study on how software developers build applications in the cloud. We conducted a mixed-method study, consisting of qualitative interviews of 25 professional developers and a quantitative survey with 294 responses. Our results show that adopting the cloud has a profound impact throughout the software development process, as well as on how developers utilize tools and data in their daily work. Among other things, we found that (1) developers need better means to anticipate runtime problems and rigorously define metrics for improved fault localization and (2) the cloud offers an abundance of operational data, however, developers still often rely on their experience and intuition rather than utilizing metrics. From our findings, we extracted a set of guidelines for cloud development and identified challenges for researchers and tool vendors.",
    "lastUpdated": "2015-03-17T16:14:56Z",
    "category": [
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/1409.6502v2"
  },
  {
    "title": "Cloud Server Benchmarks for Performance Evaluation of New Hardware Architecture",
    "author": [
      "Hao Wu",
      "Fangfei Liu",
      "Ruby B. Lee"
    ],
    "abstract": "Adding new hardware features to a cloud computing server requires testing both the functionalities and the performance of the new hardware mechanisms. However, commonly used cloud computing server workloads are not well-represented by the SPEC integer and floating-point benchmark and Parsec suites typically used by the computer architecture community. Existing cloud benchmark suites for scale-out or scale-up computing are not representative of the most common cloud usage, and are very difficult to run on a cycle-accurate simulator that can accurately model new hardware, like gem5. In this paper, we present PALMScloud, a suite of cloud computing benchmarks for performance evaluation of cloud servers, that is ready to run on the gem5 cycle-accurate simulator. We demonstrate how our cloud computing benchmarks are used in evaluating the cache performance of a new secure cache called Newcache as a case study. We hope that these cloud benchmarks, ready to run on a dual-machine gem5 simulator or on real machines, can be useful to other researchers interested in improving hardware micro-architecture and cloud server performance.",
    "lastUpdated": "2016-03-04T05:49:12Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1603.01352v1"
  },
  {
    "title": "How Fluffy is the Cloud ?: Cloud Intelligence for a Not-For-Profit",
    "author": [
      "Purva Koparkar",
      "Dale MacKrell"
    ],
    "abstract": "Business Intelligence (BI) is becoming more accessible and less expensive with fewer risks through various deployment options available in the Cloud. Cloud computing facilitates the acquisition of custom solutions for not-for-profit (NFP) organisations at affordable and scalable costs on a flexible pay-as-you-go basis. In this paper, we explore the key technical and organisational aspects of BI in the Cloud (Cloud Intelligence) deployment in an Australian NFP whose BI maturity is rising although still low. This organisation aspires to Cloud Intelligence for improved managerial decision making yet the issues surrounding the adoption of Cloud Intelligence are complex, especially where corporate and Cloud governance is concerned. From the findings of the case study, a conceptual framework has been developed and presented which offers a view of how governance could be deployed so that NFPs gain maximum leverage through their adoption of the Cloud.",
    "lastUpdated": "2016-05-28T05:24:57Z",
    "category": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1606.00752v1"
  },
  {
    "title": "Self-Aware and Self-Adaptive Autoscaling for Cloud Based Services",
    "author": [
      "Tao Chen"
    ],
    "abstract": "Modern Internet services are increasingly leveraging on cloud computing for flexible, elastic and on-demand provision. Typically, Quality of Service (QoS) of cloud-based services can be tuned using different underlying cloud configurations and resources, e.g., number of threads, CPU and memory etc., which are shared, leased and priced as utilities. This benefit is fundamentally grounded by autoscaling: an automatic and elastic process that adapts cloud configurations on-demand according to time-varying workloads. This thesis proposes a holistic cloud autoscaling framework to effectively and seamlessly address existing challenges related to different logical aspects of autoscaling, including architecting autoscaling system, modelling the QoS of cloud-based service, determining the granularity of control and deciding trade-off autoscaling decisions. The framework takes advantages of the principles of self-awareness and the related algorithms to adaptively handle the dynamics, uncertainties, QoS interference and trade-offs on objectives that are exhibited in the cloud. The major benefit is that, by leveraging the framework, cloud autoscaling can be effectively achieved without heavy human analysis and design time knowledge. Through conducting various experiments using RUBiS benchmark and realistic workload on real cloud setting, this thesis evaluates the effectiveness of the framework based on various quality indicators and compared with other state-of-the-art approaches.",
    "lastUpdated": "2016-08-13T21:46:40Z",
    "category": [
      "cs.SE",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1608.04030v1"
  },
  {
    "title": "Towards An Architecture-Centric Approach to Manage Variability of Cloud Robotics",
    "author": [
      "Lei Zhang",
      "Huaxi",
      "Zhang",
      "Zheng Fang",
      "Xianbo Xiang",
      "Marianne Huchard",
      "Rene Zapata"
    ],
    "abstract": "Cloud robotics is a field of robotics that attempts to invoke Cloud technologies such as Cloud computing, Cloud storage, and other Internet technologies centered around the benefits of converged infrastructure and shared services for robotics. In a few short years, Cloud robotics as a newly emerged field has already received much research and industrial attention. The use of the Cloud for robotics and automation brings some potential benefits largely ameliorating the performance of robotic systems. However, there are also some challenges. First of all, from the viewpoint of architecture, how to model and describe the architectures of Cloud robotic systems? How to manage the variability of Cloud robotic systems? How to maximize the reuse of their architectures? In this paper, we present an architecture approach to easily design and understand Cloud robotic systems and manage their variability.",
    "lastUpdated": "2017-01-13T09:57:11Z",
    "category": [
      "cs.RO"
    ],
    "url": "http://arxiv.org/abs/1701.03608v1"
  },
  {
    "title": "ClouNS - A Cloud-native Application Reference Model for Enterprise Architects",
    "author": [
      "Nane Kratzke",
      "René Peinl"
    ],
    "abstract": "The capability to operate cloud-native applications can generate enormous business growth and value. But enterprise architects should be aware that cloud-native applications are vulnerable to vendor lock-in. We investigated cloud-native application design principles, public cloud service providers, and industrial cloud standards. All results indicate that most cloud service categories seem to foster vendor lock-in situations which might be especially problematic for enterprise architectures. This might sound disillusioning at first. However, we present a reference model for cloud-native applications that relies only on a small subset of well standardized IaaS services. The reference model can be used for codifying cloud technologies. It can guide technology identification, classification, adoption, research and development processes for cloud-native application and for vendor lock-in aware enterprise architecture engineering methodologies.",
    "lastUpdated": "2017-09-14T17:16:09Z",
    "category": [
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/1709.04883v1"
  },
  {
    "title": "Review and Analysis of Networking Challenges in Cloud Computing",
    "author": [
      "Jose Moura",
      "David Hutchison"
    ],
    "abstract": "Cloud Computing offers virtualized computing, storage, and networking resources, over the Internet, to organizations and individual users in a completely dynamic way. These cloud resources are cheaper, easier to manage, and more elastic than sets of local, physical, ones. This encourages customers to outsource their applications and services to the cloud. The migration of both data and applications outside the administrative domain of customers into a shared environment imposes transversal, functional problems across distinct platforms and technologies. This article provides a contemporary discussion of the most relevant functional problems associated with the current evolution of Cloud Computing, mainly from the network perspective. The paper also gives a concise description of Cloud Computing concepts and technologies. It starts with a brief history about cloud computing, tracing its roots. Then, architectural models of cloud services are described, and the most relevant products for Cloud Computing are briefly discussed along with a comprehensive literature review. The paper highlights and analyzes the most pertinent and practical network issues of relevance to the provision of high-assurance cloud services through the Internet, including security. Finally, trends and future research directions are also presented.",
    "lastUpdated": "2016-01-23T11:21:52Z",
    "category": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1601.05329v2"
  },
  {
    "title": "Cloud Migration Methodologies Preliminary Findings",
    "author": [
      "Mahdi Fahmideh",
      "Farhad Daneshgar",
      "Fethi Rabhi"
    ],
    "abstract": "Research around cloud computing has largely been dedicated to ad-dressing technical aspects associated with utilizing cloud services, surveying critical success factors for the cloud adoption, and opinions about its impact on IT functions. Nevertheless, the aspect of process models for the cloud migration has been slow in pace. Several methodologies have been proposed by both aca-demia and industry for moving legacy applications to the cloud. This paper pre-sents a criteria-based appraisal of such existing methodologies. The results of the analysis highlight the strengths and weaknesses of these methodologies and can be used by cloud service consumers for comparing and selecting the most appropriate ones that fit specific migration scenarios. The paper also suggests research opportunities to improve the status quo. Keywords Cloud Migration; Legacy Applications; Cloud Migration Method-ology, Evaluation Framework",
    "lastUpdated": "2020-04-17T03:21:23Z",
    "category": [
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/2004.10137v1"
  },
  {
    "title": "Demonstrating 100 Gbps in and out of the public Clouds",
    "author": [
      "Igor Sfiligoi"
    ],
    "abstract": "There is increased awareness and recognition that public Cloud providers do provide capabilities not found elsewhere, with elasticity being a major driver. The value of elastic scaling is however tightly coupled to the capabilities of the networks that connect all involved resources, both in the public Clouds and at the various research institutions. This paper presents results of measurements involving file transfers inside public Cloud providers, fetching data from on-prem resources into public Cloud instances and fetching data from public Cloud storage into on-prem nodes. The networking of the three major Cloud providers, namely Amazon Web Services, Microsoft Azure and the Google Cloud Platform, has been benchmarked. The on-prem nodes were managed by either the Pacific Research Platform or located at the University of Wisconsin - Madison. The observed sustained throughput was of the order of 100 Gbps in all the tests moving data in and out of the public Clouds and throughput reaching into the Tbps range for data movements inside the public Cloud providers themselves. All the tests used HTTP as the transfer protocol.",
    "lastUpdated": "2020-05-12T14:56:05Z",
    "category": [
      "cs.PF",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/2005.05836v1"
  },
  {
    "title": "ShapeAdv: Generating Shape-Aware Adversarial 3D Point Clouds",
    "author": [
      "Kibok Lee",
      "Zhuoyuan Chen",
      "Xinchen Yan",
      "Raquel Urtasun",
      "Ersin Yumer"
    ],
    "abstract": "We introduce ShapeAdv, a novel framework to study shape-aware adversarial perturbations that reflect the underlying shape variations (e.g., geometric deformations and structural differences) in the 3D point cloud space. We develop shape-aware adversarial 3D point cloud attacks by leveraging the learned latent space of a point cloud auto-encoder where the adversarial noise is applied in the latent space. Specifically, we propose three different variants including an exemplar-based one by guiding the shape deformation with auxiliary data, such that the generated point cloud resembles the shape morphing between objects in the same category. Different from prior works, the resulting adversarial 3D point clouds reflect the shape variations in the 3D point cloud space while still being close to the original one. In addition, experimental evaluations on the ModelNet40 benchmark demonstrate that our adversaries are more difficult to defend with existing point cloud defense methods and exhibit a higher attack transferability across classifiers. Our shape-aware adversarial attacks are orthogonal to existing point cloud based attacks and shed light on the vulnerability of 3D deep neural networks.",
    "lastUpdated": "2020-05-24T00:03:27Z",
    "category": [
      "cs.CV",
      "cs.LG",
      "eess.IV"
    ],
    "url": "http://arxiv.org/abs/2005.11626v1"
  },
  {
    "title": "An Agent-based Cloud Service Negotiation in Hybrid Cloud Computing",
    "author": [
      "Saurabh Deochake",
      "Debajyoti Mukhopadhyay"
    ],
    "abstract": "With the advent of evolution of cloud computing, large organizations have been scaling the on-premise IT infrastructure to the cloud. Although this being a popular practice, it lacks comprehensive efforts to study the aspects of automated negotiation of resources among cloud customers and providers. This paper proposes a full-fledged framework for the multi-party, multi-issue negotiation system for cloud resources. It introduces a robust cloud marketplace system to buy and sell cloud resources. The Belief-Desire-Intention (BDI) model-based cloud customer and provider agents concurrently negotiate on multiple issues, pursuing a hybrid tactic of time and resource-based dynamic deadline algorithms to generate offers and counter-offers. The cloud marketplace-based system is further augmented with the assignment of behavior norm score and reputation index to the agents to establish trust among them.",
    "lastUpdated": "2020-06-16T05:23:38Z",
    "category": [
      "cs.MA",
      "cs.DC",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/2006.13109v1"
  },
  {
    "title": "Real-Time Spatio-Temporal LiDAR Point Cloud Compression",
    "author": [
      "Yu Feng",
      "Shaoshan Liu",
      "Yuhao Zhu"
    ],
    "abstract": "Compressing massive LiDAR point clouds in real-time is critical to autonomous machines such as drones and self-driving cars. While most of the recent prior work has focused on compressing individual point cloud frames, this paper proposes a novel system that effectively compresses a sequence of point clouds. The idea to exploit both the spatial and temporal redundancies in a sequence of point cloud frames. We first identify a key frame in a point cloud sequence and spatially encode the key frame by iterative plane fitting. We then exploit the fact that consecutive point clouds have large overlaps in the physical space, and thus spatially encoded data can be (re-)used to encode the temporal stream. Temporal encoding by reusing spatial encoding data not only improves the compression rate, but also avoids redundant computations, which significantly improves the compression speed. Experiments show that our compression system achieves 40x to 90x compression rate, significantly higher than the MPEG's LiDAR point cloud compression standard, while retaining high end-to-end application accuracies. Meanwhile, our compression system has a compression speed that matches the point cloud generation rate by today LiDARs and out-performs existing compression systems, enabling real-time point cloud transmission.",
    "lastUpdated": "2020-08-16T18:44:00Z",
    "category": [
      "eess.IV",
      "cs.RO"
    ],
    "url": "http://arxiv.org/abs/2008.06972v1"
  },
  {
    "title": "Multi-scale Receptive Fields Graph Attention Network for Point Cloud Classification",
    "author": [
      "Xi-An Li",
      "Lei Zhang",
      "Li-Yan Wang",
      "Jian Lu"
    ],
    "abstract": "Understanding the implication of point cloud is still challenging to achieve the goal of classification or segmentation due to the irregular and sparse structure of point cloud. As we have known, PointNet architecture as a ground-breaking work for point cloud which can learn efficiently shape features directly on unordered 3D point cloud and have achieved favorable performance. However, this model fail to consider the fine-grained semantic information of local structure for point cloud. Afterwards, many valuable works are proposed to enhance the performance of PointNet by means of semantic features of local patch for point cloud. In this paper, a multi-scale receptive fields graph attention network (named after MRFGAT) for point cloud classification is proposed. By focusing on the local fine features of point cloud and applying multi attention modules based on channel affinity, the learned feature map for our network can well capture the abundant features information of point cloud. The proposed MRFGAT architecture is tested on ModelNet10 and ModelNet40 datasets, and results show it achieves state-of-the-art performance in shape classification tasks.",
    "lastUpdated": "2020-09-28T13:01:28Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2009.13289v1"
  },
  {
    "title": "Cloud Forensics: A Meta-Study of Challenges, Approaches, and Open Problems",
    "author": [
      "Shams Zawoad",
      "Ragib Hasan"
    ],
    "abstract": "In recent years, cloud computing has become popular as a cost-effective and efficient computing paradigm. Unfortunately, today's cloud computing architectures are not designed for security and forensics. To date, very little research has been done to develop the theory and practice of cloud forensics. Many factors complicate forensic investigations in a cloud environment. First, the storage system is no longer local. Therefore, even with a subpoena, law enforcement agents cannot confiscate the suspect's computer and get access to the suspect's files. Second, each cloud server contains files from many users. Hence, it is not feasible to seize servers from a data center without violating the privacy of many other users. Third, even if the data belonging to a particular suspect is identified, separating it from other users' data is difficult. Moreover, other than the cloud provider's word, there is usually no evidence that links a given data file to a particular suspect. For such challenges, clouds cannot be used to store healthcare, business, or national security related data, which require audit and regulatory compliance. In this paper, we systematically examine the cloud forensics problem and explore the challenges and issues in cloud forensics. We then discuss existing research projects and finally, we highlight the open problems and future directions in cloud forensics research area. We posit that our systematic approach towards understanding the nature and challenges of cloud forensics will allow us to examine possible secure solution approaches, leading to increased trust on and adoption of cloud computing, especially in business, healthcare, and national security. This in turn will lead to lower cost and long-term benefit to our society as a whole.",
    "lastUpdated": "2013-02-26T04:55:53Z",
    "category": [
      "cs.DC",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1302.6312v1"
  },
  {
    "title": "A Decision Matrix and Monitoring based Framework for Infrastructure Performance Enhancement in A Cloud based Environment",
    "author": [
      "Mansaf Alam",
      "Kashish Ara Shakil"
    ],
    "abstract": "Cloud environment is very different from traditional computing environment and therefore tracking the performance of cloud leverages additional requirements. The movement of data in cloud is very fast. Hence, it requires that resources and infrastructure available at disposal must be equally competent. Infrastructure level performance in cloud involves the performance of servers, network and storage which act as the heart and soul for driving the entire cloud business. Thus a constant improvement and enhancement of infrastructure level performance is an important task that needs to be taken into account. This paper proposes a framework for infrastructure performance enhancement in a cloud based environment. The framework is broadly divided into four steps: a) Infrastructure level monitoring of usage pattern and behaviour of the cloud end users, b) Reporting of the monitoring activities to the cloud service provider c) Cloud service provider assigns priority according to our decision matrix based max-min algorithm (DMMM) d) Providing services to cloud users leading to infrastructure performance enhancement. Our framework is based on decision matrix and monitoring in cloud using our proposed decision matrix based max-min algorithm, which draws its inspiration from the original min-min algorithm. This algorithm makes use of decision matrix to make decisions regarding distribution of resources among the cloud users.",
    "lastUpdated": "2014-12-27T08:54:53Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1412.8029v1"
  },
  {
    "title": "A Cooperative Scheduling Scheme of Local Cloud and Internet Cloud for Delay-Aware Mobile Cloud Computing",
    "author": [
      "Tianchu Zhao",
      "Sheng Zhou",
      "Xueying Guo",
      "Yun Zhao",
      "Zhisheng Niu"
    ],
    "abstract": "With the proliferation of mobile applications, Mobile Cloud Computing (MCC) has been proposed to help mobile devices save energy and improve computation performance. To further improve the quality of service (QoS) of MCC, cloud servers can be deployed locally so that the latency is decreased. However, the computational resource of the local cloud is generally limited. In this paper, we design a threshold-based policy to improve the QoS of MCC by cooperation of the local cloud and Internet cloud resources, which takes the advantages of low latency of the local cloud and abundant computational resources of the Internet cloud simultaneously. This policy also applies a priority queue in terms of delay requirements of applications. The optimal thresholds depending on the traffic load is obtained via a proposed algorithm. Numerical results show that the QoS can be greatly enhanced with the assistance of Internet cloud when the local cloud is overloaded. Better QoS is achieved if the local cloud order tasks according to their delay requirements, where delay-sensitive applications are executed ahead of delay-tolerant applications. Moreover, the optimal thresholds of the policy have a sound impact on the QoS of the system.",
    "lastUpdated": "2015-11-27T01:38:25Z",
    "category": [
      "cs.NI",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1511.08540v1"
  },
  {
    "title": "Using Cloud-Aware Provenance to Reproduce Scientific Workflow Execution on Cloud",
    "author": [
      "Khawar Hasham",
      "Kamran Munir",
      "Richard McClatchey"
    ],
    "abstract": "Provenance has been thought of a mechanism to verify a workflow and to provide workflow reproducibility. This provenance of scientific workflows has been effectively carried out in Grid based scientific workflow systems. However, recent adoption of Cloud-based scientific workflows present an opportunity to investigate the suitability of existing approaches or propose new approaches to collect provenance information from the Cloud and to utilize it for workflow repeatability in the Cloud infrastructure. This paper presents a novel approach that can assist in mitigating this challenge. This approach can collect Cloud infrastructure information from an outside Cloud client along with workflow provenance and can establish a mapping between them. This mapping is later used to re-provision resources on the Cloud for workflow execution. The reproducibility of the workflow execution is performed by: (a) capturing the Cloud infrastructure information (virtual machine configuration) along with the workflow provenance, (b) re-provisioning the similar resources on the Cloud and re-executing the workflow on them and (c) by comparing the outputs of workflows. The evaluation of the prototype suggests that the proposed approach is feasible and can be investigated further. Moreover, there is no reference reproducibility model exists in literature that can provide guidelines to achieve this goal in Cloud. This paper also attempts to present a model that is used in the proposed design to achieve workflow reproducibility in the Cloud environment.",
    "lastUpdated": "2015-11-29T18:54:58Z",
    "category": [
      "cs.DB"
    ],
    "url": "http://arxiv.org/abs/1511.09061v1"
  },
  {
    "title": "Ready for Rain? A View from SPEC Research on the Future of Cloud Metrics",
    "author": [
      "Nikolas Herbst",
      "Rouven Krebs",
      "Giorgos Oikonomou",
      "George Kousiouris",
      "Athanasia Evangelinou",
      "Alexandru Iosup",
      "Samuel Kounev"
    ],
    "abstract": "In the past decade, cloud computing has emerged from a pursuit for a service-driven information and communication technology (ICT), into a signifcant fraction of the ICT market. Responding to the growth of the market, many alternative cloud services and their underlying systems are currently vying for the attention of cloud users and providers. Thus, benchmarking them is needed, to enable cloud users to make an informed choice, and to enable system DevOps to tune, design, and evaluate their systems. This requires focusing on old and new system properties, possibly leading to the re-design of classic benchmarking metrics, such as expressing performance as throughput and latency (response time), and the design of new, cloud-specififc metrics. Addressing this requirement, in this work we focus on four system properties: (i) elasticity of the cloud service, to accommodate large variations in the amount of service requested, (ii) performance isolation between the tenants of shared cloud systems, (iii) availability of cloud services and systems, and the (iv) operational risk of running a production system in a cloud environment.Focusing on key metrics, for each of these properties we review the state-of-the-art, then select or propose new metrics together with measurement approaches. We see the presented metrics as a foundation towards upcoming, industry-standard, cloud benchmarks. Keywords: Cloud Computing; Metrics; Measurement; Benchmarking; Elasticity; Isolation; Performance; Service Level Objective; Availability; Operational Risk.",
    "lastUpdated": "2016-04-12T16:23:15Z",
    "category": [
      "cs.DC",
      "cs.PF"
    ],
    "url": "http://arxiv.org/abs/1604.03470v1"
  },
  {
    "title": "A Multi-layer hierarchical inter-cloud connectivity model for sequential packet inspection of tenant sessions accessing BI as a service",
    "author": [
      "Hussain Al-Aqrabi",
      "Lu Liu",
      "Richard Hill",
      "Nick Antonopoulos"
    ],
    "abstract": "Business Intelligence (BI) has gained a new lease of life through Cloud computing as its demand for unlimited hardware and platform resources expandability is fulfilled by the Cloud elasticity features. BI can be seamlessly deployed on the Cloud given that its multilayered model coincides with the Cloud multilayer models. It is considered by many Cloud service providers as one of the prominent applications services on public, outsourced private and outsourced community Clouds. However, in the shared domains of Cloud computing, BI is exposed to security and privacy threats by virtue of exploits, eavesdropping, distributed attacks, malware attacks, and such other known challenges on Cloud computing. Given the multi-layered model of BI and Cloud computing, its protection on Cloud computing needs to be ensured through multilayered controls. In this paper, a multi-layered security and privacy model of BI as a service on Cloud computing is proposed through an algorithm for ensuring multi-level session inspections, and ensuring maximum security controls at all the seven layers, and prevent an attack from occurring. This will not only reduce the risk of security breaches, but allow an organisation time to detect, and respond to an attack. The simulations present the effects of distributed attacks on the BI systems by attackers posing as genuine Cloud tenants. The results reflect how the attackers are blocked by the multilayered security and privacy controls deployed for protecting the BI servers and databases",
    "lastUpdated": "2020-02-10T19:01:05Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/2002.04047v1"
  },
  {
    "title": "Commercial Cloud Computing for Connected Vehicle Applications in Transportation Cyber-Physical Systems",
    "author": [
      "Hsien-Wen Deng",
      "Mizanur Rahman",
      "Mashrur Chowdhury",
      "M Sabbir Salek",
      "Mitch Shue"
    ],
    "abstract": "This study focuses on the feasibility of commercial cloud services for connected vehicle (CV) applications in a Transportation Cyber-Physical Systems (TCPS) environment. TCPS implies that CVs, in addition to being connected with each other, communicates with the transportation and computing infrastructure to fulfill application requirements. The motivation of this study is to accelerate commercial cloud-based CV application development by presenting the lessons learned by implementing a CV mobility application using Amazon Web Services (AWS). The feasibility of the cloud-based CV application is assessed at three levels: (i) the development of a cloud-based TCPS architecture, (ii) the deployment of a cloud-based CV application using AWS, and (iii) the evaluation of the cloud-based CV application. We implemented this CV mobility application using a serverless cloud architecture and found that such a cloud-based TCPS environment could meet the permissible delay limits of CV mobility applications. Commercial cloud services, as an integral part of TCPS, could reduce costs associated with establishing and maintaining vast computing infrastructure for supporting CV applications. As the CV penetration levels on the surface transportation systems increase significantly over the next several years, scaling the backend infrastructure to support such applications is a critical issue. This study shows how commercial cloud services could automatically scale the backend infrastructure to meet the rapidly changing demands of real-world CV applications. Through real-world experiments, we demonstrate how commercial cloud services along with serverless cloud architecture could advance the transportation digital infrastructure for supporting connected mobility applications in a TCPS environment.",
    "lastUpdated": "2020-08-17T13:15:44Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/2008.07290v1"
  },
  {
    "title": "Multi-feature combined cloud and cloud shadow detection in GaoFen-1 wide field of view imagery",
    "author": [
      "Zhiwei Li",
      "Huanfeng Shen",
      "Huifang Li",
      "Guisong Xia",
      "Paolo Gamba",
      "Liangpei Zhang"
    ],
    "abstract": "The wide field of view (WFV) imaging system onboard the Chinese GaoFen-1 (GF-1) optical satellite has a 16-m resolution and four-day revisit cycle for large-scale Earth observation. The advantages of the high temporal-spatial resolution and the wide field of view make the GF-1 WFV imagery very popular. However, cloud cover is an inevitable problem in GF-1 WFV imagery, which influences its precise application. Accurate cloud and cloud shadow detection in GF-1 WFV imagery is quite difficult due to the fact that there are only three visible bands and one near-infrared band. In this paper, an automatic multi-feature combined (MFC) method is proposed for cloud and cloud shadow detection in GF-1 WFV imagery. The MFC algorithm first implements threshold segmentation based on the spectral features and mask refinement based on guided filtering to generate a preliminary cloud mask. The geometric features are then used in combination with the texture features to improve the cloud detection results and produce the final cloud mask. Finally, the cloud shadow mask can be acquired by means of the cloud and shadow matching and follow-up correction process. The method was validated using 108 globally distributed scenes. The results indicate that MFC performs well under most conditions, and the average overall accuracy of MFC cloud detection is as high as 96.8%. In the contrastive analysis with the official provided cloud fractions, MFC shows a significant improvement in cloud fraction estimation, and achieves a high accuracy for the cloud and cloud shadow detection in the GF-1 WFV imagery with fewer spectral bands. The proposed method could be used as a preprocessing step in the future to monitor land-cover change, and it could also be easily extended to other optical satellite imagery which has a similar spectral setting.",
    "lastUpdated": "2017-02-05T04:59:29Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1606.05415v4"
  },
  {
    "title": "Cloud Computing and Grid Computing 360-Degree Compared",
    "author": [
      "Ian Foster",
      "Yong Zhao",
      "Ioan Raicu",
      "Shiyong Lu"
    ],
    "abstract": "Cloud Computing has become another buzzword after Web 2.0. However, there are dozens of different definitions for Cloud Computing and there seems to be no consensus on what a Cloud is. On the other hand, Cloud Computing is not a completely new concept; it has intricate connection to the relatively new but thirteen-year established Grid Computing paradigm, and other relevant technologies such as utility computing, cluster computing, and distributed systems in general. This paper strives to compare and contrast Cloud Computing with Grid Computing from various angles and give insights into the essential characteristics of both.",
    "lastUpdated": "2008-12-31T19:13:05Z",
    "category": [
      "cs.DC",
      "C.2.4; A.1"
    ],
    "url": "http://arxiv.org/abs/0901.0131v1"
  },
  {
    "title": "A Flow Sensitive Security Model for Cloud Computing Systems",
    "author": [
      "Wen Zeng",
      "Chunyan Mu",
      "Maciej Koutny",
      "Paul Watson"
    ],
    "abstract": "The extent and importance of cloud computing is rapidly increasing due to the ever increasing demand for internet services and communications. Instead of building individual information technology infrastructure to host databases or software, a third party can host them in its large server clouds. Large organizations may wish to keep sensitive information on their more restricted servers rather than in the public cloud. This has led to the introduction of federated cloud computing (FCC) in which both public and private cloud computing resources are used.",
    "lastUpdated": "2014-04-30T15:23:49Z",
    "category": [
      "cs.CR",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1404.7760v1"
  },
  {
    "title": "Ad hoc Cloud Computing: From Concept to Realization",
    "author": [
      "Gary Andrew McGilvary",
      "Adam Barker",
      "Malcolm Atkinson"
    ],
    "abstract": "This paper presents the first complete, integrated and end-to-end solution for ad hoc cloud computing environments. Ad hoc clouds harvest resources from existing sporadically available, non-exclusive (i.e. primarily used for some other purpose) and unreliable infrastructures. In this paper we discuss the problems ad hoc cloud computing solves and outline our architecture which is based on BOINC.",
    "lastUpdated": "2015-07-19T16:02:20Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1505.08097v2"
  },
  {
    "title": "Cloud-based DDoS Attacks and Defenses",
    "author": [
      "Marwan Darwish",
      "Abdelkader Ouda",
      "Luiz Fernando Capretz"
    ],
    "abstract": "Safety and reliability are important in the cloud computing environment. This is especially true today as distributed denial-of-service (DDoS) attacks constitute one of the largest threats faced by Internet users and cloud computing services. DDoS attacks target the resources of these services, lowering their ability to provide optimum usage of the network infrastructure. Due to the nature of cloud computing, the methodologies for preventing or stopping DDoS attacks are quite different compared to those used in traditional networks. In this paper, we investigate the effect of DDoS attacks on cloud resources and recommend practical defense mechanisms against different types of DDoS attacks in the cloud environment.",
    "lastUpdated": "2015-11-27T22:18:44Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1511.08839v1"
  },
  {
    "title": "On Mobile Cloud for Smart City Applications",
    "author": [
      "Manfred Sneps-Sneppe",
      "Dmitry Namiot"
    ],
    "abstract": "This paper is devoted to mobile cloud services in Smart City projects. As per mobile cloud computing paradigm, the data processing and storage are moved from the mobile device to a cloud. In the same time, Smart City services typically contain a set of applications with data sharing options. Most of the services in Smart Cities are actually mashups combined data from several sources. This means that access to all available data is vital to the services. And the mobile cloud is vital because the mobile terminals are one of the main sources for data gathering. In our work, we discuss criteria for selecting mobile cloud services.",
    "lastUpdated": "2016-05-10T08:14:05Z",
    "category": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1605.02886v1"
  },
  {
    "title": "A Resource Management Protocol for Mobile Cloud Using Auto-Scaling",
    "author": [
      "Chathura Sarathchandra Magurawalage",
      "Kun Yang",
      "Ritosa Patrik",
      "Michael Georgiades",
      "Kezhi Wang"
    ],
    "abstract": "Cloud radio access networks (C-RAN) and Mobile Cloud Computing (MCC) have emerged as promising candidates for the next generation access network techniques. MCC enables resource limited mobile devices to offload computationally intensive tasks to the cloud, while C-RAN offers a technology that addresses the increasing mobile traffic. In this paper, we propose a protocol for task offloading and for managing resources in both C-RAN and mobile cloud together using a centralised controller. Experiments on resource management using cloud auto-scaling shows that resource (CPU, RAM, Storage) scaling times vary.",
    "lastUpdated": "2017-01-20T12:59:02Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1701.00384v3"
  },
  {
    "title": "Systematic study of color spaces and components for the segmentation of sky/cloud images",
    "author": [
      "Soumyabrata Dev",
      "Yee Hui Lee",
      "Stefan Winkler"
    ],
    "abstract": "Sky/cloud imaging using ground-based Whole Sky Imagers (WSI) is a cost-effective means to understanding cloud cover and weather patterns. The accurate segmentation of clouds in these images is a challenging task, as clouds do not possess any clear structure. Several algorithms using different color models have been proposed in the literature. This paper presents a systematic approach for the selection of color spaces and components for optimal segmentation of sky/cloud images. Using mainly principal component analysis (PCA) and fuzzy clustering for evaluation, we identify the most suitable color components for this task.",
    "lastUpdated": "2017-01-17T03:27:56Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1701.04520v1"
  },
  {
    "title": "Proceedings of the Third International Conference on Cloud and Robotics (ICCR2016)",
    "author": [
      "Lei Zhang",
      "Huaxi",
      "Zhang"
    ],
    "abstract": "The 3rd International conference on Cloud and Robotics (ICCR2016) was held November 23-23, 2016 in Saint Quentin (France). ICCR is the premier gathering of practitioners and researchers interested in how to bring the power of Cloud computing and Robotics to a new cutting-edge domain: Cloud robotics. The objective of ICCR is a working conference, where together Cloud computing and robotics researchers/practitioners to exchange their ideas. Different with traditional academic conference, ICCR is also a forum for researchers and practitioners in the two disciplines, fostering the collaboration of Cloud computing with robotics, and for practitioners to show their working projects and to discuss and exchange their problems with researchers to find a solution.",
    "lastUpdated": "2017-06-10T09:24:02Z",
    "category": [
      "cs.RO"
    ],
    "url": "http://arxiv.org/abs/1706.05424v1"
  },
  {
    "title": "Cloud Services Brokerage: A Survey and Research Roadmap",
    "author": [
      "Adam Barker",
      "Blesson Varghese",
      "Long Thai"
    ],
    "abstract": "A Cloud Services Brokerage (CSB) acts as an intermediary between cloud service providers (e.g., Amazon and Google) and cloud service end users, providing a number of value adding services. CSBs as a research topic are in there infancy. The goal of this paper is to provide a concise survey of existing CSB technologies in a variety of areas and highlight a roadmap, which details five future opportunities for research.",
    "lastUpdated": "2015-06-01T13:21:31Z",
    "category": [
      "cs.DC",
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/1506.00485v1"
  },
  {
    "title": "Sustainability-Aware Cloud Computing Using Virtual Carbon Tax",
    "author": [
      "Fereydoun Farrahi Moghaddam",
      "Mohamed Cheriet"
    ],
    "abstract": "In this paper, a solution for sustainable cloud system is proposed and then implemented on a real testbed. The solution composes of optimization of a profit model and introduction of virtual carbon tax to limit environmental footprint of the cloud. The proposed multi-criteria optimizer of the cloud system suggests new optimum CPU frequencies for CPU-cores when the local grid energy mix or the cloud workload changes. The cloud system is implemented on a blade system, and proper middlewares are developed to interact with the blades. The experimental results show that it is possible to significantly decrease the targeted environmental footprint of the system and keep it profitable.",
    "lastUpdated": "2017-11-01T12:55:42Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1510.05182v2"
  },
  {
    "title": "Advanced Cloud Privacy Threat Modeling",
    "author": [
      "Ali Gholami",
      "Erwin Laure"
    ],
    "abstract": "Privacy-preservation for sensitive data has become a challenging issue in cloud computing. Threat modeling as a part of requirements engineering in secure software development provides a structured approach for identifying attacks and proposing countermeasures against the exploitation of vulnerabilities in a system . This paper describes an extension of Cloud Privacy Threat Modeling (CPTM) methodology for privacy threat modeling in relation to processing sensitive data in cloud computing environments. It describes the modeling methodology that involved applying Method Engineering to specify characteristics of a cloud privacy threat modeling methodology, different steps in the proposed methodology and corresponding products. We believe that the extended methodology facilitates the application of a privacy-preserving cloud software development approach from requirements engineering to design.",
    "lastUpdated": "2016-01-07T12:00:16Z",
    "category": [
      "cs.SE",
      "cs.CR",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1601.01500v1"
  },
  {
    "title": "Towards the Secure Storage of Images on Multi-Cloud System",
    "author": [
      "Dr. Grasha Jacob",
      "Dr. A. Murugan"
    ],
    "abstract": "With the rapidly changing technological realm, there is an urgent need to provide and protect the confidentiality of confidential images when stored in a cloud environment. To overcome the security risks associated with single cloud, multiple clouds offered by unrelated cloud providers have to be used. This paper outlines an integrated encryption scheme for the secure storage of confidential images on multiple clouds based on DNA sequences.",
    "lastUpdated": "2016-11-23T03:55:22Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1611.07633v1"
  },
  {
    "title": "Transplantation of Data Mining Algorithms to Cloud Computing Platform when Dealing Big Data",
    "author": [
      "Yong Wang",
      "Ya Wei Zhao"
    ],
    "abstract": "This paper made a short review of Cloud Computing and Big Data, and discussed the portability of general data mining algorithms to Cloud Computing platform. It revealed the Cloud Computing platform based on Map-Reduce cannot solve all the Big Data and data mining problems. Transplanting the general data mining algorithms to the real-time Cloud Computing platform will be one of the research focuses in Cloud Computing and Big Data.",
    "lastUpdated": "2017-02-06T06:37:39Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1702.01508v1"
  },
  {
    "title": "Cloud Security Architecture and Implementation - A practical approach",
    "author": [
      "Max Farnga"
    ],
    "abstract": "While cloud computing provides lower Infrastructure cost, higher agility and faster delivery, it also presents higher operational and security risks for business critical assets, but a well-designed solution and security architecture will keep businesses safe during and after migrating their assets to the cloud. This paper has researched and identified best security practices and how to improve a security architecture in a cloud environment.",
    "lastUpdated": "2018-09-23T04:35:57Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1808.03892v2"
  },
  {
    "title": "Accelerator Virtualization in Fog Computing: Moving From the Cloud to the Edge",
    "author": [
      "Blesson Varghese",
      "Carlos Reano",
      "Federico Silla"
    ],
    "abstract": "Hardware accelerators are available on the Cloud for enhanced analytics. Next generation Clouds aim to bring enhanced analytics using accelerators closer to user devices at the edge of the network for improving Quality-of-Service by minimizing end-to-end latencies and response times. The collective computing model that utilizes resources at the Cloud-Edge continuum in a multi-tier hierarchy comprising the Cloud, the Edge and user devices is referred to as Fog computing. This article identifies challenges and opportunities in making accelerators accessible at the Edge. A holistic view of the Fog architecture is key to pursuing meaningful research in this area.",
    "lastUpdated": "2018-10-14T15:30:55Z",
    "category": [
      "cs.DC",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1810.06046v1"
  },
  {
    "title": "Service-Oriented Software Architecture for Cloud Robotics",
    "author": [
      "Anis Koubaa"
    ],
    "abstract": "In this article, we present an overview of the use of service-oriented architecture and Web services in developing robotics applications and software integrated with the Internet and the Cloud. This is a recent trend that emerged since 2010 from the concept of cloud robotics, which leverages the use of cloud infrastructures for robotics applications following a service-oriented architecture approach. In particular, we distinguish two main categories: (\\textit{i.}) virtualization of robotics systems and (\\textit{ii.}) computation offloading from robots to cloud-based services. We discuss the main approaches proposed in the literature to design robotics systems through the Web and their integration to the cloud through a service-oriented computing framework.",
    "lastUpdated": "2019-06-30T20:29:49Z",
    "category": [
      "cs.RO",
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/1901.08173v2"
  },
  {
    "title": "DPDist : Comparing Point Clouds Using Deep Point Cloud Distance",
    "author": [
      "Dahlia Urbach",
      "Yizhak Ben-Shabat",
      "Michael Lindenbaum"
    ],
    "abstract": "We introduce a new deep learning method for point cloud comparison. Our approach, named Deep Point Cloud Distance (DPDist), measures the distance between the points in one cloud and the estimated surface from which the other point cloud is sampled. The surface is estimated locally and efficiently using the 3D modified Fisher vector representation. The local representation reduces the complexity of the surface, enabling efficient and effective learning, which generalizes well between object categories. We test the proposed distance in challenging tasks, such as similar object comparison and registration, and show that it provides significant improvements over commonly used distances such as Chamfer distance, Earth mover's distance, and others.",
    "lastUpdated": "2020-07-23T07:46:09Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2004.11784v2"
  },
  {
    "title": "Cloud Computing",
    "author": [
      "Shivaji P. Mirashe",
      "N. V. Kalyankar"
    ],
    "abstract": "Computing as you know it is about to change, your applications and documents are going to move from the desktop into the cloud. I'm talking about cloud computing, where applications and files are hosted on a \"cloud\" consisting of thousands of computers and servers, all linked together and accessible via the Internet. With cloud computing, everything you do is now web based instead of being desktop based. You can access all your programs and documents from any computer that's connected to the Internet. How will cloud computing change the way you work? For one thing, you're no longer tied to a single computer. You can take your work anywhere because it's always accessible via the web. In addition, cloud computing facilitates group collaboration, as all group members can access the same programs and documents from wherever they happen to be located. Cloud computing might sound far-fetched, but chances are you're already using some cloud applications. If you're using a web-based email program, such as Gmail or Hotmail, you're computing in the cloud. If you're using a web-based application such as Google Calendar or Apple Mobile Me, you're computing in the cloud. If you're using a file- or photo-sharing site, such as Flickr or Picasa Web Albums, you're computing in the cloud. It's the technology of the future, available to use today.",
    "lastUpdated": "2010-03-22T06:16:48Z",
    "category": [
      "cs.DC",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1003.4074v1"
  },
  {
    "title": "On the Economics of Cloud Markets",
    "author": [
      "Ranjan Pal",
      "Pan Hui"
    ],
    "abstract": "Cloud computing is a paradigm that has the potential to transform and revolutionalize the next generation IT industry by making software available to end-users as a service. A cloud, also commonly known as a cloud network, typically comprises of hardware (network of servers) and a collection of softwares that is made available to end-users in a pay-as-you-go manner. Multiple public cloud providers (ex., Amazon) co-existing in a cloud computing market provide similar services (software as a service) to its clients, both in terms of the nature of an application, as well as in quality of service (QoS) provision. The decision of whether a cloud hosts (or finds it profitable to host) a service in the long-term would depend jointly on the price it sets, the QoS guarantees it provides to its customers, and the satisfaction of the advertised guarantees. In this paper, we devise and analyze three inter-organizational economic models relevant to cloud networks. We formulate our problems as non co-operative price and QoS games between multiple cloud providers existing in a cloud market. We prove that a unique pure strategy Nash equilibrium (NE) exists in two of the three models. Our analysis paves the path for each cloud provider to 1) know what prices and QoS level to set for end-users of a given service type, such that the provider could exist in the cloud market, and 2) practically and dynamically provision appropriate capacity for satisfying advertised QoS guarantees.",
    "lastUpdated": "2011-02-28T22:43:47Z",
    "category": [
      "cs.NI",
      "cs.GT"
    ],
    "url": "http://arxiv.org/abs/1103.0045v1"
  },
  {
    "title": "CloudMine: Multi-Party Privacy-Preserving Data Analytics Service",
    "author": [
      "Dinh Tien Tuan Anh",
      "Quach Vinh Thanh",
      "Anwitaman Datta"
    ],
    "abstract": "An increasing number of businesses are replacing their data storage and computation infrastructure with cloud services. Likewise, there is an increased emphasis on performing analytics based on multiple datasets obtained from different data sources. While ensuring security of data and computation outsourced to a third party cloud is in itself challenging, supporting analytics using data distributed across multiple, independent clouds is even further from trivial. In this paper we present CloudMine, a cloud-based service which allows multiple data owners to perform privacy-preserved computation over the joint data using their clouds as delegates. CloudMine protects data privacy with respect to semi-honest data owners and semi-honest clouds. It furthermore ensures the privacy of the computation outputs from the curious clouds. It allows data owners to reliably detect if their cloud delegates have been lazy when carrying out the delegated computation. CloudMine can run as a centralized service on a single cloud, or as a distributed service over multiple, independent clouds. CloudMine supports a set of basic computations that can be used to construct a variety of highly complex, distributed privacy-preserving data analytics. We demonstrate how a simple instance of CloudMine (secure sum service) is used to implement three classical data mining tasks (classification, association rule mining and clustering) in a cloud environment. We experiment with a prototype of the service, the results of which suggest its practicality for supporting privacy-preserving data analytics as a (multi) cloud-based service.",
    "lastUpdated": "2013-10-01T05:14:19Z",
    "category": [
      "cs.CR",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1206.2038v2"
  },
  {
    "title": "Teaching cloud computing: a software engineering perspective",
    "author": [
      "Ian Sommerville"
    ],
    "abstract": "This short papers discusses the issues of teaching cloud computing from a software engineering rather than a business perspective. It discusses what topics might be covered in a senior course on cloud software engineering.",
    "lastUpdated": "2012-09-05T12:31:34Z",
    "category": [
      "cs.DC",
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/1209.0948v1"
  },
  {
    "title": "Cloud Usage Patterns: A Formalism for Description of Cloud Usage Scenarios",
    "author": [
      "Aleksandar Milenkoski",
      "Alexandru Iosup",
      "Samuel Kounev",
      "Kai Sachs",
      "Piotr Rygielski",
      "Jason Ding",
      "Walfredo Cirne",
      "Florian Rosenberg"
    ],
    "abstract": "Cloud computing is becoming an increasingly lucrative branch of the existing information and communication technologies (ICT). Enabling a debate about cloud usage scenarios can help with attracting new customers, sharing best-practices, and designing new cloud services. In contrast to previous approaches, which have attempted mainly to formalize the common service delivery models (i.e., Infrastructure-as-a-Service, Platform-as-a-Service, and Software-as-a-Service), in this work, we propose a formalism for describing common cloud usage scenarios referred to as cloud usage patterns. Our formalism takes a structuralist approach allowing decomposition of a cloud usage scenario into elements corresponding to the common cloud service delivery models. Furthermore, our formalism considers several cloud usage patterns that have recently emerged, such as hybrid services and value chains in which mediators are involved, also referred to as value chains with mediators. We propose a simple yet expressive textual and visual language for our formalism, and we show how it can be used in practice for describing a variety of real-world cloud usage scenarios. The scenarios for which we demonstrate our formalism include resource provisioning of global providers of infrastructure and/or platform resources, online social networking services, user-data processing services, online customer and ticketing services, online asset management and banking applications, CRM (Customer Relationship Management) applications, and online social gaming applications.",
    "lastUpdated": "2014-10-05T13:28:42Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1410.1159v1"
  },
  {
    "title": "Experimental Report on Setting up a Cloud Computing Environment at the University of Bradford",
    "author": [
      "Bashir Mohammed",
      "Mariam Kiran"
    ],
    "abstract": "Cloud computing is increasingly attracting large attention in computing both in academic research and in industrial initiatives. Emerging as a popular paradigm and an attractive model of providing computing, information technology (IT) infrastructure, network and storage to large and small enterprises both in private and public sectors. This project was initiated and aimed at designing and Setting up a basic Cloud lab Testbed running on Open stack under Virtual box for experiments and Hosting Cloud Platforms in the networking laboratory at the University of Bradford. This report presents the methodology of setting up a cloud lab testbed for experiment running on open stack. Current resources, in the Networking lab at the university were used and turned into virtual platforms for cloud computing testing. This report serves as a practical guideline, concentrating on the practical infrastructure related questions and issues, on setting up a cloud lab for testing and proof of concept. Finally the report proposes an experimental validation showing feasibility of migrating to cloud. The primary focus of this report is to provide a brief background on different theoretical concepts of cloud computing, particularly virtualisation, and then it elaborates on the practical aspects concerning the setup and implementation of a Cloud lab test bed using open source solutions. This reports serves as a reference for institutions looking at the possibilities of implementing cloud solutions, in order to benefit from getting the basics and a view on the different aspects of cloud migration concepts.",
    "lastUpdated": "2014-12-15T13:38:45Z",
    "category": [
      "cs.DC",
      "C.0; C.1.4"
    ],
    "url": "http://arxiv.org/abs/1412.4582v1"
  },
  {
    "title": "An NBDMMM Algorithm Based Framework for Allocation of Resources in Cloud",
    "author": [
      "Mansaf Alam",
      "Kashish Ara Shakil"
    ],
    "abstract": "Cloud computing is a technological advancement in the arena of computing and has taken the utility vision of computing a step further by providing computing resources such as network, storage, compute capacity and servers, as a service via an internet connection. These services are provided to the users in a pay per use manner subjected to the amount of usage of these resources by the cloud users. Since the usage of these resources is done in an elastic manner thus an on demand provisioning of these resources is the driving force behind the entire cloud computing infrastructure therefore the maintenance of these resources is a decisive task that must be taken into account. Eventually, infrastructure level performance monitoring and enhancement is also important. This paper proposes a framework for allocation of resources in a cloud based environment thereby leading to an infrastructure level enhancement of performance in a cloud environment. The framework is divided into four stages Stage 1: Cloud service provider monitors the infrastructure level pattern of usage of resources and behavior of the cloud users. Stage 2: Report the monitoring activities about the usage to cloud service providers. Stage 3: Apply proposed Network Bandwidth Dependent DMMM algorithm .Stage 4: Allocate resources or provide services to cloud users, thereby leading to infrastructure level performance enhancement and efficient management of resources. Analysis of resource usage pattern is considered as an important factor for proper allocation of resources by the service providers, in this paper Google cluster trace has been used for accessing the resource usage pattern in cloud. Experiments have been conducted on cloudsim simulation framework and the results reveal that NBDMMM algorithm improvises allocation of resources in a virtualized cloud.",
    "lastUpdated": "2014-12-27T08:49:32Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1412.8028v1"
  },
  {
    "title": "Dispersing Instant Social Video Service Across Multiple Clouds",
    "author": [
      "Zhi Wang",
      "Baochun Li",
      "Lifeng Sun",
      "Wenwu Zhu",
      "Shiqiang Yang"
    ],
    "abstract": "Instant social video sharing which combines the online social network and user-generated short video streaming services, has become popular in today's Internet. Cloud-based hosting of such instant social video contents has become a norm to serve the increasing users with user-generated contents. A fundamental problem of cloud-based social video sharing service is that users are located globally, who cannot be served with good service quality with a single cloud provider. In this paper, we investigate the feasibility of dispersing instant social video contents to multiple cloud providers. The challenge is that inter-cloud social \\emph{propagation} is indispensable with such multi-cloud social video hosting, yet such inter-cloud traffic incurs substantial operational cost. We analyze and formulate the multi-cloud hosting of an instant social video system as an optimization problem. We conduct large-scale measurement studies to show the characteristics of instant social video deployment, and demonstrate the trade-off between satisfying users with their ideal cloud providers, and reducing the inter-cloud data propagation. Our measurement insights of the social propagation allow us to propose a heuristic algorithm with acceptable complexity to solve the optimization problem, by partitioning a propagation-weighted social graph in two phases: a preference-aware initial cloud provider selection and a propagation-aware re-hosting. Our simulation experiments driven by real-world social network traces show the superiority of our design.",
    "lastUpdated": "2015-02-08T08:28:43Z",
    "category": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1502.02226v1"
  },
  {
    "title": "Emerging Security Challenges of Cloud Virtual Infrastructure",
    "author": [
      "Amani S. Ibrahim",
      "James Hamlyn-Harris",
      "John Grundy"
    ],
    "abstract": "The cloud computing model is rapidly transforming the IT landscape. Cloud computing is a new computing paradigm that delivers computing resources as a set of reliable and scalable internet-based services allowing customers to remotely run and manage these services. Infrastructure-as-a-service (IaaS) is one of the popular cloud computing services. IaaS allows customers to increase their computing resources on the fly without investing in new hardware. IaaS adapts virtualization to enable on-demand access to a pool of virtual computing resources. Although there are great benefits to be gained from cloud computing, cloud computing also enables new categories of threats to be introduced. These threats are a result of the cloud virtual infrastructure complexity created by the adoption of the virtualization technology. Breaching the security of any component in the cloud virtual infrastructure significantly impacts on the security of other components and consequently affects the overall system security. This paper explores the security problem of the cloud platform virtual infrastructure identifying the existing security threats and the complexities of this virtual infrastructure. The paper also discusses the existing security approaches to secure the cloud virtual infrastructure and their drawbacks. Finally, we propose and explore some key research challenges of implementing new virtualization-aware security solutions that can provide the pre-emptive protection for complex and ever- dynamic cloud virtual infrastructure.",
    "lastUpdated": "2016-12-29T07:46:28Z",
    "category": [
      "cs.CR",
      "cs.DC",
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/1612.09059v1"
  },
  {
    "title": "The State of the Art Forensic Techniques in Mobile Cloud Environment: A Survey, Challenges and Current Trends",
    "author": [
      "Muhammad Faheem",
      "M-Tahar Kechadi",
      "Nhien-An Le-Khac"
    ],
    "abstract": "Smartphones have become popular in recent days due to the accessibility of a wide range of applications. These sophisticated applications demand more computing resources in a resource constraint smartphone. Cloud computing is the motivating factor for the progress of these applications. The emerging mobile cloud computing introduces a new architecture to offload smartphone and utilize cloud computing technology to solve resource requirements. The popularity of mobile cloud computing is an opportunity for misuse and unlawful activities. Therefore, it is a challenging platform for digital forensic investigations due to the non-availability of methodologies, tools and techniques. The aim of this work is to analyze the forensic tools and methodologies for crime investigation in a mobile cloud platform as it poses challenges in proving the evidence. The advancement of forensic tools and methodologies are much slower than the current technology development in mobile cloud computing. Thus, forces the available tools, and techniques become increasingly obsolete. Therefore, it opens up the door for the new forensic tools and techniques to cope up with recent developments. Hence, this work presents a detailed survey of forensic methodology and corresponding issues in a mobile device, cloud environment, and mobile cloud applications. It mainly focuses on digital forensic issues related to mobile cloud applications and also analyze the scope, challenges and opportunities. Finally, this work reviewed the forensic procedures of two cloud storage services used for mobile cloud applications such as Dropbox and SkyDrive.",
    "lastUpdated": "2016-11-29T11:00:09Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1611.09566v1"
  },
  {
    "title": "SNC: A Cloud Service Platform for Symbolic-Numeric Computation using Just-In-Time Compilation",
    "author": [
      "Peng Zhang",
      "Yueming Liu",
      "Meikang Qiu"
    ],
    "abstract": "Cloud services have been widely employed in IT industry and scientific research. By using Cloud services users can move computing tasks and data away from local computers to remote datacenters. By accessing Internet-based services over lightweight and mobile devices, users deploy diversified Cloud applications on powerful machines. The key drivers towards this paradigm for the scientific computing field include the substantial computing capacity, on-demand provisioning and cross-platform interoperability. To fully harness the Cloud services for scientific computing, however, we need to design an application-specific platform to help the users efficiently migrate their applications. In this, we propose a Cloud service platform for symbolic-numeric computation - SNC. SNC allows the Cloud users to describe tasks as symbolic expressions through C/C++, Python, Java APIs and SNC script. Just-In-Time (JIT) compilation through using LLVM/JVM is used to compile the user code to the machine code. We implemented the SNC design and tested a wide range of symbolic-numeric computation applications (including nonlinear minimization, Monte Carlo integration, finite element assembly and multibody dynamics) on several popular cloud platforms (including the Google Compute Engine, Amazon EC2, Microsoft Azure, Rackspace, HP Helion and VMWare vCloud). These results demonstrate that our approach can work across multiple cloud platforms, support different languages and significantly improve the performance of symbolic-numeric computation using cloud platforms. This offered a way to stimulate the need for using the cloud computing for the symbolic-numeric computation in the field of scientific research.",
    "lastUpdated": "2018-02-09T20:20:14Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1802.04766v1"
  },
  {
    "title": "Energy Efficient Cloud Control and Pricing in Geographically Distributed Data Centers",
    "author": [
      "Dražen Lučanin"
    ],
    "abstract": "It is estimated that data centers constitute 1.5% of global electricity usage. At the same time, to serve increasing user requirements, modern cloud providers are operating multiple geographically distributed data centers. Distributed data center infrastructure changes the rules of cloud control, as energy costs depend on current regional electricity prices and temperatures that we call geotemporal inputs. Furthermore, pricing policies at which cloud providers can offer computational resources depend on the quality of service (QoS). With such pricing schemes and the increasing energy costs in data centres, balancing energy savings with performance and revenue losses is a challenging problem. Existing cloud control methods are suitable only for a single data center or do not consider all the available cloud control actions that can reduce energy costs in geographically distributed data centers. In this thesis, we propose a pervasive cloud control approach consisting of multiple methods for dynamic resource reallocation and hardware configuration adapted to volatile geotemporal inputs. The proposed methods consider the QoS impact of cloud control actions and the data quality limits of time series forecasting methods. We offer a cloud controller design that supports future extensions when new decision support components need to be added. We also propose novel pricing schemes which account for the computational resource availability and costs that arise from our cloud control approach to enable both flexible, energy-aware and high performance cloud computing. We evaluate our methods empirically and in a number of simulations using historical traces of electricity prices, temperatures, workloads and other data. Our results show that significant energy cost savings are possible without harming the QoS or service revenue in geographically distributed cloud computing.",
    "lastUpdated": "2018-09-16T10:52:43Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1809.05853v1"
  },
  {
    "title": "An API for Development of User-Defined Scheduling Algorithms in Aneka PaaS Cloud Software: User Defined Schedulers in Aneka PaaS Cloud Software",
    "author": [
      "Rajinder Sandhu",
      "Adel Nadjaran Toosi",
      "Rajkumar Buyya"
    ],
    "abstract": "Cloud computing has been developed as one of the prominent paradigm for providing on demand resources to the end user based on signed service level agreement and pay as use model. Cloud computing provides resources using multitenant architecture where infrastructure is generated from multiple or single geographical distributed cloud datacenters. Scheduling of cloud application requests to cloud infrastructure is one of the main research area in cloud computing. Researchers have developed many scheduling applications for which they have used different simulators available in the market such as CloudSim. Performance of any scheduling algorithm will be different when applied to real time cloud environment as compared to simulation software. Aneka is one of the prominent PaaS software which allows users to develop cloud application using various programming models and underline infrastructure. In this chapter, a scheduling API is developed over the Aneka software platform which can be easily integrated with the Aneka software. Users can develop their own scheduling algorithms using this API and integrate it with Aneka software so that they can test their scheduling algorithm in real cloud environment. The proposed API provides all the required functionalities to integrate and schedule private, public or hybrid cloud with the Aneka software.",
    "lastUpdated": "2019-04-06T10:01:03Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1812.00302v2"
  },
  {
    "title": "An Automated Security Analysis Framework and Implementation for Cloud",
    "author": [
      "Hootan Alavizadeh",
      "Hooman Alavizadeh",
      "Dong Seong Kim",
      "Julian Jang-Jaccard",
      "Masood Niazi Torshiz"
    ],
    "abstract": "Cloud service providers offer their customers with on-demand and cost-effective services, scalable computing, and network infrastructures. Enterprises migrate their services to the cloud to utilize the benefit of cloud computing such as eliminating the capital expense of their computing need. There are security vulnerabilities and threats in the cloud. Many researches have been proposed to analyze the cloud security using Graphical Security Models (GSMs) and security metrics. In addition, it has been widely researched in finding appropriate defensive strategies for the security of the cloud. Moving Target Defense (MTD) techniques can utilize the cloud elasticity features to change the attack surface and confuse attackers. Most of the previous work incorporating MTDs into the GSMs are theoretical and the performance was evaluated based on the simulation. In this paper, we realized the previous framework and designed, implemented and tested a cloud security assessment tool in a real cloud platform named UniteCloud. Our security solution can (1) monitor cloud computing in real-time, (2) automate the security modeling and analysis and visualize the GSMs using a Graphical User Interface via a web application, and (3) deploy three MTD techniques including Diversity, Redundancy, and Shuffle on the real cloud infrastructure. We analyzed the automation process using the APIs and showed the practicality and feasibility of automation of deploying all the three MTD techniques on the UniteCloud.",
    "lastUpdated": "2019-04-03T04:19:18Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1904.01758v1"
  },
  {
    "title": "DeepMask: an algorithm for cloud and cloud shadow detection in optical satellite remote sensing images using deep residual network",
    "author": [
      "Ke Xu",
      "Kaiyu Guan",
      "Jian Peng",
      "Yunan Luo",
      "Sibo Wang"
    ],
    "abstract": "Detecting and masking cloud and cloud shadow from satellite remote sensing images is a pervasive problem in the remote sensing community. Accurate and efficient detection of cloud and cloud shadow is an essential step to harness the value of remotely sensed data for almost all downstream analysis. DeepMask, a new algorithm for cloud and cloud shadow detection in optical satellite remote sensing imagery, is proposed in this study. DeepMask utilizes ResNet, a deep convolutional neural network, for pixel-level cloud mask generation. The algorithm is trained and evaluated on the Landsat 8 Cloud Cover Assessment Validation Dataset distributed across 8 different land types. Compared with CFMask, the most widely used cloud detection algorithm, land-type-specific DeepMask models achieve higher accuracy across all land types. The average accuracy is 93.56%, compared with 85.36% from CFMask. DeepMask also achieves 91.02% accuracy on all-land-type dataset. Compared with other CNN-based cloud mask algorithms, DeepMask benefits from the parsimonious architecture and the residual connection of ResNet. It is compatible with input of any size and shape. DeepMask still maintains high performance when using only red, green, blue, and NIR bands, indicating its potential to be applied to other satellite platforms that only have limited optical bands.",
    "lastUpdated": "2019-11-09T03:44:07Z",
    "category": [
      "cs.CV",
      "eess.IV"
    ],
    "url": "http://arxiv.org/abs/1911.03607v1"
  },
  {
    "title": "Drivers affecting cloud ERP deployment decisions: an Australian study",
    "author": [
      "Xinyu Zhang"
    ],
    "abstract": "Cloud-based Enterprise Resources Planning (Cloud ERP) is hosting an ERP system through the cloud environment. Cloud ERP is responsible for organisational business processes such as purchasing, financial, and human resource by providing a real-time infrastructure for the enterprise. With the development of technology, cloud ERP is noticed by more and more enterprises. Currently, limited researches have been conducted for cloud ERP systems in the Australian context. Furthermore, no studies have indicated how different perspectives (client company & consultant company) bring insights into the deployment decisions on cloud ERP. Hence, this research intends to understand drivers affecting cloud ERP deployment decisions from both the client company and the consultant company perspective in an Australian context. This paper identifies 31 relevant literature on cloud ERP adoption; 79 critical drivers affecting cloud ERP deployment decisions were identified from the selected literature, and those drivers are then categorized using the Technology-Organisation-Environment (TOE) framework to develop the initial theoretical model. By conducting a Case Study Approach using a semi-structured interview and secondary resources analysis, findings are then compared to the theoretical model. As a result, an empirically validated model on drivers affecting cloud ERP deployment decisions from both client company and consultant company perspectives has been developed; this model contains 15 drivers and 7 of them are new. The theoretical and practical contributions of the findings are then outlined.",
    "lastUpdated": "2019-11-26T02:13:12Z",
    "category": [
      "cs.CY",
      "H.4.0",
      "H.4.0"
    ],
    "url": "http://arxiv.org/abs/1911.11309v1"
  },
  {
    "title": "Review: deep learning on 3D point clouds",
    "author": [
      "Saifullahi Aminu Bello",
      "Shangshu Yu",
      "Cheng Wang"
    ],
    "abstract": "Point cloud is point sets defined in 3D metric space. Point cloud has become one of the most significant data format for 3D representation. Its gaining increased popularity as a result of increased availability of acquisition devices, such as LiDAR, as well as increased application in areas such as robotics, autonomous driving, augmented and virtual reality. Deep learning is now the most powerful tool for data processing in computer vision, becoming the most preferred technique for tasks such as classification, segmentation, and detection. While deep learning techniques are mainly applied to data with a structured grid, point cloud, on the other hand, is unstructured. The unstructuredness of point clouds makes use of deep learning for its processing directly very challenging. Earlier approaches overcome this challenge by preprocessing the point cloud into a structured grid format at the cost of increased computational cost or lost of depth information. Recently, however, many state-of-the-arts deep learning techniques that directly operate on point cloud are being developed. This paper contains a survey of the recent state-of-the-art deep learning techniques that mainly focused on point cloud data. We first briefly discussed the major challenges faced when using deep learning directly on point cloud, we also briefly discussed earlier approaches which overcome the challenges by preprocessing the point cloud into a structured grid. We then give the review of the various state-of-the-art deep learning approaches that directly process point cloud in its unstructured form. We introduced the popular 3D point cloud benchmark datasets. And we also further discussed the application of deep learning in popular 3D vision tasks including classification, segmentation and detection.",
    "lastUpdated": "2020-01-17T12:55:23Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2001.06280v1"
  },
  {
    "title": "Cybersecurity in the AWS Cloud",
    "author": [
      "Michael Soltys"
    ],
    "abstract": "This paper re-examines the content of a standard advanced course in Cybersecurity from the perspective of Cloud Computing. More precisely, we review the core concepts of Cybersecurity, as presented in a senior undergraduate or graduate class, in light of the Amazon Web Services (AWS) cloud.",
    "lastUpdated": "2020-03-28T22:45:28Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/2003.12905v1"
  },
  {
    "title": "Peer-to-Peer Cloud Provisioning: Service Discovery and Load-Balancing",
    "author": [
      "Rajiv Ranjan",
      "Liang Zhao",
      "Xiaomin Wu",
      "Anna Liu"
    ],
    "abstract": "This chapter presents: (i) a layered peer-to-peer Cloud provisioning architecture; (ii) a summary of the current state-of-the-art in Cloud provisioning with particular emphasis on service discovery and load-balancing; (iii) a classification of the existing peer-to-peer network management model with focus on extending the DHTs for indexing and managing complex provisioning information; and (iv) the design and implementation of novel, extensible software fabric (Cloud peer) that combines public/private clouds, overlay networking and structured peer-to-peer indexing techniques for supporting scalable and self-managing service discovery and load-balancing in Cloud computing environments. Finally, an experimental evaluation is presented that demonstrates the feasibility of building next generation Cloud provisioning systems based on peer-to-peer network management and information dissemination models. The experimental test-bed has been deployed on a public cloud computing platform, Amazon EC2, which demonstrates the effectiveness of the proposed peer-to-peer Cloud provisioning software fabric.",
    "lastUpdated": "2009-12-10T02:07:40Z",
    "category": [
      "cs.DC",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/0912.1905v1"
  },
  {
    "title": "Research Agenda in Cloud Technologies",
    "author": [
      "Ilango Sriram",
      "Ali Khajeh-Hosseini"
    ],
    "abstract": "Cloud computing is the latest effort in delivering computing resources as a service. It represents a shift away from computing as a product that is purchased, to computing as a service that is delivered to consumers over the internet from large-scale data centres - or \"clouds\". Whilst cloud computing is gaining growing popularity in the IT industry, academia appeared to be lagging behind the rapid developments in this field. This paper is the first systematic review of peer-reviewed academic research published in this field, and aims to provide an overview of the swiftly developing advances in the technical foundations of cloud computing and their research efforts. Structured along the technical aspects on the cloud agenda, we discuss lessons from related technologies; advances in the introduction of protocols, interfaces, and standards; techniques for modelling and building clouds; and new use-cases arising through cloud computing.",
    "lastUpdated": "2010-01-19T15:53:41Z",
    "category": [
      "cs.DC",
      "C.2.4; A.1"
    ],
    "url": "http://arxiv.org/abs/1001.3259v1"
  },
  {
    "title": "In Cloud, Can Scientific Communities Benefit from the Economies of Scale?",
    "author": [
      "Lei Wang",
      "Jianfeng Zhan",
      "Weisong Shi",
      "Yi Liang"
    ],
    "abstract": "The basic idea behind Cloud computing is that resource providers offer elastic resources to end users. In this paper, we intend to answer one key question to the success of Cloud computing: in Cloud, can small or medium-scale scientific computing communities benefit from the economies of scale? Our research contributions are three-fold: first, we propose an enhanced scientific public cloud model (ESP) that encourages small- or medium-scale organizations to rent elastic resources from a public cloud provider; second, on a basis of the ESP model, we design and implement the DawningCloud system that can consolidate heterogeneous scientific workloads on a Cloud site; third, we propose an innovative emulation methodology and perform a comprehensive evaluation. We found that for two typical workloads: high throughput computing (HTC) and many task computing (MTC), DawningCloud saves the resource consumption maximally by 44.5% (HTC) and 72.6% (MTC) for service providers, and saves the total resource consumption maximally by 47.3% for a resource provider with respect to the previous two public Cloud solutions. To this end, we conclude that for typical workloads: HTC and MTC, DawningCloud can enable scientific communities to benefit from the economies of scale of public Clouds.",
    "lastUpdated": "2010-04-08T08:07:08Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1004.1276v1"
  },
  {
    "title": "A Model of Cloud Based Application Environment for Software Testing",
    "author": [
      "T. Vengattaraman",
      "P. Dhavachelvan",
      "R. Baskaran"
    ],
    "abstract": "Cloud computing is an emerging platform of service computing designed for swift and dynamic delivery of assured computing resources. Cloud computing provide Service-Level Agreements (SLAs) for guaranteed uptime availability for enabling convenient and on-demand network access to the distributed and shared computing resources. Though the cloud computing paradigm holds its potential status in the field of distributed computing, cloud platforms are not yet to the attention of majority of the researchers and practitioners. More specifically, still the researchers and practitioners community has fragmented and imperfect knowledge on cloud computing principles and techniques. In this context, one of the primary motivations of the work presented in this paper is to reveal the versatile merits of cloud computing paradigm and hence the objective of this work is defined to bring out the remarkable significances of cloud computing paradigm through an application environment. In this work, a cloud computing model for software testing is developed.",
    "lastUpdated": "2010-04-11T08:14:56Z",
    "category": [
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/1004.1773v1"
  },
  {
    "title": "Scientific Workflow Applications on Amazon EC2",
    "author": [
      "Gideon Juve",
      "Ewa Deelman",
      "Karan Vahi",
      "Gaurang Mehta",
      "Bruce Berriman",
      "Benjamin P. Berman",
      "Phil Maechling"
    ],
    "abstract": "The proliferation of commercial cloud computing providers has generated significant interest in the scientific computing community. Much recent research has attempted to determine the benefits and drawbacks of cloud computing for scientific applications. Although clouds have many attractive features, such as virtualization, on-demand provisioning, and \"pay as you go\" usage-based pricing, it is not clear whether they are able to deliver the performance required for scientific applications at a reasonable price. In this paper we examine the performance and cost of clouds from the perspective of scientific workflow applications. We use three characteristic workflows to compare the performance of a commercial cloud with that of a typical HPC system, and we analyze the various costs associated with running those workflows in the cloud. We find that the performance of clouds is not unreasonable given the hardware resources provided, and that performance comparable to HPC systems can be achieved given similar resources. We also find that the cost of running workflows on a commercial cloud can be reduced by storing data in the cloud rather than transferring it from outside.",
    "lastUpdated": "2010-05-16T03:20:05Z",
    "category": [
      "astro-ph.IM",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1005.2718v1"
  },
  {
    "title": "Cloud Scheduler: a resource manager for distributed compute clouds",
    "author": [
      "P. Armstrong",
      "A. Agarwal",
      "A. Bishop",
      "A. Charbonneau",
      "R. Desmarais",
      "K. Fransham",
      "N. Hill",
      "I. Gable",
      "S. Gaudet",
      "S. Goliath",
      "R. Impey",
      "C. Leavett-Brown",
      "J. Ouellete",
      "M. Paterson",
      "C. Pritchet",
      "D. Penfold-Brown",
      "W. Podaima",
      "D. Schade",
      "R. J. Sobie"
    ],
    "abstract": "The availability of Infrastructure-as-a-Service (IaaS) computing clouds gives researchers access to a large set of new resources for running complex scientific applications. However, exploiting cloud resources for large numbers of jobs requires significant effort and expertise. In order to make it simple and transparent for researchers to deploy their applications, we have developed a virtual machine resource manager (Cloud Scheduler) for distributed compute clouds. Cloud Scheduler boots and manages the user-customized virtual machines in response to a user's job submission. We describe the motivation and design of the Cloud Scheduler and present results on its use on both science and commercial clouds.",
    "lastUpdated": "2010-06-30T23:54:01Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1007.0050v1"
  },
  {
    "title": "The Cloud Adoption Toolkit: Supporting Cloud Adoption Decisions in the Enterprise",
    "author": [
      "Ali Khajeh-Hosseini",
      "David Greenwood",
      "James W. Smith",
      "Ian Sommerville"
    ],
    "abstract": "Cloud computing promises a radical shift in the provisioning of computing resource within the enterprise. This paper describes the challenges that decision makers face when assessing the feasibility of the adoption of cloud computing in their organisations, and describes our Cloud Adoption Toolkit, which has been developed to support this process. The toolkit provides a framework to support decision makers in identifying their concerns, and matching these concerns to appropriate tools/techniques that can be used to address them. Cost Modeling is the most mature tool in the toolkit, and this paper shows its effectiveness by demonstrating how practitioners can use it to examine the costs of deploying their IT systems on the cloud. The Cost Modeling tool is evaluated using a case study of an organization that is considering the migration of some of its IT systems to the cloud. The case study shows that running systems on the cloud using a traditional \"always on\" approach can be less cost effective, and the elastic nature of the cloud has to be used to reduce costs. Therefore, decision makers have to be able to model the variations in resource usage and their systems deployment options to obtain accurate cost estimates.",
    "lastUpdated": "2010-08-11T12:56:32Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1008.1900v1"
  },
  {
    "title": "Icebergs in the Clouds: the Other Risks of Cloud Computing",
    "author": [
      "Bryan Ford"
    ],
    "abstract": "Cloud computing is appealing from management and efficiency perspectives, but brings risks both known and unknown. Well-known and hotly-debated information security risks, due to software vulnerabilities, insider attacks, and side-channels for example, may be only the \"tip of the iceberg.\" As diverse, independently developed cloud services share ever more fluidly and aggressively multiplexed hardware resource pools, unpredictable interactions between load-balancing and other reactive mechanisms could lead to dynamic instabilities or \"meltdowns.\" Non-transparent layering structures, where alternative cloud services may appear independent but share deep, hidden resource dependencies, may create unexpected and potentially catastrophic failure correlations, reminiscent of financial industry crashes. Finally, cloud computing exacerbates already-difficult digital preservation challenges, because only the provider of a cloud-based application or service can archive a \"live,\" functional copy of a cloud artifact and its data for long-term cultural preservation. This paper explores these largely unrecognized risks, making the case that we should study them before our socioeconomic fabric becomes inextricably dependent on a convenient but potentially unstable computing model.",
    "lastUpdated": "2012-05-17T02:45:08Z",
    "category": [
      "cs.CY",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1203.1979v2"
  },
  {
    "title": "An Effective Fusion Technique of Cloud Computing and Networking Series",
    "author": [
      "K. Saravanan",
      "S. Akshaya",
      "R. Pavithra",
      "K. Pushpavalli"
    ],
    "abstract": "Cloud computing is making it possible to separate the process of building an infrastructure for service provisioning from the business of providing end user services. Today, such infrastructures are normally provided in large data centres and the applications are executed remotely from the users. One reason for this is that cloud computing requires a reasonably stable infrastructure and networking environment, largely due to management reasons. Networking of Information (NetInf) is an information centric networking paradigm that can support cloud computing by providing new possibilities for network transport and storage. It offers direct access to information objects through a simple API, independent of their location in the network. This abstraction can hide much of the complexity of storage and network transport systems that cloud computing today has to deal with. In this paper we analyze how cloud computing and NetInf can be combined to make cloud computing infrastructures easier to manage, and potentially enable deployment in smaller and more dynamic networking environments. NetInf should thus be understood as an enhancement to the infrastructure for cloud computing rather than a change to cloud computing technology as such. To illustrate the approach taken by NetInf, we also describe how it can be implemented by introducing a specific name resolution and routing mechanism.",
    "lastUpdated": "2012-10-10T16:43:57Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1210.2977v1"
  },
  {
    "title": "Building an Expert System for Evaluation of Commercial Cloud Services",
    "author": [
      "Zheng Li",
      "Liam O'Brien",
      "Rainbow Cai",
      "He Zhang"
    ],
    "abstract": "Commercial Cloud services have been increasingly supplied to customers in industry. To facilitate customers' decision makings like cost-benefit analysis or Cloud provider selection, evaluation of those Cloud services are becoming more and more crucial. However, compared with evaluation of traditional computing systems, more challenges will inevitably appear when evaluating rapidly-changing and user-uncontrollable commercial Cloud services. This paper proposes an expert system for Cloud evaluation that addresses emerging evaluation challenges in the context of Cloud Computing. Based on the knowledge and data accumulated by exploring the existing evaluation work, this expert system has been conceptually validated to be able to give suggestions and guidelines for implementing new evaluation experiments. As such, users can conveniently obtain evaluation experiences by using this expert system, which is essentially able to make existing efforts in Cloud services evaluation reusable and sustainable.",
    "lastUpdated": "2013-02-09T06:04:35Z",
    "category": [
      "cs.DC",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1302.2202v1"
  },
  {
    "title": "Cooperative Caching Framework for Mobile Cloud Computing",
    "author": [
      "Preetha Theresa Joy",
      "K. Poulose Jacob"
    ],
    "abstract": "Due to the advancement in mobile devices and wireless networks mobile cloud computing, which combines mobile computing and cloud computing has gained momentum since 2009. The characteristics of mobile devices and wireless network makes the implementation of mobile cloud computing more complicated than for fixed clouds. This section lists some of the major issues in Mobile Cloud Computing. One of the key issues in mobile cloud computing is the end to end delay in servicing a request. Data caching is o ne of the techniques widely used in wired and wireless networks to improve data access efficiency. In this paper we explore the possibility of a cooperative caching approach to enhance data access efficiency in mobile cloud computing. The proposed approach is based on cloudlets, one of the architecture designed for mobile cloud computing.",
    "lastUpdated": "2013-07-29T12:57:54Z",
    "category": [
      "cs.NI",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1307.7563v1"
  },
  {
    "title": "NetSecCC: A Scalable and Fault-tolerant Architecture without Outsourcing Cloud Network Security",
    "author": [
      "Jin He",
      "Mianxiong Dong",
      "Kaoru Ota",
      "Minyu Fan",
      "Guangwei Wang"
    ],
    "abstract": "Modern cloud computing platforms based on virtual machine monitors carry a variety of complex business that present many network security vulnerabilities. At present, the traditional architecture employs a number of security devices at front-end of cloud computing to protect its network security. Under the new environment, however, this approach can not meet the needs of cloud security. New cloud security vendors and academia also made great efforts to solve network security of cloud computing, unfortunately, they also cannot provide a perfect and effective method to solve this problem. We introduce a novel network security architecture for cloud computing (NetSecCC) that addresses this problem. NetSecCC not only provides an effective solution for network security issues of cloud computing, but also greatly improves in scalability, fault-tolerant, resource utilization, etc. We have implemented a proof-of-concept prototype about NetSecCC and proved by experiments that NetSecCC is an effective architecture with minimal performance overhead that can be applied to the extensive practical promotion in cloud computing.",
    "lastUpdated": "2014-05-04T07:31:42Z",
    "category": [
      "cs.CR",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1405.0660v1"
  },
  {
    "title": "Ontological Approach toward Cybersecurity in Cloud Computing",
    "author": [
      "Takeshi Takahashi",
      "Youki Kadobayashi",
      "Hiroyuki Fujiwara"
    ],
    "abstract": "Widespread deployment of the Internet enabled building of an emerging IT delivery model, i.e., cloud computing. Albeit cloud computing-based services have rapidly developed, their security aspects are still at the initial stage of development. In order to preserve cybersecurity in cloud computing, cybersecurity information that will be exchanged within it needs to be identified and discussed. For this purpose, we propose an ontological approach to cybersecurity in cloud computing. We build an ontology for cybersecurity operational information based on actual cybersecurity operations mainly focused on non-cloud computing. In order to discuss necessary cybersecurity information in cloud computing, we apply the ontology to cloud computing. Through the discussion, we identify essential changes in cloud computing such as data-asset decoupling and clarify the cybersecurity information required by the changes such as data provenance and resource dependency information.",
    "lastUpdated": "2014-04-01T08:10:42Z",
    "category": [
      "cs.CR",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1405.6169v1"
  },
  {
    "title": "Agri-Info: Cloud Based Autonomic System for Delivering Agriculture as a Service",
    "author": [
      "Sukhpal Singh",
      "Inderveer Chana",
      "Rajkumar Buyya"
    ],
    "abstract": "Cloud computing has emerged as an important paradigm for managing and delivering services efficiently over the Internet. Convergence of cloud computing with technologies such as wireless sensor networking and mobile computing offers new applications of cloud services but this requires management of Quality of Service (QoS) parameters to efficiently monitor and measure the delivered services. This paper presents a QoS-aware Cloud Based Autonomic Information System for delivering agriculture related information as a service through the use of latest Cloud technologies which manage various types of agriculture related data based on different domains. Proposed system gathers information from various users through preconfigured devices and manages and provides required information to users automatically. Further, Cuckoo Optimization Algorithm has been used for efficient resource allocation at infrastructure level for effective utilization of resources. We have evaluated the performance of the proposed approach in Cloud environment and experimental results show that the proposed system performs better in terms of resource utilization, execution time, cost and computing capacity along with other QoS parameters.",
    "lastUpdated": "2015-11-29T09:51:36Z",
    "category": [
      "cs.DC",
      "C.2.4"
    ],
    "url": "http://arxiv.org/abs/1511.08986v1"
  },
  {
    "title": "Data Migration among Different Clouds",
    "author": [
      "Ismail Hababeh"
    ],
    "abstract": "Cloud computing services are becoming more and more popular. However, the high concentration of data and services on the clouds make them attractive targets for various security attacks, including DoS, data theft, and privacy attacks. Additionally, cloud providers may fail to comply with service level agreement in terms of performance, availability, and security guarantees. Moreover, users may choose to utilize public cloud services from multiple vendors for various reasons including fault tolerance and availability. Therefore, it is of paramount importance to have secure and efficient mechanisms that enable users to transparently copy and move their data from one provider to another. In this paper, we explore the state of the art inter cloud migration techniques and identify the potential security threats in the scope of Hadoop Distributed File System HDFS. We propose an inter cloud data migration mechanism that offers better security guarantees and faster response time for migrating large scale data files in cloud database management systems. The proposed approach enhances the data security processes used to achieve secure data migration between cloud nodes thus improves applications response time and throughput. The performance of the proposed approach is validated by measuring its impact on response time and throughput, and comparing the performance to that of other techniques in the literature.",
    "lastUpdated": "2015-12-28T12:11:36Z",
    "category": [
      "cs.DC",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1512.08383v1"
  },
  {
    "title": "Mitigating Data Exfiltration in Storage-as-a-Service Clouds",
    "author": [
      "Duane Wilson",
      "Jeff Avery"
    ],
    "abstract": "Existing processes and methods for incident handling are geared towards infrastructures and operational models that will be increasingly outdated by cloud computing. Research has shown that to adapt incident handling to cloud computing environments, cloud customers must establish clarity about their requirements on Cloud Service Providers (CSPs) for successful handling of incidents and contract CSPs accordingly. Secondly, CSPs must strive to support these requirements and mirror them in their Service Level Agreements. Intrusion Detection Systems (IDS) have been used widely to detect malicious behaviors in network communication and hosts. Facing new application scenarios in Cloud Computing, the IDS approaches yield several problems since the operator of the IDS should be the user, not the administrator of the Cloud infrastructure. Cloud providers need to enable possibilities to deploy and configure IDS for the user - which poses its own challenges. Current research and commercial solutions primarily focus on protecting against Denial of Service attacks and attacks against the Cloud's virtual infrastructure. To counter these challenges, we propose a capability that aims to both detect and prevent the potential of data exfiltration by using a novel deception-based methodology. We also introduce a method of increasing the data protection level based on various threat conditions.",
    "lastUpdated": "2016-06-27T17:34:02Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1606.08378v1"
  },
  {
    "title": "A Relative Study of Task Scheduling Algorithms in Cloud Computing Environment",
    "author": [
      "Syed Arshad Ali",
      "Mansaf Alam"
    ],
    "abstract": "Cloud Computing is a paradigm of both parallel processing and distributed computing. It offers computing facilities as a utility service in pay as par use manner. Virtualization, self service provisioning, elasticity and pay per use are the key features of Cloud Computing. It provides different types of resources over the Internet to perform user submitted tasks. In cloud environment, huge number of tasks are executed simultaneously, an effective Task Scheduling is required to gain better performance of the cloud system. Various Cloud Based Task Scheduling algorithms are available that schedule the task of user to resources for execution. Due to the novelty of Cloud Computing, traditional scheduling algorithms cannot satisfy the needs of cloud , the researchers are trying to modify traditional algorithms that can fulfill the cloud requirements like rapid elasticity, resource pooling and on demand self service. In this paper the current state of Task Scheduling algorithms has been discussed and compared on the basis of various scheduling parameters like execution time, throughput, make span, resource utilization, quality of service, energy consumption, response time and cost.",
    "lastUpdated": "2016-12-16T06:55:22Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1612.05633v1"
  },
  {
    "title": "An Android Cloud Storage Apps Forensic Taxonomy",
    "author": [
      "M. Amine Chelihi",
      "Akintunde Elutilo",
      "Imran Ahmed",
      "Christos Papadopoulos",
      "Ali Dehghantanha"
    ],
    "abstract": "Mobile phones have been playing a very significant role in our daily activities for the last decade. With the increase need for these devices, people are now more reliant on their smartphone applications for their daily tasks and many prefer to save their mobile data on a cloud platform to access them anywhere on any device. Cloud technology is the new way for better data storage, as it offers better security, more flexibility, and mobility. Many smartphones have been investigated as subjects, objects or tools of the crime. Many of these investigations include analysing data stored through cloud storage apps which contributes to importance of cloud apps forensics on mobile devices. In this paper, various cloud Android applications are analysed using the forensics tool XRY and a forensics taxonomy for investigation of these apps is suggested. The proposed taxonomy reflects residual artefacts retrievable from 31 different cloud applications. It is expected that the proposed taxonomy and the forensic findings in this paper will assist future forensic investigations involving cloud based storage applications.",
    "lastUpdated": "2017-06-25T07:18:04Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1706.08045v1"
  },
  {
    "title": "Software-Defined Multi-Cloud Computing: A Vision, Architectural Elements, and Future Directions",
    "author": [
      "Rajkumar Buyya",
      "Jungmin Son"
    ],
    "abstract": "Cloud computing has been emerged in the last decade to enable utility-based computing resource management without purchasing hardware equipment. Cloud providers run multiple data centers in various locations to manage and provision the Cloud resources to their customers. More recently, the introduction of Software-Defined Networking (SDN) and Network Function Virtualization (NFV) opens more opportunities in Clouds which enables dynamic and autonomic configuration and provisioning of the resources in Cloud data centers. This paper proposes architectural framework and principles for Programmable Network Clouds hosting SDNs and NFVs for geographically distributed Multi-Cloud computing environments. Cost and SLA-aware resource provisioning and scheduling that minimizes the operating cost without violating the negotiated SLAs are investigated and discussed in regards of techniques for autonomic and timely VNF composition, deployment and management across multiple Clouds. We also discuss open challenges and directions for creating auto-scaling solutions for performance optimization of VNFs using analytics and monitoring techniques, algorithms for SDN controller for scalable traffic and deployment management. The simulation platform and the proof-of-concept prototype are presented with initial evaluation results.",
    "lastUpdated": "2018-05-28T05:59:00Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1805.10780v1"
  },
  {
    "title": "Mobile Cloud Computing: A Comparison of Application Models",
    "author": [
      "Dejan Kovachev",
      "Yiwei Cao",
      "Ralf Klamma"
    ],
    "abstract": "Cloud computing is an emerging concept combining many fields of computing. The foundation of cloud computing is the delivery of services, software and processing capacity over the Internet, reducing cost, increasing storage, automating systems, decoupling of service delivery from underlying technology, and providing flexibility and mobility of information. However, the actual realization of these benefits is far from being achieved for mobile applications and open many new research questions. In order to better understand how to facilitate the building of mobile cloud-based applications, we have surveyed existing work in mobile computing through the prism of cloud computing principles. We give a definition of mobile cloud coputing and provide an overview of the results from this review, in particular, models of mobile cloud applications. We also highlight research challenges in the area of mobile cloud computing. We conclude with recommendations for how this better understanding of mobile cloud computing can help building more powerful mobile applications.",
    "lastUpdated": "2011-07-25T13:17:13Z",
    "category": [
      "cs.NI",
      "cs.DC",
      "cs.MM"
    ],
    "url": "http://arxiv.org/abs/1107.4940v1"
  },
  {
    "title": "Improving Scientific Workflow with Cloud Offloading",
    "author": [
      "Hao Qian"
    ],
    "abstract": "Scientific workflow is a powerful tool to streamline and organize computational steps of scientific application. This paper presents Emerald, a system that adds sophisticated cloud offloading capabilities to scientific workflows. Emerald automatically offloads computation intensive steps of scientific workflow to the cloud in order to enhance workflow performance. Emerald provides easy-to-use APIs to help developers build cloud offloading enabled scientific workflows. Evaluation showed that Emerald can effectively reduce up to 55% of execution time for scientific applications.",
    "lastUpdated": "2017-10-04T00:38:39Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1710.01429v1"
  },
  {
    "title": "Dynamic Adaptive Point Cloud Streaming",
    "author": [
      "Mohammad Hosseini",
      "Christian Timmerer"
    ],
    "abstract": "High-quality point clouds have recently gained interest as an emerging form of representing immersive 3D graphics. Unfortunately, these 3D media are bulky and severely bandwidth intensive, which makes it difficult for streaming to resource-limited and mobile devices. This has called researchers to propose efficient and adaptive approaches for streaming of high-quality point clouds. In this paper, we run a pilot study towards dynamic adaptive point cloud streaming, and extend the concept of dynamic adaptive streaming over HTTP (DASH) towards DASH-PC, a dynamic adaptive bandwidth-efficient and view-aware point cloud streaming system. DASH-PC can tackle the huge bandwidth demands of dense point cloud streaming while at the same time can semantically link to human visual acuity to maintain high visual quality when needed. In order to describe the various quality representations, we propose multiple thinning approaches to spatially sub-sample point clouds in the 3D space, and design a DASH Media Presentation Description manifest specific for point cloud streaming. Our initial evaluations show that we can achieve significant bandwidth and performance improvement on dense point cloud streaming with minor negative quality impacts compared to the baseline scenario when no adaptations is applied.",
    "lastUpdated": "2019-04-08T22:49:22Z",
    "category": [
      "cs.MM"
    ],
    "url": "http://arxiv.org/abs/1804.10878v2"
  },
  {
    "title": "Emerging from The Cloud: A Bibliometric Analysis of Cloud Forensics Studies",
    "author": [
      "James Baldwin",
      "Omar M. K. Alhawi",
      "Simone Shaughnessy",
      "Alex Akinbi",
      "Ali Dehghantanha"
    ],
    "abstract": "The emergence of cloud computing technologies has changed the way we store, retrieve, and archive our data. With the promise of unlimited, reliable and always-available storage, a lot of private and confidential data are now stored on different cloud platforms. Being such a gold mine of data, cloud platforms are among the most valuable targets for attackers. Therefore, many forensics investigators have tried to develop tools, tactics and procedures to collect, preserve, analyse and report evidences of attackers activities on different cloud platforms. Despite the number of published articles there is not a bibliometric study that presents cloud forensics research trends. This paper aims to address this problem by providing a comprehensive assessment of cloud forensics research trends between 2009 and 2016. Moreover, we provide a classification of cloud forensics process to detect the most profound research areas and highlight remaining challenges.",
    "lastUpdated": "2018-07-27T05:25:44Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1807.10436v1"
  },
  {
    "title": "A Cloud Controller for Performance-Based Pricing",
    "author": [
      "Dražen Lučanin",
      "Ilia Pietri",
      "Ivona Brandic",
      "Rizos Sakellariou"
    ],
    "abstract": "New dynamic cloud pricing options are emerging with cloud providers offering resources as a wide range of CPU frequencies and matching prices that can be switched at runtime. On the other hand, cloud providers are facing the problem of growing operational energy costs. This raises a trade-off problem between energy savings and revenue loss when performing actions such as CPU frequency scaling. Although existing cloud con- trollers for managing cloud resources deploy frequency scaling, they only consider fixed virtual machine (VM) pricing. In this paper we propose a performance-based pricing model adapted for VMs with different CPU-boundedness properties. We present a cloud controller that scales CPU frequencies to achieve energy cost savings that exceed service revenue losses. We evaluate the approach in a simulation based on real VM workload, electricity price and temperature traces, estimating energy cost savings up to 32% in certain scenarios.",
    "lastUpdated": "2018-09-16T08:57:14Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1809.05840v1"
  },
  {
    "title": "Convolutional LSTMs for Cloud-Robust Segmentation of Remote Sensing Imagery",
    "author": [
      "Marc Rußwurm",
      "Marco Körner"
    ],
    "abstract": "Clouds frequently cover the Earth's surface and pose an omnipresent challenge to optical Earth observation methods. The vast majority of remote sensing approaches either selectively choose single cloud-free observations or employ a pre-classification strategy to identify and mask cloudy pixels. We follow a different strategy and treat cloud coverage as noise that is inherent to the observed satellite data. In prior work, we directly employed a straightforward \\emph{convolutional long short-term memory} network for vegetation classification without explicit cloud filtering and achieved state-of-the-art classification accuracies. In this work, we investigate this cloud-robustness further by visualizing internal cell activations and performing an ablation experiment on datasets of different cloud coverage. In the visualizations of network states, we identified some cells in which modulation and input gates closed on cloudy pixels. This indicates that the network has internalized a cloud-filtering mechanism without being specifically trained on cloud labels. Overall, our results question the necessity of sophisticated pre-processing pipelines for multi-temporal deep learning approaches.",
    "lastUpdated": "2018-12-02T11:30:38Z",
    "category": [
      "cs.CV",
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1811.02471v2"
  },
  {
    "title": "Data Security and Privacy Protection Data Security and Privacy Protection in Public Cloud",
    "author": [
      "Yue Shi"
    ],
    "abstract": "This paper discusses about the challenges, advantages and shortcomings of existing solutions in data security and privacy in public cloud computing. As in cloud computing, oceans of data will be stored. Data stored in public cloud would face both outside attacks and inside attacks since public cloud provider themselves are untrusted. Conventional encryption could be used for storage, however most data in cloud needs further computation. Decryption before computation will cause large overheads for data operation and lots of inconvenience. Thus, efficient methods to protect data security as well as privacy for large amount of data in cloud are necessary. In the paper, different mechanisms to protect data security and privacy in public cloud are discussed. A data security and privacy enabled multi-cloud architecture is proposed.",
    "lastUpdated": "2018-12-14T00:12:55Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1812.05745v1"
  },
  {
    "title": "A Remote Sensing Image Dataset for Cloud Removal",
    "author": [
      "Daoyu Lin",
      "Guangluan Xu",
      "Xiaoke Wang",
      "Yang Wang",
      "Xian Sun",
      "Kun Fu"
    ],
    "abstract": "Cloud-based overlays are often present in optical remote sensing images, thus limiting the application of acquired data. Removing clouds is an indispensable pre-processing step in remote sensing image analysis. Deep learning has achieved great success in the field of remote sensing in recent years, including scene classification and change detection. However, deep learning is rarely applied in remote sensing image removal clouds. The reason is the lack of data sets for training neural networks. In order to solve this problem, this paper first proposed the Remote sensing Image Cloud rEmoving dataset (RICE). The proposed dataset consists of two parts: RICE1 contains 500 pairs of images, each pair has images with cloud and cloudless size of 512*512; RICE2 contains 450 sets of images, each set contains three 512*512 size images. , respectively, the reference picture without clouds, the picture of the cloud and the mask of its cloud. The dataset is freely available at \\url{https://github.com/BUPTLdy/RICE_DATASET}.",
    "lastUpdated": "2019-01-03T03:43:38Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1901.00600v1"
  },
  {
    "title": "Dense 3D Point Cloud Reconstruction Using a Deep Pyramid Network",
    "author": [
      "Priyanka Mandikal",
      "R. Venkatesh Babu"
    ],
    "abstract": "Reconstructing a high-resolution 3D model of an object is a challenging task in computer vision. Designing scalable and light-weight architectures is crucial while addressing this problem. Existing point-cloud based reconstruction approaches directly predict the entire point cloud in a single stage. Although this technique can handle low-resolution point clouds, it is not a viable solution for generating dense, high-resolution outputs. In this work, we introduce DensePCR, a deep pyramidal network for point cloud reconstruction that hierarchically predicts point clouds of increasing resolution. Towards this end, we propose an architecture that first predicts a low-resolution point cloud, and then hierarchically increases the resolution by aggregating local and global point features to deform a grid. Our method generates point clouds that are accurate, uniform and dense. Through extensive quantitative and qualitative evaluation on synthetic and real datasets, we demonstrate that DensePCR outperforms the existing state-of-the-art point cloud reconstruction works, while also providing a light-weight and scalable architecture for predicting high-resolution outputs.",
    "lastUpdated": "2019-01-25T15:07:44Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1901.08906v1"
  },
  {
    "title": "Cloud Programming Simplified: A Berkeley View on Serverless Computing",
    "author": [
      "Eric Jonas",
      "Johann Schleier-Smith",
      "Vikram Sreekanti",
      "Chia-Che Tsai",
      "Anurag Khandelwal",
      "Qifan Pu",
      "Vaishaal Shankar",
      "Joao Carreira",
      "Karl Krauth",
      "Neeraja Yadwadkar",
      "Joseph E. Gonzalez",
      "Raluca Ada Popa",
      "Ion Stoica",
      "David A. Patterson"
    ],
    "abstract": "Serverless cloud computing handles virtually all the system administration operations needed to make it easier for programmers to use the cloud. It provides an interface that greatly simplifies cloud programming, and represents an evolution that parallels the transition from assembly language to high-level programming languages. This paper gives a quick history of cloud computing, including an accounting of the predictions of the 2009 Berkeley View of Cloud Computing paper, explains the motivation for serverless computing, describes applications that stretch the current limits of serverless, and then lists obstacles and research opportunities required for serverless computing to fulfill its full potential. Just as the 2009 paper identified challenges for the cloud and predicted they would be addressed and that cloud use would accelerate, we predict these issues are solvable and that serverless computing will grow to dominate the future of cloud computing.",
    "lastUpdated": "2019-02-09T07:25:09Z",
    "category": [
      "cs.OS"
    ],
    "url": "http://arxiv.org/abs/1902.03383v1"
  },
  {
    "title": "Middleware Implementation in Cloud-MANET Mobility Model for Internet of Smart Devices",
    "author": [
      "Tanweer Alam"
    ],
    "abstract": "The smart devices are extremely useful devices that are making our lives easier than before. A smart device is facilitated us to establish a connection with another smart device in a wireless network with a decentralized approach. The mobile ad hoc network (MANET) is a novel methodology that discovers neighborhood devices and establishes connection among them without centralized infrastructure. Cloud provides service to the MANET users to access cloud and communicates with another MANET users. In this article, I integrated MANET and cloud together and formed a new mobility model named Cloud-MANET. In this Mobility model, if one smart device of MANET is able to connect to the internet then all smart devices are enabled to use cloud service and can be interacted with another smart device in the Cloud-MANET framework. A middleware acts as an interface between MANET and cloud. The objective of this article is to implement a middleware in Cloud-MANET mobility model for communication on internet of smart devices.",
    "lastUpdated": "2020-06-05T14:28:37Z",
    "category": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1902.09744v2"
  },
  {
    "title": "CloudSafe: A Tool for an Automated Security Analysis for Cloud Computing",
    "author": [
      "Seoungmo An",
      "Taehoon Eom",
      "Jong Sou Park",
      "Jin B. Hong",
      "Armstrong Nhlabatsi",
      "Noora Fetais",
      "Khaled M. Khan",
      "Dong Seong Kim"
    ],
    "abstract": "Cloud computing has been adopted widely, providing on-demand computing resources to improve perfornance and reduce the operational costs. However, these new functionalities also bring new ways to exploit the cloud computing environment. To assess the security of the cloud, graphical security models can be used, such as Attack Graphs and Attack Trees. However, existing models do not consider all types of threats, and also automating the security assessment functions are difficult. In this paper, we propose a new security assessment tool for the cloud named CloudSafe, an automated security assessment for the cloud. The CloudSafe tool collates various tools and frameworks to automate the security assessment process. To demonstrate the applicability of the CloudSafe, we conducted security assessment in Amazon AWS, where our experimental results showed that we can effectively gather security information of the cloud and carry out security assessment to produce security reports. Users and cloud service providers can use the security report generated by the CloudSafe to understand the security posture of the cloud being used/provided.",
    "lastUpdated": "2019-03-11T13:05:12Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1903.04271v1"
  },
  {
    "title": "Above the Clouds: A Brief Survey",
    "author": [
      "Ananga Thapaliya",
      "Subham Chakraborty"
    ],
    "abstract": "Cloud Computing is a versatile technology that can support a broad-spectrum of applications. The low cost of cloud computing and its dynamic scaling renders it an innovation driver for small companies, particularly in the developing world. Cloud deployed enterprise resource planning (ERP), supply chain management applications (SCM), customer relationship management (CRM) applications, medical applications, business applications and mobile applications have potential to reach millions of users. In this paper, we explore the different concepts involved in cloud computing and we also examine clouds from technical aspects. We highlight some of the opportunities in cloud computing underlining the importance of clouds showing why that technology must succeed and we have provided additional cloud computing problems that businesses may need to address. Finally, we discuss some of the issues that this area should deal with.",
    "lastUpdated": "2019-08-09T19:02:00Z",
    "category": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1908.02124v2"
  },
  {
    "title": "Visualizing Point Cloud Classifiers by Curvature Smoothing",
    "author": [
      "Chen Ziwen",
      "Wenxuan Wu",
      "Zhongang Qi",
      "Li Fuxin"
    ],
    "abstract": "Recently, several networks that operate directly on point clouds have been proposed. There is significant utility in understanding their mechanisms to classify point clouds, which can potentially help diagnosing these networks and designing better architectures. In this paper, we propose a novel approach to visualize features important to the point cloud classifiers. Our approach is based on smoothing curved areas on a point cloud. After prominent features were smoothed, the resulting point cloud can be evaluated on the network to assess whether the feature is important to the classifier. A technical contribution of the paper is an approximated curvature smoothing algorithm, which can smoothly transition from the original point cloud to one of constant curvature, such as a uniform sphere. Based on the smoothing algorithm, we propose PCI-GOS (Point Cloud Integrated-Gradients Optimized Saliency), a visualization technique that can automatically find the minimal saliency map that covers the most important features on a shape. Experiment results revealed insights into different point cloud classifiers.",
    "lastUpdated": "2020-09-01T04:11:49Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1911.10415v3"
  },
  {
    "title": "Smart Cloud: Scalable Cloud Robotic Architecture for Web-powered Multi-Robot Applications",
    "author": [
      "Manoj Penmetcha",
      "Shyam Sundar Kannan",
      "Byung-Cheol Min"
    ],
    "abstract": "Robots have inherently limited onboard processing, storage, and power capabilities. Cloud computing resources have the potential to provide significant advantages for robots in many applications. However, to make use of these resources, frameworks must be developed that facilitate robot interactions with cloud services. In this paper, we propose a cloud-based architecture called Smart Cloud that intends to overcome the physical limitations of single- or multi-robot systems through massively parallel computation, provided on demand by cloud services. Smart Cloud is implemented on Amazon Web Services (AWS) and available for robots running on the Robot Operating System (ROS) and on the non-ROS systems. Smart Cloud features a first-of-its-kind architecture that incorporates JavaScript-based libraries to run various robotic applications related to machine learning and other methods. This paper presents the architecture and its performance in terms of CPU usage and latency, and finally validates it for navigation and machine learning applications.",
    "lastUpdated": "2020-09-15T08:24:19Z",
    "category": [
      "cs.RO",
      "cs.DC",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1912.02927v3"
  },
  {
    "title": "Cloud-Net+: A Cloud Segmentation CNN for Landsat 8 Remote Sensing Imagery Optimized with Filtered Jaccard Loss Function",
    "author": [
      "Sorour Mohajerani",
      "Parvaneh Saeedi"
    ],
    "abstract": "Cloud Segmentation is one of the fundamental steps in optical remote sensing image analysis. Current methods for identification of cloud regions in aerial or satellite images are not accurate enough especially in the presence of snow and haze. This paper presents a deep learning-based framework to address the problem of cloud detection in Landsat 8 imagery. The proposed method benefits from a convolutional neural network (Cloud-Net+) with multiple blocks, which is trained with a novel loss function (Filtered Jaccard loss). The proposed loss function is more sensitive to the absence of cloud pixels in an image and penalizes/rewards the predicted mask more accurately. The combination of Cloud-Net+ and Filtered Jaccard loss function delivers superior results over four public cloud detection datasets. Our experiments on one of the most common public datasets in computer vision (Pascal VOC dataset) show that the proposed network/loss function could be used in other segmentation tasks for more accurate performance/evaluation.",
    "lastUpdated": "2020-01-23T19:13:00Z",
    "category": [
      "cs.CV",
      "cs.LG",
      "cs.NE",
      "eess.IV"
    ],
    "url": "http://arxiv.org/abs/2001.08768v1"
  },
  {
    "title": "Cloud-scale VM Deflation for Running Interactive Applications On Transient Servers",
    "author": [
      "Alexander Fuerst",
      "Ahmed Ali-Eldin",
      "Prashant Shenoy",
      "Prateek Sharma"
    ],
    "abstract": "Transient computing has become popular in public cloud environments for running delay-insensitive batch and data processing applications at low cost. Since transient cloud servers can be revoked at any time by the cloud provider, they are considered unsuitable for running interactive application such as web services. In this paper, we present VM deflation as an alternative mechanism to server preemption for reclaiming resources from transient cloud servers under resource pressure. Using real traces from top-tier cloud providers, we show the feasibility of using VM deflation as a resource reclamation mechanism for interactive applications in public clouds. We show how current hypervisor mechanisms can be used to implement VM deflation and present cluster deflation policies for resource management of transient and on-demand cloud VMs. Experimental evaluation of our deflation system on a Linux cluster shows that microservice-based applications can be deflated by up to 50\\% with negligible performance overhead. Our cluster-level deflation policies allow overcommitment levels as high as 50\\%, with less than a 1\\% decrease in application throughput, and can enable cloud platforms to increase revenue by 30\\%.",
    "lastUpdated": "2020-05-31T12:40:43Z",
    "category": [
      "cs.DC",
      "cs.PF"
    ],
    "url": "http://arxiv.org/abs/2006.00508v1"
  },
  {
    "title": "TearingNet: Point Cloud Autoencoder to Learn Topology-Friendly Representations",
    "author": [
      "Jiahao Pang",
      "Duanshun Li",
      "Dong Tian"
    ],
    "abstract": "Topology matters. Despite the recent success of point cloud processing with geometric deep learning, it remains arduous to capture the complex topologies of point cloud data with a learning model. Given a point cloud dataset containing objects with various genera, or scenes with multiple objects, we propose an autoencoder, TearingNet, which tackles the challenging task of representing the point clouds using a fixed-length descriptor. Unlike existing works directly deforming predefined primitives of genus zero (e.g., a 2D square patch) to an object-level point cloud, our TearingNet is characterized by a proposed Tearing network module and a Folding network module interacting with each other iteratively. Particularly, the Tearing network module learns the point cloud topology explicitly. By breaking the edges of a primitive graph, it tears the graph into patches or with holes to emulate the topology of a target point cloud, leading to faithful reconstructions. Experimentation shows the superiority of our proposal in terms of reconstructing point clouds as well as generating more topology-friendly representations than benchmarks.",
    "lastUpdated": "2020-11-23T21:24:30Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2006.10187v2"
  },
  {
    "title": "Progressive Point Cloud Deconvolution Generation Network",
    "author": [
      "Le Hui",
      "Rui Xu",
      "Jin Xie",
      "Jianjun Qian",
      "Jian Yang"
    ],
    "abstract": "In this paper, we propose an effective point cloud generation method, which can generate multi-resolution point clouds of the same shape from a latent vector. Specifically, we develop a novel progressive deconvolution network with the learning-based bilateral interpolation. The learning-based bilateral interpolation is performed in the spatial and feature spaces of point clouds so that local geometric structure information of point clouds can be exploited. Starting from the low-resolution point clouds, with the bilateral interpolation and max-pooling operations, the deconvolution network can progressively output high-resolution local and global feature maps. By concatenating different resolutions of local and global feature maps, we employ the multi-layer perceptron as the generation network to generate multi-resolution point clouds. In order to keep the shapes of different resolutions of point clouds consistent, we propose a shape-preserving adversarial loss to train the point cloud deconvolution generation network. Experimental results demonstrate the effectiveness of our proposed method.",
    "lastUpdated": "2020-07-10T13:07:00Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2007.05361v1"
  },
  {
    "title": "Pre-Training by Completing Point Clouds",
    "author": [
      "Hanchen Wang",
      "Qi Liu",
      "Xiangyu Yue",
      "Joan Lasenby",
      "Matthew J. Kusner"
    ],
    "abstract": "There has recently been a flurry of exciting advances in deep learning models on point clouds. However, these advances have been hampered by the difficulty of creating labelled point cloud datasets: sparse point clouds often have unclear label identities for certain points, while dense point clouds are time-consuming to annotate. Inspired by mask-based pre-training in the natural language processing community, we propose a novel pre-training mechanism for point clouds. It works by masking occluded points that result from observing the point cloud at different camera views. It then optimizes a completion model that learns how to reconstruct the occluded points, given the partial point cloud. In this way, our method learns a pre-trained representation that can identify the visual constraints inherently embedded in real-world point clouds. We call our method Occlusion Completion (OcCo). We demonstrate that OcCo learns representations that improve generalization on downstream tasks over prior pre-training methods, that transfer to different datasets, that reduce training time, and improve labelled sample efficiency. %, and (e) more effective than previous pre-training methods. Our code and dataset are available at https://github.com/hansen7/OcCo",
    "lastUpdated": "2020-10-02T16:43:14Z",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2010.01089v1"
  },
  {
    "title": "Proactive DDoS Attack Mitigation in Cloud-Fog Environment using Moving Target Defense",
    "author": [
      "Vaishali Kansal",
      "Mayank Dave"
    ],
    "abstract": "Distributed Denial of Service (DDoS) attacks are serious cyber attacks and mitigating DDoS attacks in cloud is a topic of ongoing research interest which remains a major security challenge. Fog computing is an extension of cloud computing which has been used to secure cloud. Moving Target Defense (MTD) is a newly recognized, proactive security defense that can be used to mitigate DDoS attacks on cloud. MTD intends to make a system dynamic in nature and uncertain by changing attack surface continuously to confuse attackers. In this paper, a novel DDoS mitigation framework is presented to support Cloud-Fog Platform using MTD technique (CFPM). CFPM applies migration MTD technique at fog layer to mitigate DDoS attacks in cloud. It detects attacker among all the legitimate clients proactively at the fog layer and isolate it from innocent clients. CFPM uses an effective request handling procedure for load balancing and attacker isolation procedure which aims to minimize disruption to cloud server as well as serving fog servers. In addition, effectiveness of CFPM is evaluated by analyzing the behavior of the system before and after attack, considering different possible scenarios. This approach is effective as it uses the advantage of both MTD technique and Fog computing paradigm supporting cloud environment.",
    "lastUpdated": "2020-12-03T14:37:12Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/2012.01964v1"
  },
  {
    "title": "Cyber Situation Awareness Monitoring and Proactive Response for Enterprises on the Cloud",
    "author": [
      "Hootan Alavizadeh",
      "Hooman Alavizadeh",
      "Julian Jang-Jaccard"
    ],
    "abstract": "The cloud model allows many enterprises able to outsource computing resources at an affordable price without having to commit the expense upfront. Although the cloud providers are responsible for the security of the cloud, there are still many security concerns due to inherently complex model the cloud providers operate on (e.g.,multi-tenancy). In addition, the enterprises whose services have migrated into the cloud have a preference for their own cybersecurity situation awareness capability on top of the security mechanisms provided by the cloud providers. In this way, the enterprises can monitor the performance of the security offerings of the cloud and have a choice to decide and select potential response strategies more appropriate to the enterprise in the presence of the attack where the defense provided by the cloud doesn't work for them. However, some response strategies, such as Moving Target Defense (MTD) techniques shown to be effective to secure cloud, cannot be deployed by the enterprise themselves. In this paper, we propose a framework that enables better collaboration between enterprises and cloud providers. Our proposed framework, which offers more in-depth security analysis based on the set of most advanced security metrics, allows the security experts of the enterprise to obtain better situational awareness in the cloud. With better and more effective situation awareness of cloud security, our framework can support better decision making and further allows to deploy more appropriate threat responses to protect the outsourced resources. We also propose a secure protocol which can facilitate more secure communication between the enterprises and cloud provider. Using our proposed secure protocol, which is based on authentication and key exchange mechanism, the enterprises can send a secure request to the cloud provider to perform a selected defensive strategy.",
    "lastUpdated": "2020-09-03T12:21:18Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/2009.01604v1"
  },
  {
    "title": "Internet ware cloud computing :Challenges",
    "author": [
      "S Qamar",
      "Niranjan Lal",
      "Mrityunjay Singh"
    ],
    "abstract": "After decades of engineering development and infrastructural investment, Internet connections have become commodity product in many countries, and Internet scale \"cloud computing\" has started to compete with traditional software business through its technological advantages and economy of scale. Cloud computing is a promising enabling technology of Internet ware Cloud Computing is termed as the next big thing in the modern corporate world. Apart from the present day software and technologies, cloud computing will have a growing impact on enterprise IT and business activities in many large organizations. This paper provides an insight to cloud computing, its impacts and discusses various issues that business organizations face while implementing cloud computing. Further, it recommends various strategies that organizations need to adopt while migrating to cloud computing. The purpose of this paper is to develop an understanding of cloud computing in the modern world and its impact on organizations and businesses. Initially the paper provides a brief description of the cloud computing model introduction and its purposes. Further it discusses various technical and non-technical issues that need to be overcome in order for the benefits of cloud computing to be realized in corporate businesses and organizations. It then provides various recommendations and strategies that businesses need to work on before stepping into new technologies.",
    "lastUpdated": "2010-04-10T22:17:18Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1004.1746v1"
  },
  {
    "title": "Toward Cloud Computing Evolution",
    "author": [
      "Heru Susanto",
      "Mohammad Nabil Almunawar",
      "Chen Chin Kang"
    ],
    "abstract": "-Information Technology (IT) shaped the success of organizations, giving them a solid foundation that increases both their level of efficiency as well as productivity. The computing industry is witnessing a paradigm shift in the way computing is performed worldwide. There is a growing awareness among consumers and enterprises to access their IT resources extensively through a \"utility\" model known as \"cloud computing.\" Cloud computing was initially rooted in distributed grid-based computing. It has become a significant technology trend and expect that cloud computing will reshape IT processes and the IT marketplace. With the cloud computing technology, clients use a variety of smart mobile devices to access programs, storage, and application-development platforms over the network and internet, through services offered by cloud computing providers.An innovative new way to boost capacity and add capabilities in computing without spending money on a new infrastructure, training new personnel or licensing software is one of the characteristics of a cloud computing. Demands for fastest access to information is changing and increasing, therefore, the availability of cloud computing has made it easier for organizations to share and store related data and information with their stakeholders.Moreover, cloud computing is the use of internet-based services to support business processes.Our research is to find out what the demand and main emphasized of cloud computing compared with efficiency, trendy and security that leads to improved business processes within corporate as cloud user.",
    "lastUpdated": "2012-09-27T05:13:45Z",
    "category": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1209.6125v1"
  },
  {
    "title": "CernVM Online and Cloud Gateway: a uniform interface for CernVM contextualization and deployment",
    "author": [
      "G. Lestaris",
      "I. Charalampidis",
      "D. Berzano",
      "J. Blomer",
      "P. Buncic",
      "G. Ganis",
      "R. Meusel"
    ],
    "abstract": "In a virtualized environment, contextualization is the process of configuring a VM instance for the needs of various deployment use cases. Contextualization in CernVM can be done by passing a handwritten context to the user data field of cloud APIs, when running CernVM on the cloud, or by using CernVM web interface when running the VM locally. CernVM Online is a publicly accessible web interface that unifies these two procedures. A user is able to define, store and share CernVM contexts using CernVM Online and then apply them either in a cloud by using CernVM Cloud Gateway or on a local VM with the single-step pairing mechanism. CernVM Cloud Gateway is a distributed system that provides a single interface to use multiple and different clouds (by location or type, private or public). Cloud gateway has been so far integrated with OpenNebula, CloudStack and EC2 tools interfaces. A user, with access to a number of clouds, can run CernVM cloud agents that will communicate with these clouds using their interfaces, and then use one single interface to deploy and scale CernVM clusters. CernVM clusters are defined in CernVM Online and consist of a set of CernVM instances that are contextualized and can communicate with each other.",
    "lastUpdated": "2014-04-07T15:11:38Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1404.1814v1"
  },
  {
    "title": "Cross-Layer Multi-Cloud Real-Time Application QoS Monitoring and Benchmarking As-a-Service Framework",
    "author": [
      "Khalid Alhamazani",
      "Rajiv Ranjan",
      "Prem Prakash Jayaraman",
      "Karan Mitra",
      "Chang Liu",
      "Fethi Rabhi",
      "Dimitrios Georgakopoulos",
      "Lizhe Wang"
    ],
    "abstract": "Cloud computing provides on-demand access to affordable hardware (multi-core CPUs, GPUs, disks, and networking equipment) and software (databases, application servers and data processing frameworks) platforms with features such as elasticity, pay-per-use, low upfront investment and low time to market. This has led to the proliferation of business critical applications that leverage various cloud platforms. Such applications hosted on single or multiple cloud provider platforms have diverse characteristics requiring extensive monitoring and benchmarking mechanisms to ensure run-time Quality of Service (QoS) (e.g., latency and throughput). This paper proposes, develops and validates CLAMBS:Cross-Layer Multi-Cloud Application Monitoring and Benchmarking as-a-Service for efficient QoS monitoring and benchmarking of cloud applications hosted on multi-clouds environments. The major highlight of CLAMBS is its capability of monitoring and benchmarking individual application components such as databases and web servers, distributed across cloud layers, spread among multiple cloud providers. We validate CLAMBS using prototype implementation and extensive experimentation and show that CLAMBS efficiently monitors and benchmarks application components on multi-cloud platforms including Amazon EC2 and Microsoft Azure.",
    "lastUpdated": "2015-04-29T05:28:14Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1502.00206v2"
  },
  {
    "title": "Self-Learning Cloud Controllers: Fuzzy Q-Learning for Knowledge Evolution",
    "author": [
      "Pooyan Jamshidi",
      "Amir Sharifloo",
      "Claus Pahl",
      "Andreas Metzger",
      "Giovani Estrada"
    ],
    "abstract": "Cloud controllers aim at responding to application demands by automatically scaling the compute resources at runtime to meet performance guarantees and minimize resource costs. Existing cloud controllers often resort to scaling strategies that are codified as a set of adaptation rules. However, for a cloud provider, applications running on top of the cloud infrastructure are more or less black-boxes, making it difficult at design time to define optimal or pre-emptive adaptation rules. Thus, the burden of taking adaptation decisions often is delegated to the cloud application. Yet, in most cases, application developers in turn have limited knowledge of the cloud infrastructure. In this paper, we propose learning adaptation rules during runtime. To this end, we introduce FQL4KE, a self-learning fuzzy cloud controller. In particular, FQL4KE learns and modifies fuzzy rules at runtime. The benefit is that for designing cloud controllers, we do not have to rely solely on precise design-time knowledge, which may be difficult to acquire. FQL4KE empowers users to specify cloud controllers by simply adjusting weights representing priorities in system goals instead of specifying complex adaptation rules. The applicability of FQL4KE has been experimentally assessed as part of the cloud application framework ElasticBench. The experimental results indicate that FQL4KE outperforms our previously developed fuzzy controller without learning mechanisms and the native Azure auto-scaling.",
    "lastUpdated": "2015-07-02T13:11:22Z",
    "category": [
      "cs.SY",
      "cs.AI",
      "cs.DC",
      "cs.LG",
      "cs.SE",
      "I.2.6; D.2.11"
    ],
    "url": "http://arxiv.org/abs/1507.00567v1"
  },
  {
    "title": "Flip the Cloud: Cyber-Physical Signaling Games in the Presence of Advanced Persistent Threats",
    "author": [
      "Jeffrey Pawlick",
      "Sadegh Farhang",
      "Quanyan Zhu"
    ],
    "abstract": "Access to the cloud has the potential to provide scalable and cost effective enhancements of physical devices through the use of advanced computational processes run on apparently limitless cyber infrastructure. On the other hand, cyber-physical systems and cloud-controlled devices are subject to numerous design challenges; among them is that of security. In particular, recent advances in adversary technology pose Advanced Persistent Threats (APTs) which may stealthily and completely compromise a cyber system. In this paper, we design a framework for the security of cloud-based systems that specifies when a device should trust commands from the cloud which may be compromised. This interaction can be considered as a game between three players: a cloud defender/administrator, an attacker, and a device. We use traditional signaling games to model the interaction between the cloud and the device, and we use the recently proposed FlipIt game to model the struggle between the defender and attacker for control of the cloud. Because attacks upon the cloud can occur without knowledge of the defender, we assume that strategies in both games are picked according to prior commitment. This framework requires a new equilibrium concept, which we call Gestalt Equilibrium, a fixed-point that expresses the interdependence of the signaling and FlipIt games. We present the solution to this fixed-point problem under certain parameter cases, and illustrate an example application of cloud control of an unmanned vehicle. Our results contribute to the growing understanding of cloud-controlled systems.",
    "lastUpdated": "2015-09-14T20:10:13Z",
    "category": [
      "cs.CR",
      "cs.GT"
    ],
    "url": "http://arxiv.org/abs/1507.00576v2"
  },
  {
    "title": "A Review of Technical Problems when Conducting an Investigation in Cloud Based Environments",
    "author": [
      "Manuel Jesús Rivas Sández"
    ],
    "abstract": "Cloud computing is a relatively new technology which is quickly becoming one of the most important technological advances for computer science. This technology has had a significant growth in recent years. It is now more affordable and cloud platforms are becoming more stable. Businesses are successfully migrating their systems to a cloud infrastructure, obtaining technological and economic benefits. However, others still remain reluctant to do it due to both security concerns and the loss of control over their infrastructures and data that the migration entails. At the same time that new technologies progress, its benefits appeal to criminals too. They can not only steal data from clouds, but they can also hide data in clouds, which has provoked an increased in the number of cybercrimes and their economic impacts. Their victims range from children and adults to companies and even countries. On the other hand, digital forensics have negatively suffered the impact of the boom of cloud computing due to its dynamic nature. The tools and procedures that were successfully proved and used in digital investigations are now becoming irrelevant, making it an urging necessity to develop new forensics capabilities for conducting an investigation in this new environment. As a consequence of these needs a new area has emerged, Cloud Forensics, which is the result of the intersection between cloud computing and digital forensics. Keywords: Cloud forensics, cloud computing, forensics investigation, forensic challenges.",
    "lastUpdated": "2015-08-05T12:34:24Z",
    "category": [
      "cs.CR",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1508.01053v1"
  },
  {
    "title": "Declarative Modeling for Building a Cloud Federation and Cloud Applications",
    "author": [
      "Giuseppe Attardi",
      "Alex Barchiesi",
      "Alberto Colla",
      "Fulvio Galeazzi",
      "Giovanni Marzulli",
      "Mario Reale"
    ],
    "abstract": "The paper illustrates how we built a federated cloud computing platform dedicated to the Italian research community. Building a cloud platform is a daunting task, that requires coordinating the deployment of many services, interrelated and dependent on each other. Provisioning, servicing and maintaining the platform must be automated. For our deployment, we chose a declarative modeling tool, that allows describing the parts that compose the system and their relations of supplier/consumer of specific interfaces. The tool arranges the steps to bring the deployment to convergence by transforming the state of the system until it reaches a configuration that satisfies all constraints. We chose a declarative service modeling approach for orchestrating both the deployment of the platform by the administrators and the deployment of applications by users. The cloud platform has been designed so that it can be managed by this kind of automation, facilitating the deployment of federated regions by anyone wishing to join and to contribute resources to the federation. Federated resources are integrated into a single cloud platform available to any user of the federation. The federation can also seamlessly include public clouds. We describe the architectural choices, how we adapted the OpenStack basic facilities to the needs of a federation of multiple independent organizations, how we control resource allocation according to committed plans and correspondingly how we handle accounting and billing of resource usage. Besides providing traditional IaaS services, the cloud supports self-service deployment of cloud applications. The cloud thus addresses the long tail of science, allowing researchers of any discipline, without expertise in system or cloud administration, to deploy applications readily available for their perusal.",
    "lastUpdated": "2017-06-16T13:36:04Z",
    "category": [
      "cs.DC",
      "C.2.4"
    ],
    "url": "http://arxiv.org/abs/1706.05272v1"
  },
  {
    "title": "Spot Pricing in the Cloud Ecosystem: A Comparative Investigation",
    "author": [
      "Zheng Li",
      "He Zhang",
      "Liam O'Brien",
      "Shu Jiang",
      "You Zhou",
      "Maria Kihl",
      "Rajiv Ranjan"
    ],
    "abstract": "Background: Spot pricing is considered as a significant supplement for building a full-fledged market economy for the Cloud ecosystem. However, it seems that both providers and consumers are still hesitating to enter the Cloud spot market. The relevant academic community also has conflicting opinions about Cloud spot pricing in terms of revenue generation. Aim: This work aims to systematically identify, assess, synthesize and report the published evidence in favor of or against spot-price scheme compared with fixed-price scheme of Cloud computing, so as to help relieve the aforementioned conflict. Method: We employed the systematic literature review (SLR) method to collect and investigate the empirical studies of Cloud spot pricing indexed by major electronic libraries. Results: This SLR identified 61 primary studies that either delivered discussions or conducted experiments to perform comparison between spot pricing and fixed pricing in the Cloud domain. The reported benefits and limitations were summarized to facilitate cost-benefit analysis of being a Cloud spot pricing player, while four types of theories were distinguished to help both researchers and practitioners better understand the Cloud spot market. Conclusions: This SLR shows that the academic community strongly advocates the emerging Cloud spot market. Although there is still a lack of practical and easily deployable market-driven mechanisms, the overall findings of our work indicate that spot pricing plays a promising role in the sustainability of Cloud resource exploitation.",
    "lastUpdated": "2017-08-04T07:23:05Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1708.01401v1"
  },
  {
    "title": "On Evaluating Commercial Cloud Services: A Systematic Review",
    "author": [
      "Zheng Li",
      "He Zhang",
      "Liam O'Brien",
      "Rainbow Cai",
      "Shayne Flint"
    ],
    "abstract": "Background: Cloud Computing is increasingly booming in industry with many competing providers and services. Accordingly, evaluation of commercial Cloud services is necessary. However, the existing evaluation studies are relatively chaotic. There exists tremendous confusion and gap between practices and theory about Cloud services evaluation. Aim: To facilitate relieving the aforementioned chaos, this work aims to synthesize the existing evaluation implementations to outline the state-of-the-practice and also identify research opportunities in Cloud services evaluation. Method: Based on a conceptual evaluation model comprising six steps, the Systematic Literature Review (SLR) method was employed to collect relevant evidence to investigate the Cloud services evaluation step by step. Results: This SLR identified 82 relevant evaluation studies. The overall data collected from these studies essentially represent the current practical landscape of implementing Cloud services evaluation, and in turn can be reused to facilitate future evaluation work. Conclusions: Evaluation of commercial Cloud services has become a world-wide research topic. Some of the findings of this SLR identify several research gaps in the area of Cloud services evaluation (e.g., the Elasticity and Security evaluation of commercial Cloud services could be a long-term challenge), while some other findings suggest the trend of applying commercial Cloud services (e.g., compared with PaaS, IaaS seems more suitable for customers and is particularly important in industry). This SLR study itself also confirms some previous experiences and reveals new Evidence-Based Software Engineering (EBSE) lessons.",
    "lastUpdated": "2017-08-04T08:12:59Z",
    "category": [
      "cs.DC",
      "cs.PF"
    ],
    "url": "http://arxiv.org/abs/1708.01412v1"
  },
  {
    "title": "Cloud Infrastructure Provenance Collection and Management to Reproduce Scientific Workflow Execution",
    "author": [
      "Khawar Hasham",
      "Kamran Munir",
      "Richard McClatchey"
    ],
    "abstract": "The emergence of Cloud computing provides a new computing paradigm for scientific workflow execution. It provides dynamic, on-demand and scalable resources that enable the processing of complex workflow-based experiments. With the ever growing size of the experimental data and increasingly complex processing workflows, the need for reproducibility has also become essential. Provenance has been thought of a mechanism to verify a workflow and to provide workflow reproducibility. One of the obstacles in reproducing an experiment execution is the lack of information about the execution infrastructure in the collected provenance. This information becomes critical in the context of Cloud in which resources are provisioned on-demand and by specifying resource configurations. Therefore, a mechanism is required that enables capturing of infrastructure information along with the provenance of workflows executing on the Cloud to facilitate the re-creation of execution environment on the Cloud. This paper presents a framework, ReCAP, along with the proposed mapping approaches that aid in capturing the Cloud-aware provenance information and help in re-provisioning the execution resource on the Cloud with similar configurations. Experimental evaluation has shown the impact of different resource configurations on the workflow execution performance, therefore justifies the need for collecting such provenance information in the context of Cloud. The evaluation has also demonstrated that the proposed mapping approaches can capture Cloud information in various Cloud usage scenarios without causing performance overhead and can also enable the re-provisioning of resources on Cloud. Experiments were conducted using workflows from different scientific domains such as astronomy and neuroscience to demonstrate the applicability of this research for different workflows.",
    "lastUpdated": "2018-03-19T10:52:43Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1803.06867v1"
  },
  {
    "title": "Recovering Residual Forensic Data from Smartphone Interactions with Cloud Storage Providers",
    "author": [
      "George Grispos",
      "William Bradley Glisson",
      "Tim Storer"
    ],
    "abstract": "There is a growing demand for cloud storage services such as Dropbox, Box, Syncplicity and SugarSync. These public cloud storage services can store gigabytes of corporate and personal data in remote data centres around the world, which can then be synchronized to multiple devices. This creates an environment which is potentially conducive to security incidents, data breaches and other malicious activities. The forensic investigation of public cloud environments presents a number of new challenges for the digital forensics community. However, it is anticipated that end-devices such as smartphones, will retain data from these cloud storage services. This research investigates how forensic tools that are currently available to practitioners can be used to provide a practical solution for the problems related to investigating cloud storage environments. The research contribution is threefold. First, the findings from this research support the idea that end-devices which have been used to access cloud storage services can be used to provide a partial view of the evidence stored in the cloud service. Second, the research provides a comparison of the number of files which can be recovered from different versions of cloud storage applications. In doing so, it also supports the idea that amalgamating the files recovered from more than one device can result in the recovery of a more complete dataset. Third, the chapter contributes to the documentation and evidentiary discussion of the artefacts created from specific cloud storage applications and different versions of these applications on iOS and Android smartphones.",
    "lastUpdated": "2015-06-07T14:07:12Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1506.02268v1"
  },
  {
    "title": "RenderSelect: a Cloud Broker Framework for Cloud Renderfarm Services",
    "author": [
      "Annette J Ruby",
      "Banu W Aisha",
      "Chandran P Subash"
    ],
    "abstract": "In the 3D studios the animation scene files undergo a process called as rendering, where the 3D wire frame models are converted into 3D photorealistic images. As the rendering process is both a computationally intensive and a time consuming task, the cloud services based rendering in cloud render farms is gaining popularity among the animators. Though cloud render farms offer many benefits, the animators hesitate to move from their traditional offline rendering to cloud services based render farms as they lack the knowledge, expertise and the time to compare the render farm service providers based on the Quality of Service (QoS) offered by them, negotiate the QoS and monitor whether the agreed upon QoS is actually offered by the renderfarm service providers. In this paper we propose a Cloud Service Broker (CSB) framework called the RenderSelect that helps in the dynamic ranking, selection, negotiation and monitoring of the cloud based render farm services. The cloud services based renderfarms are ranked and selected services based on multi criteria QoS requirements. Analytical Hierarchical Process (AHP), the popular Multi Criteria Decision Making (MCDM) method is used for ranking and selecting the cloud services based renderfarms. The AHP method of ranking is illustrated in detail with an example. It could be verified that AHP method ranks the cloud services effectively with less time and complexity.",
    "lastUpdated": "2016-11-29T04:34:10Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1611.10210v1"
  },
  {
    "title": "Variational Graph Methods for Efficient Point Cloud Sparsification",
    "author": [
      "Daniel Tenbrinck",
      "Fjedor Gaede",
      "Martin Burger"
    ],
    "abstract": "In recent years new application areas have emerged in which one aims to capture the geometry of objects by means of three-dimensional point clouds. Often the obtained data consist of a dense sampling of the object's surface, containing many redundant 3D points. These unnecessary data samples lead to high computational effort in subsequent processing steps. Thus, point cloud sparsification or compression is often applied as a preprocessing step. The two standard methods to compress dense 3D point clouds are random subsampling and approximation schemes based on hierarchical tree structures, e.g., octree representations. However, both approaches give little flexibility for adjusting point cloud compression based on a-priori knowledge on the geometry of the scanned object. Furthermore, these methods lead to suboptimal approximations if the 3D point cloud data is prone to noise. In this paper we propose a variational method defined on finite weighted graphs, which allows to sparsify a given 3D point cloud while giving the flexibility to control the appearance of the resulting approximation based on the chosen regularization functional. The main contribution in this paper is a novel coarse-to-fine optimization scheme for point cloud sparsification, inspired by the efficiency of the recently proposed Cut Pursuit algorithm for total variation denoising. This strategy gives a substantial speed up in computing sparse point clouds compared to a direct application on all points as done in previous works and renders variational methods now applicable for this task. We compare different settings for our point cloud sparsification method both on unperturbed as well as noisy 3D point cloud data.",
    "lastUpdated": "2019-09-30T10:01:43Z",
    "category": [
      "math.NA",
      "cs.DM",
      "cs.DS",
      "cs.NA",
      "math.OC"
    ],
    "url": "http://arxiv.org/abs/1903.02858v3"
  },
  {
    "title": "PointNLM: Point Nonlocal-Means for vegetation segmentation based on middle echo point clouds",
    "author": [
      "Jonathan Li",
      "Rongren Wu",
      "Yiping Chen",
      "Qing Zhu",
      "Zhipeng Luo",
      "Cheng Wang"
    ],
    "abstract": "Middle-echo, which covers one or a few corresponding points, is a specific type of 3D point cloud acquired by a multi-echo laser scanner. In this paper, we propose a novel approach for automatic segmentation of trees that leverages middle-echo information from LiDAR point clouds. First, using a convolution classification method, the proposed type of point clouds reflected by the middle echoes are identified from all point clouds. The middle-echo point clouds are distinguished from the first and last echoes. Hence, the crown positions of the trees are quickly detected from the huge number of point clouds. Second, to accurately extract trees from all point clouds, we propose a 3D deep learning network, PointNLM, to semantically segment tree crowns. PointNLM captures the long-range relationship between the point clouds via a non-local branch and extracts high-level features via max-pooling applied to unordered points. The whole framework is evaluated using the Semantic 3D reduced-test set. The IoU of tree point cloud segmentation reached 0.864. In addition, the semantic segmentation network was tested using the Paris-Lille-3D dataset. The average IoU outperformed several other popular methods. The experimental results indicate that the proposed algorithm provides an excellent solution for vegetation segmentation from LiDAR point clouds.",
    "lastUpdated": "2019-09-19T04:50:13Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1906.08476v2"
  },
  {
    "title": "Quality of Service (QoS) Modelling in Federated Cloud Computing",
    "author": [
      "Kun Ma",
      "Antoine Bagula",
      "Olasupo Ajayi"
    ],
    "abstract": "Building around the idea of a large scale server infrastructure with a potentially large number of tailored resources, which are capable of interacting to facilitate the deployment, adaptation, and support of services, cloud computing needs to frequently reschedule and manage various application tasks in order to accommodate the requests of a wide range and number of users. One of the challenges of cloud computing is to support and manage Quality-of-Service (QoS) by designing efficient techniques for the allocation of tasks between users and the cloud virtual resources, as well as assigning virtual resources to the cloud physical resources. The migration of virtual resources across physical resources is another challenge that requires considerable attention; especially in federated cloud computing environments wherein, providers might be willing to offer their unused resources as a service to the federation (cooperative allocation) and pull back these resources for their own use when they are needed (competitive allocation). This paper revisits the issue of QoS in cloud computing by formulating and presenting i) a multi-QoS task allocation model for the assignment of tasks to virtual machines and ii) a virtual machine migration model for a federated cloud computing environment by considering cases where resource providers are operating in cooperative or competitive mode. A new differential evolution (DE) based binding policy for task allocation and a novel virtual machine model are proposed as solutions for the problem of QoS support in federated cloud environments. The experimental results show that the proposed solutions improved the quality of service in the cloud computing environment and reveal the relative advantages of operating a mixed cooperation and competition model in a federated cloud environment.",
    "lastUpdated": "2019-11-08T05:07:14Z",
    "category": [
      "cs.DC",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1911.03051v1"
  },
  {
    "title": "Self Organization Agent Oriented Dynamic Resource Allocation on Open Federated Clouds Environment",
    "author": [
      "Kemchi Sofiane",
      "Abdelhafid Zitouni",
      "Mahieddine Djoudi"
    ],
    "abstract": "To ensure uninterrupted services to the cloud clients from federated cloud providers, it is important to guarantee an efficient allocation of the cloud resources to users to improve the rate of client satisfaction and the quality of the service provisions. It is better to get as more computing and storage resources as possible. In cloud domain several Multi Agent Resource Allocation methods have been proposed to implement the problem of dynamic resource allocation. However the problem is still open and many works to do in this field. In cloud computing robustness is important so in this paper we focus on auto-adaptive method to deal with changes of open federated cloud computing environment. Our approach is hybrid, we first adopt an existing organizations optimization approach for self organization in broker agent organization to combine it with already existing Multi Agent Resource Allocation approach on Federated Clouds. We consider an open clouds federation environment which is dynamic and in constant evolution, new cloud operators can join the federation or leave this one. At the same time our approach is multi criterion which can take in account various parameters (i.e. computing load balance of mediator agent, geographical distance (network delay) between costumer and provider...).",
    "lastUpdated": "2020-01-21T13:05:46Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/2001.07496v1"
  },
  {
    "title": "A Framework for Cloud Security Risk Management Based on the Business Objectives of Organizations",
    "author": [
      "Ahmed E. Youssef"
    ],
    "abstract": "Security is considered one of the top ranked risks of Cloud Computing (CC) due to the outsourcing of sensitive data onto a third party. In addition, the complexity of the cloud model results in a large number of heterogeneous security controls that must be consistently managed. Hence, no matter how strongly the cloud model is secured, organizations continue suffering from lack of trust on CC and remain uncertain about its security risk consequences. Traditional risk management frameworks do not consider the impact of CC security risks on the business objectives of the organizations. In this paper, we propose a novel Cloud Security Risk Management Framework (CSRMF) that helps organizations adopting CC identify, analyze, evaluate, and mitigate security risks in their Cloud platforms. Unlike traditional risk management frameworks, CSRMF is driven by the business objectives of the organizations. It allows any organization adopting CC to be aware of cloud security risks and align their low-level management decisions according to high-level business objectives. In essence, it is designed to address impacts of cloud-specific security risks into business objectives in a given organization. Consequently, organizations are able to conduct a cost-value analysis regarding the adoption of CC technology and gain an adequate level of confidence in Cloud technology. On the other hand, Cloud Service Providers (CSP) are able to improve productivity and profitability by managing cloud-related risks. The proposed framework has been validated and evaluated through a use-case scenario.",
    "lastUpdated": "2020-01-13T18:46:38Z",
    "category": [
      "cs.CR",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/2001.08993v1"
  },
  {
    "title": "A Cloud Security Framework Based on Trust Model and Mobile Agent",
    "author": [
      "Saddek Benabied",
      "Abdelhafid Zitouni",
      "Mahieddine Djoudi"
    ],
    "abstract": "Cloud computing as a potential paradigm offers tremendous advantages to enterprises. With the cloud computing, the market's entrance time is reduced, computing capabilities is augmented and computing power is really limitless. Usually, to use the full power of cloud computing, cloud users has to rely on external cloud service provider for managing their data. Nevertheless, the management of data and services are probably not fully trustworthy. Hence, data owners are uncomfortable to place their sensitive data outside their own system .i.e., in the cloud. Bringing transparency, trustworthiness and security in the cloud model, in order to fulfill client's requirements are still ongoing. To achieve this goal, our paper introduces two levels security framework: Cloud Service Provider (CSP) and Cloud Service User (CSU). Each level is responsible for a particular task of the security. The CSU level includes a proxy agent and a trust agent, dealing with the first verification. Then a second verification is performed at the CSP level. The framework incorporates a trust model to monitor users' behaviors. The use of mobile agents will exploit their intrinsic features such as mobility, deliberate localization and secure communication channel provision. This model aims to protect user's sensitive information from other internal or external users and hackers. Moreover, it can detect policy breaches, where the users are notified in order to take necessary actions when malicious access or malicious activity would occur.",
    "lastUpdated": "2020-01-22T14:26:24Z",
    "category": [
      "cs.CR",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/2001.09090v1"
  },
  {
    "title": "Attaining High Bandwidth In Cloud Computing Through SDN-enabled Multi-tree Multicast",
    "author": [
      "Sayantan Guha",
      "Adel Alshamrani"
    ],
    "abstract": "Achieving high bandwidth utilization in cloud computing is essential for better network performance. However, it is difficult to attain high bandwidth utilization in cloud computing due to the complex and distributed natures of cloud computing resources. Recently, a growing demand for multicast transmission is perceived in cloud computing, due to the explosive growth of multi-point communication applications, such as video conferencing, online gaming, etc. Nonetheless, the inherent complexity in multicast routing in cloud computing, existing multicast plans failed to produce effective and efficient protocol schemes, which limits the application of multicast communication on the Internet. In this paper, a technique is proposed in how the newly developed network architecture, Software Defined Network (SDN), can promote the design of the multicast protocol and improve the performance of the multicast transmission in the cloud computing. The approach is to use the SDN-cloud Computing-enabled multicast communication scheme with ultra-high bandwidth utilization. The bandwidth utilization is enhanced by measuring various routing trees for each multicast transmission session and distributing the traffic load over all available routes in the cloud computing resources. The SDN is utilized to tackle with various design hurdles in the cloud computing, including both the current ones with the conventional multicast pattern and the newly emerged ones with multi-tree multicast. The prototype implementation and experiments demonstrate the performance enhancement of the proposed approach in the cloud computing in compared to conventional single-tree multicast designs.",
    "lastUpdated": "2020-08-06T08:45:26Z",
    "category": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/2008.02522v1"
  },
  {
    "title": "Representing Point Clouds with Generative Conditional Invertible Flow Networks",
    "author": [
      "Michał Stypułkowski",
      "Kacper Kania",
      "Maciej Zamorski",
      "Maciej Zięba",
      "Tomasz Trzciński",
      "Jan Chorowski"
    ],
    "abstract": "In this paper, we propose a simple yet effective method to represent point clouds as sets of samples drawn from a cloud-specific probability distribution. This interpretation matches intrinsic characteristics of point clouds: the number of points and their ordering within a cloud is not important as all points are drawn from the proximity of the object boundary. We postulate to represent each cloud as a parameterized probability distribution defined by a generative neural network. Once trained, such a model provides a natural framework for point cloud manipulation operations, such as aligning a new cloud into a default spatial orientation. To exploit similarities between same-class objects and to improve model performance, we turn to weight sharing: networks that model densities of points belonging to objects in the same family share all parameters with the exception of a small, object-specific embedding vector. We show that these embedding vectors capture semantic relationships between objects. Our method leverages generative invertible flow networks to learn embeddings as well as to generate point clouds. Thanks to this formulation and contrary to similar approaches, we are able to train our model in an end-to-end fashion. As a result, our model offers competitive or superior quantitative results on benchmark datasets, while enabling unprecedented capabilities to perform cloud manipulation tasks, such as point cloud registration and regeneration, by a generative network.",
    "lastUpdated": "2020-10-07T18:30:47Z",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2010.11087v1"
  },
  {
    "title": "Improved hierarchical role based access control model for cloud computing",
    "author": [
      "N. N. Thilakarathne",
      "Dilani Wickramaaarachchi"
    ],
    "abstract": "Cloud computing is considered as the one of the most dominant paradigm in field of information technology which offers on demand cost effective services such as Software as a service (SAAS), Infrastructure as a service (IAAS) and Platform as a service (PAAS).Promising all these services as it is, this cloud computing paradigm still associates number of challenges such as data security, abuse of cloud services, malicious insider and cyber-attacks. Among all these security requirements of cloud computing access control is the one of the fundamental requirement in order to avoid unauthorized access to a system and organizational assets. Main purpose of this research is to review the existing methods of cloud access control models and their variants pros and cons and to identify further related research directions for developing an improved access control model for public cloud data storage. We have presented detailed access control requirement analysis for cloud computing and have identified important gaps, which are not fulfilled by conventional access control models. As the outcome of the study we have come up with an improved access control model with hybrid cryptographic schema and hybrid cloud architecture and practical implementation of it. We have tested our model for security implications, performance, functionality and data integrity to prove the validity. We have used AES and RSA cryptographic algorithms to implement the cryptographic schema and used public and private cloud to enforce our access control security and reliability.By validating and testing we have proved that our model can withstand against most of the cyber attacks in real cloud environment. Hence it has improved capabilities compared with other previous access control models that we have reviewed through literature.",
    "lastUpdated": "2020-11-16T07:49:32Z",
    "category": [
      "cs.CR",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/2011.07764v1"
  },
  {
    "title": "PointINet: Point Cloud Frame Interpolation Network",
    "author": [
      "Fan Lu",
      "Guang Chen",
      "Sanqing Qu",
      "Zhijun Li",
      "Yinlong Liu",
      "Alois Knoll"
    ],
    "abstract": "LiDAR point cloud streams are usually sparse in time dimension, which is limited by hardware performance. Generally, the frame rates of mechanical LiDAR sensors are 10 to 20 Hz, which is much lower than other commonly used sensors like cameras. To overcome the temporal limitations of LiDAR sensors, a novel task named Point Cloud Frame Interpolation is studied in this paper. Given two consecutive point cloud frames, Point Cloud Frame Interpolation aims to generate intermediate frame(s) between them. To achieve that, we propose a novel framework, namely Point Cloud Frame Interpolation Network (PointINet). Based on the proposed method, the low frame rate point cloud streams can be upsampled to higher frame rates. We start by estimating bi-directional 3D scene flow between the two point clouds and then warp them to the given time step based on the 3D scene flow. To fuse the two warped frames and generate intermediate point cloud(s), we propose a novel learning-based points fusion module, which simultaneously takes two warped point clouds into consideration. We design both quantitative and qualitative experiments to evaluate the performance of the point cloud frame interpolation method and extensive experiments on two large scale outdoor LiDAR datasets demonstrate the effectiveness of the proposed PointINet. Our code is available at https://github.com/ispc-lab/PointINet.git.",
    "lastUpdated": "2020-12-18T06:15:01Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2012.10066v1"
  },
  {
    "title": "Data Mining Using High Performance Data Clouds: Experimental Studies Using Sector and Sphere",
    "author": [
      "Robert L Grossman",
      "Yunhong Gu"
    ],
    "abstract": "We describe the design and implementation of a high performance cloud that we have used to archive, analyze and mine large distributed data sets. By a cloud, we mean an infrastructure that provides resources and/or services over the Internet. A storage cloud provides storage services, while a compute cloud provides compute services. We describe the design of the Sector storage cloud and how it provides the storage services required by the Sphere compute cloud. We also describe the programming paradigm supported by the Sphere compute cloud. Sector and Sphere are designed for analyzing large data sets using computer clusters connected with wide area high performance networks (for example, 10+ Gb/s). We describe a distributed data mining application that we have developed using Sector and Sphere. Finally, we describe some experimental studies comparing Sector/Sphere to Hadoop.",
    "lastUpdated": "2008-08-22T01:24:06Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/0808.3019v1"
  },
  {
    "title": "Community Cloud Computing",
    "author": [
      "Alexandros Marinos",
      "Gerard Briscoe"
    ],
    "abstract": "Cloud Computing is rising fast, with its data centres growing at an unprecedented rate. However, this has come with concerns over privacy, efficiency at the expense of resilience, and environmental sustainability, because of the dependence on Cloud vendors such as Google, Amazon and Microsoft. Our response is an alternative model for the Cloud conceptualisation, providing a paradigm for Clouds in the community, utilising networked personal computers for liberation from the centralised vendor model. Community Cloud Computing (C3) offers an alternative architecture, created by combing the Cloud with paradigms from Grid Computing, principles from Digital Ecosystems, and sustainability from Green Computing, while remaining true to the original vision of the Internet. It is more technically challenging than Cloud Computing, having to deal with distributed computing issues, including heterogeneous nodes, varying quality of service, and additional security constraints. However, these are not insurmountable challenges, and with the need to retain control over our digital lives and the potential environmental consequences, it is a challenge we must pursue.",
    "lastUpdated": "2009-10-12T07:15:07Z",
    "category": [
      "cs.NI",
      "cs.DC",
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/0907.2485v3"
  },
  {
    "title": "The Cloud Adoption Toolkit: Addressing the Challenges of Cloud Adoption in Enterprise",
    "author": [
      "Ali Khajeh-Hosseini",
      "David Greenwood",
      "James W. Smith",
      "Ian Sommerville"
    ],
    "abstract": "Cloud computing promises a radical shift in the provisioning of computing resource within the enterprise. This paper: i) describes the challenges that decision makers face when attempting to determine the feasibility of the adoption of cloud computing in their organisations; ii) illustrates a lack of existing work to address the feasibility challenges of cloud adoption in the enterprise; iii) introduces the Cloud Adoption Toolkit that provides a framework to support decision makers in identifying their concerns, and matching these concerns to appropriate tools/techniques that can be used to address them. The paper adopts a position paper methodology such that case study evidence is provided, where available, to support claims. We conclude that the Cloud Adoption Toolkit, whilst still under development, shows signs that it is a useful tool for decision makers as it helps address the feasibility challenges of cloud adoption in the enterprise.",
    "lastUpdated": "2010-05-13T14:54:25Z",
    "category": [
      "cs.DC",
      "C.2.4"
    ],
    "url": "http://arxiv.org/abs/1003.3866v2"
  },
  {
    "title": "Handling Confidential Data on the Untrusted Cloud: An Agent-based Approach",
    "author": [
      "Ernesto Damiani",
      "Francesco Pagano"
    ],
    "abstract": "Cloud computing allows shared computer and storage facilities to be used by a multitude of clients. While cloud management is centralized, the information resides in the cloud and information sharing can be implemented via off-the-shelf techniques for multiuser databases. Users, however, are very diffident for not having full control over their sensitive data. Untrusted database-as-a-server techniques are neither readily extendable to the cloud environment nor easily understandable by non-technical users. To solve this problem, we present an approach where agents share reserved data in a secure manner by the use of simple grant-and-revoke permissions on shared data.",
    "lastUpdated": "2010-12-03T15:07:36Z",
    "category": [
      "cs.CR",
      "cs.DC",
      "cs.MA",
      "D.4.6; C.2.4; E.3"
    ],
    "url": "http://arxiv.org/abs/1012.0759v1"
  },
  {
    "title": "Secure Data Processing in a Hybrid Cloud",
    "author": [
      "Vaibhav Khadilkar",
      "Murat Kantarcioglu",
      "Bhavani Thuraisingham",
      "Sharad Mehrotra"
    ],
    "abstract": "Cloud computing has made it possible for a user to be able to select a computing service precisely when needed. However, certain factors such as security of data and regulatory issues will impact a user's choice of using such a service. A solution to these problems is the use of a hybrid cloud that combines a user's local computing capabilities (for mission- or organization-critical tasks) with a public cloud (for less influential tasks). We foresee three challenges that must be overcome before the adoption of a hybrid cloud approach: 1) data design: How to partition relations in a hybrid cloud? The solution to this problem must account for the sensitivity of attributes in a relation as well as the workload of a user; 2) data security: How to protect a user's data in a public cloud with encryption while enabling query processing over this encrypted data? and 3) query processing: How to execute queries efficiently over both, encrypted and unencrypted data? This paper addresses these challenges and incorporates their solutions into an add-on tool for a Hadoop and Hive based cloud computing infrastructure.",
    "lastUpdated": "2011-05-10T15:49:38Z",
    "category": [
      "cs.DC",
      "D.4.6; H.3.3; H.3.4"
    ],
    "url": "http://arxiv.org/abs/1105.1982v1"
  },
  {
    "title": "Data Integrity and Dynamic Storage Way in Cloud Computing",
    "author": [
      "C. Dinesh"
    ],
    "abstract": "It is not an easy task to securely maintain all essential data where it has the need in many applications for clients in cloud. To maintain our data in cloud, it may not be fully trustworthy because client doesn't have copy of all stored data. But any authors don't tell us data integrity through its user and CSP level by comparison before and after the data update in cloud. So we have to establish new proposed system for this using our data reading protocol algorithm to check the integrity of data before and after the data insertion in cloud. Here the security of data before and after is checked by client with the help of CSP using our \"effective automatic data reading protocol from user as well as cloud level into the cloud\" with truthfulness. Also we have proposed the multi-server data comparison algorithm with the calculation of overall data in each update before its outsourced level for server restore access point for future data recovery from cloud data server. Our proposed scheme efficiently checks integrity in efficient manner so that data integrity as well as security can be maintained in all cases by considering drawbacks of existing methods.",
    "lastUpdated": "2011-11-10T08:23:47Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1111.2418v1"
  },
  {
    "title": "Management of Data Replication for PC Cluster-based Cloud Storage System",
    "author": [
      "Julia Myint",
      "Thinn Thu Naing"
    ],
    "abstract": "Storage systems are essential building blocks for cloud computing infrastructures. Although high performance storage servers are the ultimate solution for cloud storage, the implementation of inexpensive storage system remains an open issue. To address this problem, the efficient cloud storage system is implemented with inexpensive and commodity computer nodes that are organized into PC cluster based datacenter. Hadoop Distributed File System (HDFS) is an open source cloud based storage platform and designed to be deployed in low-cost hardware. PC Cluster based Cloud Storage System is implemented with HDFS by enhancing replication management scheme. Data objects are distributed and replicated in a cluster of commodity nodes located in the cloud. This system provides optimum replica number as well as weighting and balancing among the storage server nodes. The experimental results show that storage can be balanced depending on the available disk space, expected availability and failure probability of each node in PC cluster.",
    "lastUpdated": "2011-12-27T03:58:36Z",
    "category": [
      "cs.DC",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1112.5917v1"
  },
  {
    "title": "The cloud paradigm: Are you tuned for the lyrics?",
    "author": [
      "Fernando Brito e Abreu"
    ],
    "abstract": "Major players, business angels and opinion-makers are broadcasting beguiled lyrics on the most recent IT hype: your software should ascend to the clouds. There are many clouds and the stake is high. Distractedly, many of us became assiduous users of the cloud, but perhaps due to the legacy systems and legacy knowledge, IT professionals, mainly those many that work in business information systems for the long tail, are not as much plunged into producing cloud-based systems for their clients. This keynote will delve into several aspects of this cloud paradigm, from more generic concerns regarding security and value for money, to more specific worries that reach software engineers in general. Do we need a different software development process? Are development techniques and tools mature enough? What about the role of open-source in the cloud? How do we assess the quality in cloud-based development? Please stay tuned for more!",
    "lastUpdated": "2012-02-12T09:50:28Z",
    "category": [
      "cs.DC",
      "cs.SE",
      "A.1"
    ],
    "url": "http://arxiv.org/abs/1203.0964v1"
  },
  {
    "title": "High performance computing network for cloud environment using simulators",
    "author": [
      "N. Ajith Singh",
      "M. Hemalatha"
    ],
    "abstract": "Cloud computing is the next generation computing. Adopting the cloud computing is like signing up new form of a website. The GUI which controls the cloud computing make is directly control the hardware resource and your application. The difficulty part in cloud computing is to deploy in real environment. Its' difficult to know the exact cost and it's requirement until and unless we buy the service not only that whether it will support the existing application which is available on traditional data center or had to design a new application for the cloud computing environment. The security issue, latency, fault tolerance are some parameter which we need to keen care before deploying, all this we only know after deploying but by using simulation we can do the experiment before deploying it to real environment. By simulation we can understand the real environment of cloud computing and then after it successful result we can start deploying your application in cloud computing environment. By using the simulator it will save us lots of time and money.",
    "lastUpdated": "2012-03-08T10:06:49Z",
    "category": [
      "cs.DC",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1203.1728v1"
  },
  {
    "title": "Multiparty Cloud Computation",
    "author": [
      "Qingji Zheng",
      "Xinwen Zhang"
    ],
    "abstract": "With the increasing popularity of the cloud, clients oursource their data to clouds in order to take advantage of unlimited virtualized storage space and the low management cost. Such trend prompts the privately oursourcing computation, called \\emph{multiparty cloud computation} (\\MCC): Given $k$ clients storing their data in the cloud, how can they perform the joint functionality by contributing their private data as inputs, and making use of cloud's powerful computation capability. Namely, the clients wish to oursource computation to the cloud together with their private data stored in the cloud, which naturally happens when the computation is involved with large datasets, e.g., to analyze malicious URLs. We note that the \\MCC\\ problem is different from widely considered concepts, e.g., secure multiparty computation and multiparty computation with server aid. To address this problem, we introduce the notion of \\emph{homomorphic threshold proxy re-encryption} schemes, which are encryption schemes that enjoy three promising properties: proxy re-encryption -- transforming encrypted data of one user to encrypted data of target user, threshold decryption -- decrypting encrypted data by combining secret key shares obtained by a set of users, and homomorphic computation -- evaluating functions on the encrypted data. To demonstrate the feasibility of the proposed approach, we present an encryption scheme which allows anyone to compute arbitrary many additions and at most one multiplications.",
    "lastUpdated": "2012-06-17T02:33:22Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1206.3717v1"
  },
  {
    "title": "Secure Cloud Communication for Effective Cost Management System through MSBE",
    "author": [
      "Gaurav Raj",
      "Kamaljit Kaur"
    ],
    "abstract": "In Cloud Computing Architecture, Brokers are responsible to provide services to the end users. An Effective Cost Management System (ECMS) which works over Secure Cloud Communication Paradigm (SCCP) helps in finding a communication link with overall minimum cost of links. We propose an improved Broker Cloud Communication Paradigm (BCCP) with integration of security issues. Two algorithms are included, first is Secure Optimized Route Cost Finder (S-ORCF) to find optimum route between broker and cloud on the behalf of cost factor and second is Secure Optimized Route Management (S-ORM) to maintain optimum route. These algorithms proposed with cryptographic integrity of the secure route discovery process in efficient routing approaches between broker and cloud. There is lack in Dynamic Source Routing Approach to verify whether any intermediate node has been deleted, inserted or modified with no valid authentication. We use symmetric cryptographic primitives, which is made possible due to multisource broadcast encryption scheme. This paper outlines the use of secure route discovery protocol (SRDP)that employs such a security paradigm in cloud computing.",
    "lastUpdated": "2012-07-11T16:51:01Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1207.2706v1"
  },
  {
    "title": "Implementation of Private Cloud using Eucalyptus and an open source Operating System",
    "author": [
      "Nandan Mirajkar",
      "Mohan Barde",
      "Harshal Kamble",
      "Dr. Rahul Athale",
      "Kumud Singh"
    ],
    "abstract": "Cloud computing is bringing a revolution in computing environment replacing traditional software installations, licensing issues into complete on-demand services through internet. Microsoft office 365 a cloud based office application is available to clients online hence no need to buy and install the software. On Facebook a social networking website, users upload videos which uses cloud provider's storage service so less hardware cost for clients.Virtualization technology has great contribution in advent of cloud computing. Paper describes implementation of Private Cloud using open source operating system Ubuntu 10.04 server edition, installation of Ubuntu Enterprise Cloud with Eucalyptus 1.6.2 and providing CentOS 5.3 operating system through cloud.",
    "lastUpdated": "2012-07-11T15:57:29Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1207.3037v1"
  },
  {
    "title": "Trust Management in Cloud Computing: A Critical Review",
    "author": [
      "Mohamed Firdhous",
      "Osman Ghazali",
      "Suhaidi Hassan"
    ],
    "abstract": "Cloud computing has been attracting the attention of several researchers both in the academia and the industry as it provides many opportunities for organizations by offering a range of computing services. For cloud computing to become widely adopted by both the enterprises and individuals, several issues have to be solved. A key issue that needs special attention is security of clouds, and trust management is an important component of cloud security. In this paper, the authors look at what trust is and how trust has been applied in distributed computing. Trust models proposed for various distributed system has then been summarized. The trust management systems proposed for cloud computing have been investigated with special emphasis on their capability, applicability in practical heterogonous cloud environment and implementabilty. Finally, the proposed models/systems have been compared with each other based on a selected set of cloud computing parameters in a table.",
    "lastUpdated": "2012-11-12T02:22:54Z",
    "category": [
      "cs.DC",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1211.3979v1"
  },
  {
    "title": "Integrated Green Cloud Computing Architecture",
    "author": [
      "M. N. Hulkury",
      "M. R. Doomun"
    ],
    "abstract": "Arbitrary usage of cloud computing, either private or public, can lead to uneconomical energy consumption in data processing, storage and communication. Hence, green cloud computing solutions aim not only to save energy but also reduce operational costs and carbon footprints on the environment. In this paper, an Integrated Green Cloud Architecture (IGCA) is proposed that comprises of a client-oriented Green Cloud Middleware to assist managers in better overseeing and configuring their overall access to cloud services in the greenest or most energy-efficient way. Decision making, whether to use local machine processing, private or public clouds, is smartly handled by the middleware using predefined system specifications such as service level agreement (SLA), Quality of service (QoS), equipment specifications and job description provided by IT department. Analytical model is used to show the feasibility to achieve efficient energy consumption while choosing between local, private and public Cloud service provider (CSP).",
    "lastUpdated": "2012-12-06T10:57:59Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1212.1284v1"
  },
  {
    "title": "Word Storms: Multiples of Word Clouds for Visual Comparison of Documents",
    "author": [
      "Quim Castella",
      "Charles Sutton"
    ],
    "abstract": "Word clouds are a popular tool for visualizing documents, but they are not a good tool for comparing documents, because identical words are not presented consistently across different clouds. We introduce the concept of word storms, a visualization tool for analysing corpora of documents. A word storm is a group of word clouds, in which each cloud represents a single document, juxtaposed to allow the viewer to compare and contrast the documents. We present a novel algorithm that creates a coordinated word storm, in which words that appear in multiple documents are placed in the same location, using the same color and orientation, in all of the corresponding clouds. In this way, similar documents are represented by similar-looking word clouds, making them easier to compare and contrast visually. We evaluate the algorithm in two ways: first, an automatic evaluation based on document classification; and second, a user study. The results confirm that unlike standard word clouds, a coordinated word storm better allows for visual comparison of documents.",
    "lastUpdated": "2013-01-03T17:02:56Z",
    "category": [
      "cs.IR",
      "cs.DL",
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/1301.0503v1"
  },
  {
    "title": "On a Catalogue of Metrics for Evaluating Commercial Cloud Services",
    "author": [
      "Zheng Li",
      "Liam O'Brien",
      "He Zhang",
      "Rainbow Cai"
    ],
    "abstract": "Given the continually increasing amount of commercial Cloud services in the market, evaluation of different services plays a significant role in cost-benefit analysis or decision making for choosing Cloud Computing. In particular, employing suitable metrics is essential in evaluation implementations. However, to the best of our knowledge, there is not any systematic discussion about metrics for evaluating Cloud services. By using the method of Systematic Literature Review (SLR), we have collected the de facto metrics adopted in the existing Cloud services evaluation work. The collected metrics were arranged following different Cloud service features to be evaluated, which essentially constructed an evaluation metrics catalogue, as shown in this paper. This metrics catalogue can be used to facilitate the future practice and research in the area of Cloud services evaluation. Moreover, considering metrics selection is a prerequisite of benchmark selection in evaluation implementations, this work also supplements the existing research in benchmarking the commercial Cloud services.",
    "lastUpdated": "2013-02-08T07:10:19Z",
    "category": [
      "cs.DC",
      "cs.PF"
    ],
    "url": "http://arxiv.org/abs/1302.1954v1"
  },
  {
    "title": "Cloud Computing: a Prologue",
    "author": [
      "Sultan Ullah",
      "Zheng Xuefeng"
    ],
    "abstract": "An emerging internet based super computing model is represented by cloud computing. Cloud computing is the convergence and evolution of several concepts from virtualization, distributed storage, grid, and automation management to enable a more flexible approach for deploying and scaling applications. However, cloud computing moves the application software and databases to the large data centers, where the management of the data and services may not be fully trustworthy. The concept of cloud computing on the basis of the various definitions available in the industry and the characteristics of cloud computing are being analyzed in this paper. The paper also describes the main cloud service providers and their products followed by primary cloud computing operating systems.",
    "lastUpdated": "2013-04-28T01:48:59Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1304.2981v2"
  },
  {
    "title": "Energy-aware Application Scaling on a Cloud",
    "author": [
      "Ashkan Paya",
      "Dan C. Marinescu"
    ],
    "abstract": "Cloud elasticity - the ability to use as much resources as needed at any given time - and low cost - a user pays only for the resources it consumes - represent solid incentives for many organizations to migrate some of their computational activities to a public cloud. As the interest in cloud computing grows, so does the size of the cloud computing centers and their energy footprint. The realization that power consumption of cloud computing centers is significant and it is expected to increase substantially in the future motivates our interest in scheduling and scaling algorithms which minimize power consumption. We propose energy-aware application scaling and resource management algorithms. Though targeting primarily the Infrastructure as a Service (IaaS), the system models and the algorithms we propose can be applied to the other cloud delivery models and to private clouds.",
    "lastUpdated": "2013-07-12T02:43:46Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1307.3306v1"
  },
  {
    "title": "Toward Cloud-based Vehicular Networks with Efficient Resource Management",
    "author": [
      "Rong Yu",
      "Yan Zhang",
      "Stein Gjessing",
      "Wenlong Xia",
      "Kun Yang"
    ],
    "abstract": "In the era of Internet of Things, all components in intelligent transportation systems will be connected to improve transport safety, relieve traffic congestion, reduce air pollution and enhance the comfort of driving. The vision of all vehicles connected poses a significant challenge to the collection and storage of large amounts of traffic-related data. In this article, we propose to integrate cloud computing into vehicular networks such that the vehicles can share computation resources, storage resources and bandwidth resources. The proposed architecture includes a vehicular cloud, a roadside cloud, and a central cloud. Then, we study cloud resource allocation and virtual machine migration for effective resource management in this cloud-based vehicular network. A game-theoretical approach is presented to optimally allocate cloud resources. Virtual machine migration due to vehicle mobility is solved based on a resource reservation scheme.",
    "lastUpdated": "2013-08-28T16:31:55Z",
    "category": [
      "cs.DC",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1308.6208v1"
  },
  {
    "title": "Operating the Cloud from Inside Out",
    "author": [
      "Josef Spillner",
      "Andrii Chaichenko",
      "Andrey Brito",
      "Francisco Brasileiro",
      "Alexander Schill"
    ],
    "abstract": "Virtual machine images and instances (VMs) in cloud computing centres are typically designed as isolation containers for applications, databases and networking functions. In order to build complex distributed applications, multiple virtual machines must be connected, orchestrated and combined with platform and infrastructure services from the hosting environment. There are several reasons why sometimes it is beneficial to introduce a new layer, Cloud-in-a-VM, which acts as a portable management interface to a cluster of VMs. We reason about the benefits and present our Cloud-in-a-VM implementation called Nested Cloud which allows consumers to become light-weight cloud operators on demand and reap multiple advantages, including fully utilised resource allocations. The practical usefulness and the performance of the intermediate cloud stack VM are evaluated in a marketplace scenario.",
    "lastUpdated": "2013-09-21T06:43:06Z",
    "category": [
      "cs.DC",
      "C.2.4; D.4.8; H.3.5"
    ],
    "url": "http://arxiv.org/abs/1309.5442v1"
  },
  {
    "title": "The Cloud's Cloudy Moment: A Systematic Survey of Public Cloud Service Outage",
    "author": [
      "Zheng Li",
      "Mingfei Liang",
      "Liam O'Brien",
      "He Zhang"
    ],
    "abstract": "Inadequate service availability is the top concern when employing Cloud computing. It has been recognized that zero downtime is impossible for large-scale Internet services. By learning from the previous and others' mistakes, nevertheless, it is possible for Cloud vendors to minimize the risk of future downtime or at least keep the downtime short. To facilitate summarizing lessons for Cloud providers, we performed a systematic survey of public Cloud service outage events. This paper reports the result of this survey. In addition to a set of findings, our work generated a lessons framework by classifying the outage root causes. The framework can in turn be used to arrange outage lessons for reference by Cloud providers. By including potentially new root causes, this lessons framework will be smoothly expanded in our future work.",
    "lastUpdated": "2013-12-23T08:53:23Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1312.6485v1"
  },
  {
    "title": "Identifying Benefits and risks associated with utilizing cloud computing",
    "author": [
      "Jafar Shayan",
      "Ahmad Azarnik",
      "Suriayati Chuprat",
      "Sasan Karamizadeh",
      "Mojtaba Alizadeh"
    ],
    "abstract": "Cloud computing is an emerging computing model where IT and computing operations are delivered as services in highly scalable and cost effective manner. Recently, embarking this new model in business has become popular. Companies in diverse sectors intend to leverage cloud computing architecture, platforms and applications in order to gain higher competitive advantages. Likewise other models, cloud computing brought advantages to attract business but meanwhile fostering cloud has led to some risks, which can cause major impacts if business does not plan for mitigation. This paper surveys the advantages of cloud computing and in contrast the risks associated using them. Finally we conclude that a well-defined risk management program that focused on cloud computing is an essential part of gaining value from benefits of cloud computing.",
    "lastUpdated": "2014-01-21T02:52:39Z",
    "category": [
      "cs.DC",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1401.5155v1"
  },
  {
    "title": "Achieve Better Ranking Accuracy Using CloudRank Framework for Cloud Services",
    "author": [
      "M. Subha",
      "K. Saravanan"
    ],
    "abstract": "Building high quality cloud applications becomes an urgently required research problem. Nonfunctional performance of cloud services is usually described by quality-of-service (QoS). In cloud applications, cloud services are invoked remotely by internet connections. The QoS Ranking of cloud services for a user cannot be transferred directly to another user, since the locations of the cloud applications are quite different. Personalized QoS Ranking is required to evaluate all candidate services at the user - side but it is impractical in reality. To get QoS values, the service candidates are usually required and it is very expensive. To avoid time consuming and expensive realworld service invocations, this paper proposes a CloudRank framework which predicts the QoS ranking directly without predicting the corresponding QoS values. This framework provides an accurate ranking but the QoS values are same in both algorithms so, an optimal VM allocation policy is used to improve the QoS performance of cloud services and it also provides better ranking accuracy than CloudRank2 algorithm.",
    "lastUpdated": "2014-02-11T14:51:11Z",
    "category": [
      "cs.DC",
      "cs.IR"
    ],
    "url": "http://arxiv.org/abs/1402.2509v1"
  },
  {
    "title": "A Taxonomy and Survey on eScience as a Service in the Cloud",
    "author": [
      "Amelie Chi Zhou",
      "Bingsheng He",
      "Shadi Ibrahim"
    ],
    "abstract": "Cloud computing has recently evolved as a popular computing infrastructure for many applications. Scientific computing, which was mainly hosted in private clusters and grids, has started to migrate development and deployment to the public cloud environment. eScience as a service becomes an emerging and promising direction for science computing. We review recent efforts in developing and deploying scientific computing applications in the cloud. In particular, we introduce a taxonomy specifically designed for scientific computing in the cloud, and further review the taxonomy with four major kinds of science applications, including life sciences, physics sciences, social and humanities sciences, and climate and earth sciences. Our major finding is that, despite existing efforts in developing cloud-based eScience, eScience still has a long way to go to fully unlock the power of cloud computing paradigm. Therefore, we present the challenges and opportunities in the future development of cloud-based eScience services, and call for collaborations and innovations from both the scientific and computer system communities to address those challenges.",
    "lastUpdated": "2014-07-28T09:14:35Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1407.7360v1"
  },
  {
    "title": "Cloud Benchmarking for Performance",
    "author": [
      "Blesson Varghese",
      "Ozgur Akgun",
      "Ian Miguel",
      "Long Thai",
      "Adam Barker"
    ],
    "abstract": "How can applications be deployed on the cloud to achieve maximum performance? This question has become significant and challenging with the availability of a wide variety of Virtual Machines (VMs) with different performance capabilities in the cloud. The above question is addressed by proposing a six step benchmarking methodology in which a user provides a set of four weights that indicate how important each of the following groups: memory, processor, computation and storage are to the application that needs to be executed on the cloud. The weights along with cloud benchmarking data are used to generate a ranking of VMs that can maximise performance of the application. The rankings are validated through an empirical analysis using two case study applications; the first is a financial risk application and the second is a molecular dynamics simulation, which are both representative of workloads that can benefit from execution on the cloud. Both case studies validate the feasibility of the methodology and highlight that maximum performance can be achieved on the cloud by selecting the top ranked VMs produced by the methodology.",
    "lastUpdated": "2014-11-04T13:57:24Z",
    "category": [
      "cs.DC",
      "cs.PF"
    ],
    "url": "http://arxiv.org/abs/1411.0912v1"
  },
  {
    "title": "Distributed Cloud Association in Downlink Multicloud Radio Access Networks",
    "author": [
      "Hayssam Dahrouj",
      "Tareq Y. Al-Naffouri",
      "Mohamed-Slim Alouini"
    ],
    "abstract": "This paper considers a multicloud radio access network (M-CRAN), wherein each cloud serves a cluster of base-stations (BS's) which are connected to the clouds through high capacity digital links. The network comprises several remote users, where each user can be connected to one (and only one) cloud. This paper studies the user-to-cloud-assignment problem by maximizing a network-wide utility subject to practical cloud connectivity constraints. The paper solves the problem by using an auction-based iterative algorithm, which can be implemented in a distributed fashion through a reasonable exchange of information between the clouds. The paper further proposes a centralized heuristic algorithm, with low computational complexity. Simulations results show that the proposed algorithms provide appreciable performance improvements as compared to the conventional cloud-less assignment solutions.",
    "lastUpdated": "2015-03-01T12:52:23Z",
    "category": [
      "cs.IT",
      "cs.NI",
      "math.IT"
    ],
    "url": "http://arxiv.org/abs/1503.00267v1"
  },
  {
    "title": "A Study on Optimized Resource Provisioning in Federated Cloud",
    "author": [
      "Thiruselvan Subramanian",
      "Nickolas Savarimuthu"
    ],
    "abstract": "Cloud computing changed the way of computing as utility services offered through public network. Selecting multiple providers for various computational requirements improves performance and minimizes cost of cloud services than choosing a single cloud provider. Federated cloud improves scalability, cost minimization, performance maximization, collaboration with other providers, multi-site deployment for fault tolerance and recovery, reliability and less energy consumption. Both providers and consumers could benefit from federated cloud where providers serve the consumers by satisfying Service Level Agreement, minimizing overall management and infrastructure cost; consumers get best services with less deployment cost and high availability. Efficient provisioning of resources to consumers in federated cloud is a challenging task. In this paper, the benefits of utilizing services from federated cloud, architecture with various coupling levels, different optimized resource provisioning methods and challenges associated with it are discussed and a comparative study is carried out over these aspects.",
    "lastUpdated": "2015-03-12T04:21:02Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1503.03579v1"
  },
  {
    "title": "Laypeople and Experts risk perception of Cloud Computing Services",
    "author": [
      "Gianfranco Elena",
      "Christopher W. Johnson"
    ],
    "abstract": "Cloud computing is revolutionising the way software services are procured and used by Government organizations and SMEs. Quantitative risk assessment of Cloud services is complex and undermined by specific security concerns regarding data confidentiality, integrity and availability. This study explores how the gap between the quantitative risk assessment and the perception of the risk can produce a bias in the decision-making process about Cloud computing adoption. The risk perception of experts in Cloud computing (N=37) and laypeople (N=81) about ten Cloud computing services was investigated using the psychometric paradigm. Results suggest that the risk perception of Cloud services can be represented by two components, called dread risk and unknown risk, which may explain up to 46% of the variance. Other factors influencing the risk perception were perceived benefits, trust in regulatory authorities and technology attitude. This study suggests some implications that could support Government and non-Government organizations in their strategies for Cloud computing adoption.",
    "lastUpdated": "2015-09-22T10:04:42Z",
    "category": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1509.06536v1"
  },
  {
    "title": "TEMPO: Feature-Endowed Teichmüller Extremal Mappings of Point Clouds",
    "author": [
      "Ting Wei Meng",
      "Gary Pui-Tung Choi",
      "Lok Ming Lui"
    ],
    "abstract": "In recent decades, the use of 3D point clouds has been widespread in computer industry. The development of techniques in analyzing point clouds is increasingly important. In particular, mapping of point clouds has been a challenging problem. In this paper, we develop a discrete analogue of the Teichm\\\"{u}ller extremal mappings, which guarantee uniform conformality distortions, on point cloud surfaces. Based on the discrete analogue, we propose a novel method called TEMPO for computing Teichm\\\"{u}ller extremal mappings between feature-endowed point clouds. Using our proposed method, the Teichm\\\"{u}ller metric is introduced for evaluating the dissimilarity of point clouds. Consequently, our algorithm enables accurate recognition and classification of point clouds. Experimental results demonstrate the effectiveness of our proposed method.",
    "lastUpdated": "2016-04-26T12:37:02Z",
    "category": [
      "cs.CG",
      "cs.CV",
      "cs.GR",
      "math.DG"
    ],
    "url": "http://arxiv.org/abs/1511.06624v2"
  },
  {
    "title": "Case Study on Cloud Based Library Software as a Service: Evaluating EZproxy",
    "author": [
      "Emre Erturk",
      "Howard Robert Edward Iles"
    ],
    "abstract": "There is a growing relationship between academic libraries and cloud computing. Therefore, understanding the beginnings and the current use of cloud base services in libraries is important. This will help understand the factors that libraries should consider in the future. The purpose of this paper is to better understand the future implementation of the cloud based software in academic settings. Using cloud based, web based, and other remote services may bring both advantages and disadvantages, some of which this paper will bring out. First, a brief literature review of the academic literature, and a review of available general-purpose cloud-based library products are conducted. Next, a real-life scenario for a mid-sized New Zealand institution of higher education is evaluated. This case involves moving from a locally hosted version of EZproxy to a cloud based version with support from the vendor. As this information system decision is an important one, this paper makes a contribution to the available literature and can be informative for librarians. In conclusion, academic libraries will gradually involve more pervasive use of cloud based systems. The examples of important factors to be considered in future decisions include timing and staffing.",
    "lastUpdated": "2015-11-24T06:05:13Z",
    "category": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1511.07578v1"
  },
  {
    "title": "Heading for the Clouds: Implications for Cloud Computing Adopters",
    "author": [
      "Norah Abokhodair",
      "Hazel Taylor",
      "Surry Jones Mowery",
      "Jitsuko Hasegawa"
    ],
    "abstract": "Cloud computing projects have many implications, including issues such as security, compliance, funding, cohesion with existing systems, operational resource requirements, and number of employees involved. In order to gain a better understanding of why businesses are interested in adopting cloud services in spite of these potential difficulties, we interviewed senior IT personnel at five different organizations about their processes related to cloud decisions, their thoughts before and during the process, and the outcome of their endeavor. Our results provide insights from their perspectives into the similarities and differences among the organizations and the implications of going into the cloud. We conclude with a list of recommended questions and areas to consider for use by other organizations looking into adopting cloud services. The ultimate goal is to help businesses considering a cloud computing project by providing advice from other organizations based on their experience.",
    "lastUpdated": "2016-04-13T00:45:43Z",
    "category": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1604.00737v2"
  },
  {
    "title": "CYCLONE Unified Deployment and Management of Federated, Multi-Cloud Applications",
    "author": [
      "Mathias Slawik",
      "Begüm İlke Zilci",
      "Yuri Demchenko",
      "José Ignacio Aznar Baranda",
      "Robert Branchat",
      "Charles Loomis",
      "Oleg Lodygensky",
      "Christophe Blanchet"
    ],
    "abstract": "Various Cloud layers have to work in concert in order to manage and deploy complex multi-cloud applications, executing sophisticated workflows for Cloud resource deployment, activation, adjustment, interaction, and monitoring. While there are ample solutions for managing individual Cloud aspects (e.g. network controllers, deployment tools, and application security software), there are no well-integrated suites for managing an entire multi cloud environment with multiple providers and deployment models. This paper presents the CYCLONE architecture that integrates a number of existing solutions to create an open, unified, holistic Cloud management platform for multi-cloud applications, tailored to the needs of research organizations and SMEs. It discusses major challenges in providing a network and security infrastructure for the Intercloud and concludes with the demonstration how the architecture is implemented in a real life bioinformatics use case.",
    "lastUpdated": "2016-07-22T14:18:22Z",
    "category": [
      "cs.DC",
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/1607.06688v1"
  },
  {
    "title": "ALPINE: A Bayesian System for Cloud Performance Diagnosis and Prediction",
    "author": [
      "Karan Mitra",
      "Saguna Saguna",
      "Christer Åhlund",
      "Rajiv Ranjan"
    ],
    "abstract": "Cloud performance diagnosis and prediction is a challenging problem due to the stochastic nature of the cloud systems. Cloud performance is affected by a large set of factors including (but not limited to) virtual machine types, regions, workloads, wide area network delay and bandwidth. Therefore, necessitating the determination of complex relationships between these factors. The current research in this area does not address the challenge of building models that capture the uncertain and complex relationships between these factors. Further, the challenge of cloud performance prediction under uncertainty has not garnered sufficient attention. This paper proposes develops and validates ALPINE, a Bayesian system for cloud performance diagnosis and prediction. ALPINE incorporates Bayesian networks to model uncertain and complex relationships between several factors mentioned above. It handles missing, scarce and sparse data to diagnose and predict stochastic cloud performance efficiently. We validate our proposed system using extensive real data and trace-driven analysis and show that it predicts cloud performance with high accuracy of 91.93%.",
    "lastUpdated": "2016-12-16T14:21:18Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1612.05477v1"
  },
  {
    "title": "Resource Management in Cloud Networking Using Economic Analysis and Pricing Models: A Survey",
    "author": [
      "Nguyen Cong Luong",
      "Ping Wang",
      "Dusit Niyato",
      "Wen Yonggang",
      "Zhu Han"
    ],
    "abstract": "This paper presents a comprehensive literature review on applications of economic and pricing models for resource management in cloud networking. To achieve sustainable profit advantage, cost reduction, and flexibility in provisioning of cloud resources, resource management in cloud networking requires adaptive and robust designs to address many issues, e.g., resource allocation, bandwidth reservation, request allocation, and workload allocation. Economic and pricing models have received a lot of attention as they can lead to desirable performance in terms of social welfare, fairness, truthfulness, profit, user satisfaction, and resource utilization. This paper reviews applications of the economic and pricing models to develop adaptive algorithms and protocols for resource management in cloud networking. Besides, we survey a variety of incentive mechanisms using the pricing strategies in sharing resources in edge computing. In addition, we consider using pricing models in cloud-based Software Defined Wireless Networking (cloud-based SDWN). Finally, we highlight important challenges, open issues and future research directions of applying economic and pricing models to cloud networking",
    "lastUpdated": "2017-01-08T14:32:54Z",
    "category": [
      "cs.GT",
      "cs.DC",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1701.01963v1"
  },
  {
    "title": "Fog-Assisted Operational Cost Reduction for Cloud Data Centers",
    "author": [
      "Liang Yu",
      "Tao Jiang",
      "Yulong Zou"
    ],
    "abstract": "In this paper, we intend to reduce the operational cost of cloud data centers with the help of fog devices, which can avoid the revenue loss due to wide-area network propagation delay and save network bandwidth cost by serving nearby cloud users. Since fog devices may not be owned by a cloud service provider, they should be compensated for serving the requests of cloud users. When taking economical compensation into consideration, the optimal number of requests processed locally by each fog device should be decided. As a result, existing load balancing schemes developed for cloud data centers can not be applied directly and it is very necessary to redesign a cost-ware load balancing algorithm for the fog-cloud system. To achieve the above aim, we first formulate a fog-assisted operational cost minimization problem for the cloud service provider. Then, we design a parallel and distributed load balancing algorithm with low computational complexity based on Proximal Jacobian Alternating Direction Method of Multipliers (PJ-ADMM). Finally, extensive simulation results show the effectiveness of the proposed algorithm.",
    "lastUpdated": "2017-08-03T05:12:51Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1701.07154v3"
  },
  {
    "title": "Privacy Preserving Face Retrieval in the Cloud for Mobile Users",
    "author": [
      "Xin Jin",
      "Shiming Ge",
      "Chenggen Song"
    ],
    "abstract": "Recently, cloud storage and processing have been widely adopted. Mobile users in one family or one team may automatically backup their photos to the same shared cloud storage space. The powerful face detector trained and provided by a 3rd party may be used to retrieve the photo collection which contains a specific group of persons from the cloud storage server. However, the privacy of the mobile users may be leaked to the cloud server providers. In the meanwhile, the copyright of the face detector should be protected. Thus, in this paper, we propose a protocol of privacy preserving face retrieval in the cloud for mobile users, which protects the user photos and the face detector simultaneously. The cloud server only provides the resources of storage and computing and can not learn anything of the user photos and the face detector. We test our protocol inside several families and classes. The experimental results reveal that our protocol can successfully retrieve the proper photos from the cloud server and protect the user photos and the face detector.",
    "lastUpdated": "2017-08-09T15:21:42Z",
    "category": [
      "cs.CV",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1708.02872v1"
  },
  {
    "title": "Learning a 3D descriptor for cross-source point cloud registration from synthetic data",
    "author": [
      "Xiaoshui Huang"
    ],
    "abstract": "As the development of 3D sensors, registration of 3D data (e.g. point cloud) coming from different kind of sensor is dispensable and shows great demanding. However, point cloud registration between different sensors is challenging because of the variant of density, missing data, different viewpoint, noise and outliers, and geometric transformation. In this paper, we propose a method to learn a 3D descriptor for finding the correspondent relations between these challenging point clouds. To train the deep learning framework, we use synthetic 3D point cloud as input. Starting from synthetic dataset, we use region-based sampling method to select reasonable, large and diverse training samples from synthetic samples. Then, we use data augmentation to extend our network be robust to rotation transformation. We focus our work on more general cases that point clouds coming from different sensors, named cross-source point cloud. The experiments show that our descriptor is not only able to generalize to new scenes, but also generalize to different sensors. The results demonstrate that the proposed method successfully aligns two 3D cross-source point clouds which outperforms state-of-the-art method.",
    "lastUpdated": "2017-08-24T22:38:02Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1708.08997v1"
  },
  {
    "title": "Cloud Workload Prediction based on Workflow Execution Time Discrepancies",
    "author": [
      "Gabor Kecskemeti",
      "Zsolt Nemeth",
      "Attila Kertesz",
      "Rajiv Ranjan"
    ],
    "abstract": "Infrastructure as a service clouds hide the complexity of maintaining the physical infrastructure with a slight disadvantage: they also hide their internal working details. Should users need knowledge about these details e.g., to increase the reliability or performance of their applications, they would need solutions to detect behavioural changes in the underlying system. Existing runtime solutions for such purposes offer limited capabilities as they are mostly restricted to revealing weekly or yearly behavioural periodicity in the infrastructure. This article proposes a technique for predicting generic background workload by means of simulations that are capable of providing additional knowledge of the underlying private cloud systems in order to support activities like cloud orchestration or workflow enactment. Our technique uses long-running scientific workflows and their behaviour discrepancies and tries to replicate these in a simulated cloud with known (trace-based) workloads. We argue that the better we can mimic the current discrepancies the better we can tell expected workloads in the near future on the real life cloud. We evaluated the proposed prediction approach with a biochemical application on both real and simulated cloud infrastructures. The proposed algorithm has shown to produce significantly (~20%) better workload predictions for the future of simulated clouds than random workload selection.",
    "lastUpdated": "2018-03-19T13:55:33Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1803.06924v1"
  },
  {
    "title": "Point Convolutional Neural Networks by Extension Operators",
    "author": [
      "Matan Atzmon",
      "Haggai Maron",
      "Yaron Lipman"
    ],
    "abstract": "This paper presents Point Convolutional Neural Networks (PCNN): a novel framework for applying convolutional neural networks to point clouds. The framework consists of two operators: extension and restriction, mapping point cloud functions to volumetric functions and vise-versa. A point cloud convolution is defined by pull-back of the Euclidean volumetric convolution via an extension-restriction mechanism. The point cloud convolution is computationally efficient, invariant to the order of points in the point cloud, robust to different samplings and varying densities, and translation invariant, that is the same convolution kernel is used at all points. PCNN generalizes image CNNs and allows readily adapting their architectures to the point cloud setting. Evaluation of PCNN on three central point cloud learning benchmarks convincingly outperform competing point cloud learning methods, and the vast majority of methods working with more informative shape representations such as surfaces and/or normals.",
    "lastUpdated": "2018-03-27T14:06:16Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1803.10091v1"
  },
  {
    "title": "CloudLaunch: Discover and Deploy Cloud Applications",
    "author": [
      "Enis Afgan",
      "Andrew Lonie",
      "James Taylor",
      "Nuwan Goonasekera"
    ],
    "abstract": "Cloud computing is a common platform for delivering software to end users. However, the process of making complex-to-deploy applications available across different cloud providers requires isolated and uncoordinated application-specific solutions, often locking-in developers to a particular cloud provider. Here, we present the CloudLaunch application as a uniform platform for discovering and deploying applications for different cloud providers. CloudLaunch allows arbitrary applications to be added to a catalog with each application having its own customizable user interface and control over the launch process, while preserving cloud-agnosticism so that authors can easily make their applications available on multiple clouds with minimal effort. It then provides a uniform interface for launching available applications by end users across different cloud providers. Architecture details are presented along with examples of different deployable applications that highlight architectural features.",
    "lastUpdated": "2018-05-11T02:19:53Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1805.04005v2"
  },
  {
    "title": "Coded Computation Against Distributed Straggling Channel Decoders in the Cloud for Gaussian Uplink Channels",
    "author": [
      "Jinwen Shi",
      "Cong Ling",
      "Osvaldo Simeone",
      "Jörg Kliewer"
    ],
    "abstract": "The uplink of a Cloud Radio Access Network (CRAN) architecture is studied, where decoding at the cloud takes place at distributed decoding processors. To mitigate the impact of straggling decoders in the cloud, the cloud re-encodes the received frames via a linear code before distributing them to the decoding processors. Focusing on Gaussian channels, and assuming the use of lattice codes at the users, in this paper the maximum user rate is derived such that all the servers can reliably recover the linear combinations of the messages corresponding to the employed linear code at the cloud. Furthermore, two analytical upper bounds on the frame error rate (FER) as a function of the decoding latency are developed, in order to quantify the performance of the cloud's linear code in terms of the tradeoff between FER and decoding latency at the cloud.",
    "lastUpdated": "2018-07-12T17:27:41Z",
    "category": [
      "cs.IT",
      "math.IT"
    ],
    "url": "http://arxiv.org/abs/1805.11698v3"
  },
  {
    "title": "On Challenges of Cloud Monitoring",
    "author": [
      "William Pourmajidi",
      "John Steinbacher",
      "Tony Erwin",
      "Andriy Miranskyy"
    ],
    "abstract": "Cloud services are becoming increasingly popular: 60\\% of information technology spending in 2016 was Cloud-based, and the size of the public Cloud service market will reach \\$236B by 2020. To ensure reliable operation of the Cloud services, one must monitor their health. While a number of research challenges in the area of Cloud monitoring have been solved, problems are remaining. This prompted us to highlight three areas, which cause problems to practitioners and require further research. These three areas are as follows: A) defining health states of Cloud systems, B) creating unified monitoring environments, and C) establishing high availability strategies. In this paper we provide details of these areas and suggest a number of potential solutions to the challenges. We also show that Cloud monitoring presents exciting opportunities for novel research and practice.",
    "lastUpdated": "2018-06-15T11:38:01Z",
    "category": [
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/1806.05914v1"
  },
  {
    "title": "Virtual Machine Migration Enabled Cloud Resource Management: A Challenging Task",
    "author": [
      "Misbah Liaqat",
      "Shalini Ninoriya",
      "Junaid Shuja",
      "Raja Wasim Ahmad",
      "Abdullah Gani"
    ],
    "abstract": "Virtualization technology reduces cloud operational cost by increasing cloud resource utilization level. The incorporation of virtualization within cloud data centers can severely degrade cloud performance if not properly managed. Virtual machine (VM) migration is a method that assists cloud service providers to efficiently manage cloud resources while eliminating the need of human supervision. VM migration methodology migrates current-hosted workload from one server to another by either employing live or non-live migration pattern. In comparison to non-live migration, live migration does not suspend application services prior to VM migration process. VM migration enables cloud operators to achieve various resource management goals, such as, green computing, load balancing, fault management, and real time server maintenance. In this paper, we have thoroughly surveyed VM migration methods and applications. We have briefly discussed VM migration applications. Some open research issues have been highlighted to represent future challenges in this domain. A queue based migration model has been proposed and discussed to efficiently migrate VM memory pages.",
    "lastUpdated": "2016-01-15T09:36:25Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1601.03854v1"
  },
  {
    "title": "Exploration of object recognition from 3D point cloud",
    "author": [
      "Lin Duan"
    ],
    "abstract": "We present our latest experiment results of object recognition from 3D point cloud data collected through moving car.",
    "lastUpdated": "2017-07-05T07:43:00Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1707.01243v1"
  },
  {
    "title": "MLBench: How Good Are Machine Learning Clouds for Binary Classification Tasks on Structured Data?",
    "author": [
      "Yu Liu",
      "Hantian Zhang",
      "Luyuan Zeng",
      "Wentao Wu",
      "Ce Zhang"
    ],
    "abstract": "We conduct an empirical study of machine learning functionalities provided by major cloud service providers, which we call machine learning clouds. Machine learning clouds hold the promise of hiding all the sophistication of running large-scale machine learning: Instead of specifying how to run a machine learning task, users only specify what machine learning task to run and the cloud figures out the rest. Raising the level of abstraction, however, rarely comes free - a performance penalty is possible. How good, then, are current machine learning clouds on real-world machine learning workloads? We study this question with a focus on binary classication problems. We present mlbench, a novel benchmark constructed by harvesting datasets from Kaggle competitions. We then compare the performance of the top winning code available from Kaggle with that of running machine learning clouds from both Azure and Amazon on mlbench. Our comparative study reveals the strength and weakness of existing machine learning clouds and points out potential future directions for improvement.",
    "lastUpdated": "2017-10-16T11:13:32Z",
    "category": [
      "cs.DC",
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1707.09562v3"
  },
  {
    "title": "Revealing the Unseen: How to Expose Cloud Usage While Protecting User Privacy",
    "author": [
      "Ata Turk",
      "Mayank Varia",
      "Georgios Kellaris"
    ],
    "abstract": "Cloud users have little visibility into the performance characteristics and utilization of the physical machines underpinning the virtualized cloud resources they use. This uncertainty forces users and researchers to reverse engineer the inner workings of cloud systems in order to understand and optimize the conditions their applications operate. At Massachusetts Open Cloud (MOC), as a public cloud operator, we'd like to expose the utilization of our physical infrastructure to stop this wasteful effort. Mindful that such exposure can be used maliciously for gaining insight into other users workloads, in this position paper we argue for the need for an approach that balances openness of the cloud overall with privacy for each tenant inside of it. We believe that this approach can be instantiated via a novel combination of several security and privacy technologies. We discuss the potential benefits, implications of transparency for cloud systems and users, and technical challenges/possibilities.",
    "lastUpdated": "2017-10-02T15:05:25Z",
    "category": [
      "cs.CR",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1710.00714v1"
  },
  {
    "title": "Orchestrating Complex Application Architectures in Heterogeneous Clouds",
    "author": [
      "Miguel Caballer",
      "Sahdev Zala",
      "Álvaro López García",
      "Germán Moltó",
      "Pablo Orviz Fernández",
      "Mathieu Velten"
    ],
    "abstract": "Private cloud infrastructures are now widely deployed and adopted across technology industries and research institutions. Although cloud computing has emerged as a reality, it is now known that a single cloud provider cannot fully satisfy complex user requirements. This has resulted in a growing interest in developing hybrid cloud solutions that bind together distinct and heterogeneous cloud infrastructures. In this paper we describe the orchestration approach for heterogeneous clouds that has been implemented and used within the INDIGO-DataCloud project. This orchestration model uses existing open-source software like OpenStack and leverages the OASIS Topology and Specification for Cloud Applications (TOSCA) open standard as the modeling language. Our approach uses virtual machines and Docker containers in an homogeneous and transparent way providing consistent application deployment for the users. This approach is illustrated by means of two different use cases in different scientific communities, implemented using the INDIGO-DataCloud solutions.",
    "lastUpdated": "2017-11-09T11:30:40Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1711.03334v1"
  },
  {
    "title": "Cloud Computing and Content Management Systems: A Case Study in Macedonian Education",
    "author": [
      "Jove Jankulovski",
      "Pece Mitrevski"
    ],
    "abstract": "Technologies have become inseparable of our lives, economy, and the society as a whole. For example, clouds provide numerous computing resources that can facilitate our lives, whereas the Content Management Systems (CMSs) can provide the right content for the right user. Thus, education must embrace these emerging technologies in order to prepare citizens for the 21st century. The research explored 'if' and 'how' Cloud Computing influences the application of CMSs, and 'if' and 'how' it fosters the usage of mobile technologies to access cloud resources. The analyses revealed that some of the respondents have sound experience in using clouds and in using CMSs. Nevertheless, it was evident that significant number of respondents have limited or no experience in cloud computing concepts, cloud security and CMSs, as well. Institutions of the system should update educational policies in order to enable education innovation, provide means and support, and continuously update/upgrade educational infrastructure.",
    "lastUpdated": "2017-11-09T16:49:57Z",
    "category": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1711.04025v1"
  },
  {
    "title": "Formal Analysis of an Authentication Protocol Against External Cloud-Based Denial-of-Service (DoS) Attack",
    "author": [
      "Marwan Darwish",
      "Abdelkader Ouda",
      "Luiz Fernando Capretz"
    ],
    "abstract": "The Denial-of-service (DoS) attack is considered one of the largest threats to the availability of cloud-computing services. Due to the unique architecture of cloud-computing systems, the methods for detecting and preventing DoS attacks are quite different from those used in traditional network systems. A main target for DoS attackers is the authentication protocol because it is considered a gateway to accessing cloud resources. In this work, we propose a cloud-based authentication protocol - one that securely authenticates the cloud user and effectively prevents DoS attack on the cloud-computing system-by involving the user in a high computation process. Then, we analyze the protocol via Syverson and Van Oorschot (SVO) logic to verify the authentication process of the protocol in a cloud-computing system.",
    "lastUpdated": "2017-11-22T22:47:30Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1711.09985v1"
  },
  {
    "title": "A Stochastic Programming Approach for Risk Management in Mobile Cloud Computing",
    "author": [
      "Dinh Thai Hoang",
      "Dusit Niyato",
      "Ping Wang",
      "Shaun Shuxun Wang",
      "Diep Nguyen",
      "Eryk Dutkiewicz"
    ],
    "abstract": "The development of mobile cloud computing has brought many benefits to mobile users as well as cloud service providers. However, mobile cloud computing is facing some challenges, especially security-related problems due to the growing number of cyberattacks which can cause serious losses. In this paper, we propose a dynamic framework together with advanced risk management strategies to minimize losses caused by cyberattacks to a cloud service provider. In particular, this framework allows the cloud service provider to select appropriate security solutions, e.g., security software/hardware implementation and insurance policies, to deal with different types of attacks. Furthermore, the stochastic programming approach is adopted to minimize the expected total loss for the cloud service provider under its financial capability and uncertainty of attacks and their potential losses. Through numerical evaluation, we show that our approach is an effective tool in not only dealing with cyberattacks under uncertainty, but also minimizing the total loss for the cloud service provider given its available budget.",
    "lastUpdated": "2017-12-16T07:18:46Z",
    "category": [
      "cs.CR",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1712.05913v1"
  },
  {
    "title": "Edge Cloud System Evaluation",
    "author": [
      "Sumit Maheshwari",
      "Dipankar Raychaudhuri"
    ],
    "abstract": "Real-time applications in the next generation networks often rely upon offloading the computational task to a \\textit{nearby} server to achieve ultra-low latency. Augmented reality applications for instance have strict latency requirements which can be fulfilled by an interplay between cloud and edge servers. In this work, we study the impact of load on a hybrid edge cloud system. The resource distribution between central cloud and edge affects the capacity of the network. Optimizing delay and capacity constraints of this hybrid network is similar to maximum cardinal bin packing problem which is NP-hard. We design a simulation framework using a city-scale access point dataset to propose an enhanced capacity edge cloud network while answering following questions: (a) how much load an edge cloud network can support without affecting the performance of an application, (b) how is application delay-constraint limit affects the capacity of the network, (c) what is the impact of load and resource distribution on goodput, (d) under what circumstances, cloud can perform better than edge network and (e) what is the impact of inter-edge networking bandwidth on the system capacity. An evaluation system and model is developed to analyze the tradeoffs of different edge cloud deployments and results are shown to support the claims.",
    "lastUpdated": "2018-09-16T20:29:11Z",
    "category": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1811.11244v1"
  },
  {
    "title": "A Security Framework for Cloud Data Storage(CDS) Based on Agent",
    "author": [
      "Oussama Arki",
      "Abdelhafid Zitouni"
    ],
    "abstract": "The Cloud has become a new Information Technology(IT) model for delivering resources such as computing and storage to customers on demand, it provides both high flexibility and resources use. However we are gaining these advantages at the cost of high security threats, which presents the major brake for the migration towards Cloud Computing. Cloud Data Storage(CDS) is one of the Cloud services, it allows users to store their data in the Cloud, this service is very useful for companies and individuals, but data security remains the problem which makes customers worried about their data that reside in the Cloud. In this paper, we propose a framework of security to ensure the CDS, which is based on agents, it contains three layers: Cloud Provider layer, Customer layer and Trusted Third Party(TTP) layer.",
    "lastUpdated": "2019-01-09T18:36:52Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1901.02866v1"
  },
  {
    "title": "Self-Supervised Deep Learning on Point Clouds by Reconstructing Space",
    "author": [
      "Jonathan Sauder",
      "Bjarne Sievers"
    ],
    "abstract": "Point clouds provide a flexible and natural representation usable in countless applications such as robotics or self-driving cars. Recently, deep neural networks operating on raw point cloud data have shown promising results on supervised learning tasks such as object classification and semantic segmentation. While massive point cloud datasets can be captured using modern scanning technology, manually labelling such large 3D point clouds for supervised learning tasks is a cumbersome process. This necessitates methods that can learn from unlabelled data to significantly reduce the number of annotated samples needed in supervised learning. We propose a self-supervised learning task for deep learning on raw point cloud data in which a neural network is trained to reconstruct point clouds whose parts have been randomly rearranged. While solving this task, representations that capture semantic properties of the point cloud are learned. Our method is agnostic of network architecture and outperforms current unsupervised learning approaches in downstream object classification tasks. We show experimentally, that pre-training with our method before supervised training improves the performance of state-of-the-art models and significantly improves sample efficiency.",
    "lastUpdated": "2019-06-02T20:06:50Z",
    "category": [
      "cs.LG",
      "cs.CV",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1901.08396v2"
  },
  {
    "title": "Proceedings of the Fifth International Conference on Cloud and Robotics (ICCR2018)",
    "author": [
      "Huaxi",
      "Zhang",
      "Jacques Malenfant"
    ],
    "abstract": "The 5th edition of the International Conference on Cloud and Robotics (ICCR 2018 - http://cloudrobotics.info) will be held on November 12-14 2018 in Paris and Saint-Quentin, France. The conference is a co-event with GDR ALROB and the industry exposition Robonumerique (http://www.robonumerique.fr). The domain of cloud robotics aims to converge robots with computation, storage and communication resources provided by the cloud. The cloud may complement robotic resources in several ways, including crowd-sourcing knowledge databases, context information, computational offloading or data-intensive information processing for artificial intelligence. Today, the paradigms of cloud/fog/edge computing propose software architecture solutions for robots to share computations or offload them to ambiant and networked resources. Yet, combining distant computations with the real time constraints of robotics is very challenging. As the challenges in this domain are multi-disciplinary and similar in other research areas, Cloud Robotics aims at building bridges among experts from academia and industry working in different fields, such as robotics, cyber-physical systems, automotive, aerospace, machine learning, artificial intelligence, software architecture, big data analytics, Internet-of-Things, networked control and distributed cloud systems.",
    "lastUpdated": "2019-03-12T10:28:36Z",
    "category": [
      "cs.RO"
    ],
    "url": "http://arxiv.org/abs/1903.04824v1"
  },
  {
    "title": "Neural Style Transfer for Point Clouds",
    "author": [
      "Xu Cao",
      "Weimin Wang",
      "Katashi Nagao"
    ],
    "abstract": "How can we edit or transform the geometric or color property of a point cloud? In this study, we propose a neural style transfer method for point clouds which allows us to transfer the style of geometry or color from one point cloud either independently or simultaneously to another. This transfer is achieved by manipulating the content representations and Gram-based style representations extracted from a pre-trained PointNet-based classification network for colored point clouds. As Gram-based style representation is invariant to the number or the order of points, the same method can be extended to transfer the style extracted from an image to the color expression of a point cloud by merely treating the image as a set of pixels. Experimental results demonstrate the capability of the proposed method for transferring style from either an image or a point cloud to another point cloud of a single object or even an indoor scene.",
    "lastUpdated": "2019-03-14T03:56:06Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1903.05807v1"
  },
  {
    "title": "Fog Computing Vs. Cloud Computing",
    "author": [
      "Moonmoon Chakraborty"
    ],
    "abstract": "This article gives an overview of what Fog computing is, its uses and the comparison between Fog computing and Cloud computing. Cloud is performing well in todays World and boosting the ability to use the internet more than ever. Cloud computing gradually developed a method to use the benefits of it in most of the organizations. Fog computing can be apparent both in big data structures and large cloud systems, making reference to the growing complications in retrieving the data accurately. Fog computing is outspreading cloud computing by transporting computation on the advantage of network systems such as cell phone devices or fixed nodes with in-built data storage. Fog provides important points of improved abilities, strong security controls, and processes, establish data transmission capabilities carefully and in a flexible manner. This paper gives an overview of the connections and attributes for both Fog computing and cloud varies by outline, preparation, directions, and strategies for associations and clients. This also explains how Fog computing is flexible and provide better service for data processing by overwhelming low network bandwidth instead of moving whole data to the cloud platform.",
    "lastUpdated": "2019-03-24T18:16:42Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1904.04026v1"
  },
  {
    "title": "Cloud Service ranking using Checkpoint based Load balancing in real time scheduling of Cloud Computing",
    "author": [
      "Mohammad Riyaz Belgaum",
      "Safeeullah Soomro",
      "Zainab Alansari",
      "Muhammad Alam"
    ],
    "abstract": "Cloud computing has been gaining popularity in the recent years. Several studies are being proceeded to build cloud applications with exquisite quality based on users demands. In achieving the same, one of the applied criteria is checkpoint based load balancing in real time scheduling through which suitable cloud service is chosen from a group of cloud services candidates. Valuable information can be collected to rank the services within this checkpoint based load balancing. In order to attain ranking, different services are needed to be invoked in the cloud, which is time consuming and wastage of services invocation. To avoid the same, this chapter proposes an algorithm for predicting the ranks of different cloud services by using the values from previously offered services.",
    "lastUpdated": "2019-04-16T09:18:53Z",
    "category": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1905.03093v1"
  },
  {
    "title": "Adaptive Rate Allocation for View-Aware Point-Cloud Streaming",
    "author": [
      "Mohammad Hosseini"
    ],
    "abstract": "In the context of view-dependent point-cloud streaming in a scene, our rate allocation is \"adaptive\" in the sense that it priorities the point-cloud models depending on the camera view and the visibility of the objects and their distance as described. The algorithm delivers higher bitrate to the point-cloud models which are inside user's viewport, more likely for the user to look at, or are closer to the view camera or, while delivers lower quality level to the point-cloud models outside of a user's immediate viewport or farther away from the camera. For that purpose, we hereby explain the rate allocation problem within the context of multi-point-cloud streaming where multiple point-cloud models are aimed to be streamed to the target device, and propose a rate allocation heuristic algorithm to enable the adaptations within this context. To the best of our knowledge, this is the first work to mathematically model, and propose a rate allocation heuristic algorithm within the context of point-cloud streaming.",
    "lastUpdated": "2019-11-03T02:56:24Z",
    "category": [
      "cs.MM"
    ],
    "url": "http://arxiv.org/abs/1911.00812v1"
  },
  {
    "title": "Starling: A Scalable Query Engine on Cloud Function Services",
    "author": [
      "Matthew Perron",
      "Raul Castro Fernandez",
      "David DeWitt",
      "Samuel Madden"
    ],
    "abstract": "Much like on-premises systems, the natural choice for running database analytics workloads in the cloud is to provision a cluster of nodes to run a database instance. However, analytics workloads are often bursty or low volume, leaving clusters idle much of the time, meaning customers pay for compute resources even when unused. The ability of cloud function services, such as AWS Lambda or Azure Functions, to run small, fine granularity tasks make them appear to be a natural choice for query processing in such settings. But implementing an analytics system on cloud functions comes with its own set of challenges. These include managing hundreds of tiny stateless resource-constrained workers, handling stragglers, and shuffling data through opaque cloud services. In this paper we present Starling, a query execution engine built on cloud function services that employs number of techniques to mitigate these challenges, providing interactive query latency at a lower total cost than provisioned systems with low-to-moderate utilization. In particular, on a 1TB TPC-H dataset in cloud storage, Starling is less expensive than the best provisioned systems for workloads when queries arrive 1 minute apart or more. Starling also has lower latency than competing systems reading from cloud object stores and can scale to larger datasets.",
    "lastUpdated": "2019-11-26T18:03:16Z",
    "category": [
      "cs.DB"
    ],
    "url": "http://arxiv.org/abs/1911.11727v1"
  },
  {
    "title": "SampleNet: Differentiable Point Cloud Sampling",
    "author": [
      "Itai Lang",
      "Asaf Manor",
      "Shai Avidan"
    ],
    "abstract": "There is a growing number of tasks that work directly on point clouds. As the size of the point cloud grows, so do the computational demands of these tasks. A possible solution is to sample the point cloud first. Classic sampling approaches, such as farthest point sampling (FPS), do not consider the downstream task. A recent work showed that learning a task-specific sampling can improve results significantly. However, the proposed technique did not deal with the non-differentiability of the sampling operation and offered a workaround instead. We introduce a novel differentiable relaxation for point cloud sampling that approximates sampled points as a mixture of points in the primary input cloud. Our approximation scheme leads to consistently good results on classification and geometry reconstruction applications. We also show that the proposed sampling method can be used as a front to a point cloud registration network. This is a challenging task since sampling must be consistent across two different point clouds for a shared downstream task. In all cases, our approach outperforms existing non-learned and learned sampling alternatives. Our code is publicly available at https://github.com/itailang/SampleNet.",
    "lastUpdated": "2020-04-04T19:39:54Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1912.03663v2"
  },
  {
    "title": "Deep Learning for 3D Point Clouds: A Survey",
    "author": [
      "Yulan Guo",
      "Hanyun Wang",
      "Qingyong Hu",
      "Hao Liu",
      "Li Liu",
      "Mohammed Bennamoun"
    ],
    "abstract": "Point cloud learning has lately attracted increasing attention due to its wide applications in many areas, such as computer vision, autonomous driving, and robotics. As a dominating technique in AI, deep learning has been successfully used to solve various 2D vision problems. However, deep learning on point clouds is still in its infancy due to the unique challenges faced by the processing of point clouds with deep neural networks. Recently, deep learning on point clouds has become even thriving, with numerous methods being proposed to address different problems in this area. To stimulate future research, this paper presents a comprehensive review of recent progress in deep learning methods for point clouds. It covers three major tasks, including 3D shape classification, 3D object detection and tracking, and 3D point cloud segmentation. It also presents comparative results on several publicly available datasets, together with insightful observations and inspiring future research directions.",
    "lastUpdated": "2020-06-23T10:54:36Z",
    "category": [
      "cs.CV",
      "cs.LG",
      "cs.RO",
      "eess.IV"
    ],
    "url": "http://arxiv.org/abs/1912.12033v2"
  },
  {
    "title": "Engineering and Experimentally Benchmarking a Container-based Edge Computing System",
    "author": [
      "Francisco Carpio",
      "Marta Delgado",
      "Admela Jukan"
    ],
    "abstract": "While edge computing is envisioned to superbly serve latency sensitive applications, the implementation-based studies benchmarking its performance are few and far between. To address this gap, we engineer a modular edge cloud computing system architecture that is built on latest advances in containerization techniques, including Kafka, for data streaming, Docker, as application platform, and Firebase Cloud, as realtime database system. We benchmark the performance of the system in terms of scalability, resource utilization and latency by comparing three scenarios: cloud-only, edge-only and combined edge-cloud. The measurements show that edge-only solution outperforms other scenarios only when deployed with data located at one edge only, i.e., without edge computing wide data synchronization. In case of applications requiring data synchronization through the cloud, edge-cloud scales around a factor 10 times better than cloud-only, until certain number of concurrent users in the system, and above this point, cloud-only scales better. In terms of resource utilization, we observe that whereas the mean utilization increases linearly with the number of user requests, the maximum values for the memory and the network I/O heavily increase when with an increasing amount of data.",
    "lastUpdated": "2020-02-10T14:38:24Z",
    "category": [
      "cs.NI",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/2002.03805v1"
  },
  {
    "title": "PF-Net: Point Fractal Network for 3D Point Cloud Completion",
    "author": [
      "Zitian Huang",
      "Yikuan Yu",
      "Jiawen Xu",
      "Feng Ni",
      "Xinyi Le"
    ],
    "abstract": "In this paper, we propose a Point Fractal Network (PF-Net), a novel learning-based approach for precise and high-fidelity point cloud completion. Unlike existing point cloud completion networks, which generate the overall shape of the point cloud from the incomplete point cloud and always change existing points and encounter noise and geometrical loss, PF-Net preserves the spatial arrangements of the incomplete point cloud and can figure out the detailed geometrical structure of the missing region(s) in the prediction. To succeed at this task, PF-Net estimates the missing point cloud hierarchically by utilizing a feature-points-based multi-scale generating network. Further, we add up multi-stage completion loss and adversarial loss to generate more realistic missing region(s). The adversarial loss can better tackle multiple modes in the prediction. Our experiments demonstrate the effectiveness of our method for several challenging point cloud completion tasks.",
    "lastUpdated": "2020-03-01T05:40:21Z",
    "category": [
      "cs.CV",
      "cs.GR"
    ],
    "url": "http://arxiv.org/abs/2003.00410v1"
  },
  {
    "title": "Cloud Migration Process A Survey Evaluation Framework and Open Challenges",
    "author": [
      "Mahdi Fahmideh",
      "Graham Low",
      "Ghassan Beydoun",
      "Farhad Daneshgar"
    ],
    "abstract": "Moving mission-oriented enterprise applications to cloud environments is a major IT strategic task and requires a systematic approach. The foci of this paper are to review and examine existing cloud migration approaches from the process models perspective. To this aim, an evaluation framework is proposed and used to analyse and compare existing approaches for highlighting their features, similarities, and key differences. The survey distills the state of the art in cloud migration research and makes a rich inventory of important activities, recommendations, techniques, and concerns that are commonly involved in the migration process in one place. This enables academia and practitioners in the cloud computing community to get an overarching view of the cloud migration process. Furthermore, the survey identifies a number challenges that have not been yet addressed by existing approaches, developing opportunities for further research endeavors.",
    "lastUpdated": "2020-04-17T02:56:13Z",
    "category": [
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/2004.10725v1"
  },
  {
    "title": "Research Challenges and Prospective Business Impacts of Cloud Computing: A Survey",
    "author": [
      "Amin Keshavarzi",
      "Abolfazl T. Haghighat",
      "Mahdi Bohlouli"
    ],
    "abstract": "In today's information technology (IT) era, a major part of the costs is being spent on computational needs. Enterprises are in efforts to increase their Return on Investment (ROI) and individuals are trying to reduce their costs. In this regard, cloud computing which emerges as a fifth utility can reduce costs and enhance performance of IT solutions. A large number of companies and institutions are dealing with cloud related issues as a provider or user. Due to the fact that cloud computing services have been proposed in recent years, organizations and individuals face with various challenges and problems such as how to migrate applications and software platforms into cloud and how to ensure security of migrated applications and etc. Given that many different definitions of cloud computing is presented in many publications and projects, a concrete and clear definition for cloud computing considering its characteristics, models and services is provided in this paper. In addition, current challenges and open issues in cloud computing is discussed in details and further recommendations and roadmaps for scientific activities and researches as well as potentials for improvements in this area from scientific and commercial points of view are given in this paper.",
    "lastUpdated": "2020-04-27T03:22:35Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/2005.01475v1"
  },
  {
    "title": "Augmented Semantic Signatures of Airborne LiDAR Point Clouds for Comparison",
    "author": [
      "Jaya Sreevalsan-Nair",
      "Pragyan Mohapatra"
    ],
    "abstract": "LiDAR point clouds provide rich geometric information, which is particularly useful for the analysis of complex scenes of urban regions. Finding structural and semantic differences between two different three-dimensional point clouds, say, of the same region but acquired at different time instances is an important problem. A comparison of point clouds involves computationally expensive registration and segmentation. We are interested in capturing the relative differences in the geometric uncertainty and semantic content of the point cloud without the registration process. Hence, we propose an orientation-invariant geometric signature of the point cloud, which integrates its probabilistic geometric and semantic classifications. We study different properties of the geometric signature, which are an image-based encoding of geometric uncertainty and semantic content. We explore different metrics to determine differences between these signatures, which in turn compare point clouds without performing point-to-point registration. Our results show that the differences in the signatures corroborate with the geometric and semantic differences of the point clouds.",
    "lastUpdated": "2020-08-08T04:32:43Z",
    "category": [
      "cs.CV",
      "cs.GR",
      "eess.IV",
      "68U05, 68U10, 68U20, 65C50",
      "G.1.3; I.4.10; I.4.8; J.2"
    ],
    "url": "http://arxiv.org/abs/2005.02152v2"
  },
  {
    "title": "A Dynamical Perspective on Point Cloud Registration",
    "author": [
      "Heng Yang"
    ],
    "abstract": "We provide a dynamical perspective on the classical problem of 3D point cloud registration with correspondences. A point cloud is considered as a rigid body consisting of particles. The problem of registering two point clouds is formulated as a dynamical system, where the dynamic model point cloud translates and rotates in a viscous environment towards the static scene point cloud, under forces and torques induced by virtual springs placed between each pair of corresponding points. We first show that the potential energy of the system recovers the objective function of the maximum likelihood estimation. We then adopt Lyapunov analysis, particularly the invariant set theorem, to analyze the rigid body dynamics and show that the system globally asymptotically tends towards the set of equilibrium points, where the globally optimal registration solution lies in. We conjecture that, besides the globally optimal equilibrium point, the system has either three or infinite \"spurious\" equilibrium points, and these spurious equilibria are all locally unstable. The case of three spurious equilibria corresponds to generic shape of the point cloud, while the case of infinite spurious equilibria happens when the point cloud exhibits symmetry. Therefore, simulating the dynamics with random perturbations guarantees to obtain the globally optimal registration solution. Numerical experiments support our analysis and conjecture.",
    "lastUpdated": "2020-05-07T01:00:29Z",
    "category": [
      "cs.CV",
      "math.DS",
      "math.OC"
    ],
    "url": "http://arxiv.org/abs/2005.03190v1"
  },
  {
    "title": "Skedulix: Hybrid Cloud Scheduling for Cost-Efficient Execution of Serverless Applications",
    "author": [
      "Anirban Das",
      "Andrew Leaf",
      "Carlos A. Varela",
      "Stacy Patterson"
    ],
    "abstract": "We present a framework for scheduling multifunction serverless applications over a hybrid public-private cloud. A set of serverless jobs is input as a batch, and the objective is to schedule function executions over the hybrid platform to minimize the cost of public cloud use, while completing all jobs by a specified deadline. As this scheduling problem is NP-Hard, we propose a greedy algorithm that dynamically determines both the order and placement of each function execution using predictive models of function execution time and network latencies. We present a prototype implementation of our framework that uses AWS Lambda and OpenFaaS, for the public and private cloud, respectively. We evaluate our prototype in live experiments using a mixture of compute and I/O heavy serverless applications. Our results show that our framework can achieve a speedup in batch processing of up to 1.92 times that of an approach that uses only the private cloud, at 40.5% the cost of an approach that uses only the public cloud.",
    "lastUpdated": "2020-06-05T22:27:42Z",
    "category": [
      "cs.DC",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/2006.03720v1"
  },
  {
    "title": "Free-boundary conformal parameterization of point clouds",
    "author": [
      "Yechen Liu",
      "Gary P. T. Choi",
      "Lok Ming Lui"
    ],
    "abstract": "With the advancement in 3D scanning technology, there has been a surge of interest in the use of point clouds in science and engineering. To facilitate the computations and analyses of point clouds, prior works have considered parameterizing them onto some simple planar domains with a fixed boundary shape such as a unit circle or a rectangle. However, the geometry of the fixed shape may lead to some undesirable distortion in the parameterization. It is therefore more natural to consider free-boundary conformal parameterizations of point clouds, which minimize the local geometric distortion of the mapping without constraining the overall shape. In this work, we propose a novel approximation scheme of the Laplace--Beltrami operator on point clouds and utilize it for developing a free-boundary conformal parameterization method for disk-type point clouds. With the aid of the free-boundary conformal parameterization, high-quality point cloud meshing can be easily achieved. Furthermore, we show that using the idea of conformal welding in complex analysis, the point cloud conformal parameterization can be computed in a divide-and-conquer manner. Experimental results are presented to demonstrate the effectiveness of the proposed method.",
    "lastUpdated": "2020-10-29T07:48:58Z",
    "category": [
      "cs.CG",
      "cs.GR",
      "cs.NA",
      "math.CV",
      "math.DG",
      "math.NA"
    ],
    "url": "http://arxiv.org/abs/2010.15399v1"
  },
  {
    "title": "End-to-End 3D Point Cloud Learning for Registration Task Using Virtual Correspondences",
    "author": [
      "Zhijian~Qiao",
      "Zhe~Liu",
      "Chuanzhe~Suo",
      "Huanshu~Wei",
      "Zhuowen~Shen",
      "Hesheng~Wang"
    ],
    "abstract": "3D Point cloud registration is still a very challenging topic due to the difficulty in finding the rigid transformation between two point clouds with partial correspondences, and it's even harder in the absence of any initial estimation information. In this paper, we present an end-to-end deep-learning based approach to resolve the point cloud registration problem. Firstly, the revised LPD-Net is introduced to extract features and aggregate them with the graph network. Secondly, the self-attention mechanism is utilized to enhance the structure information in the point cloud and the cross-attention mechanism is designed to enhance the corresponding information between the two input point clouds. Based on which, the virtual corresponding points can be generated by a soft pointer based method, and finally, the point cloud registration problem can be solved by implementing the SVD method. Comparison results in ModelNet40 dataset validate that the proposed approach reaches the state-of-the-art in point cloud registration tasks and experiment resutls in KITTI dataset validate the effectiveness of the proposed approach in real applications.",
    "lastUpdated": "2020-11-30T06:55:05Z",
    "category": [
      "cs.CV",
      "cs.RO"
    ],
    "url": "http://arxiv.org/abs/2011.14579v1"
  },
  {
    "title": "WedgeChain: A Trusted Edge-Cloud Store With Asynchronous (Lazy) Trust",
    "author": [
      "Faisal Nawab"
    ],
    "abstract": "We propose WedgeChain, a data store that spans both edge and cloud nodes (an edge-cloud system). WedgeChain consists of a logging layer and a data indexing layer. In this study, we encounter two challenges: (1) edge nodes are untrusted and potentially malicious, and (2) edge-cloud coordination is expensive. WedgeChain tackles these challenges by the following proposals: (1) Lazy (asynchronous) certification: where data is committed at the untrusted edge and then lazily certified at the cloud node. This lazy certification method takes advantage of the observation that an untrusted edge node is unlikely to act maliciously if it knows it will be detected (and punished) eventually. Our lazy certification method guarantees that malicious acts (i.e., lying) are eventually detected. (2) Data-free certification: our lazy certification method only needs to send digests of data to the cloud, instead of sending all data to the cloud, which enables saving network and cloud resources and reduce costs. (3) LSMerkle: we extend a trusted index (mLSM) to enable indexing data at the edge while utilizing lazy and data-free certification.",
    "lastUpdated": "2020-12-03T20:50:22Z",
    "category": [
      "cs.DB"
    ],
    "url": "http://arxiv.org/abs/2012.02258v1"
  },
  {
    "title": "Cloud detection machine learning algorithms for PROBA-V",
    "author": [
      "Luis Gómez-Chova",
      "Gonzalo Mateo-García",
      "Jordi Muñoz-Marí",
      "Gustau Camps-Valls"
    ],
    "abstract": "This paper presents the development and implementation of a cloud detection algorithm for Proba-V. Accurate and automatic detection of clouds in satellite scenes is a key issue for a wide range of remote sensing applications. With no accurate cloud masking, undetected clouds are one of the most significant sources of error in both sea and land cover biophysical parameter retrieval. The objective of the algorithms presented in this paper is to detect clouds accurately providing a cloud flag per pixel. For this purpose, the method exploits the information of Proba-V using statistical machine learning techniques to identify the clouds present in Proba-V products. The effectiveness of the proposed method is successfully illustrated using a large number of real Proba-V images.",
    "lastUpdated": "2020-12-09T18:23:59Z",
    "category": [
      "physics.ao-ph",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2012.10396v1"
  },
  {
    "title": "MG-SAGC: A multiscale graph and its self-adaptive graph convolution network for 3D point clouds",
    "author": [
      "Bo Wu",
      "Bo Lang"
    ],
    "abstract": "To enhance the ability of neural networks to extract local point cloud features and improve their quality, in this paper, we propose a multiscale graph generation method and a self-adaptive graph convolution method. First, we propose a multiscale graph generation method for point clouds. This approach transforms point clouds into a structured multiscale graph form that supports multiscale analysis of point clouds in the scale space and can obtain the dimensional features of point cloud data at different scales, thus making it easier to obtain the best point cloud features. Because traditional convolutional neural networks are not applicable to graph data with irregular vertex neighborhoods, this paper presents an sef-adaptive graph convolution kernel that uses the Chebyshev polynomial to fit an irregular convolution filter based on the theory of optimal approximation. In this paper, we adopt max pooling to synthesize the features of different scale maps and generate the point cloud features. In experiments conducted on three widely used public datasets, the proposed method significantly outperforms other state-of-the-art models, demonstrating its effectiveness and generalizability.",
    "lastUpdated": "2020-12-23T01:58:41Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2012.12445v1"
  },
  {
    "title": "Graph kernels between point clouds",
    "author": [
      "Francis Bach"
    ],
    "abstract": "Point clouds are sets of points in two or three dimensions. Most kernel methods for learning on sets of points have not yet dealt with the specific geometrical invariances and practical constraints associated with point clouds in computer vision and graphics. In this paper, we present extensions of graph kernels for point clouds, which allow to use kernel methods for such ob jects as shapes, line drawings, or any three-dimensional point clouds. In order to design rich and numerically efficient kernels with as few free parameters as possible, we use kernels between covariance matrices and their factorizations on graphical models. We derive polynomial time dynamic programming recursions and present applications to recognition of handwritten digits and Chinese characters from few training examples.",
    "lastUpdated": "2007-12-20T13:06:50Z",
    "category": [
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/0712.3402v1"
  },
  {
    "title": "An Overview of the Security Concerns in Enterprise Cloud Computing",
    "author": [
      "Anthony Bisong",
      "Syed",
      "M. Rahman"
    ],
    "abstract": "Deploying cloud computing in an enterprise infrastructure bring significant security concerns. Successful implementation of cloud computing in an enterprise requires proper planning and understanding of emerging risks, threats, vulnerabilities, and possible countermeasures. We believe enterprise should analyze the company/organization security risks, threats, and available countermeasures before adopting this technology. In this paper, we have discussed security risks and concerns in cloud computing and enlightened steps that an enterprise can take to reduce security risks and protect their resources. We have also explained cloud computing strengths/benefits, weaknesses, and applicable areas in information risk management.",
    "lastUpdated": "2011-01-28T19:49:30Z",
    "category": [
      "cs.CR",
      "cs.CY",
      "cs.NI",
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/1101.5613v1"
  },
  {
    "title": "An Ontology based System for Cloud Infrastructure Services Discovery",
    "author": [
      "Miranda Zhang",
      "Rajiv Ranjan",
      "Armin Haller",
      "Dimitrios Georgakopoulos",
      "Michael Menzel",
      "Surya Nepal"
    ],
    "abstract": "The Cloud infrastructure services landscape advances steadily leaving users in the agony of choice. As a result, Cloud service identification and discovery remains a hard problem due to different service descriptions, non standardised naming conventions and heterogeneous types and features of Cloud services. In this paper, we present an OWL based ontology, the Cloud Computing Ontology (CoCoOn) that defines functional and non functional concepts, attributes and relations of infrastructure services. We also present a system...",
    "lastUpdated": "2012-12-01T20:39:22Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1212.0156v1"
  },
  {
    "title": "Current Services In Cloud Computing: A Survey",
    "author": [
      "Mohamed Magdy Mosbah",
      "Hany Soliman",
      "Mohamad Abou El-Nasr"
    ],
    "abstract": "Due to the fast development of the Cloud Computing technologies, the rapid increase of cloud services are became very remarkable. The fact of integration of these services with many of the modern enterprises cannot be ignored. Microsoft, Google, Amazon, SalesForce.com and the other leading IT companies are entered the field of developing these services. This paper presents a comprehensive survey of current cloud services, which are divided into eleven categories. Also the most famous providers for these services are listed. Finally, the Deployment Models of Cloud Computing are mentioned and briefly discussed.",
    "lastUpdated": "2013-11-13T21:59:21Z",
    "category": [
      "cs.OH"
    ],
    "url": "http://arxiv.org/abs/1311.3319v1"
  },
  {
    "title": "Watchword-Oriented and Time-Stamped Algorithms for Tamper-Proof Cloud Provenance Cognition",
    "author": [
      "Asif Imran",
      "Nadia Nahar",
      "Kazi Sakib"
    ],
    "abstract": "Provenance is derivative journal information about the origin and activities of system data and processes. For a highly dynamic system like the cloud, provenance can be accurately detected and securely used in cloud digital forensic investigation activities. This paper proposes watchword oriented provenance cognition algorithm for the cloud environment. Additionally time-stamp based buffer verifying algorithm is proposed for securing the access to the detected cloud provenance. Performance analysis of the novel algorithms proposed here yields a desirable detection rate of 89.33% and miss rate of 8.66%. The securing algorithm successfully rejects 64% of malicious requests, yielding a cumulative frequency of 21.43 for MR.",
    "lastUpdated": "2014-09-19T08:33:15Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1409.5546v1"
  },
  {
    "title": "Applicability of DUKPT Key Management Scheme to Cloud Wallet and other Mobile Payments",
    "author": [
      "Amal Saha",
      "Sugata Sanyal"
    ],
    "abstract": "After discussing the concept of DUKPT based symmetric encryption key management (e.g., for 3DES) and definition of cloud or remote wallet, the paper analyses applicability of DUKPT to different use cases like mobile banking, NFC payment using EMV contactless card and mobile based EMV card emulation, web browser based transaction and cloud or remote wallet. Cloud wallet is an emerging payment method and is gaining momentum very fast. Anticipating that the wallet product managers and security specialists may face these questions from different stakeholders, the authors have addressed applicability of DUKPT to cloud wallet use case quite elaborately. As per knowledge of the authors, this topic has been analysed and discussed for the first time.",
    "lastUpdated": "2014-12-08T06:48:56Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1412.2463v1"
  },
  {
    "title": "Recent Developments in Cloud Based Systems: State of Art",
    "author": [
      "Mansaf Alam",
      "Kashish Ara Shakil"
    ],
    "abstract": "Cloud computing is the new buzzword in the head of the techies round the clock these days. The importance and the different applications of cloud computing are overwhelming and thus, it is a topic of huge significance. It provides several astounding features like Multitenancy, on demand service, pay per use etc. This manuscript presents an exhaustive survey on cloud computing technology and potential research issues in cloud computing that needs to be addressed.",
    "lastUpdated": "2015-01-05T11:07:13Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1501.01323v1"
  },
  {
    "title": "A Distributed Secure Outsourcing Scheme for Solving Linear Algebraic Equations in Ad Hoc Clouds",
    "author": [
      "Wenlong Shen",
      "Bo Yin",
      "Xianghui Cao",
      "Yu Cheng"
    ],
    "abstract": "The emerging ad hoc clouds form a new cloud computing paradigm by leveraging untapped local computation and storage resources. An important application application over ad hoc clouds is outsourcing computationally intensive problems to nearby cloud agents to solve in a distributed manner.",
    "lastUpdated": "2016-08-29T03:19:25Z",
    "category": [
      "cs.CR",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1504.01042v4"
  },
  {
    "title": "A Comparative Study of Homomorphic and Searchable Encryption Schemes for Cloud Computing",
    "author": [
      "B. T. Prasanna",
      "C. B. Akki"
    ],
    "abstract": "Cloud computing is a popular distributed network and utility model based technology. Since in cloud the data is outsourced to third parties, the protection of confidentiality and privacy of user data becomes important. Different methods for securing the data in cloud have been proposed by researchers including but not limited to Oblivious RAM, Searchable Encryption, Functional Encryption, Homomorphic Encryption etc. This paper focuses on Searchable and Homomorphic Encryption methods. Finally, a comparative study of these two efficient cloud cryptographic methods has been carried out and given here.",
    "lastUpdated": "2015-05-13T07:29:25Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1505.03263v1"
  },
  {
    "title": "Evolution of as-a-Service Era in Cloud",
    "author": [
      "Sugam Sharma"
    ],
    "abstract": "Today, a paradigm shift is being observed in science, where the focus is gradually shifting toward the cloud environments to obtain appropriate, robust and affordable services to deal with Big Data challenges (Sharma et al. 2014, 2015a, 2015b). Cloud computing avoids any need to locally maintain the overly scaled computing infrastructure that include not only dedicated space, but the expensive hardware and software also. In this paper, we study the evolution of as-a-Service modalities, stimulated by cloud computing, and explore the most complete inventory of new members beyond traditional cloud computing stack.",
    "lastUpdated": "2015-06-29T17:39:39Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1507.00939v1"
  },
  {
    "title": "Graph-based denoising for time-varying point clouds",
    "author": [
      "Yann Schoenenberger",
      "Johan Paratte",
      "Pierre Vandergheynst"
    ],
    "abstract": "Noisy 3D point clouds arise in many applications. They may be due to errors when constructing a 3D model from images or simply to imprecise depth sensors. Point clouds can be given geometrical structure using graphs created from the similarity information between points. This paper introduces a technique that uses this graph structure and convex optimization methods to denoise 3D point clouds. A short discussion presents how those methods naturally generalize to time-varying inputs such as 3D point cloud time series.",
    "lastUpdated": "2015-11-16T10:34:25Z",
    "category": [
      "cs.CV",
      "cs.GR",
      "I.5.4"
    ],
    "url": "http://arxiv.org/abs/1511.04902v1"
  },
  {
    "title": "Correlating Satellite Cloud Cover with Sky Cameras",
    "author": [
      "Shilpa Manandhar",
      "Soumyabrata Dev",
      "Yee Hui Lee",
      "Yu Song Meng"
    ],
    "abstract": "The role of clouds is manifold in understanding the various events in the atmosphere, and also in studying the radiative balance of the earth. The conventional manner of such cloud analysis is performed mainly via satellite images. However, because of its low temporal- and spatial- resolutions, ground-based sky cameras are now getting popular. In this paper, we study the relation between the cloud cover obtained from MODIS images, with the coverage obtained from ground-based sky cameras. This will help us to better understand cloud formation in the atmosphere - both from satellite images and ground-based observations.",
    "lastUpdated": "2017-08-24T17:54:57Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1709.05283v1"
  },
  {
    "title": "Short-term prediction of localized cloud motion using ground-based sky imagers",
    "author": [
      "Soumyabrata Dev",
      "Florian M. Savoy",
      "Yee Hui Lee",
      "Stefan Winkler"
    ],
    "abstract": "Fine-scale short-term cloud motion prediction is needed for several applications, including solar energy generation and satellite communications. In tropical regions such as Singapore, clouds are mostly formed by convection; they are very localized, and evolve quickly. We capture hemispherical images of the sky at regular intervals of time using ground-based cameras. They provide a high resolution and localized cloud images. We use two successive frames to compute optical flow and predict the future location of clouds. We achieve good prediction accuracy for a lead time of up to 5 minutes.",
    "lastUpdated": "2016-10-21T04:28:35Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1610.06666v1"
  },
  {
    "title": "DDoS Attacks: Tools, Mitigation Approaches, and Probable Impact on Private Cloud Environment",
    "author": [
      "Rup Kumar Deka",
      "Dhruba Kumar Bhattacharyya",
      "Jugal Kumar Kalita"
    ],
    "abstract": "The future of the Internet is predicted to be on the cloud, resulting in more complex and more intensive computing, but possibly also a more insecure digital world. The presence of a large amount of resources organized densely is a key factor in attracting DDoS attacks. Such attacks are arguably more dangerous in private individual clouds with limited resources. This paper discusses several prominent approaches introduced to counter DDoS attacks in private clouds. We also discuss issues and challenges to mitigate DDoS attacks in private clouds.",
    "lastUpdated": "2017-10-24T07:24:43Z",
    "category": [
      "cs.NI",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1710.08628v1"
  },
  {
    "title": "Constructing Locally Dense Point Clouds Using OpenSfM and ORB-SLAM2",
    "author": [
      "Fouad Amer",
      "Zixu Zhao",
      "Siwei Tang",
      "Wilfredo Torres"
    ],
    "abstract": "This paper aims at finding a method to register two different point clouds constructed by ORB-SLAM2 and OpenSfM. To do this, we post some tags with unique textures in the scene and take videos and photos of that area. Then we take short videos of only the tags to extract their features. By matching the ORB feature of the tags with their corresponding features in the scene, it is then possible to localize the position of these tags both in point clouds constructed by ORB-SLAM2 and OpenSfM. Thus, the best transformation matrix between two point clouds can be calculated, and the two point clouds can be aligned.",
    "lastUpdated": "2018-04-23T05:07:51Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1804.08243v1"
  },
  {
    "title": "Mechanical Engineers Training in Using Cloud and Mobile Services in Professional Activity",
    "author": [
      "Maryna Rassovytska",
      "Andrii Striuk"
    ],
    "abstract": "The purpose of this article is to identify mobile and cloud services of mechanical engineers professional activity and the principles of their use in higher technical education. There have been defined the criteria for evaluation of the tools for edu-cational and professional activities. On the basis of this criteria, more than 30 var-ious cloud services and mobile applications have been analyzed. The analysis has shown that the use of Autodesk cloud services and their integration with cloud services Google is appropriate for professional and practical training of special-ists in applied mechanics, and it promotes an effective development of mechanical engineers ICT competence. The learning tools integrated system model was pro-posed.",
    "lastUpdated": "2018-07-01T11:11:12Z",
    "category": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1807.00313v1"
  },
  {
    "title": "Iso-parametric tool path planning for point clouds",
    "author": [
      "Qiang Zou",
      "Jibin Zhao"
    ],
    "abstract": "The computational consuming and non-robust reconstruction from point clouds to either meshes or spline surfaces motivates the direct tool path planning for point clouds. In this paper, a novel approach for planning iso-parametric tool path from a point cloud is presented. The planning depends on the parameterization of point clouds. Accordingly, a conformal map is employed to build the parameterization which leads to a significant simplification of computing tool path parameters and boundary conformed paths. Then, Tool path is generated through linear interpolation with the forward and side step computed against specified chord deviation and scallop height, respectively. Experimental results are given to illustrate effectiveness of the proposed methods.",
    "lastUpdated": "2018-11-15T21:48:46Z",
    "category": [
      "cs.GR"
    ],
    "url": "http://arxiv.org/abs/1811.06600v1"
  },
  {
    "title": "Multi-label Cloud Segmentation Using a Deep Network",
    "author": [
      "Soumyabrata Dev",
      "Shilpa Manandhar",
      "Yee Hui Lee",
      "Stefan Winkler"
    ],
    "abstract": "Different empirical models have been developed for cloud detection. There is a growing interest in using the ground-based sky/cloud images for this purpose. Several methods exist that perform binary segmentation of clouds. In this paper, we propose to use a deep learning architecture (U-Net) to perform multi-label sky/cloud image segmentation. The proposed approach outperforms recent literature by a large margin.",
    "lastUpdated": "2019-03-15T14:09:49Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1903.06562v1"
  },
  {
    "title": "Legal Concerns and Challenges in Cloud Computing",
    "author": [
      "Sundar Krishnan",
      "Lei Chen"
    ],
    "abstract": "Legal issues have risen with the changing landscape of computing, especially when the service, data and infrastructure is not owned by the user. With the Cloud, the question arises as to who is in the possession of the data. The Cloud provider can be considered as a legal custodian, owner or possessor of the data thereby causing complexities in legal matters around trademark infringement, privacy of users and their data, abuse and security. By introducing Cloud design focusing on privacy, legal as a service on a Cloud and service provider accountability, users can expect the service providers to be accountable for privacy and data in addition to their regular SLAs.",
    "lastUpdated": "2019-05-26T20:02:59Z",
    "category": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1905.10868v1"
  },
  {
    "title": "Forecasting Short-term Dynamics of Fair-Weather Cumuli using Dynamic Mode Decomposition",
    "author": [
      "Jeff Manning",
      "Ross Baldick"
    ],
    "abstract": "Application of Dynamic Mode Decomposition to clear-sky index forecasting of shadowing effects of convective fair-weather cumulus clouds is presented. Cloud dynamics are captured by sequences of visible-light photographic video frames. This method can be more easily applied to the modeling of cloud evolution than traditional fluid-based methods, and can enhance existing frozen-cloud advection methods. Its use is demonstrated for an actual fair-weather cumulus cloud image sequence and compared to an advection-only forecast. It is concluded that the method shows promise for very short-term clear-sky index forecasting for up to seven minute horizons.",
    "lastUpdated": "2019-07-30T14:26:26Z",
    "category": [
      "cs.CE",
      "65Z05",
      "J.2"
    ],
    "url": "http://arxiv.org/abs/1907.12980v1"
  },
  {
    "title": "Experiential probabilistic assessment of cloud services",
    "author": [
      "Mahdi Fahmideh",
      "Ghassan Beydoun",
      "Graham Low"
    ],
    "abstract": "Substantial difficulties in adopting cloud services are often encountered during upgrades of existing software systems. A reliable early stage analysis can facilitate an informed decision process of moving systems to cloud platforms. It can also mitigate risks against system quality goals. Towards this, we propose an interactive goal reasoning approach which is supported by a probabilistic layer for the precise analysis of cloud migration risks to improve the reliability of risk control. The approach is illustrated using a commercial scenario of integrating a digital document processing system to Microsoft Azure cloud platform.",
    "lastUpdated": "2020-04-16T10:46:58Z",
    "category": [
      "cs.DC",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/2004.10858v1"
  },
  {
    "title": "Anomaly Detection in Cloud Components",
    "author": [
      "Mohammad Saiful Islam",
      "Andriy Miranskyy"
    ],
    "abstract": "Cloud platforms, under the hood, consist of a complex inter-connected stack of hardware and software components. Each of these components can fail which may lead to an outage. Our goal is to improve the quality of Cloud services through early detection of such failures by analyzing resource utilization metrics. We tested Gated-Recurrent-Unit-based autoencoder with a likelihood function to detect anomalies in various multi-dimensional time series and achieved high performance.",
    "lastUpdated": "2020-08-07T14:34:41Z",
    "category": [
      "cs.SE",
      "cs.DC",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2005.08739v2"
  },
  {
    "title": "Cloudbus Toolkit for Market-Oriented Cloud Computing",
    "author": [
      "Rajkumar Buyya",
      "Suraj Pandey",
      "Christian Vecchiola"
    ],
    "abstract": "This keynote paper: (1) presents the 21st century vision of computing and identifies various IT paradigms promising to deliver computing as a utility; (2) defines the architecture for creating market-oriented Clouds and computing atmosphere by leveraging technologies such as virtual machines; (3) provides thoughts on market-based resource management strategies that encompass both customer-driven service management and computational risk management to sustain SLA-oriented resource allocation; (4) presents the work carried out as part of our new Cloud Computing initiative, called Cloudbus: (i) Aneka, a Platform as a Service software system containing SDK (Software Development Kit) for construction of Cloud applications and deployment on private or public Clouds, in addition to supporting market-oriented resource management; (ii) internetworking of Clouds for dynamic creation of federated computing environments for scaling of elastic applications; (iii) creation of 3rd party Cloud brokering services for building content delivery networks and e-Science applications and their deployment on capabilities of IaaS providers such as Amazon along with Grid mashups; (iv) CloudSim supporting modelling and simulation of Clouds for performance studies; (v) Energy Efficient Resource Allocation Mechanisms and Techniques for creation and management of Green Clouds; and (vi) pathways for future research.",
    "lastUpdated": "2009-10-11T06:26:29Z",
    "category": [
      "cs.DC",
      "C.2.4"
    ],
    "url": "http://arxiv.org/abs/0910.1974v1"
  },
  {
    "title": "PC-Cluster based Storage System Architecture for Cloud Storage",
    "author": [
      "Tin Tin Yee",
      "Thinn Thu Naing"
    ],
    "abstract": "Design and architecture of cloud storage system plays a vital role in cloud computing infrastructure in order to improve the storage capacity as well as cost effectiveness. Usually cloud storage system provides users to efficient storage space with elasticity feature. One of the challenges of cloud storage system is difficult to balance the providing huge elastic capacity of storage and investment of expensive cost for it. In order to solve this issue in the cloud storage infrastructure, low cost PC cluster based storage server is configured to be activated for large amount of data to provide cloud users. Moreover, one of the contributions of this system is proposed an analytical model using M/M/1 queuing network model, which is modeled on intended architecture to provide better response time, utilization of storage as well as pending time when the system is running. According to the analytical result on experimental testing, the storage can be utilized more than 90% of storage space. In this paper, two parts have been described such as (i) design and architecture of PC cluster based cloud storage system. On this system, related to cloud applications, services configurations are explained in detailed. (ii) Analytical model has been enhanced to be increased the storage utilization on the target architecture.",
    "lastUpdated": "2011-12-09T06:58:13Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1112.2025v1"
  },
  {
    "title": "Market-Oriented Cloud Computing and the Cloudbus Toolkit",
    "author": [
      "Rajkumar Buyya",
      "Suraj Pandey",
      "Christian Vecchiola"
    ],
    "abstract": "Cloud computing has penetrated the Information Technology industry deep enough to influence major companies to adopt it into their mainstream business. A strong thrust on the use of virtualization technology to realize Infrastructure-as-a-Service (IaaS) has led enterprises to leverage subscription-oriented computing capabilities of public Clouds for hosting their application services. In parallel, research in academia has been investigating transversal aspects such as security, software frameworks, quality of service, and standardization. We believe that the complete realization of the Cloud computing vision will lead to the introduction of a virtual market where Cloud brokers, on behalf of end users, are in charge of selecting and composing the services advertised by different Cloud vendors. In order to make this happen, existing solutions and technologies have to be redesigned and extended from a market-oriented perspective and integrated together, giving rise to what we term Market-Oriented Cloud Computing. In this paper, we will assess the current status of Cloud computing by providing a reference model, discuss the challenges that researchers and IT practitioners are facing and will encounter in the near future, and present the approach for solving them from the perspective of the Cloudbus toolkit, which comprises of a set of technologies geared towards the realization of Market Oriented Cloud Computing vision. We provide experimental results demonstrating market-oriented resource provisioning and brokering within a Cloud and across multiple distributed resources. We also include an application illustrating the hosting of ECG analysis as SaaS on Amazon IaaS (EC2 and S3) services.",
    "lastUpdated": "2012-03-23T08:50:57Z",
    "category": [
      "cs.DC",
      "D.4.7"
    ],
    "url": "http://arxiv.org/abs/1203.5196v1"
  },
  {
    "title": "Cloud Computing Security in Business Information Systems",
    "author": [
      "Sasko Ristov",
      "Marjan Gusev",
      "Magdalena Kostoska"
    ],
    "abstract": "Cloud computing providers' and customers' services are not only exposed to existing security risks, but, due to multi-tenancy, outsourcing the application and data, and virtualization, they are exposed to the emergent, as well. Therefore, both the cloud providers and customers must establish information security system and trustworthiness each other, as well as end users. In this paper we analyze main international and industrial standards targeting information security and their conformity with cloud computing security challenges. We evaluate that almost all main cloud service providers (CSPs) are ISO 27001:2005 certified, at minimum. As a result, we propose an extension to the ISO 27001:2005 standard with new control objective about virtualization, to retain generic, regardless of company's type, size and nature, that is, to be applicable for cloud systems, as well, where virtualization is its baseline. We also define a quantitative metric and evaluate the importance factor of ISO 27001:2005 control objectives if customer services are hosted on-premise or in cloud. The conclusion is that obtaining the ISO 27001:2005 certificate (or if already obtained) will further improve CSP and CC information security systems, and introduce mutual trust in cloud services but will not cover all relevant issues. In this paper we also continue our efforts in business continuity detriments cloud computing produces, and propose some solutions that mitigate the risks.",
    "lastUpdated": "2012-04-05T08:08:04Z",
    "category": [
      "cs.CR",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1204.1140v1"
  },
  {
    "title": "A threshold secure data sharing scheme for federated clouds",
    "author": [
      "K. Venkataramana",
      "M. Padmavathamma"
    ],
    "abstract": "Cloud computing allows users to view computing in a new direction, as it uses the existing technologies to provide better IT services at low-cost. To offer high QOS to customers according SLA, cloud services broker or cloud service provider uses individual cloud providers that work collaboratively to form a federation of clouds. It is required in applications like Real-time online interactive applications, weather research and forecasting etc., in which the data and applications are complex and distributed. In these applications secret data should be shared, so secure data sharing mechanism is required in Federated clouds to reduce the risk of data intrusion, the loss of service availability and to ensure data integrity. So In this paper we have proposed zero knowledge data sharing scheme where Trusted Cloud Authority (TCA) will control federated clouds for data sharing where the secret to be exchanged for computation is encrypted and retrieved by individual cloud at the end. Our scheme is based on the difficulty of solving the Discrete Logarithm problem (DLOG) in a finite abelian group of large prime order which is NP-Hard. So our proposed scheme provides data integrity in transit, data availability when one of host providers are not available during the computation.",
    "lastUpdated": "2012-09-12T13:44:48Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1209.2614v1"
  },
  {
    "title": "The Case for Cloud Service Trustmarks and Assurance-as-a-Service",
    "author": [
      "Theo Lynn",
      "Philip Healy",
      "Richard McClatchey",
      "John Morrison",
      "Claus Pahl",
      "Brian Lee"
    ],
    "abstract": "Cloud computing represents a significant economic opportunity for Europe. However, this growth is threatened by adoption barriers largely related to trust. This position paper examines trust and confidence issues in cloud computing and advances a case for addressing them through the implementation of a novel trustmark scheme for cloud service providers. The proposed trustmark would be both active and dynamic featuring multi-modal information about the performance of the underlying cloud service. The trustmarks would be informed by live performance data from the cloud service provider, or ideally an independent third-party accountability and assurance service that would communicate up-to-date information relating to service performance and dependability. By combining assurance measures with a remediation scheme, cloud service providers could both signal dependability to customers and the wider marketplace and provide customers, auditors and regulators with a mechanism for determining accountability in the event of failure or non-compliance. As a result, the trustmarks would convey to consumers of cloud services and other stakeholders that strong assurance and accountability measures are in place for the service in question and thereby address trust and confidence issues in cloud computing.",
    "lastUpdated": "2014-02-24T10:05:04Z",
    "category": [
      "cs.DC",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1402.5770v1"
  },
  {
    "title": "Cloud Network Management Model A Novel Approach to Manage Cloud Traffic",
    "author": [
      "Mamta Madan",
      "Mohit Mathur"
    ],
    "abstract": "Cloud is in the air. More and More companies and personals are connecting to cloud with so many variety of offering provided by the companies. The cloud services are based on Internet i.e. TCP IP. The paper discusses limitations of one of the main existing network management protocol i.e. Simple Network Management Protocol (SNMP) with respect to the current network conditions. The network traffic is growing at a high speed. When we talk about the networked environment of cloud, the monitoring tool should be capable of handling the traffic tribulations efficiently and represent a correct scenario of the network condition. The proposed Model Cloud Network Management Model provides a comprehensive solution to manage the growing traffic in cloud and trying to improve communication of manager and agents as in SNMP (the traditional TCP IP network management protocol). Firstly CNMM concentrates on reduction of packet exchange between manager and agent. Secondly it eliminates the counter problems exist in SNMP by having periodic updates from agent without querying by the manager. For better management we are including managers using virtualized technology. CNMM is a proposed model with efficient communication, secure packet delivery and reduced traffic. Though the proposed model supposed to manage the cloud traffic in a better and efficient way, the model is still a theoretical study, its implementation and results are yet to discover. The model however is the first step towards development of supported algorithms and protocol. Our further study will concentrate on development of supported algorithms.",
    "lastUpdated": "2014-11-08T05:34:26Z",
    "category": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1411.2084v1"
  },
  {
    "title": "Scientific Workflow Repeatability through Cloud-Aware Provenance",
    "author": [
      "Khawar Hasham",
      "Kamran Munir",
      "Jetendr Shamdasani",
      "Richard McClatchey"
    ],
    "abstract": "The transformations, analyses and interpretations of data in scientific workflows are vital for the repeatability and reliability of scientific workflows. This provenance of scientific workflows has been effectively carried out in Grid based scientific workflow systems. However, recent adoption of Cloud-based scientific workflows present an opportunity to investigate the suitability of existing approaches or propose new approaches to collect provenance information from the Cloud and to utilize it for workflow repeatability in the Cloud infrastructure. The dynamic nature of the Cloud in comparison to the Grid makes it difficult because resources are provisioned on-demand unlike the Grid. This paper presents a novel approach that can assist in mitigating this challenge. This approach can collect Cloud infrastructure information along with workflow provenance and can establish a mapping between them. This mapping is later used to re-provision resources on the Cloud. The repeatability of the workflow execution is performed by: (a) capturing the Cloud infrastructure information (virtual machine configuration) along with the workflow provenance, and (b) re-provisioning the similar resources on the Cloud and re-executing the workflow on them. The evaluation of an initial prototype suggests that the proposed approach is feasible and can be investigated further.",
    "lastUpdated": "2015-02-05T13:33:07Z",
    "category": [
      "cs.DB",
      "H.2.8"
    ],
    "url": "http://arxiv.org/abs/1502.01539v1"
  },
  {
    "title": "Hybrid Scheduling/Signal-Level Coordination in the Downlink of Multi-Cloud Radio-Access Networks",
    "author": [
      "Ahmed Douik",
      "Hayssam Dahrouj",
      "Tareq Y. Al-Naffouri",
      "Mohamed-Slim Alouini"
    ],
    "abstract": "In the context of resource allocation in cloud-radio access networks, recent studies assume either signal-level or scheduling-level coordination. This paper, instead, considers a hybrid level of coordination for the scheduling problem in the downlink of a multi-cloud radio-access network, as a means to benefit from both scheduling policies. Consider a multi-cloud radio access network, where each cloud is connected to several base-stations (BSs) via high capacity links, and therefore allows joint signal processing between them. Across the multiple clouds, however, only scheduling-level coordination is permitted, as it requires a lower level of backhaul communication. The frame structure of every BS is composed of various time/frequency blocks, called power-zones (PZs), and kept at fixed power level. The paper addresses the problem of maximizing a network-wide utility by associating users to clouds and scheduling them to the PZs, under the practical constraints that each user is scheduled, at most, to a single cloud, but possibly to many BSs within the cloud, and can be served by one or more distinct PZs within the BSs' frame. The paper solves the problem using graph theory techniques by constructing the conflict graph. The scheduling problem is, then, shown to be equivalent to a maximum-weight independent set problem in the constructed graph, in which each vertex symbolizes an association of cloud, user, BS and PZ, with a weight representing the utility of that association. Simulation results suggest that the proposed hybrid scheduling strategy provides appreciable gain as compared to the scheduling-level coordinated networks, with a negligible degradation to signal-level coordination.",
    "lastUpdated": "2015-04-07T11:23:39Z",
    "category": [
      "cs.IT",
      "math.IT"
    ],
    "url": "http://arxiv.org/abs/1504.01552v1"
  },
  {
    "title": "A Multi Perspective Approach for Understanding the Determinants of Cloud Computing Adoption among Australian SMEs",
    "author": [
      "Salim Alismaili",
      "Mengxiang Li",
      "Jun Shen",
      "Qiang He"
    ],
    "abstract": "Cloud computing is proved to be an effective computing technology for organisations through the advantages that it offers such as cost-effectiveness, IT technical agility and scalability, enhancing businesses processes, and increasing enterprises competitiveness. In Australia, there is an emerging trend that small and medium-sized enterprises (SMEs) begin to adopt this technology in the conventional working practices. However, there is a dearth of prior studies on examining the factors that influence the cloud computing adoption among Australian SMEs. To fill the empirical vacuum, this research-in-progress proposes an integrated framework for examining the determinants of cloud computing service adoption with the consideration of the unique characteristics of Australian SMEs, such as relatively low adoption of cloud computing services, less innovative, and limited knowledge about cloud computing and its benefits and hindrances. To this end, we are conducting consecutive studies to investigate this research issue. An exploratory interview study will be undertaken to identify and verify the unique characteristics of Australian SMEs toward the cloud computing adoption. This is followed by an organisational level survey that examines the effects of those determinants on cloud computing adoption. Finally, a decision model for cloud computing adoption among Australian SMEs will be developed by using a Multi Criteria Decision Approach (MCDA) through rating, prioritising, and ranking of various criteria and alternatives available to the decision makers. Adopting the mixed-method research fashion, this research-in-progress intends to make significant implications to scholars and practitioners alike in the cloud computing research and applications areas.",
    "lastUpdated": "2016-05-28T05:48:41Z",
    "category": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1606.00745v1"
  },
  {
    "title": "A Survey and Taxonomy of Self-Aware and Self-Adaptive Cloud Autoscaling Systems",
    "author": [
      "Tao Chen",
      "Rami Bahsoon",
      "Xin Yao"
    ],
    "abstract": "Autoscaling system can reconfigure cloud-based services and applications, through various configurations of cloud software and provisions of hardware resources, to adapt to the changing environment at runtime. Such a behavior offers the foundation for achieving elasticity in modern cloud computing paradigm. Given the dynamic and uncertain nature of the shared cloud infrastructure, cloud autoscaling system has been engineered as one of the most complex, sophisticated and intelligent artifacts created by human, aiming to achieve self-aware, self-adaptive and dependable runtime scaling. Yet, existing Self-aware and Self-adaptive Cloud Autoscaling System (SSCAS) is not mature to a state that it can be reliably exploited in the cloud. In this article, we survey the state-of-the-art research studies on SSCAS and provide a comprehensive taxonomy for this field. We present detailed analysis of the results and provide insights on open challenges, as well as the promising directions that are worth investigated in the future work of this area of research. Our survey and taxonomy contribute to the fundamentals of engineering more intelligent autoscaling systems in the cloud.",
    "lastUpdated": "2018-04-25T13:05:23Z",
    "category": [
      "cs.SE",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1609.03590v4"
  },
  {
    "title": "Betrayal, Distrust, and Rationality: Smart Counter-Collusion Contracts for Verifiable Cloud Computing",
    "author": [
      "Changyu Dong",
      "Yilei Wang",
      "Amjad Aldweesh",
      "Patrick McCorry",
      "Aad van Moorsel"
    ],
    "abstract": "Cloud computing has become an irreversible trend. Together comes the pressing need for verifiability, to assure the client the correctness of computation outsourced to the cloud. Existing verifiable computation techniques all have a high overhead, thus if being deployed in the clouds, would render cloud computing more expensive than the on-premises counterpart. To achieve verifiability at a reasonable cost, we leverage game theory and propose a smart contract based solution. In a nutshell, a client lets two clouds compute the same task, and uses smart contracts to stimulate tension, betrayal and distrust between the clouds, so that rational clouds will not collude and cheat. In the absence of collusion, verification of correctness can be done easily by crosschecking the results from the two clouds. We provide a formal analysis of the games induced by the contracts, and prove that the contracts will be effective under certain reasonable assumptions. By resorting to game theory and smart contracts, we are able to avoid heavy cryptographic protocols. The client only needs to pay two clouds to compute in the clear, and a small transaction fee to use the smart contracts. We also conducted a feasibility study that involves implementing the contracts in Solidity and running them on the official Ethereum network.",
    "lastUpdated": "2017-09-04T16:44:25Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1708.01171v4"
  },
  {
    "title": "Optimal Dynamic Cloud Network Control",
    "author": [
      "Hao Feng",
      "Jaime Llorca",
      "Antonia M. Tulino",
      "Andreas F. Molisch"
    ],
    "abstract": "Distributed cloud networking enables the deployment of a wide range of services in the form of interconnected software functions instantiated over general purpose hardware at multiple cloud locations distributed throughout the network. We consider the problem of optimal service delivery over a distributed cloud network, in which nodes are equipped with both communication and computation resources. We address the design of distributed online solutions that drive flow processing and routing decisions, along with the associated allocation of cloud and network resources. For a given set of services, each described by a chain of service functions, we characterize the cloud network capacity region and design a family of dynamic cloud network control (DCNC) algorithms that stabilize the underlying queuing system, while achieving arbitrarily close to minimum cost with a tradeoff in network delay. The proposed DCNC algorithms make local decisions based on the online minimization of linear and quadratic metrics obtained from an upper bound on the Lyapunov drift-plus-penalty of the cloud network queuing system. Minimizing a quadratic vs. a linear metric is shown to improve the cost-delay tradeoff at the expense of increased computational complexity. Our algorithms are further enhanced with a shortest transmission-plus-processing distance bias that improves delay performance without compromising throughput or overall cloud network cost. We provide throughput and cost optimality guarantees, convergence time analysis, and extensive simulations in representative cloud network scenarios.",
    "lastUpdated": "2017-08-31T04:35:19Z",
    "category": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1708.09561v1"
  },
  {
    "title": "Investigating Storage as a Service Cloud Platform: pCloud as a Case Study",
    "author": [
      "Tooska Dargahi",
      "Ali Dehghantanha",
      "Mauro Conti"
    ],
    "abstract": "Due to the flexibility, affordability and portability of cloud storage, individuals and companies envisage the cloud storage as one of the preferred storage media nowadays. This attracts the eyes of cyber criminals, since much valuable informa- tion such as user credentials, and private customer records are stored in the cloud. There are many ways for criminals to compromise cloud services; ranging from non-technical attack methods, such as social engineering, to deploying advanced malwares. Therefore, it is vital for cyber forensics examiners to be equipped and informed about best methods for investigation of different cloud platforms. In this chapter, using pCloud (an extensively used online cloud storage service) as a case study, and we elaborate on different kinds of artefacts retrievable during a forensics examination. We carried out our experiments on four different virtual machines running four popular operating systems: a 64 bit Windows 8, Ubuntu 14.04.1 LTS, Android 4.4.2, and iOS 8.1. Moreover, we examined cloud remnants of two different web browsers: Internet Explorer and Google Chrome on Windows. We believe that our study would promote awareness among digital forensic examiners on how to conduct cloud storage forensics examination.",
    "lastUpdated": "2017-09-13T17:01:36Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1709.04417v1"
  },
  {
    "title": "RGCNN: Regularized Graph CNN for Point Cloud Segmentation",
    "author": [
      "Gusi Te",
      "Wei Hu",
      "Zongming Guo",
      "Amin Zheng"
    ],
    "abstract": "Point cloud, an efficient 3D object representation, has become popular with the development of depth sensing and 3D laser scanning techniques. It has attracted attention in various applications such as 3D tele-presence, navigation for unmanned vehicles and heritage reconstruction. The understanding of point clouds, such as point cloud segmentation, is crucial in exploiting the informative value of point clouds for such applications. Due to the irregularity of the data format, previous deep learning works often convert point clouds to regular 3D voxel grids or collections of images before feeding them into neural networks, which leads to voluminous data and quantization artifacts. In this paper, we instead propose a regularized graph convolutional neural network (RGCNN) that directly consumes point clouds. Leveraging on spectral graph theory, we treat features of points in a point cloud as signals on graph, and define the convolution over graph by Chebyshev polynomial approximation. In particular, we update the graph Laplacian matrix that describes the connectivity of features in each layer according to the corresponding learned features, which adaptively captures the structure of dynamic graphs. Further, we deploy a graph-signal smoothness prior in the loss function, thus regularizing the learning process. Experimental results on the ShapeNet part dataset show that the proposed approach significantly reduces the computational complexity while achieving competitive performance with the state of the art. Also, experiments show RGCNN is much more robust to both noise and point cloud density in comparison with other methods. We further apply RGCNN to point cloud classification and achieve competitive results on ModelNet40 dataset.",
    "lastUpdated": "2018-06-08T02:50:19Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1806.02952v1"
  },
  {
    "title": "Complying with Data Handling Requirements in Cloud Storage Systems",
    "author": [
      "Martin Henze",
      "Roman Matzutt",
      "Jens Hiller",
      "Erik Mühmer",
      "Jan Henrik Ziegeldorf",
      "Johannes van der Giet",
      "Klaus Wehrle"
    ],
    "abstract": "In past years, cloud storage systems saw an enormous rise in usage. However, despite their popularity and importance as underlying infrastructure for more complex cloud services, today's cloud storage systems do not account for compliance with regulatory, organizational, or contractual data handling requirements by design. Since legislation increasingly responds to rising data protection and privacy concerns, complying with data handling requirements becomes a crucial property for cloud storage systems. We present PRADA, a practical approach to account for compliance with data handling requirements in key-value based cloud storage systems. To achieve this goal, PRADA introduces a transparent data handling layer, which empowers clients to request specific data handling requirements and enables operators of cloud storage systems to comply with them. We implement PRADA on top of the distributed database Cassandra and show in our evaluation that complying with data handling requirements in cloud storage systems is practical in real-world cloud deployments as used for microblogging, data sharing in the Internet of Things, and distributed email storage.",
    "lastUpdated": "2020-06-07T18:45:40Z",
    "category": [
      "cs.NI",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1806.11448v2"
  },
  {
    "title": "Toward a new mobile cloud forensic framework",
    "author": [
      "Muhammad Faheem",
      "M-Tahar Kechadi",
      "Nhien-An Le-Khac"
    ],
    "abstract": "Smartphones have created a significant impact on the day to day activities of every individual. Now a days a wide range of Smartphone applications are available and it necessitates high computing resources in order to build these applications. Cloud computing offers enormous resources and extends services to resource-constrained mobile devices. Mobile Cloud Computing is emerging as a key technology to utilize virtually unlimited resources over the Internet using Smartphones. Offloading data and computations to improve productivity, enhance performance, save energy, and improve user experience. Social network applications largely utilize Mobile Cloud Computing to reap the benefits. The social network has witnessed unprecedented growth in the recent years, and millions of registered users access it using Smartphones. The mobile cloud social network applications introduce not only convenience but also various issues related to criminal and illegal activities. Despite being primarily used to communicate and socialize with contacts, the multifarious and anonymous nature of social networking websites increases susceptibility to cybercrimes. Taking into account, the advantage of mobile cloud computing and popularity of social network applications, it is essential to establish a forensic framework based on mobile cloud platform that solves the problems of today forensic requirements. In this paper we present a mobile cloud forensic framework that allows the forensic investigator to collect the automated synchronized copies of data on both mobile and cloud servers to prove the evidence of cloud usage. We also show our preliminary results of this study.",
    "lastUpdated": "2016-11-29T10:53:29Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1611.09564v1"
  },
  {
    "title": "Cloudroid: A Cloud Framework for Transparent and QoS-aware Robotic Computation Outsourcing",
    "author": [
      "Ben Hu",
      "Huaimin Wang",
      "Pengfei Zhang",
      "Bo Ding",
      "Huimin Che"
    ],
    "abstract": "Many robotic tasks require heavy computation, which can easily exceed the robot's onboard computer capability. A promising solution to address this challenge is outsourcing the computation to the cloud. However, exploiting the potential of cloud resources in robotic software is difficult, because it involves complex code modification and extensive (re)configuration procedures. Moreover, quality of service (QoS) such as timeliness, which is critical to robot's behavior, have to be considered. In this paper, we propose a transparent and QoS-aware software framework called Cloudroid for cloud robotic applications. This framework supports direct deployment of existing robotic software packages to the cloud, transparently transforming them into Internet-accessible cloud services. And with the automatically generated service stubs, robotic applications can outsource their computation to the cloud without any code modification. Furthermore, the robot and the cloud can cooperate to maintain the specific QoS property such as request response time, even in a highly dynamic and resource-competitive environment. We evaluated Cloudroid based on a group of typical robotic scenarios and a set of software packages widely adopted in real-world robot practices. Results show that robot's capability can be enhanced significantly without code modification and specific QoS objectives can be guaranteed. In certain tasks, the \"cloud + robot\" setup shows improved performance in orders of magnitude compared with the robot native setup.",
    "lastUpdated": "2017-05-16T12:57:39Z",
    "category": [
      "cs.DC",
      "cs.RO"
    ],
    "url": "http://arxiv.org/abs/1705.05691v1"
  },
  {
    "title": "Privacy-preserving data outsourcing in the cloud via semantic data splitting",
    "author": [
      "David Sánchez",
      "Montserrat Batet"
    ],
    "abstract": "Even though cloud computing provides many intrinsic benefits, privacy concerns related to the lack of control over the storage and management of the outsourced data still prevent many customers from migrating to the cloud. Several privacy-protection mechanisms based on a prior encryption of the data to be outsourced have been proposed. Data encryption offers robust security, but at the cost of hampering the efficiency of the service and limiting the functionalities that can be applied over the (encrypted) data stored on cloud premises. Because both efficiency and functionality are crucial advantages of cloud computing, in this paper we aim at retaining them by proposing a privacy-protection mechanism that relies on splitting (clear) data, and on the distributed storage offered by the increasingly popular notion of multi-clouds. We propose a semantically-grounded data splitting mechanism that is able to automatically detect pieces of data that may cause privacy risks and split them on local premises, so that each chunk does not incur in those risks; then, chunks of clear data are independently stored into the separate locations of a multi-cloud, so that external entities cannot have access to the whole confidential data. Because partial data are stored in clear on cloud premises, outsourced functionalities are seamlessly and efficiently supported by just broadcasting queries to the different cloud locations. To enforce a robust privacy notion, our proposal relies on a privacy model that offers a priori privacy guarantees; to ensure its feasibility, we have designed heuristic algorithms that minimize the number of cloud storage locations we need; to show its potential and generality, we have applied it to the least structured and most challenging data type: plain textual documents.",
    "lastUpdated": "2017-07-03T08:49:20Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1707.00445v1"
  },
  {
    "title": "A Comparative Taxonomy and Survey of Public Cloud Infrastructure Vendors",
    "author": [
      "Dimitrios Sikeridis",
      "Ioannis Papapanagiotou",
      "Bhaskar Prasad Rimal",
      "Michael Devetsikiotis"
    ],
    "abstract": "An increasing number of technology enterprises are adopting cloud-native architectures to offer their web-based products, by moving away from privately-owned data-centers and relying exclusively on cloud service providers. As a result, cloud vendors have lately increased, along with the estimated annual revenue they share. However, in the process of selecting a provider's cloud service over the competition, we observe a lack of universal common ground in terms of terminology, functionality of services and billing models. This is an important gap especially under the new reality of the industry where each cloud provider has moved towards his own service taxonomy, while the number of specialized services has grown exponentially. This work discusses cloud services offered by four dominant, in terms of their current market share, cloud vendors. We provide a taxonomy of their services and sub-services that designates major service families namely computing, storage, databases, analytics, data pipelines, machine learning, and networking. The aim of such clustering is to indicate similarities, common design approaches and functional differences of the offered services. The outcomes are essential both for individual researchers, and bigger enterprises in their attempt to identify the set of cloud services that will utterly meet their needs without compromises. While we acknowledge the fact that this is a dynamic industry, where new services arise constantly, and old ones experience important updates, this study paints a solid image of the current offerings and gives prominence to the directions that cloud service providers are following.",
    "lastUpdated": "2018-01-28T23:33:00Z",
    "category": [
      "cs.DC",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1710.01476v2"
  },
  {
    "title": "A Taxonomy and Future Directions for Sustainable Cloud Computing: 360 Degree View",
    "author": [
      "Sukhpal Singh Gill",
      "Rajkumar Buyya"
    ],
    "abstract": "The cloud computing paradigm offers on-demand services over the Internet and supports a wide variety of applications. With the recent growth of Internet of Things (IoT) based applications the usage of cloud services is increasing exponentially. The next generation of cloud computing must be energy-efficient and sustainable to fulfil the end-user requirements which are changing dynamically. Presently, cloud providers are facing challenges to ensure the energy efficiency and sustainability of their services. The usage of large number of cloud datacenters increases cost as well as carbon footprints, which further effects the sustainability of cloud services. In this paper, we propose a comprehensive taxonomy of sustainable cloud computing. The taxonomy is used to investigate the existing techniques for sustainability that need careful attention and investigation as proposed by several academic and industry groups. Further, the current research on sustainable cloud computing is organized into several categories: application design, sustainability metrics, capacity planning, energy management, virtualization, thermal-aware scheduling, cooling management, renewable energy and waste heat utilization. The existing techniques have been compared and categorized based on the common characteristics and properties. A conceptual model for sustainable cloud computing has been proposed along with discussion on future research directions.",
    "lastUpdated": "2018-07-09T05:02:58Z",
    "category": [
      "cs.DC",
      "D.4.1"
    ],
    "url": "http://arxiv.org/abs/1712.02899v2"
  },
  {
    "title": "ReplicaTEE: Enabling Seamless Replication of SGX Enclaves in the Cloud",
    "author": [
      "Claudio Soriente",
      "Ghassan Karame",
      "Wenting Li",
      "Sergey Fedorov"
    ],
    "abstract": "With the proliferation of Trusted Execution Environments (TEEs) such as Intel SGX, a number of cloud providers will soon introduce TEE capabilities within their offering (e.g., Microsoft Azure). Although the integration of SGX within the cloud considerably strengthens the threat model for cloud applications, the current model to deploy and provision enclaves prevents the cloud operator from adding or removing enclaves dynamically - thus preventing elasticity for TEE-based applications in the cloud. In this paper, we propose ReplicaTEE, a solution that enables seamless provisioning and decommissioning of TEE-based applications in the cloud. ReplicaTEE leverages an SGX-based provisioning layer that interfaces with a Byzantine Fault-Tolerant storage service to securely orchestrate enclave replication in the cloud, without the active intervention of the application owner. Namely, in ReplicaTEE, the application owner entrusts application secret to the provisioning layer; the latter handles all enclave commissioning and de-commissioning operations throughout the application lifetime. We analyze the security of ReplicaTEE and show that it is secure against attacks by a powerful adversary that can compromise a large fraction of the cloud infrastructure. We implement a prototype of ReplicaTEE in a realistic cloud environment and evaluate its performance. ReplicaTEE moderately increments the TCB by ~800 LoC. Our evaluation shows that ReplicaTEE does not add significant overhead to existing SGX-based applications.",
    "lastUpdated": "2018-09-13T15:58:43Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1809.05027v1"
  },
  {
    "title": "Cloud BI: Future of Business Intelligence in the Cloud",
    "author": [
      "Hussain Al-Aqrabi",
      "Lu Liu",
      "Richard Hill",
      "Nick Antonopoulos"
    ],
    "abstract": "Cloud computing is gradually gaining popularity among businesses due to its distinct advantages over self-hosted IT infrastructures. Business Intelligence (BI) is a highly resource intensive system requiring large-scale parallel processing and significant storage capacities to host data warehouses. In self-hosted environments it was feared that BI will eventually face a resource crunch situation because it will not be feasible for companies to keep adding resources to host a neverending expansion of data warehouses and the online analytical processing (OLAP) demands on the underlying networking. Cloud computing has instigated a new hope for future prospects of BI. However, how will BI be implemented on cloud and how will the traffic and demand profile look like? This research attempts to answer these key questions in regards to taking BI to the cloud. The cloud hosting of BI has been demonstrated with the help of a simulation on OPNET comprising a cloud model with multiple OLAP application servers applying parallel query loads on an array of servers hosting relational databases. The simulation results have reflected that true and extensible parallel processing of database servers on the cloud can efficiently process OLAP application demands on cloud computing. Hence, the BI designer needs to plan for a highly partitioned database running on massively parallel database servers in which, each server hosts at least one partition of the underlying database serving the OLAP demands.",
    "lastUpdated": "2019-01-23T22:11:24Z",
    "category": [
      "cs.DC",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1901.08151v1"
  },
  {
    "title": "Transferable Knowledge for Low-cost Decision Making in Cloud Environments",
    "author": [
      "Faiza Samreen",
      "Gordon S Blair",
      "Yehia Elkhatib"
    ],
    "abstract": "Users of cloud computing are increasingly overwhelmed with the wide range of providers and services offered by each provider. As such, many users select cloud services based on description alone. An emerging alternative is to use a decision support system (DSS), which typically relies on gaining insights from observational data in order to assist a customer in making decisions regarding optimal deployment or redeployment of cloud applications. The primary activity of such systems is the generation of a prediction model (e.g. using machine learning), which requires a significantly large amount of training data. However, considering the varying architectures of applications, cloud providers, and cloud offerings, this activity is not sustainable as it incurs additional time and cost to collect training data and subsequently train the models. We overcome this through developing a Transfer Learning (TL) approach where the knowledge (in the form of the prediction model and associated data set) gained from running an application on a particular cloud infrastructure is transferred in order to substantially reduce the overhead of building new models for the performance of new applications and/or cloud infrastructures. In this paper, we present our approach and evaluate it through extensive experimentation involving three real world applications over two major public cloud providers, namely Amazon and Google. Our evaluation shows that our novel two-mode TL scheme increases overall efficiency with a factor of 60\\% reduction in the time and cost of generating a new prediction model. We test this under a number of cross-application and cross-cloud scenarios.",
    "lastUpdated": "2019-05-07T10:08:19Z",
    "category": [
      "cs.DC",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1905.02448v1"
  },
  {
    "title": "Domain Adaptation for Vehicle Detection from Bird's Eye View LiDAR Point Cloud Data",
    "author": [
      "Khaled Saleh",
      "Ahmed Abobakr",
      "Mohammed Attia",
      "Julie Iskander",
      "Darius Nahavandi",
      "Mohammed Hossny"
    ],
    "abstract": "Point cloud data from 3D LiDAR sensors are one of the most crucial sensor modalities for versatile safety-critical applications such as self-driving vehicles. Since the annotations of point cloud data is an expensive and time-consuming process, therefore recently the utilisation of simulated environments and 3D LiDAR sensors for this task started to get some popularity. With simulated sensors and environments, the process for obtaining an annotated synthetic point cloud data became much easier. However, the generated synthetic point cloud data are still missing the artefacts usually exist in point cloud data from real 3D LiDAR sensors. As a result, the performance of the trained models on this data for perception tasks when tested on real point cloud data is degraded due to the domain shift between simulated and real environments. Thus, in this work, we are proposing a domain adaptation framework for bridging this gap between synthetic and real point cloud data. Our proposed framework is based on the deep cycle-consistent generative adversarial networks (CycleGAN) architecture. We have evaluated the performance of our proposed framework on the task of vehicle detection from a bird's eye view (BEV) point cloud images coming from real 3D LiDAR sensors. The framework has shown competitive results with an improvement of more than 7% in average precision score over other baseline approaches when tested on real BEV point cloud images.",
    "lastUpdated": "2019-05-22T05:24:26Z",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1905.08955v1"
  },
  {
    "title": "Point Cloud Rendering after Coding: Impacts on Subjective and Objective Quality",
    "author": [
      "Alireza Javaheri",
      "Catarina Brites",
      "Fernando Pereira",
      "Joao Ascenso"
    ],
    "abstract": "Recently, point clouds have shown to be a promising way to represent 3D visual data for a wide range of immersive applications, from augmented reality to autonomous cars. Emerging imaging sensors have made easier to perform richer and denser point cloud acquisition, notably with millions of points, thus raising the need for efficient point cloud coding solutions. In such a scenario, it is important to evaluate the impact and performance of several processing steps in a point cloud communication system, notably the quality degradations associated to point cloud coding solutions. Moreover, since point clouds are not directly visualized but rather processed with a rendering algorithm before shown on any display, the perceived quality of point cloud data highly depends on the rendering solution. In this context, the main objective of this paper is to study the impact of several coding and rendering solutions on the perceived user quality and in the performance of available objective quality assessment metrics. Another contribution regards the assessment of recent MPEG point cloud coding solutions for several popular rendering methods which were never presented before. The conclusions regard the visibility of three types of coding artifacts for the three considered rendering approaches as well as the strengths and weakness of objective quality metrics when point clouds are rendered after coding.",
    "lastUpdated": "2020-10-15T15:30:25Z",
    "category": [
      "eess.IV",
      "cs.MM"
    ],
    "url": "http://arxiv.org/abs/1912.09137v2"
  },
  {
    "title": "Deep-learning-based classification and retrieval of components of a process plant from segmented point clouds",
    "author": [
      "Hyungki Kim",
      "Duhwan Mun"
    ],
    "abstract": "Technology to recognize the type of component represented by a point cloud is required in the reconstruction process of an as-built model of a process plant based on laser scanning. The reconstruction process of a process plant through laser scanning is divided into point cloud registration, point cloud segmentation, and component type recognition and placement. Loss of shape data or imbalance of point cloud density problems generally occur in the point cloud data collected from large-scale facilities. In this study, we experimented with the possibility of applying object recognition technology based on 3D deep learning networks, which have been showing high performance recently, and analyzed the results. For training data, we used a segmented point cloud repository about components that we constructed by scanning a process plant. For networks, we selected the multi-view convolutional neural network (MVCNN), which is a view-based method, and PointNet, which is designed to allow the direct input of point cloud data. In the case of the MVCNN, we also performed an experiment on the generation method for two types of multi-view images that can complement the shape occlusion of the segmented point cloud. In this experiment, the MVCNN showed the highest retrieval accuracy of approximately 87%, whereas PointNet showed the highest retrieval mean average precision of approximately 84%. Furthermore, both networks showed high recognition performance for the segmented point cloud of plant components when there was sufficient training data.",
    "lastUpdated": "2019-12-13T01:34:28Z",
    "category": [
      "cs.CV",
      "cs.IR"
    ],
    "url": "http://arxiv.org/abs/1912.12135v1"
  },
  {
    "title": "Energy Efficient Cloud-Fog Architecture",
    "author": [
      "Hatem A. Alharbi",
      "Taisir E. H. Elgorashi",
      "Jaafar M. H. Elmirghani"
    ],
    "abstract": "The advancements of cloud computing came as a radical transformation in the way Information and Communication Technology (ICT) services are deployed and maintained. Cloud computing provides ubiquitous on-demand access to an Internet-based pool of processing, storage, and communication resources offered to a large set of geographically distributed users. As the cloud computing infrastructure grows and demand increases, the need for a new breed of on-demand computing that can efficiently maintain Quality of Service (QoS) requirements has increased. Fog computing was proposed to address the limitations of cloud computing, in terms of delay and high bandwidth requirements, by extending the on-demand resources of clouds to the edge of the network bringing them closer to the users. The massive growth and wide use of cloud-fog services have created serious power consumption concerns. This article delves into the energy consumption of cloud-fog services by raising headline questions related to; how significant the problem itself is, how different conditions/scenarios affect the energy consumption of the architecture, and how to orchestrate the use of the architecture in an energy-efficient manner. We start by summarizing the cloud-fog architecture including different communication and computing layers. Additionally, we give a brief overview of the role of Virtual Machine (VM) placement in optimally using cloud-fog resources in a dynamic manner. Then, we present the problem of energy efficient VMs placement and provide numerical results.",
    "lastUpdated": "2020-01-16T00:54:08Z",
    "category": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/2001.06328v1"
  },
  {
    "title": "Airborne LiDAR Point Cloud Classification with Graph Attention Convolution Neural Network",
    "author": [
      "Congcong Wen",
      "Xiang Li",
      "Xiaojing Yao",
      "Ling Peng",
      "Tianhe Chi"
    ],
    "abstract": "Airborne light detection and ranging (LiDAR) plays an increasingly significant role in urban planning, topographic mapping, environmental monitoring, power line detection and other fields thanks to its capability to quickly acquire large-scale and high-precision ground information. To achieve point cloud classification, previous studies proposed point cloud deep learning models that can directly process raw point clouds based on PointNet-like architectures. And some recent works proposed graph convolution neural network based on the inherent topology of point clouds. However, the above point cloud deep learning models only pay attention to exploring local geometric structures, yet ignore global contextual relationships among all points. In this paper, we present a graph attention convolution neural network (GACNN) that can be directly applied to the classification of unstructured 3D point clouds obtained by airborne LiDAR. Specifically, we first introduce a graph attention convolution module that incorporates global contextual information and local structural features. Based on the proposed graph attention convolution module, we further design an end-to-end encoder-decoder network, named GACNN, to capture multiscale features of the point clouds and therefore enable more accurate airborne point cloud classification. Experiments on the ISPRS 3D labeling dataset show that the proposed model achieves a new state-of-the-art performance in terms of average F1 score (71.5\\%) and a satisfying overall accuracy (83.2\\%). Additionally, experiments further conducted on the 2019 Data Fusion Contest Dataset by comparing with other prevalent point cloud deep learning models demonstrate the favorable generalization capability of the proposed model.",
    "lastUpdated": "2020-04-20T05:12:31Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2004.09057v1"
  },
  {
    "title": "Challenges in migrating legacy software systems to the cloud an empirical study",
    "author": [
      "Mahdi Fahmideh",
      "Farhad Daneshgar",
      "Ghassan Beydoun",
      "Fethi Rabhi"
    ],
    "abstract": "Moving existing legacy systems to cloud platforms is a difficult and high cost process that may involve technical and non-technical resources and challenges. There is evidence that the lack of understanding and preparedness of cloud computing migration underpin many migration failures in achieving organisations goals. The main goal of this article is to identify the most important challenging activities for moving legacy systems to cloud platforms from a perspective of reengineering process. Through a combination of a bottom-up and a top-down analysis, a set of common activities is derived from the extant cloud computing literature. These are expressed as a model and are validated using a population of 104 shortlisted and randomly selected domain experts from different industry sectors. We used a Web-based survey questionnaire to collect data and analysed them using SPSS Sample T-Test. The results of this study highlight the most important and critical challenges that should be addressed by various roles within a legacy to cloud migration endeavour. The study provides an overall understanding of this process including common occurring activities, concerns and recommendations. In addition, the findings of this study constitute a practical guide to conduct this transition. This guide is platform agnostic and independent from any specific migration scenario, cloud platform, or an application domain. Keywords. Cloud Computing, Legacy Systems, Cloud Migration, Cloud Migration Process",
    "lastUpdated": "2020-04-17T03:05:44Z",
    "category": [
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/2004.10724v1"
  },
  {
    "title": "High-performance cloud computing for exhaustive protein-protein docking",
    "author": [
      "Masahito Ohue",
      "Kento Aoyama",
      "Yutaka Akiyama"
    ],
    "abstract": "Public cloud computing environments, such as Amazon AWS, Microsoft Azure, and the Google Cloud Platform, have achieved remarkable improvements in computational performance in recent years, and are also expected to be able to perform massively parallel computing. As the cloud enables users to use thousands of CPU cores and GPU accelerators casually, and various software types can be used very easily by cloud images, the cloud is beginning to be used in the field of bioinformatics. In this study, we ported the original protein-protein interaction prediction (protein-protein docking) software, MEGADOCK, into Microsoft Azure as an example of an HPC cloud environment. A cloud parallel computing environment with up to 1,600 CPU cores and 960 GPUs was constructed using four CPU instance types and two GPU instance types, and the parallel computing performance was evaluated. Our MEGADOCK on Azure system showed a strong scaling value of 0.93 for the CPU instance when H16 instance with 100 instances were used compared to 50, and a strong scaling value of 0.89 for the GPU instance when NC24 instance with 20 were used compared to 5. Moreover, the results of the usage fee and total computation time supported that using a GPU instance reduced the computation time of MEGADOCK and the cloud usage fee required for the computation. The developed environment deployed on the cloud is highly portable, making it suitable for applications in which an on-demand and large-scale HPC environment is desirable.",
    "lastUpdated": "2020-06-16T03:37:50Z",
    "category": [
      "cs.DC",
      "q-bio.BM",
      "q-bio.MN",
      "q-bio.QM"
    ],
    "url": "http://arxiv.org/abs/2006.08905v1"
  },
  {
    "title": "Pseudo-LiDAR Point Cloud Interpolation Based on 3D Motion Representation and Spatial Supervision",
    "author": [
      "Haojie Liu",
      "Kang Liao",
      "Chunyu Lin",
      "Yao Zhao",
      "Yulan Guo"
    ],
    "abstract": "Pseudo-LiDAR point cloud interpolation is a novel and challenging task in the field of autonomous driving, which aims to address the frequency mismatching problem between camera and LiDAR. Previous works represent the 3D spatial motion relationship induced by a coarse 2D optical flow, and the quality of interpolated point clouds only depends on the supervision of depth maps. As a result, the generated point clouds suffer from inferior global distributions and local appearances. To solve the above problems, we propose a Pseudo-LiDAR point cloud interpolation network to generates temporally and spatially high-quality point cloud sequences. By exploiting the scene flow between point clouds, the proposed network is able to learn a more accurate representation of the 3D spatial motion relationship. For the more comprehensive perception of the distribution of point cloud, we design a novel reconstruction loss function that implements the chamfer distance to supervise the generation of Pseudo-LiDAR point clouds in 3D space. In addition, we introduce a multi-modal deep aggregation module to facilitate the efficient fusion of texture and depth features. As the benefits of the improved motion representation, training loss function, and model structure, our approach gains significant improvements on the Pseudo-LiDAR point cloud interpolation task. The experimental results evaluated on KITTI dataset demonstrate the state-of-the-art performance of the proposed network, quantitatively and qualitatively.",
    "lastUpdated": "2020-06-20T03:11:04Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2006.11481v1"
  },
  {
    "title": "Privacy Preserving Visual SLAM",
    "author": [
      "Mikiya Shibuya",
      "Shinya Sumikura",
      "Ken Sakurada"
    ],
    "abstract": "This study proposes a privacy-preserving Visual SLAM framework for estimating camera poses and performing bundle adjustment with mixed line and point clouds in real time. Previous studies have proposed localization methods to estimate a camera pose using a line-cloud map for a single image or a reconstructed point cloud. These methods offer a scene privacy protection against the inversion attacks by converting a point cloud to a line cloud, which reconstruct the scene images from the point cloud. However, they are not directly applicable to a video sequence because they do not address computational efficiency. This is a critical issue to solve for estimating camera poses and performing bundle adjustment with mixed line and point clouds in real time. Moreover, there has been no study on a method to optimize a line-cloud map of a server with a point cloud reconstructed from a client video because any observation points on the image coordinates are not available to prevent the inversion attacks, namely the reversibility of the 3D lines. The experimental results with synthetic and real data show that our Visual SLAM framework achieves the intended privacy-preserving formation and real-time performance using a line-cloud map.",
    "lastUpdated": "2020-07-27T07:34:46Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2007.10361v2"
  },
  {
    "title": "Study on State-of-the-art Cloud Services Integration Capabilities with Autonomous Ground Vehicles",
    "author": [
      "Praveen Damacharla",
      "Dhwani Mehta",
      "Ahmad Y Javaid",
      "Vijay K. Devabhaktuni"
    ],
    "abstract": "Computing and intelligence are substantial requirements for the accurate performance of autonomous ground vehicles (AGVs). In this context, the use of cloud services in addition to onboard computers enhances computing and intelligence capabilities of AGVs. In addition, the vast amount of data processed in a cloud system contributes to overall performance and capabilities of the onboard system. This research study entails a qualitative analysis to gather insights on the applicability of the leading cloud service providers in AGV operations. These services include Google Cloud, Microsoft Azure, Amazon AWS, and IBM Cloud. The study begins with a brief review of AGV technical requirements that are necessary to determine the rationale for identifying the most suitable cloud service. The qualitative analysis studies and addresses the applicability of the cloud service over the proposed generalized AGV's architecture integration, performance, and manageability. Our findings conclude that a generalized AGV architecture can be supported by state-of-the-art cloud service, but there should be a clear line of separation between the primary and secondary computing needs. Moreover, our results show significant lags while using cloud services and preventing their use in real-time AGV operation.",
    "lastUpdated": "2020-08-11T16:56:14Z",
    "category": [
      "cs.CY",
      "cs.CC",
      "cs.PF"
    ],
    "url": "http://arxiv.org/abs/2008.04853v1"
  },
  {
    "title": "Virtual Machine Trading in a Federation of Clouds: Individual Profit and Social Welfare Maximization",
    "author": [
      "Hongxing Li",
      "Chuan Wu",
      "Zongpeng Li",
      "Francis C. M. Lau"
    ],
    "abstract": "By sharing resources among different cloud providers, the paradigm of federated clouds exploits temporal availability of resources and geographical diversity of operational costs for efficient job service. While interoperability issues across different cloud platforms in a cloud federation have been extensively studied, fundamental questions on cloud economics remain: When and how should a cloud trade resources (e.g., virtual machines) with others, such that its net profit is maximized over the long run, while a close-to-optimal social welfare in the entire federation can also be guaranteed? To answer this question, a number of important, inter-related decisions, including job scheduling, server provisioning and resource pricing, should be dynamically and jointly made, while the long-term profit optimality is pursued. In this work, we design efficient algorithms for inter-cloud virtual machine (VM) trading and scheduling in a cloud federation. For VM transactions among clouds, we design a double-auction based mechanism that is strategyproof, individual rational, ex-post budget balanced, and efficient to execute over time. Closely combined with the auction mechanism is a dynamic VM trading and scheduling algorithm, which carefully decides the true valuations of VMs in the auction, optimally schedules stochastic job arrivals with different SLAs onto the VMs, and judiciously turns on and off servers based on the current electricity prices. Through rigorous analysis, we show that each individual cloud, by carrying out the dynamic algorithm in the online double auction, can achieve a time-averaged profit arbitrarily close to the offline optimum. Asymptotic optimality in social welfare is also achieved under homogeneous cloud settings. We carry out trace-driven simulations to examine the effectiveness of our algorithms and the achievable social welfare under heterogeneous cloud settings.",
    "lastUpdated": "2013-04-24T07:11:55Z",
    "category": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1304.6491v1"
  },
  {
    "title": "ZeroTouch Provisioning (ZTP) Model and Infrastructure Components for Multi-provider Cloud Services Provisioning",
    "author": [
      "Yuri Demchenko",
      "Paola Grosso",
      "Cees de Laat",
      "Sonja Filiposka",
      "Migiel de Vos"
    ],
    "abstract": "This paper presents results of the ongoing development of the Cloud Services Delivery Infrastructure (CSDI) that provides a basis for infrastructure centric cloud services provisioning, operation and management in multi-cloud multi-provider environment defined as a Zero Touch Provisioning, Operation and Management (ZTP/ZTPOM) model. The presented work refers to use cases from data intensive research that require high performance computation resources and large storage volumes that are typically distributed between datacenters often involving multiple cloud providers. Automation for large scale scientific (and industrial) applications should include provisioning of both inter-cloud network infrastructure and intra-cloud application resources. It should provide support for the complete application operation workflow together with the possible application infrastructure and resources changes that can occur during the application lifecycle. The authors investigate existing technologies for automation of the service provisioning and management processes aiming to cross-pollinate best practices from currently disconnected domains such as cloud based applications provisioning and multi-domain high-performance network provisioning. The paper refers to the previous and legacy research by authors, the Open Cloud eXchange (OCX), that has been proposed to address the last mile problem in cloud services delivery to campuses over trans-national backbone networks such as GEANT. OCX will serve as an integral component of the prospective ZTP infrastructure over the GEANT network. Another important component, the Marketplace, is defined for providing cloud services and applications discovery (in generally intercloud environment) and may also support additional services such as services composition and trust brokering for establishing customer-provider federations.",
    "lastUpdated": "2016-11-08T22:58:39Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1611.02758v1"
  },
  {
    "title": "Digital Ecosystems in the Clouds: Towards Community Cloud Computing",
    "author": [
      "Gerard Briscoe",
      "Alexandros Marinos"
    ],
    "abstract": "Cloud Computing is rising fast, with its data centres growing at an unprecedented rate. However, this has come with concerns of privacy, efficiency at the expense of resilience, and environmental sustainability, because of the dependence on Cloud vendors such as Google, Amazon, and Microsoft. Community Cloud Computing makes use of the principles of Digital Ecosystems to provide a paradigm for Clouds in the community, offering an alternative architecture for the use cases of Cloud Computing. It is more technically challenging to deal with issues of distributed computing, such as latency, differential resource management, and additional security requirements. However, these are not insurmountable challenges, and with the need to retain control over our digital lives and the potential environmental consequences, it is a challenge we must pursue.",
    "lastUpdated": "2009-10-05T01:16:50Z",
    "category": [
      "cs.NI",
      "cs.DC",
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/0903.0694v3"
  },
  {
    "title": "An Approach to Ad hoc Cloud Computing",
    "author": [
      "Graham Kirby",
      "Alan Dearle",
      "Angus Macdonald",
      "Alvaro Fernandes"
    ],
    "abstract": "We consider how underused computing resources within an enterprise may be harnessed to improve utilization and create an elastic computing infrastructure. Most current cloud provision involves a data center model, in which clusters of machines are dedicated to running cloud infrastructure software. We propose an additional model, the ad hoc cloud, in which infrastructure software is distributed over resources harvested from machines already in existence within an enterprise. In contrast to the data center cloud model, resource levels are not established a priori, nor are resources dedicated exclusively to the cloud while in use. A participating machine is not dedicated to the cloud, but has some other primary purpose such as running interactive processes for a particular user. We outline the major implementation challenges and one approach to tackling them.",
    "lastUpdated": "2010-02-25T10:19:37Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1002.4738v1"
  },
  {
    "title": "Radiation therapy calculations using an on-demand virtual cluster via cloud computing",
    "author": [
      "Roy W. Keyes",
      "Christian Romano",
      "Dorian Arnold",
      "Shuang Luan"
    ],
    "abstract": "Computer hardware costs are the limiting factor in producing highly accurate radiation dose calculations on convenient time scales. Because of this, large-scale, full Monte Carlo simulations and other resource intensive algorithms are often considered infeasible for clinical settings. The emerging cloud computing paradigm promises to fundamentally alter the economics of such calculations by providing relatively cheap, on-demand, pay-as-you-go computing resources over the Internet. We believe that cloud computing will usher in a new era, in which very large scale calculations will be routinely performed by clinics and researchers using cloud-based resources. In this research, several proof-of-concept radiation therapy calculations were successfully performed on a cloud-based virtual Monte Carlo cluster. Performance evaluations were made of a distributed processing framework developed specifically for this project. The expected 1/n performance was observed with some caveats. The economics of cloud-based virtual computing clusters versus traditional in-house hardware is also discussed. For most situations, cloud computing can provide a substantial cost savings for distributed calculations.",
    "lastUpdated": "2010-09-27T15:11:07Z",
    "category": [
      "physics.med-ph",
      "cs.DC",
      "physics.comp-ph"
    ],
    "url": "http://arxiv.org/abs/1009.5282v1"
  },
  {
    "title": "Decision Support Tools for Cloud Migration in the Enterprise",
    "author": [
      "Ali Khajeh-Hosseini",
      "Ian Sommerville",
      "Jurgen Bogaerts",
      "Pradeep Teregowda"
    ],
    "abstract": "This paper describes two tools that aim to support decision making during the migration of IT systems to the cloud. The first is a modeling tool that produces cost estimates of using public IaaS clouds. The tool enables IT architects to model their applications, data and infrastructure requirements in addition to their computational resource usage patterns. The tool can be used to compare the cost of different cloud providers, deployment options and usage scenarios. The second tool is a spreadsheet that outlines the benefits and risks of using IaaS clouds from an enterprise perspective; this tool provides a starting point for risk assessment. Two case studies were used to evaluate the tools. The tools were useful as they informed decision makers about the costs, benefits and risks of using the cloud.",
    "lastUpdated": "2011-05-01T07:48:42Z",
    "category": [
      "cs.DC",
      "C.2.4"
    ],
    "url": "http://arxiv.org/abs/1105.0149v1"
  },
  {
    "title": "Effective Ways of Secure, Private and Trusted Cloud Computing",
    "author": [
      "Pardeep Kumar",
      "Vivek Kumar Sehgal",
      "Durg Singh Chauhan",
      "P. K. Gupta",
      "Manoj Diwakar"
    ],
    "abstract": "Cloud computing is an Internet-based computing, where shared resources, software and information, are provided to computers and devices on-demand. It provides people the way to share distributed resources and services that belong to different organization. Since cloud computing uses distributed resources in open environment, thus it is important to provide the security and trust to share the data for developing cloud computing applications. In this paper we assess how can cloud providers earn their customers' trust and provide the security, privacy and reliability, when a third party is processing sensitive data in a remote machine located in various countries? A concept of utility cloud has been represented to provide the various services to the users. Emerging technologies can help address the challenges of Security, Privacy and Trust in cloud computing.",
    "lastUpdated": "2011-11-14T10:28:59Z",
    "category": [
      "cs.DC",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1111.3165v1"
  },
  {
    "title": "(MC2)2: A Generic Decision-Making Framework and its Application to Cloud Computing",
    "author": [
      "Michael Menzel",
      "Marten Schönherr",
      "Jens Nimis",
      "Stefan Tai"
    ],
    "abstract": "Cloud computing is a disruptive technology, representing a new model for information technology (IT) solution engineering and management that promises to introduce significant cost savings and other benefits. The adoption of Cloud computing requires a detailed comparison of infrastructure alternatives, taking a number of aspects into careful consideration. Existing methods of evaluation, however, limit decision making to the relative costs of cloud computing, but do not take a broader range of criteria into account. In this paper, we introduce a generic, multi-criteria-based decision framework and an application for Cloud Computing, the Multi-Criteria Comparison Method for Cloud Computing ((MC2)2). The framework and method allow organizations to determine what infrastructure best suits their needs by evaluating and ranking infrastructure alternatives using multiple criteria. Therefore, (MC2)2 offers a way to differentiate infrastructures not only by costs, but also in terms of benefits, opportunities and risks. (MC2)2 can be adapted to facilitate a wide array of decision-making scenarios within the domain of information technology infrastructures, depending on the criteria selected to support the framework.",
    "lastUpdated": "2011-12-16T16:34:59Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1112.1851v2"
  },
  {
    "title": "Toward Governance of Cross-Cloud Application Deployment",
    "author": [
      "Pierre de Leusse",
      "Krzysztof Zielinski"
    ],
    "abstract": "In this article, the authors introduce the main ideas around the governance of cross-Cloud application deployment and their related concepts. It is argued that, due to the increasing complexity and nature of the Cloud market, an intermediary specialized in brokering the deployment of different components of a same application onto different Cloud products could both facilitate said deployment and in some cases improve its quality in terms of cost, security & reliability and QoS. In order to fulfill these objectives, the authors propose a high level architecture that relies on their previous work on governance of policy & rule driven distributed systems. This architecture aims at supplying five main functions of 1) translation of Service Level Agreements (SLAs) and pricing into a common shared DSL, 2) correlation of analytical data (e.g. monitoring, metering), 3) combination of Cloud products, 4) information from third parties regarding different aspects of Quality of Service (QoS) and 5) cross-Cloud application deployment specification and governance.",
    "lastUpdated": "2012-03-02T12:03:02Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1203.0432v1"
  },
  {
    "title": "Efficient Resource Allocation in Resource provisioning policies over Resource Cloud Communication Paradigm",
    "author": [
      "Gaurav Raj",
      "Ankit Nischal"
    ],
    "abstract": "Optimal resource utilization for executing tasks within the cloud is one of the biggest challenges. In executing the task over a cloud, the resource provisioner is responsible for providing the resources to create virtual machines. To utilize the resources optimally, the resource provisioner has to take care of the process of allocating resources to Virtual Machine Manager (VMM). In this paper, an efficient way to utilize the resources, within the cloud, to create virtual machines has been proposed considering optimum cost based on performance factor. This performance factor depends upon the overall cost of the resource, communication channel cost, reliability and popularity factor. We have proposed a framework for communication between resource owner and cloud using Resource Cloud Communication Paradigm (RCCP). We extend the CloudSim[2] adding provisioner policies and Efficient Resource Allocation (ERA) algorithm in VMM allocation policy as a decision support for resource provisioner.",
    "lastUpdated": "2012-07-11T16:37:51Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1207.2704v1"
  },
  {
    "title": "Confidentiality without Encryption For Cloud Computational Privacy",
    "author": [
      "Sashank Dara"
    ],
    "abstract": "Advances in technology has given rise to new computing models where any individual/organization (Cloud Service Consumers here by denoted as CSC's) can outsource their computational intensive tasks on their data to a remote Cloud Service Provider (CSP) for many advantages like lower costs, scalability etc. But such advantages come for a bigger cost \"Security and Privacy of data\" for this very reason many CSC's are skeptical to move towards cloud computing models. While the advances in cryptography research are promising, there are no practical solutions yet for performing any operations on encrypted data [1]. For this very reason there is strong need for finding alternative viable solutions for us to benefit from Cloud Computing. A technique to provide confidentiality without encryption was proposed in the past namely \"Chaffing and Winnowing: Confidentiality without Encryption\" by Ronald L. Rivest [2]. While this technique has been proposed for packet based communication system, its not adaptable in all cloud service models like Software-as-Service, Platform-as-Service or Infrastructure-as-Service [3]. In this paper we propose an adaptation of this technique in a cloud computational setup where CSC's outsource computational intensive tasks like web log parsing, DNA Sequencing etc to a MapReduce like CSP service.",
    "lastUpdated": "2012-08-01T03:05:17Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1208.0070v1"
  },
  {
    "title": "Enhanced Load Balancing Approach to Avoid Deadlocks in Cloud",
    "author": [
      "K. S. Rashmi",
      "V. Suma",
      "M. Vaidehi"
    ],
    "abstract": "The state-of-art of the technology focuses on data processing to deal with massive amount of data. Cloud computing is an emerging technology, which enables one to accomplish the aforementioned objective, leading towards improved business performance. It comprises of users requesting for the services of diverse applications from various distributed virtual servers. The cloud should provide resources on demand to its clients with high availability, scalability and with reduced cost. Load balancing is one of the essential factors to enhance the working performance of the cloud service provider. Since, cloud has inherited characteristic of distributed computing and virtualization there is a possibility of occurrence of deadlock. Hence, in this paper, a load balancing algorithm has been proposed to avoid deadlocks among the Virtual Machines (VMs) while processing the requests received from the users by VM migration. Further, this paper also provides the anticipated results with the implementation of the proposed algorithm. The deadlock avoidance enhances the number of jobs to be serviced by cloud service provider and thereby improving working performance and the business of the cloud service provider.",
    "lastUpdated": "2012-09-28T10:13:18Z",
    "category": [
      "cs.DC",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1209.6470v1"
  },
  {
    "title": "A Factor Framework for Experimental Design for Performance Evaluation of Commercial Cloud Services",
    "author": [
      "Zheng Li",
      "Liam O'Brien",
      "He Zhang",
      "Rainbow Cai"
    ],
    "abstract": "Given the diversity of commercial Cloud services, performance evaluations of candidate services would be crucial and beneficial for both service customers (e.g. cost-benefit analysis) and providers (e.g. direction of service improvement). Before an evaluation implementation, the selection of suitable factors (also called parameters or variables) plays a prerequisite role in designing evaluation experiments. However, there seems a lack of systematic approaches to factor selection for Cloud services performance evaluation. In other words, evaluators randomly and intuitively concerned experimental factors in most of the existing evaluation studies. Based on our previous taxonomy and modeling work, this paper proposes a factor framework for experimental design for performance evaluation of commercial Cloud services. This framework capsules the state-of-the-practice of performance evaluation factors that people currently take into account in the Cloud Computing domain, and in turn can help facilitate designing new experiments for evaluating Cloud services.",
    "lastUpdated": "2013-02-09T06:18:04Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1302.2203v1"
  },
  {
    "title": "A Newer User Authentication, File encryption and Distributed Server Based Cloud Computing Security Architecture",
    "author": [
      "Kawser Wazed Nafi",
      "Tonny Shekha Kar",
      "Sayed Anisul Hoque",
      "M. M. A. Hashem"
    ],
    "abstract": "The cloud computing platform gives people the opportunity for sharing resources, services and information among the people of the whole world. In private cloud system, information is shared among the persons who are in that cloud. For this, security or personal information hiding process hampers. In this paper we have proposed new security architecture for cloud computing platform. This ensures secure communication system and hiding information from others. AES based file encryption system and asynchronous key system for exchanging information or data is included in this model. This structure can be easily applied with main cloud computing features, e.g. PaaS, SaaS and IaaS. This model also includes onetime password system for user authentication process. Our work mainly deals with the security system of the whole cloud computing platform.",
    "lastUpdated": "2013-03-04T04:19:15Z",
    "category": [
      "cs.DC",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1303.0598v1"
  },
  {
    "title": "Using Smartphones as a Proxy for Forensic Evidence contained in Cloud Storage Services",
    "author": [
      "George Grispos",
      "William Bradley Glisson",
      "Tim Storer"
    ],
    "abstract": "Cloud storage services such as Dropbox, Box and SugarSync have been embraced by both individuals and organizations. This creates an environment that is potentially conducive to security breaches and malicious activities. The investigation of these cloud environments presents new challenges for the digital forensics community. It is anticipated that smartphone devices will retain data from these storage services. Hence, this research presents a preliminary investigation into the residual artifacts created on an iOS and Android device that has accessed a cloud storage service. The contribution of this paper is twofold. First, it provides an initial assessment on the extent to which cloud storage data is stored on these client-side devices. This view acts as a proxy for data stored in the cloud. Secondly, it provides documentation on the artifacts that could be useful in a digital forensics investigation of cloud services.",
    "lastUpdated": "2013-03-17T16:49:14Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1303.4078v1"
  },
  {
    "title": "Security and Privacy Issues in Cloud Computing",
    "author": [
      "Jaydip Sen"
    ],
    "abstract": "Cloud computing transforms the way information technology (IT) is consumed and managed, promising improved cost efficiencies, accelerated innovation, faster time-to-market, and the ability to scale applications on demand (Leighton, 2009). According to Gartner, while the hype grew exponentially during 2008 and continued since, it is clear that there is a major shift towards the cloud computing model and that the benefits may be substantial (Gartner Hype-Cycle, 2012). However, as the shape of the cloud computing is emerging and developing rapidly both conceptually and in reality, the legal/contractual, economic, service quality, interoperability, security and privacy issues still pose significant challenges. In this chapter, we describe various service and deployment models of cloud computing and identify major challenges. In particular, we discuss three critical challenges: regulatory, security and privacy issues in cloud computing. Some solutions to mitigate these challenges are also proposed along with a brief presentation on the future trends in cloud computing deployment.",
    "lastUpdated": "2013-03-20T02:24:14Z",
    "category": [
      "cs.CR",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1303.4814v1"
  },
  {
    "title": "Enhanced CBF Packet Filtering Method to Detect DDoS Attack in Cloud Computing Environment",
    "author": [
      "Priyanka Negi",
      "Anupama Mishra",
      "B. B. Gupta"
    ],
    "abstract": "Tremendous and extraordinary growths in the field of internet, intranet, extranet and its users have developed an innovative era of great global competition and contention. Denial of service attack by multiple nodes is accomplished of disturbing the services of rival servers. The attack can be for multiple reasons. So it is a major threat for cloud environment. Due to low effectiveness and large storage conventional defending approaches cannot be easily applied in cloud security. The effects of various attacks can decrease the influence of a cloud. So, in view of this challenge task, this paper aims at enhancing a proposed method for cloud security. We propose a modification to the confidence Based Filtering method (CBF) which is investigated for cloud computing environment based on correlation pattern to mitigate DDoS attacks on Cloud. The modification introduces nominal additional bandwidth and tries to increase the processing speed of the victim initiated server.",
    "lastUpdated": "2013-04-26T06:08:48Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1304.7073v1"
  },
  {
    "title": "A fast and robust algorithm to count topologically persistent holes in noisy clouds",
    "author": [
      "Vitaliy Kurlin"
    ],
    "abstract": "Preprocessing a 2D image often produces a noisy cloud of interest points. We study the problem of counting holes in unorganized clouds in the plane. The holes in a given cloud are quantified by the topological persistence of their boundary contours when the cloud is analyzed at all possible scales. We design the algorithm to count holes that are most persistent in the filtration of offsets (neighborhoods) around given points. The input is a cloud of $n$ points in the plane without any user-defined parameters. The algorithm has $O(n\\log n)$ time and $O(n)$ space. The output is the array (number of holes, relative persistence in the filtration). We prove theoretical guarantees when the algorithm finds the correct number of holes (components in the complement) of an unknown shape approximated by a cloud.",
    "lastUpdated": "2014-07-19T20:38:54Z",
    "category": [
      "cs.CG",
      "cs.CV",
      "math.AT",
      "68U05 (Primary) 65D18, 68U10 (Secondary)"
    ],
    "url": "http://arxiv.org/abs/1312.1492v3"
  },
  {
    "title": "Cloud Service-Aware Location Update in Mobile Cloud Computing",
    "author": [
      "Qi Qi",
      "Yufei Cao"
    ],
    "abstract": "Mobile devices are becoming the primary platforms for many users who always roam around when accessing the cloud computing services. From this, the cloud computing is integrated into the mobile environment by introducing a new paradigm, mobile cloud computing. In the context of mobile computing, the battery life of mobile device is limited, and it is important to balance the mobility performance and energy consumption. Fortunately, cloud services provide both opportunities and challenges for mobility management. Taking the activities of cloud services accessing into consideration, we propose a service-aware location update mechanism, which can detect the presence and location of the mobile device without traditional periodic registration update. Analytic model and simulation are developed to investigate the new mechanism. The results demonstrate that the service-aware location update management can reduce the location update times and handoff signaling, which can efficiently save power consumption for mobile devices.",
    "lastUpdated": "2013-12-13T15:53:34Z",
    "category": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1312.3847v1"
  },
  {
    "title": "A Novel Admission Control Model in Cloud Computing",
    "author": [
      "Yunlong He",
      "Jun Huang",
      "Qiang Duan",
      "Zi Xiong",
      "Juan Lv",
      "Yanbing Liu"
    ],
    "abstract": "With the rapid development of Cloud computing technologies and wide adopt of Cloud services and applications, QoS provisioning in Clouds becomes an important research topic. In this paper, we propose an admission control mechanism for Cloud computing. In particular we consider the high volume of simultaneous requests for Cloud services and develop admission control for aggregated traffic flows to address this challenge. By employ network calculus, we determine effective bandwidth for aggregate flow, which is used for making admission control decision. In order to improve network resource allocation while achieving Cloud service QoS, we investigate the relationship between effective bandwidth and equivalent capacity. We have also conducted extensive experiments to evaluate performance of the proposed admission control mechanism.",
    "lastUpdated": "2014-01-26T02:53:18Z",
    "category": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1401.4716v2"
  },
  {
    "title": "Truthful Market-based Trading of Cloud Resources with Reservation Price",
    "author": [
      "Sergei Chichin",
      "Quoc Bao Vo",
      "Ryszard Kowalczyk"
    ],
    "abstract": "With the rapidly growing demand for the cloud services, a need for efficient methods to trade computing resources increases. Commonly used fixed-price model is not always the best approach for trading cloud resources, because of its inflexible and static nature. Dynamic trading systems, which make use of market mechanisms, show promise for more efficient resource allocation and pricing in the cloud. However, most of the existing mechanisms ignore the seller's costs of providing the resources. In order to address it, we propose a single-sided market mechanism for trading virtual machine instances in the cloud, where the cloud provider can express the reservation prices for traded cloud services. We investigate the theoretical properties of the proposed mechanism and prove that it is truthful, i.e. the buyers do not have an incentive to lie about their true valuation of the resources. We perform extensive experiments in order to investigate the impact of the reserve price on the market outcome. Our experiments show that the proposed mechanism yields near optimal allocations and has a low execution time.",
    "lastUpdated": "2014-01-31T02:07:15Z",
    "category": [
      "cs.GT"
    ],
    "url": "http://arxiv.org/abs/1401.8038v1"
  },
  {
    "title": "Towards Cloud Computing: A SWOT Analysis on its Adoption in SMEs",
    "author": [
      "Kimia Ghaffari",
      "Mohammad Soltani Delgosha",
      "Neda Abdolvand"
    ],
    "abstract": "Over the past few years, emergence of cloud computing has notably made an evolution in the IT industry by putting forward an \"everything as a service\" idea .Cloud Computing is of growing interest to companies throughout the world, but there are many barriers associated with its adoption which should be eliminated. This paper aims to investigate Cloud Computing and discusses the drivers and inhibitors of its adoption. Moreover, an attempt has been made to identify the key stakeholders of Cloud Computing and outline the current security challenges. A SWOT analysis which consists of strengths, weaknesses, opportunities and threats has also carried out in which Cloud Computing adoption for SMEs (Small and Medium-sized Enterprises) is evaluated. Finally, the paper concludes with some further research areas in the field of Cloud Computing.",
    "lastUpdated": "2014-05-08T14:04:43Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1405.1932v1"
  },
  {
    "title": "Identity Management issues in Cloud Computing",
    "author": [
      "Smita Saini",
      "Deep Mann"
    ],
    "abstract": "Cloud computing is providing a low cost on demand services to the users, omnipresent network,large storage capacity due to these features of cloud computing web applications are moving towards the cloud and due to this migration of the web application,cloud computing platform is raised many issues like privacy, security etc. Privacy issue are major concern for the cloud computing. Privacy is to preserve the sensitive information of the cloud consumer and the major issues to the privacy are unauthorized secondary usage, lack of user control, unclear responsibility. For dealing with these privacy issues Identity management method are used. This paper discusses the privacy issue and different kind of identity management technique that are used for preserving the privacy.",
    "lastUpdated": "2014-06-03T12:08:44Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1406.1033v1"
  },
  {
    "title": "Laboratory Test Bench for Research Network and Cloud Computing",
    "author": [
      "Evgeniy Pluzhnik",
      "Evgeny Nikulchev",
      "Simon Payain"
    ],
    "abstract": "At present moment, there is a great interest in development of information systems operating in cloud infrastructures. Generally, many of tasks remain unresolved such as tasks of optimization of large databases in a hybrid cloud infrastructure, quality of service (QoS) at different levels of cloud services, dynamic control of distribution of cloud resources in application systems and many others. Research and development of new solutions can be limited in case of using emulators or international commercial cloud services, due to the closed architecture and limited opportunities for experimentation. Article provides answers to questions on the establishment of a pilot cloud practically \"at home\" with the ability to adjust the width of the emulation channel and delays in data transmission. It also describes architecture and configuration of the experimental setup. The proposed modular structure can be expanded by available computing power.",
    "lastUpdated": "2014-09-14T18:00:13Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1409.4626v1"
  },
  {
    "title": "Heterogeneous Cloud Radio Access Networks: A New Perspective for Enhancing Spectral and Energy Efficiencies",
    "author": [
      "Mugen Peng",
      "Yuan Li",
      "Jiamo Jiang",
      "Jian Li",
      "Chonggang Wang"
    ],
    "abstract": "To mitigate the severe inter-tier interference and enhance limited cooperative gains resulting from the constrained and non-ideal transmissions between adjacent base stations in heterogeneous networks (HetNets), heterogeneous cloud radio access networks (H-CRANs) are proposed as cost-efficient potential solutions through incorporating the cloud computing into HetNets. In this article, state-of-the-art research achievements and challenges on H-CRANs are surveyed. In particular, we discuss issues of system architectures, spectral and energy efficiency performances, and promising key techniques. A great emphasis is given towards promising key techniques in H-CRANs to improve both spectral and energy efficiencies, including cloud computing based coordinated multi-point transmission and reception, large-scale cooperative multiple antenna, cloud computing based cooperative radio resource management, and cloud computing based self-organizing network in the cloud converging scenarios. The major challenges and open issues in terms of theoretical performance with stochastic geometry, fronthaul constrained resource allocation, and standard development that may block the promotion of H-CRANs are discussed as well.",
    "lastUpdated": "2014-10-11T20:44:47Z",
    "category": [
      "cs.NI",
      "C.2.1"
    ],
    "url": "http://arxiv.org/abs/1410.3028v1"
  },
  {
    "title": "Quantum Clouds: A future perspective",
    "author": [
      "Satish Bhambri"
    ],
    "abstract": "Quantum computing and cloud computing are two giants for futuristic computing. Both technologies complement each other. Quantum clouds, therefore, is deploying the resources of quantum computation in a cloud environment to provide solution to the challenges and problems faced by present model of classical cloud computation. State of the art challenges faced by the cloud such as VM migration, data security, traffic management can be addressed by the quantum principles. But the merging of these two technologies have challenges of their own which need to be addressed before moving forward. What are those challenges and how does a quantum computer solve the cloud problems? The relation among quantum parallelism, superposition and flash crowd effect; Laundauer's principle and energy management; photon polarization principle and data security; these fascinating queries are addressed in the paper.",
    "lastUpdated": "2014-10-05T16:59:57Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1410.6502v1"
  },
  {
    "title": "Social Cloud: Concept, Current Trends and Future Scope",
    "author": [
      "Pramod Mane",
      "Monalisa Sarma",
      "Debasis Samanta",
      "Kapil Ahuja"
    ],
    "abstract": "In recent years, various kinds of distributed resource sharing setups have been proposed by taking social relationships into consideration. These dissimilar resource sharing setups are tagged as Social Cloud. These setups have appeared in various distributed computing forms such as community cloud, grid, volunteer computing and network services. Such setups are discrete in nature, and hence, do not conceptualize the totality of the Social Cloud concept. In fact, it is difficult to conceptualize Social Cloud without a general framework. There are three main objectives of this work. First, to present a general framework of Social Cloud. Second, to report various Social Cloud setups with corresponding architectural prototypes and current trends. Third, to discuss research challenges.",
    "lastUpdated": "2015-08-30T15:36:11Z",
    "category": [
      "cs.CY",
      "cs.SI"
    ],
    "url": "http://arxiv.org/abs/1411.2702v4"
  },
  {
    "title": "Performance-oriented Cloud Provisioning: Taxonomy and Survey",
    "author": [
      "Yasir Shoaib",
      "Olivia Das"
    ],
    "abstract": "Cloud computing is being viewed as the technology of today and the future. Through this paradigm, the customers gain access to shared computing resources located in remote data centers that are hosted by cloud providers (CP). This technology allows for provisioning of various resources such as virtual machines (VM), physical machines, processors, memory, network, storage and software as per the needs of customers. Application providers (AP), who are customers of the CP, deploy applications on the cloud infrastructure and then these applications are used by the end-users. To meet the fluctuating application workload demands, dynamic provisioning is essential and this article provides a detailed literature survey of dynamic provisioning within cloud systems with focus on application performance. The well-known types of provisioning and the associated problems are clearly and pictorially explained and the provisioning terminology is clarified. A very detailed and general cloud provisioning classification is presented, which views provisioning from different perspectives, aiding in understanding the process inside-out. Cloud dynamic provisioning is explained by considering resources, stakeholders, techniques, technologies, algorithms, problems, goals and more.",
    "lastUpdated": "2014-11-19T00:04:52Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1411.5077v1"
  },
  {
    "title": "Efficient Support of Big Data Storage Systems on the Cloud",
    "author": [
      "Akshay MS",
      "Suhas Mohan",
      "Vincent Kuri",
      "Dinkar Sitaram",
      "H. L. Phalachandra"
    ],
    "abstract": "Due to its advantages over traditional data centers, there has been a rapid growth in the usage of cloud infrastructures. These include public clouds (e.g., Amazon EC2), or private clouds, such as clouds deployed using OpenStack. A common factor in many of the well known infrastructures, for example OpenStack and CloudStack, is that networked storage is used for storage of persistent data. However, traditional Big Data systems, including Hadoop, store data in commodity local storage for reasons of high performance and low cost. We present an architecture for supporting Hadoop on Openstack using local storage. Subsequently, we use benchmarks on Openstack and Amazon to show that for supporting Hadoop, local storage has better performance and lower cost. We conclude that cloud systems should support local storage for persistent data (in addition to networked storage) so as to provide efficient support for Hadoop and other Big Data systems",
    "lastUpdated": "2014-11-27T09:25:54Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1411.7507v1"
  },
  {
    "title": "Survey of Uncertainty Handling in Cloud Service Discovery and Composition",
    "author": [
      "Nouha Khédiri",
      "Montaceur Zaghdoud"
    ],
    "abstract": "With the spread of services related to cloud environment, it is tiresome and time consuming for users to look for the appropriate service that meet with their needs. Therefore, finding a valid and reliable service is essential. However, in case a single cloud service cannot fulfil every user requirements, a composition of cloud services is needed. In addition, the need to treat uncertainty in cloud service discovery and composition induces a lot of concerns in order to minimize the risk. Risk includes some sort of either loss or damage which is possible to be received by a target (i.e., the environment, cloud providers or customers). In this paper, we will focus on the uncertainty application for cloud service discovery and composition. A set of existing approaches in literature are reviewed and categorized according to the risk modeling.",
    "lastUpdated": "2015-01-07T15:58:25Z",
    "category": [
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/1501.01537v1"
  },
  {
    "title": "Don't Trust the Cloud, Verify: Integrity and Consistency for Cloud Object Stores",
    "author": [
      "Marcus Brandenburger",
      "Christian Cachin",
      "Nikola Knežević"
    ],
    "abstract": "Cloud services have turned remote computation into a commodity and enable convenient online collaboration. However, they require that clients fully trust the service provider in terms of confidentiality, integrity, and availability. Towards reducing this dependency, this paper introduces a protocol for verification of integrity and consistency for cloud object storage (VICOS), which enables a group of mutually trusting clients to detect data-integrity and consistency violations for a cloud object-storage service. It aims at services where multiple clients cooperate on data stored remotely on a potentially misbehaving service. VICOS enforces the consistency notion of fork-linearizability, supports wait-free client semantics for most operations, and reduces the computation and communication overhead compared to previous protocols. VICOS is based in a generic way on any authenticated data structure. Moreover, its operations cover the hierarchical name space of a cloud object store, supporting a real-world interface and not only a simplistic abstraction. A prototype of VICOS that works with the key-value store interface of commodity cloud storage services has been implemented, and an evaluation demonstrates its advantage compared to existing systems.",
    "lastUpdated": "2016-09-02T14:49:35Z",
    "category": [
      "cs.DC",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1502.04496v2"
  },
  {
    "title": "A New Secure Mobile Cloud Architecture",
    "author": [
      "Olayinka Olafare",
      "Hani Parhizkar",
      "Silas Vem"
    ],
    "abstract": "The demand and use of mobile phones, PDAs and smart phones are constantly on the rise as such, manufacturers of these devices are improving the technology and usability of these devices constantly. Due to the handy shape and size these devices come in, their processing capabilities and functionalities, they are preferred by many over the conventional desktop or laptop computers. Mobile devices are being used today to perform most tasks that a desktop or laptop computer could be used for. On this premise, mobile devices are also used to connect to the resources of cloud computing hence, mobile cloud computing (MCC). The seemingly ubiquitous and pervasive nature of most mobile devices has made it acceptable and adequate to match the ubiquitous and pervasive nature of cloud computing. Mobile cloud computing is said to have increased the challenges known to cloud computing due to the security loop holes that most mobile devices have.",
    "lastUpdated": "2015-04-25T08:28:46Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1504.07563v1"
  },
  {
    "title": "Evaluation of Two-Level Load Balancing Framework in Cloud Environment",
    "author": [
      "Po-Huei Liang",
      "Jiann-Min Yang"
    ],
    "abstract": "With technological advancements and constant changes of Internet, cloud computing has been today's trend. With the lower cost and convenience of cloud computing services, users have increasingly put their Web resources and information in the cloud environment. The availability and reliability of the client systems will become increasingly important. Today cloud applications slightest interruption, the impact will be significant for users. It is an important issue that how to ensure reliability and stability of the cloud sites. Load balancing would be one good solution. This paper presents a framework for global server load balancing of the Web sites in a cloud with two-level load balancing model. The proposed framework is intended for adapting an open-source load-balancing system and the framework allows the network service provider to deploy a load balancer in different data centers dynamically while the customers need more load balancers for increasing the availability.",
    "lastUpdated": "2015-05-12T06:20:57Z",
    "category": [
      "cs.NI",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1505.02884v1"
  },
  {
    "title": "Video Surveillance in the Cloud?",
    "author": [
      "DJ Neal",
      "Shawon Rahman"
    ],
    "abstract": "A high-resolution video surveillance management system incurs huge amounts of storage and network bandwidth. The current infrastructure required to support a high resolution video surveillance management system (VMS) is expensive and time consuming to plan, implement and maintain. With the recent advances in cloud technologies, opportunity for the utilization of virtualization and the opportunity for distributed computing techniques of cloud storage have been pursued on the basis to find out if the various cloud computing services that are available can support the current requirements to a high resolution video surveillance management system. The research concludes, after investigating and comparing various Software as a Service (SaaS), Platform as a Service (PaaS), and Infrastructure as a Service (IaaS) cloud computing provides what is possible to architect a VMS using cloud technologies; however, it is more expensive and it will require additional reviews for legal implications, as well as emerging threats and countermeasures associated with using cloud technologies for a video surveillance management system",
    "lastUpdated": "2015-11-30T22:24:33Z",
    "category": [
      "cs.CR",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1512.00070v1"
  },
  {
    "title": "(Literally) above the clouds: virtualizing the network over multiple clouds",
    "author": [
      "Max Alaluna",
      "Fernando M. V. Ramos",
      "Nuno Neves"
    ],
    "abstract": "Recent SDN-based solutions give cloud providers the opportunity to extend their \"as-a-service\" model with the offer of complete network virtualization. They provide tenants with the freedom to specify the network topologies and addressing schemes of their choosing, while guaranteeing the required level of isolation among them. These platforms, however, have been targeting the datacenter of a single cloud provider with full control over the infrastructure. This paper extends this concept further by supporting the creation of virtual networks that span across several datacenters, which may belong to distinct cloud providers, while including private facilities owned by the tenant. In order to achieve this, we introduce a new network layer above the existing cloud hypervisors, affording the necessary level of control over the communications while hiding the heterogeneity of the clouds. The benefits of this approach are various, such as enabling finer decisions on where to place the virtual machines (e.g., to fulfill legal requirements), avoiding single points of failure, and potentially decreasing costs. Although our focus in the paper is on architecture design, we also present experimental results of a first prototype of the proposed solution.",
    "lastUpdated": "2016-03-10T17:29:51Z",
    "category": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1512.01196v2"
  },
  {
    "title": "Towards Media Intercloud Standardization Evaluating Impact of Cloud Storage Heterogeneity",
    "author": [
      "Mohammad Aazam",
      "Marc StHilaire",
      "EuiNam Huh"
    ],
    "abstract": "Digital media has been increasing very rapidly, resulting in cloud computing's popularity gain. Cloud computing provides ease of management of large amount of data and resources. With a lot of devices communicating over the Internet and with the rapidly increasing user demands, solitary clouds have to communicate to other clouds to fulfill the demands and discover services elsewhere. This scenario is called intercloud computing or cloud federation. Intercloud computing still lacks standard architecture. Prior works discuss some of the architectural blueprints, but none of them highlight the key issues involved and their impact, so that a valid and reliable architecture could be envisioned. In this paper, we discuss the importance of intercloud computing and present in detail its architectural components. Intercloud computing also involves some issues. We discuss key issues as well and present impact of storage heterogeneity. We have evaluated some of the most noteworthy cloud storage services, namely Dropbox, Amazon CloudDrive, GoogleDrive, Microsoft OneDrive (formerly SkyDrive), Box, and SugarSync in terms of Quality of Experience (QoE), Quality of Service (QoS), and storage space efficiency. Discussion on the results shows the acceptability level of these storage services and the shortcomings in their design.",
    "lastUpdated": "2016-02-19T18:20:52Z",
    "category": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1602.06246v1"
  },
  {
    "title": "IOTSim: a Cloud based Simulator for Analysing IoT Applications",
    "author": [
      "Xuezhi Zeng",
      "Saurabh Kumar Garg",
      "Peter Strazdins",
      "Prem Jayaraman",
      "Dimitrios Georgakopoulos",
      "Rajiv Ranjan"
    ],
    "abstract": "A disruptive technology that is influencing not only computing paradigm but every other business is the rise of big data. Internet of Things (IoT) applications are considered to be a major source of big data. Such IoT applications are in general supported through clouds where data is stored and processed by big data processing systems. In order to improve the efficiency of cloud infrastructure so that they can efficiently support IoT big data applications, it is important to understand how these applications and the corresponding big data processing systems will perform in cloud computing environments. However, given the scalability and complex requirements of big data processing systems, an empirical evaluation on actual cloud infrastructure can hinder the development of timely and cost effective IoT solutions. Therefore, a simulator supporting IoT applications in cloud environment is highly demanded, but such work is still in its infancy. To fill this gap, we have designed and implemented IOTSim which supports and enables simulation of IoT big data processing using MapReduce model in cloud computing environment. A real case study validates the efficacy of the simulator.",
    "lastUpdated": "2016-02-21T02:32:03Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1602.06488v1"
  },
  {
    "title": "Achieving Energy Efficiency in Cloud Brokering",
    "author": [
      "Lin Wang",
      "Lei Jiao",
      "Mateusz Guzek",
      "Dzmitry Kliazovich",
      "Pascal Bouvry"
    ],
    "abstract": "The proliferation of cloud providers has brought substantial interoperability complexity to the public cloud market, in which cloud brokering has been playing an important role. However, energy-related issues for public clouds have not been well addressed in the literature. In this paper, we claim that the broker is also situated in a perfect position where necessary actions can be taken to achieve energy efficiency for public cloud systems, particularly through job assignment and scheduling. We formulate the problem by a mixed integer program and prove its NP-hardness. Based on the complexity analysis, we simplify the problem by introducing admission control on jobs. In the sequel, optimal job assignment can be done straightforwardly and the problem is transformed into improving job admission rate by scheduling on two coupled phases: data transfer and job execution. The two scheduling phases are further decoupled and we develop efficient scheduling algorithm for each of them. Experimental results show that the proposed solution can achieve significant reduction on energy consumption with admission rates improved as well, even in large-scale public cloud systems.",
    "lastUpdated": "2016-04-11T14:21:00Z",
    "category": [
      "cs.NI",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1604.02971v1"
  },
  {
    "title": "Using Design Science to build a Watermark System for Righful Ownership Protection in the Cloud",
    "author": [
      "Brian Cusack",
      "Reza Khaleghparast"
    ],
    "abstract": "Cloud computing opportunities have presented service options for users that are both economical and flexible to use requirements. However, the risk analysis for the user identifies vulnerabilities for intellectual property ownership and vulnerabilities for the identification of rightful property owners when cloud services are used. It is common for image owners to embed watermarks and other security mechanisms into their property so that the rightful ownership may be identified. In this paper we present a design that overcomes many of the current limitations in cloud watermarking uses and propose a schema that places responsibility on the cloud provider to have a robust information protection program. Such a design solution lays out an information security architecture that enhances utility for cloud services and gives better options for users to securely place properties in the cloud. The Design Science methodology is used to build the artefact.",
    "lastUpdated": "2016-06-08T11:04:39Z",
    "category": [
      "cs.CY",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1606.02508v1"
  },
  {
    "title": "SICS: Secure In-Cloud Service Function Chaining",
    "author": [
      "Huazhe Wang",
      "Xin Li",
      "Yu Zhao",
      "Ye Yu",
      "Hongkun Yang",
      "Chen Qian"
    ],
    "abstract": "There is an increasing trend that enterprises outsource their network functions to the cloud for lower cost and ease of management. However, network function outsourcing brings threats to the privacy of enterprises since the cloud is able to access the traffic and rules of in-cloud network functions. Current tools for secure network function outsourcing either incur large performance overhead or do not support real-time updates. In this paper, we present SICS, a secure service function chain outsourcing framework. SICS encrypts each packet header and use a label for in-cloud rule matching, which enables the cloud to perform its functionalities correctly with minimum header information leakage. Evaluation results show that SICS achieves higher throughput, faster construction and update speed, and lower resource overhead at both enterprise and cloud sides, compared to existing solutions.",
    "lastUpdated": "2016-06-22T20:03:56Z",
    "category": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1606.07079v1"
  },
  {
    "title": "Internet of Things Cloud: Architecture and Implementation",
    "author": [
      "Lu Hou",
      "Shaohang Zhao",
      "Xiong Xiong",
      "Kan Zheng",
      "Periklis Chatzimisios",
      "M. Shamim Hossain",
      "Wei Xiang"
    ],
    "abstract": "The Internet of Things (IoT), which enables common objects to be intelligent and interactive, is considered the next evolution of the Internet. Its pervasiveness and abilities to collect and analyze data which can be converted into information have motivated a plethora of IoT applications. For the successful deployment and management of these applications, cloud computing techniques are indispensable since they provide high computational capabilities as well as large storage capacity. This paper aims at providing insights about the architecture, implementation and performance of the IoT cloud. Several potential application scenarios of IoT cloud are studied, and an architecture is discussed regarding the functionality of each component. Moreover, the implementation details of the IoT cloud are presented along with the services that it offers. The main contributions of this paper lie in the combination of the Hypertext Transfer Protocol (HTTP) and Message Queuing Telemetry Transport (MQTT) servers to offer IoT services in the architecture of the IoT cloud with various techniques to guarantee high performance. Finally, experimental results are given in order to demonstrate the service capabilities of the IoT cloud under certain conditions.",
    "lastUpdated": "2016-09-25T08:15:24Z",
    "category": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1609.07712v1"
  },
  {
    "title": "Analyzing Cloud Optical Properties Using Sky Cameras",
    "author": [
      "Shilpa Manandhar",
      "Soumyabrata Dev",
      "Yee Hui Lee",
      "Yu Song Meng"
    ],
    "abstract": "Clouds play a significant role in the fluctuation of solar radiation received by the earth's surface. It is important to study the various cloud properties, as it impacts the total solar irradiance falling on the earth's surface. One of such important optical properties of the cloud is the Cloud Optical Thickness (COT). It is defined with the amount of light that can pass through the clouds. The COT values are generally obtained from satellite images. However, satellite images have a low temporal- and spatial- resolutions; and are not suitable for study in applications as solar energy generation and forecasting. Therefore, ground-based sky cameras are now getting popular in such fields. In this paper, we analyze the cloud optical thickness value, from the ground-based sky cameras, and provide future research directions.",
    "lastUpdated": "2017-08-24T16:50:54Z",
    "category": [
      "cs.CV",
      "physics.ao-ph"
    ],
    "url": "http://arxiv.org/abs/1708.08995v1"
  },
  {
    "title": "Cloud-aided collaborative estimation by ADMM-RLS algorithms for connected vehicle prognostics",
    "author": [
      "Valentina Breschi",
      "Ilya Kolmanovsky",
      "Alberto Bemporad"
    ],
    "abstract": "As the connectivity of consumer devices is rapidly growing and cloud computing technologies are becoming more widespread, cloud-aided techniques for parameter estimation can be designed to exploit the theoretically unlimited storage memory and computational power of the cloud, while relying on information provided by multiple sources. With the ultimate goal of developing monitoring and diagnostic strategies, this report focuses on the design of a Recursive Least-Squares (RLS) based estimator for identification over a group of devices connected to the cloud. The proposed approach, that relies on Node-to-Cloud-to-Node (N2C2N) transmissions, is designed so that: (i) estimates of the unknown parameters are computed locally and (ii) the local estimates are refined on the cloud. The proposed approach requires minimal changes to local (pre-existing) RLS estimators.",
    "lastUpdated": "2017-09-22T23:38:08Z",
    "category": [
      "cs.SY",
      "cs.DC",
      "cs.MA",
      "eess.SP",
      "math.OC"
    ],
    "url": "http://arxiv.org/abs/1709.07972v1"
  },
  {
    "title": "Micky: A Cheaper Alternative for Selecting Cloud Instances",
    "author": [
      "Chin-Jung Hsu",
      "Vivek Nair",
      "Tim Menzies",
      "Vincent Freeh"
    ],
    "abstract": "Most cloud computing optimizers explore and improve one workload at a time. When optimizing many workloads, the single-optimizer approach can be prohibitively expensive. Accordingly, we examine \"collective optimizer\" that concurrently explore and improve a set of workloads significantly reducing the measurement costs. Our large-scale empirical study shows that there is often a single cloud configuration which is surprisingly near-optimal for most workloads. Consequently, we create a collective-optimizer, MICKY, that reformulates the task of finding the near-optimal cloud configuration as a multi-armed bandit problem. MICKY efficiently balances exploration (of new cloud configurations) and exploitation (of known good cloud configuration). Our experiments show that MICKY can achieve on average 8.6 times reduction in measurement cost as compared to the state-of-the-art method while finding near-optimal solutions. Hence we propose MICKY as the basis of a practical collective optimization method for finding good cloud configurations (based on various constraints such as budget and tolerance to near-optimal configurations).",
    "lastUpdated": "2018-03-15T04:14:03Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1803.05587v1"
  },
  {
    "title": "Reinforcement Learning for Resource Provisioning in Vehicular Cloud",
    "author": [
      "Mohammad A. Salahuddin",
      "Ala Al-Fuqaha",
      "Mohsen Guizani"
    ],
    "abstract": "This article presents a concise view of vehicular clouds that incorporates various vehicular cloud models, which have been proposed, to date. Essentially, they all extend the traditional cloud and its utility computing functionalities across the entities in the vehicular ad hoc network (VANET). These entities include fixed road-side units (RSUs), on-board units (OBUs) embedded in the vehicle and personal smart devices of the driver and passengers. Cumulatively, these entities yield abundant processing, storage, sensing and communication resources. However, vehicular clouds require novel resource provisioning techniques, which can address the intrinsic challenges of (i) dynamic demands for the resources and (ii) stringent QoS requirements. In this article, we show the benefits of reinforcement learning based techniques for resource provisioning in the vehicular cloud. The learning techniques can perceive long term benefits and are ideal for minimizing the overhead of resource provisioning for vehicular clouds.",
    "lastUpdated": "2018-05-28T16:02:51Z",
    "category": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1805.11000v1"
  },
  {
    "title": "A Blockchain-based Flight Data Recorder for Cloud Accountability",
    "author": [
      "Gabriele D'Angelo",
      "Stefano Ferretti",
      "Moreno Marzolla"
    ],
    "abstract": "Many companies rely on Cloud infrastructures for their computation, communication and data storage requirements. While Cloud services provide some benefits, e.g., replacing high upfront costs for an IT infrastructure with a pay-as-you-go model, they also introduce serious concerns that are notoriously difficult to address. In essence, Cloud customers are storing data and running computations on infrastructures that they can not control directly. Therefore, when problems arise -- violations of Service Level Agreements, data corruption, data leakage, security breaches -- both customers and Cloud providers face the challenge of agreeing on which party is to be held responsible. In this paper, we review the challenges and requirements for enforcing accountability in Cloud infrastructures, and argue that smart contracts and blockchain technologies might provide a key contribution towards accountable Clouds.",
    "lastUpdated": "2018-06-12T14:08:25Z",
    "category": [
      "cs.DC",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1806.04544v1"
  },
  {
    "title": "Continuation of Point Clouds via Persistence Diagrams",
    "author": [
      "Marcio Gameiro",
      "Yasuaki Hiraoka",
      "Ippei Obayashi"
    ],
    "abstract": "In this paper, we present a mathematical and algorithmic framework for the continuation of point clouds by persistence diagrams. A key property used in the method is that the persistence map, which assigns a persistence diagram to a point cloud, is differentiable. This allows us to apply the Newton-Raphson continuation method in this setting. Given an original point cloud $P$, its persistence diagram $D$, and a target persistence diagram $D'$, we gradually move from $D$ to $D'$, by successively computing intermediate point clouds until we finally find a point cloud $P'$ having $D'$ as its persistence diagram. Our method can be applied to a wide variety of situations in topological data analysis where it is necessary to solve an inverse problem, from persistence diagrams to point cloud data.",
    "lastUpdated": "2015-06-10T02:25:47Z",
    "category": [
      "math.NA",
      "cs.CG",
      "math.AT",
      "math.DS"
    ],
    "url": "http://arxiv.org/abs/1506.03147v1"
  },
  {
    "title": "Security and Privacy of Sensitive Data in Cloud Computing: A Survey of Recent Developments",
    "author": [
      "Ali Gholami",
      "Erwin Laure"
    ],
    "abstract": "Cloud computing is revolutionizing many ecosystems by providing organizations with computing resources featuring easy deployment, connectivity, configuration, automation and scalability. This paradigm shift raises a broad range of security and privacy issues that must be taken into consideration. Multi-tenancy, loss of control, and trust are key challenges in cloud computing environments. This paper reviews the existing technologies and a wide array of both earlier and state-of-the-art projects on cloud security and privacy. We categorize the existing research according to the cloud reference architecture orchestration, resource control, physical resource, and cloud service management layers, in addition to reviewing the existing developments in privacy-preserving sensitive data approaches in cloud computing such as privacy threat modeling and privacy enhancing protocols and solutions.",
    "lastUpdated": "2016-01-07T11:53:20Z",
    "category": [
      "cs.CR",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1601.01498v1"
  },
  {
    "title": "About the Suitability of Clouds in High-Performance Computing",
    "author": [
      "Harald Richter"
    ],
    "abstract": "Cloud computing has become the ubiquitous computing and storage paradigm. It is also attractive for scientists, because they do not have to care any more for their own IT infrastructure, but can outsource it to a Cloud Service Provider of their choice. However, for the case of High-Performance Computing (HPC) in a cloud, as it is needed in simulations or for Big Data analysis, things are getting more intricate, because HPC codes must stay highly efficient, even when executed by many virtual cores (vCPUs). Older clouds or new standard clouds can fulfil this only under special precautions, which are given in this article. The results can be extrapolated to other cloud OSes than OpenStack and to other codes than OpenFOAM, which were used as examples.",
    "lastUpdated": "2016-01-08T15:35:41Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1601.01910v1"
  },
  {
    "title": "SENDIM for Incremental Development of Cloud Networks",
    "author": [
      "Pradeeban Kathiravelu",
      "Luís Veiga"
    ],
    "abstract": "Due to the limited and varying availability of cheap infrastructure and resources, cloud network systems and applications are tested in simulation and emulation environments prior to physical deployments, at different stages of development. Configuration management tools manage deployments and migrations across different cloud platforms, mitigating tedious system administration efforts. However, currently a cloud networking simulation cannot be migrated as an emulation, or vice versa, without rewriting and manually re-deploying the simulated application. This paper presents SENDIM (Sendim is a northeastern Portuguese town close to the Spanish border, where the rare Mirandese language is spoken), a Simulation, Emulation, aNd Deployment Integration Middleware for cloud networks. As an orchestration platform for incrementally building Software-Defined Cloud Networks (SDCN), SENDIM manages the development and deployment of algorithms and architectures the entire length from visualization, simulation, emulation, to physical deployments. Hence, SENDIM optimizes the evaluation of cloud networks.",
    "lastUpdated": "2016-01-09T16:52:23Z",
    "category": [
      "cs.NI",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1601.02130v1"
  },
  {
    "title": "Cloud-Aware Web Service Security: Information Hiding in Cloud Computing",
    "author": [
      "Okal Christopher Otieno"
    ],
    "abstract": "This study concerns the security challenges that the people face in the usage and implementation of cloud computing. Despite its growth in the past few decades, this platform has experienced different challenges. They all arise from the concern of data safety that the nature of sharing in the cloud presents. This paper looks to identify the benefits of using a cloud computing platform and the issue of information security. The paper also reviews the concept of information hiding and its relevance to the cloud. This technique has two ways about it that impact how people use cloud computing in their organizations and even for personal implementations. First it presents the potential to circulate harmful information and files that can adversely affect the data those users upload on those platforms. It is also the basis of the strategies such as steganalysis and cryptographic storage architecture that are essential for data security.",
    "lastUpdated": "2015-09-02T17:28:46Z",
    "category": [
      "cs.CY",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1610.03179v1"
  },
  {
    "title": "Combining Usability and Privacy Protection in Free-Access Public Cloud Storage Servers: Review of the Main Threats and Challenges",
    "author": [
      "Alejandro Sanchez-Gomez",
      "Jesus Diaz",
      "David Arroyo"
    ],
    "abstract": "The 21st century belongs to the world of computing, specially as a result of the so-called cloud computing. This technology enables ubiquitous information management and thus people can access all their data from any place and at any time. In this landscape, the emergence of cloud storage has had an important role in the last five years. Nowadays, several free-access public cloud storage services make it possible for users to have a free backup of their assets and to manage and share them, representing a low-cost opportunity for Small and Medium Companies (SME). However, the adoption of cloud storage involves data outsourcing, so a user does not have the guarantee about the way her data will be processed and protected. Therefore, it seems necessary to endow public cloud storage with a set of means to protect users' confidentiality and privacy, to assess data integrity and to guarantee a proper backup of information assets. Along this paper we discuss the main challenges to achieve such a goal, underlining the set of functionalities already implemented in the most popular public cloud storage services.",
    "lastUpdated": "2016-10-27T11:59:17Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1610.08727v1"
  },
  {
    "title": "A New Framework for Ranking Vulnerabilities in the Clouds",
    "author": [
      "He Zhu"
    ],
    "abstract": "Qualifying and ranking threat degrees of vulnerabilities in cloud service are known to be full of challenges. Although there have been several efforts aiming to address this problem, most of them are too simple or cannot be applied into cloud infrastructure. This paper aims to propose a novel framework to qualify and rank the vulnerabilities based on their threat degrees in cloud service. Through inputting or constructing service dependency graph, our framework is able to generate the importance degree of each service and the ranking list of all the vulnerabilities in cloud service. Moreover, our framework can be adopted not only into various cloud infrastructures, but also different categories of algorithms according to concrete requirements. To evaluate our framework, we adopt AssetRank algorithm into the framework, and present the whole design of our work. Comprehensive experiments prove the effectiveness of our framework on qualifying and ranking vulnerabilities in cloud service.",
    "lastUpdated": "2016-12-06T19:25:31Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1611.07617v2"
  },
  {
    "title": "Comparison of Multi Criteria Decision Making Algorithms for Ranking Cloud Renderfarm Services",
    "author": [
      "Annette J Ruby",
      "Banu W Aisha",
      "Chandran P Subash"
    ],
    "abstract": "Cloud services that provide a complete environment for the animators to render their files using the resources in the cloud are called Cloud Renderfarm Services. The objective of this work is to rank and compare the performance of these services using two popular Multi Criteria Decision Making (MCDM) Algorithms namely the Analytical Hierarchical Processing (AHP) and SAW (Simple Additive Weighting) methods. The performance of three real time cloud renderfarm services are ranked and compared based on five Quality of Service (QoS) attributes that are important to these services namely the Render Node Cost, File Upload Time, Availability, Elasticity and Service Response Time. The performance of these cloud renderfarm services are ranked in four different simulations by varying the weights assigned for each QoS attribute and the ranking obtained are compared. The results show that AHP and SAW assigned similar ranks to all three cloud renderfarm services for all simulations.",
    "lastUpdated": "2016-11-29T05:27:47Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1611.10204v1"
  },
  {
    "title": "Data-Intensive Supercomputing in the Cloud: Global Analytics for Satellite Imagery",
    "author": [
      "Michael S. Warren",
      "Samuel W. Skillman",
      "Rick Chartrand",
      "Tim Kelton",
      "Ryan Keisler",
      "David Raleigh",
      "Matthew Turk"
    ],
    "abstract": "We present our experiences using cloud computing to support data-intensive analytics on satellite imagery for commercial applications. Drawing from our background in high-performance computing, we draw parallels between the early days of clustered computing systems and the current state of cloud computing and its potential to disrupt the HPC market. Using our own virtual file system layer on top of cloud remote object storage, we demonstrate aggregate read bandwidth of 230 gigabytes per second using 512 Google Compute Engine (GCE) nodes accessing a USA multi-region standard storage bucket. This figure is comparable to the best HPC storage systems in existence. We also present several of our application results, including the identification of field boundaries in Ukraine, and the generation of a global cloud-free base layer from Landsat imagery.",
    "lastUpdated": "2017-02-13T19:00:04Z",
    "category": [
      "cs.DC",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1702.03935v1"
  },
  {
    "title": "Exploiting Data Reduction Principles in Cloud-Based Data Management for Cryo-Image Data",
    "author": [
      "Kashish Ara Shakil",
      "Ari Ora",
      "Mansaf Alam",
      "Shabih Shakeel"
    ],
    "abstract": "Cloud computing is a cost-effective way for start-up life sciences laboratories to store and manage their data. However, in many instances the data stored over the cloud could be redundant which makes cloud-based data management inefficient and costly because one has to pay for every byte of data stored over the cloud. Here, we tested efficient management of data generated by an electron cryo microscopy (cryoEM) lab on a cloud-based environment. The test data was obtained from cryoEM repository EMPIAR. All the images were subjected to an in-house parallelized version of principal component analysis. An efficient cloud-based MapReduce modality was used for parallelization. We showed that large data in order of terabytes could be efficiently reduced to its minimal essential self in a cost-effective scalable manner. Furthermore, on-spot instance on Amazon EC2 was shown to reduce costs by a margin of about 27 percent. This approach could be scaled to data of any large volume and type.",
    "lastUpdated": "2017-03-28T11:26:48Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1703.10105v1"
  },
  {
    "title": "Optimal Posted Prices for Online Cloud Resource Allocation",
    "author": [
      "Zijun Zhang",
      "Zongpeng Li",
      "Chuan Wu"
    ],
    "abstract": "We study online resource allocation in a cloud computing platform, through a posted pricing mechanism: The cloud provider publishes a unit price for each resource type, which may vary over time; upon arrival at the cloud system, a cloud user either takes the current prices, renting resources to execute its job, or refuses the prices without running its job there. We design pricing functions based on the current resource utilization ratios, in a wide array of demand-supply relationships and resource occupation durations, and prove worst-case competitive ratios of the pricing functions in terms of social welfare. In the basic case of a single-type, non-recycled resource (i.e., allocated resources are not later released for reuse), we prove that our pricing function design is optimal, in that any other pricing function can only lead to a worse competitive ratio. Insights obtained from the basic cases are then used to generalize the pricing functions to more realistic cloud systems with multiple types of resources, where a job occupies allocated resources for a number of time slots till completion, upon which time the resources are returned back to the cloud resource pool.",
    "lastUpdated": "2017-04-18T20:11:27Z",
    "category": [
      "cs.NI",
      "cs.GT"
    ],
    "url": "http://arxiv.org/abs/1704.05511v1"
  },
  {
    "title": "Nighttime sky/cloud image segmentation",
    "author": [
      "Soumyabrata Dev",
      "Florian M. Savoy",
      "Yee Hui Lee",
      "Stefan Winkler"
    ],
    "abstract": "Imaging the atmosphere using ground-based sky cameras is a popular approach to study various atmospheric phenomena. However, it usually focuses on the daytime. Nighttime sky/cloud images are darker and noisier, and thus harder to analyze. An accurate segmentation of sky/cloud images is already challenging because of the clouds' non-rigid structure and size, and the lower and less stable illumination of the night sky increases the difficulty. Nonetheless, nighttime cloud imaging is essential in certain applications, such as continuous weather analysis and satellite communication. In this paper, we propose a superpixel-based method to segment nighttime sky/cloud images. We also release the first nighttime sky/cloud image segmentation database to the research community. The experimental results show the efficacy of our proposed algorithm for nighttime images.",
    "lastUpdated": "2017-05-30T12:39:51Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1705.10583v1"
  },
  {
    "title": "Batch Auction Design For Cloud Container Services",
    "author": [
      "Lin Ma",
      "Ruiting Zhou",
      "Zongpeng Li"
    ],
    "abstract": "Cloud containers represent a new, light-weight alternative to virtual machines in cloud computing. A user job may be described by a container graph that specifies the resource profile of each container and container dependence relations. This work is the first in the cloud computing literature that designs efficient market mechanisms for container based cloud jobs. Our design targets simultaneously incentive compatibility, computational efficiency, and economic efficiency. It further adapts the idea of batch online optimization into the paradigm of mechanism design, leveraging agile creation of cloud containers and exploiting delay tolerance of elastic cloud jobs. The new and classic techniques we employ include: (i) compact exponential optimization for expressing and handling non-traditional constraints that arise from container dependence and job deadlines; (ii) the primal-dual schema for designing efficient approximation algorithms for social welfare maximization; and (iii) posted price mechanisms for batch decision making and truthful payment design. Theoretical analysis and trace-driven empirical evaluation verify the efficacy of our container auction algorithms.",
    "lastUpdated": "2018-01-18T01:14:37Z",
    "category": [
      "cs.GT",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1801.05896v1"
  },
  {
    "title": "Joint Orchestration of Cloud-Based Microservices and Virtual Network Functions",
    "author": [
      "Hadi Razzaghi Kouchaksaraei",
      "Holger Karl"
    ],
    "abstract": "Recent studies show the increasing popularity of distributed cloud applications, which are composed of multiple microservices. Besides their known benefits, microservice architecture also enables to mix and match cloud applications and Network Function Virtualization (NFV) services (service chains), which are composed of Virtual Network Functions (VNFs). Provisioning complex services containing VNFs and microservices in a combined NFV/cloud platform can enhance service quality and optimise cost. Such a platform can be based on the multi-cloud concept. However, current multi-cloud solutions do not support NFV requirements, making them inadequate to support complex services. In this paper, we investigate these challenges and propose a solution for jointly managing and orchestrating microservices and virtual network functions.",
    "lastUpdated": "2018-01-30T13:55:30Z",
    "category": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1801.09984v1"
  },
  {
    "title": "Survey of Communication Protocols for Internet-of-Things and Related Challenges of Fog and Cloud Computing Integration",
    "author": [
      "Jasenka Dizdarevic",
      "Francisco Carpio",
      "Admela Jukan",
      "Xavi Masip-Bruin"
    ],
    "abstract": "The fast increment in the number of IoT (Internet of Things) devices is accelerating the research on new solutions to make cloud services scalable. In this context, the novel concept of fog computing as well as the combined fog-to-cloud computing paradigm is becoming essential to decentralize the cloud, while bringing the services closer to the end-system. This paper surveys on the application layer communication protocols to fulfil the IoT communication requirements, and their potential for implementation in fog- and cloud-based IoT systems. To this end, the paper first presents a comparative analysis of the main characteristics of IoT communication protocols, including request-reply and publish-subscribe protocols. After that, the paper surveys the protocols that are widely adopted and implemented in each segment of the system (IoT, fog, cloud), and thus opens up the discussion on their interoperability and wider system integration. Finally, the paper reviews the main performance issues, including latency, energy consumption and network throughput. The survey is expected to be useful to system architects and protocol designers when choosing the communication protocols in an integrated IoT-to-fog-to-cloud system architecture.",
    "lastUpdated": "2019-02-27T14:21:07Z",
    "category": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1804.01747v2"
  },
  {
    "title": "The cloud technologies of learning: origin",
    "author": [
      "Oksana M. Markova",
      "Serhiy O. Semerikov",
      "Andrii M. Striuk"
    ],
    "abstract": "The research goal is to investigate the evolution of the concept of utility computing in the works of foreign researchers in the years 1959-1966. First the A. O. Mann's results and expanded overview of the D. F. Parkhill's results on the concept of computer (information) utility were introduced in the domestic scientific circulation. Functionally identity of the computer utility and cloud computing concepts was proved, as well as refined the primary sources of cloud service models. There was proposed the interpretation of the \"cloud technologies of learning\" concept. Continuity of the development of cloud technologies over the past 55 years and their relationship with the development of ICT in general was concluded. The research results make it possible to determine the prospects of the development of cloud computing in general and cloud technologies of learning in particular.",
    "lastUpdated": "2018-07-03T18:31:06Z",
    "category": [
      "cs.CY",
      "K.2; K.3.1; H.3.5"
    ],
    "url": "http://arxiv.org/abs/1807.07849v1"
  },
  {
    "title": "The Concept, Principles of Design and Implementation of the University Cloud-based Learning and Research Environment",
    "author": [
      "Olena Glazunova",
      "Mariya Shyshkina"
    ],
    "abstract": "The scientific and methodological background of creation and development of the university cloud-based learning and research environment is substantiated. The conceptual and terminology body of the cloud-based environment investigation is defined, the main features of such environment are revealed. The main methodological principles of the environment design and development are considered among them there are the principles of open education, open science and also the specific principles inherent to the cloud-based systems. The general model of the university cloud-based learning and research environment formation is substantiated and six main stages of this environment formation are distinguished in the model. The cloud-based environment functions, content and tools are revealed in accordance with the proposed methodological principles, the criteria for the estimation of this environment efficiency are elaborated. The results of implementation and experimental research of the cloud-based environment formation at the National University of Life and Environmental Sciences of Ukraine are described. The influence of different environment components use on students' success is explored.",
    "lastUpdated": "2018-07-23T12:29:27Z",
    "category": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1807.08560v1"
  },
  {
    "title": "The system of cloud oriented learning tools as an element of educational and scientific environment of high school",
    "author": [
      "Andrii M. Striuk",
      "Maryna V. Rassovytska"
    ],
    "abstract": "The aim of this research is to design and implementation of cloud based learning environment for separate division of the university. The analysis of existing approaches to the construction of cloud based learning environments, the formation of requirements cloud based learning tools, the selection on the basis of these requirements, cloud ICT training and pilot their use for building cloud based learning environment for separate division of the university with the use of open source software and resources its own IT infrastructure of the institution. Results of the study is planned to generalize to develop recommendations for the design of cloud based environment of high school.",
    "lastUpdated": "2018-07-29T20:54:42Z",
    "category": [
      "cs.OH",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1808.02081v1"
  },
  {
    "title": "Label-less Learning for Traffic Control in an Edge Network",
    "author": [
      "Min Chen",
      "Yixue Hao",
      "Kai Lin",
      "Zhiyong Yuan",
      "Long Hu"
    ],
    "abstract": "With the development of intelligent applications (e.g., self-driving, real-time emotion recognition, etc), there are higher requirements for the cloud intelligence. However, cloud intelligence depends on the multi-modal data collected by user equipments (UEs). Due to the limited capacity of network bandwidth, offloading all data generated from the UEs to the remote cloud is impractical. Thus, in this article, we consider the challenging issue of achieving a certain level of cloud intelligence while reducing network traffic. In order to solve this problem, we design a traffic control algorithm based on label-less learning on the edge cloud, which is dubbed as LLTC. By the use of the limited computing and storage resources at edge cloud, LLTC evaluates the value of data, which will be offloaded. Specifically, we first give a statement of the problem and the system architecture. Then, we design the LLTC algorithm in detail. Finally, we set up the system testbed. Experimental results show that the proposed LLTC can guarantee the required cloud intelligence while minimizing the amount of data transmission.",
    "lastUpdated": "2018-08-29T12:32:31Z",
    "category": [
      "cs.NI",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1809.04525v1"
  },
  {
    "title": "Point Cloud Colorization Based on Densely Annotated 3D Shape Dataset",
    "author": [
      "Xu Cao",
      "Katashi Nagao"
    ],
    "abstract": "This paper introduces DensePoint, a densely sampled and annotated point cloud dataset containing over 10,000 single objects across 16 categories, by merging different kind of information from two existing datasets. Each point cloud in DensePoint contains 40,000 points, and each point is associated with two sorts of information: RGB value and part annotation. In addition, we propose a method for point cloud colorization by utilizing Generative Adversarial Networks (GANs). The network makes it possible to generate colours for point clouds of single objects by only giving the point cloud itself. Experiments on DensePoint show that there exist clear boundaries in point clouds between different parts of an object, suggesting that the proposed network is able to generate reasonably good colours. Our dataset is publicly available on the project page.",
    "lastUpdated": "2018-10-12T08:18:24Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1810.05396v1"
  },
  {
    "title": "vFAC: Fine-Grained Access Control with Versatility for Cloud Storage",
    "author": [
      "Jingwei Liu",
      "Huifang Tang",
      "Chaoya Li",
      "Rong Sun",
      "Xiaojiang Du",
      "Mohsen Guizani"
    ],
    "abstract": "In recent years, cloud storage technology has been widely used in many fields such as education, business, medical and more because of its convenience and low cost. With the widespread applications of cloud storage technology, data access control methods become more and more important in cloud-based network. The ciphertext policy attribute-based encryption (CP-ABE) scheme is very suitable for access control of data in cloud storage. However, in many practical scenarios, all attributes of a user cannot be managed by one authority, so many multi-authority CP-ABE schemes have emerged. Moreover, cloud servers are usually semi-trusted, which may leak user information. Aiming at the above problems, we propose a fine-grained access control scheme with versatility for cloud storage based on multi-authority CP-ABE, named vFAC. The proposed vFAC has the features of large universe, no key escrow problem, online/offline mechanism, hidden policy, verifiability and user revocation. Finally, we demonstrate vFAC is static security under the random oracle model. Through the comparison of several existing schemes in terms of features, computational overhead and storage cost, we can draw a conclusion that vFAC is more comprehensive and scalable.",
    "lastUpdated": "2018-11-08T03:11:41Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1811.03243v1"
  },
  {
    "title": "RADS: Real-time Anomaly Detection System for Cloud Data Centres",
    "author": [
      "Sakil Barbhuiya",
      "Zafeirios Papazachos",
      "Peter Kilpatrick",
      "Dimitrios S. Nikolopoulos"
    ],
    "abstract": "Cybersecurity attacks in Cloud data centres are increasing alongside the growth of the Cloud services market. Existing research proposes a number of anomaly detection systems for detecting such attacks. However, these systems encounter a number of challenges, specifically due to the unknown behaviour of the attacks and the occurrence of genuine Cloud workload spikes, which must be distinguished from attacks. In this paper, we discuss these challenges and investigate the issues with the existing Cloud anomaly detection approaches. Then, we propose a Real-time Anomaly Detection System (RADS) for Cloud data centres, which uses a one class classification algorithm and a window-based time series analysis to address the challenges. Specifically, RADS can detect VM-level anomalies occurring due to DDoS and cryptomining attacks. We evaluate the performance of RADS by running lab-based experiments and by using real-world Cloud workload traces. Evaluation results demonstrate that RADS can achieve 90-95% accuracy with a low false positive rate of 0-3%. The results further reveal that RADS experiences fewer false positives when using its window-based time series analysis in comparison to using state-of-the-art average or entropy based analysis.",
    "lastUpdated": "2018-11-11T21:13:08Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1811.04481v1"
  },
  {
    "title": "Inferring Point Clouds from Single Monocular Images by Depth Intermediation",
    "author": [
      "Wei Zeng",
      "Sezer Karaoglu",
      "Theo Gevers"
    ],
    "abstract": "In this paper, we propose a pipeline to generate 3D point cloud of an object from a single-view RGB image. Most previous work predict the 3D point coordinates from single RGB images directly. We decompose this problem into depth estimation from single images and point cloud completion from partial point clouds. Our method sequentially predicts the depth maps from images and then infers the complete 3D object point clouds based on the predicted partial point clouds. We explicitly impose the camera model geometrical constraint in our pipeline and enforce the alignment of the generated point clouds and estimated depth maps. Experimental results for the single image 3D object reconstruction task show that the proposed method outperforms existing state-of-the-art methods. Both the qualitative and quantitative results demonstrate the generality and suitability of our method.",
    "lastUpdated": "2020-10-26T12:30:49Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1812.01402v3"
  },
  {
    "title": "An Overview on Data Security in Cloud Computing",
    "author": [
      "Lynda kacha",
      "Abdelhafid Zitouni"
    ],
    "abstract": "Cloud Computing refers to the use of computer resources as a service on-demand via internet. It is mainly based on data and applications outsourcing, traditionally stored on users' computers, to remote servers (datacenters) owned, administered and managed by third parts. This paper is an overview of data security issues in the cloud computing. Its objective is to highlight the principal issues related to data security that raised by cloud environment. To do this, these issues was classified into three categories: 1-data security issues raised by single cloud characteristics compared to traditional infrastructure, 2-data security issues raised by data life cycle in cloud computing (stored, used and transferred data), 3-data security issues associated to data security attributes (confidentiality, integrity and availability). For each category, the common solutions used to secure data in the cloud were emphasized.",
    "lastUpdated": "2018-12-21T11:15:41Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1812.09053v1"
  },
  {
    "title": "Feature Preserving and Uniformity-controllable Point Cloud Simplification on Graph",
    "author": [
      "Junkun Qi",
      "Wei Hu",
      "Zongming Guo"
    ],
    "abstract": "With the development of 3D sensing technologies, point clouds have attracted increasing attention in a variety of applications for 3D object representation, such as autonomous driving, 3D immersive tele-presence and heritage reconstruction. However, it is challenging to process large-scale point clouds in terms of both computation time and storage due to the tremendous amounts of data. Hence, we propose a point cloud simplification algorithm, aiming to strike a balance between preserving sharp features and keeping uniform density during resampling. In particular, leveraging on graph spectral processing, we represent irregular point clouds naturally on graphs, and propose concise formulations of feature preservation and density uniformity based on graph filters. The problem of point cloud simplification is finally formulated as a trade-off between the two factors and efficiently solved by our proposed algorithm. Experimental results demonstrate the superiority of our method, as well as its efficient application in point cloud registration.",
    "lastUpdated": "2018-12-29T15:35:06Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1812.11383v1"
  },
  {
    "title": "Touchdown on the Cloud: The impact of the Super Bowl on Cloud",
    "author": [
      "Chen Wang",
      "Hyong Kim"
    ],
    "abstract": "The Super Bowl is the world's biggest televised sporting event. We examine the impact of the increasing online activities during the Super Bowl of year 2015-2017 on various types of Cloud systems, including the Cloud infrastructure service, the Cloud content delivery networks for live streaming, and popular web services such as on-demand video streaming service and social network applications. We probe these systems from agents deployed around the world to compare their load variations and performance changes during and after the game. Through our studies of three consecutive years, we find that Super Bowl events have impacts on the Cloud. However, the current Cloud system is still able to ensure capacity to cope with the challenges brought by traffic changes during such massive events.",
    "lastUpdated": "2019-02-20T01:20:31Z",
    "category": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1902.07363v1"
  },
  {
    "title": "Fast Registration for cross-source point clouds by using weak regional affinity and pixel-wise refinement",
    "author": [
      "Xiaoshui Huang",
      "Lixin Fan",
      "Qiang Wu",
      "Jian Zhang",
      "Chun Yuan"
    ],
    "abstract": "Many types of 3D acquisition sensors have emerged in recent years and point cloud has been widely used in many areas. Accurate and fast registration of cross-source 3D point clouds from different sensors is an emerged research problem in computer vision. This problem is extremely challenging because cross-source point clouds contain a mixture of various variances, such as density, partial overlap, large noise and outliers, viewpoint changing. In this paper, an algorithm is proposed to align cross-source point clouds with both high accuracy and high efficiency. There are two main contributions: firstly, two components, the weak region affinity and pixel-wise refinement, are proposed to maintain the global and local information of 3D point clouds. Then, these two components are integrated into an iterative tensor-based registration algorithm to solve the cross-source point cloud registration problem. We conduct experiments on synthetic cross-source benchmark dataset and real cross-source datasets. Comparison with six state-of-the-art methods, the proposed method obtains both higher efficiency and accuracy.",
    "lastUpdated": "2019-03-11T22:13:46Z",
    "category": [
      "cs.CV",
      "cs.GR"
    ],
    "url": "http://arxiv.org/abs/1903.04630v1"
  },
  {
    "title": "3D Point Cloud Denoising via Deep Neural Network based Local Surface Estimation",
    "author": [
      "Chaojing Duan",
      "Siheng Chen",
      "Jelena Kovacevic"
    ],
    "abstract": "We present a neural-network-based architecture for 3D point cloud denoising called neural projection denoising (NPD). In our previous work, we proposed a two-stage denoising algorithm, which first estimates reference planes and follows by projecting noisy points to estimated reference planes. Since the estimated reference planes are inevitably noisy, multi-projection is applied to stabilize the denoising performance. NPD algorithm uses a neural network to estimate reference planes for points in noisy point clouds. With more accurate estimations of reference planes, we are able to achieve better denoising performances with only one-time projection. To the best of our knowledge, NPD is the first work to denoise 3D point clouds with deep learning techniques. To conduct the experiments, we sample 40000 point clouds from the 3D data in ShapeNet to train a network and sample 350 point clouds from the 3D data in ModelNet10 to test. Experimental results show that our algorithm can estimate normal vectors of points in noisy point clouds. Comparing to five competitive methods, the proposed algorithm achieves better denoising performance and produces much smaller variances.",
    "lastUpdated": "2019-04-09T02:29:39Z",
    "category": [
      "cs.CV",
      "eess.SP"
    ],
    "url": "http://arxiv.org/abs/1904.04427v1"
  },
  {
    "title": "3D Dynamic Point Cloud Inpainting via Temporal Consistency on Graphs",
    "author": [
      "Zeqing Fu",
      "Wei Hu",
      "Zongming Guo"
    ],
    "abstract": "With the development of 3D laser scanning techniques and depth sensors, 3D dynamic point clouds have attracted increasing attention as a representation of 3D objects in motion, enabling various applications such as 3D immersive tele-presence, gaming and navigation. However, dynamic point clouds usually exhibit holes of missing data, mainly due to the fast motion, the limitation of acquisition and complicated structure. Leveraging on graph signal processing tools, we represent irregular point clouds on graphs and propose a novel inpainting method exploiting both intra-frame self-similarity and inter-frame consistency in 3D dynamic point clouds. Specifically, for each missing region in every frame of the point cloud sequence, we search for its self-similar regions in the current frame and corresponding ones in adjacent frames as references. Then we formulate dynamic point cloud inpainting as an optimization problem based on the two types of references, which is regularized by a graph-signal smoothness prior. Experimental results show the proposed approach outperforms three competing methods significantly, both in objective and subjective quality.",
    "lastUpdated": "2020-04-06T15:01:51Z",
    "category": [
      "cs.GR",
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1904.10795v2"
  },
  {
    "title": "Oriented Point Sampling for Plane Detection in Unorganized Point Clouds",
    "author": [
      "Bo Sun",
      "Philippos Mordohai"
    ],
    "abstract": "Plane detection in 3D point clouds is a crucial pre-processing step for applications such as point cloud segmentation, semantic mapping and SLAM. In contrast to many recent plane detection methods that are only applicable on organized point clouds, our work is targeted to unorganized point clouds that do not permit a 2D parametrization. We compare three methods for detecting planes in point clouds efficiently. One is a novel method proposed in this paper that generates plane hypotheses by sampling from a set of points with estimated normals. We named this method Oriented Point Sampling (OPS) to contrast with more conventional techniques that require the sampling of three unoriented points to generate plane hypotheses. We also implemented an efficient plane detection method based on local sampling of three unoriented points and compared it with OPS and the 3D-KHT algorithm, which is based on octrees, on the detection of planes on 10,000 point clouds from the SUN RGB-D dataset.",
    "lastUpdated": "2019-05-04T01:02:57Z",
    "category": [
      "cs.CV",
      "cs.RO"
    ],
    "url": "http://arxiv.org/abs/1905.02553v1"
  },
  {
    "title": "Encrypted Speech Recognition using Deep Polynomial Networks",
    "author": [
      "Shi-Xiong Zhang",
      "Yifan Gong",
      "Dong Yu"
    ],
    "abstract": "The cloud-based speech recognition/API provides developers or enterprises an easy way to create speech-enabled features in their applications. However, sending audios about personal or company internal information to the cloud, raises concerns about the privacy and security issues. The recognition results generated in cloud may also reveal some sensitive information. This paper proposes a deep polynomial network (DPN) that can be applied to the encrypted speech as an acoustic model. It allows clients to send their data in an encrypted form to the cloud to ensure that their data remains confidential, at mean while the DPN can still make frame-level predictions over the encrypted speech and return them in encrypted form. One good property of the DPN is that it can be trained on unencrypted speech features in the traditional way. To keep the cloud away from the raw audio and recognition results, a cloud-local joint decoding framework is also proposed. We demonstrate the effectiveness of model and framework on the Switchboard and Cortana voice assistant tasks with small performance degradation and latency increased comparing with the traditional cloud-based DNNs.",
    "lastUpdated": "2019-05-11T00:14:09Z",
    "category": [
      "cs.CR",
      "cs.CL",
      "cs.SD",
      "eess.AS",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1905.05605v1"
  },
  {
    "title": "Direct Image to Point Cloud Descriptors Matching for 6-DOF Camera Localization in Dense 3D Point Cloud",
    "author": [
      "Uzair Nadeem",
      "Mohammad A. A. K. Jalwana",
      "Mohammed Bennamoun",
      "Roberto Togneri",
      "Ferdous Sohel"
    ],
    "abstract": "We propose a novel concept to directly match feature descriptors extracted from RGB images, with feature descriptors extracted from 3D point clouds. We use this concept to localize the position and orientation (pose) of the camera of a query image in dense point clouds. We generate a dataset of matching 2D and 3D descriptors, and use it to train a proposed Descriptor-Matcher algorithm. To localize a query image in a point cloud, we extract 2D keypoints and descriptors from the query image. Then the Descriptor-Matcher is used to find the corresponding pairs 2D and 3D keypoints by matching the 2D descriptors with the pre-extracted 3D descriptors of the point cloud. This information is used in a robust pose estimation algorithm to localize the query image in the 3D point cloud. Experiments demonstrate that directly matching 2D and 3D descriptors is not only a viable idea but also achieves competitive accuracy compared to other state-of-the-art approaches for camera pose localization.",
    "lastUpdated": "2019-06-14T08:01:19Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1906.06064v1"
  },
  {
    "title": "Symmetries and isomorphisms for privacy in control over the cloud",
    "author": [
      "Alimzhan Sultangazin",
      "Paulo Tabuada"
    ],
    "abstract": "Cloud computing platforms are being increasingly used for closing feedback control loops, especially when computationally expensive algorithms, such as model-predictive control, are used to optimize performance. Outsourcing of control algorithms entails an exchange of data between the control system and the cloud, and, naturally, raises concerns about the privacy of the control system's data (e.g., state trajectory, control objective). Moreover, any attempt at enforcing privacy needs to add minimal computational overhead to avoid degrading control performance. In this paper, we propose several transformation-based methods for enforcing data privacy. We also quantify the amount of provided privacy and discuss how much privacy is lost when the adversary has access to side knowledge. We address three different scenarios: a) the cloud has no knowledge about the system being controlled; b) the cloud knows what sensors and actuators the system employs but not the system dynamics; c) the cloud knows the system dynamics, its sensors, and actuators. In all of these three scenarios, the proposed methods allow for the control over the cloud without compromising private information (which information is considered private depends on the considered scenario).",
    "lastUpdated": "2019-06-18T09:28:00Z",
    "category": [
      "math.OC",
      "cs.CR",
      "cs.SY",
      "eess.SY"
    ],
    "url": "http://arxiv.org/abs/1906.07460v1"
  },
  {
    "title": "Tag Clouds for Object-Oriented Source Code Visualization",
    "author": [
      "Ra'Fat Al-Msie'deen"
    ],
    "abstract": "Software visualization helps software engineers to understand and manage the size and complexity of the object-oriented source code. The tag cloud is a simple and popular visualization technique. The main idea of the tag cloud is to represent tags according to their frequency in an alphabetical order where the most important tags are highlighted via a suitable font size. This paper proposes an original approach to visualize software code using a tag cloud. The approach exploits all software identifier names to visualize software code as a tag cloud. Experiments were conducted on several case studies. To validate the approach, it is applied on NanoXML and ArgoUML. The results of this evaluation validate the relevance and the performance of the proposed approach as all tag names and their frequencies were correctly identified. The proposed tag cloud visualization technique is a helpful addition to the software visualization toolkit. The extracted tag cloud supports software engineers as they filter and browse data.",
    "lastUpdated": "2019-06-08T16:45:08Z",
    "category": [
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/1906.11914v1"
  },
  {
    "title": "Point Cloud Super Resolution with Adversarial Residual Graph Networks",
    "author": [
      "Huikai Wu",
      "Junge Zhang",
      "Kaiqi Huang"
    ],
    "abstract": "Point cloud super-resolution is a fundamental problem for 3D reconstruction and 3D data understanding. It takes a low-resolution (LR) point cloud as input and generates a high-resolution (HR) point cloud with rich details. In this paper, we present a data-driven method for point cloud super-resolution based on graph networks and adversarial losses. The key idea of the proposed network is to exploit the local similarity of point cloud and the analogy between LR input and HR output. For the former, we design a deep network with graph convolution. For the latter, we propose to add residual connections into graph convolution and introduce a skip connection between input and output. The proposed network is trained with a novel loss function, which combines Chamfer Distance (CD) and graph adversarial loss. Such a loss function captures the characteristics of HR point cloud automatically without manual design. We conduct a series of experiments to evaluate our method and validate the superiority over other methods. Results show that the proposed method achieves the state-of-the-art performance and have a good generalization ability to unseen data.",
    "lastUpdated": "2019-08-06T12:44:42Z",
    "category": [
      "cs.GR",
      "eess.IV"
    ],
    "url": "http://arxiv.org/abs/1908.02111v1"
  },
  {
    "title": "ClustCrypt: Privacy-Preserving Clustering of Unstructured Big Data in the Cloud",
    "author": [
      "SM Zobaed",
      "Sahan Ahmad",
      "Raju Gottumukkala",
      "Mohsen Amini Salehi"
    ],
    "abstract": "Security and confidentiality of big data stored in the cloud are important concerns for many organizations to adopt cloud services. One common approach to address the concerns is client-side encryption where data is encrypted on the client machine before being stored in the cloud. Having encrypted data in the cloud, however, limits the ability of data clustering, which is a crucial part of many data analytics applications, such as search systems. To overcome the limitation, in this paper, we present an approach named ClustCrypt for efficient topic-based clustering of encrypted unstructured big data in the cloud. ClustCrypt dynamically estimates the optimal number of clusters based on the statistical characteristics of encrypted data. It also provides clustering approach for encrypted data. We deploy ClustCrypt within the context of a secure cloud-based semantic search system (S3BD). Experimental results obtained from evaluating ClustCrypt on three datasets demonstrate on average 60% improvement on clusters' coherency. ClustCrypt also decreases the search-time overhead by up to 78% and increases the accuracy of search results by up to 35%",
    "lastUpdated": "2019-08-14T05:23:12Z",
    "category": [
      "cs.CR",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1908.04960v1"
  },
  {
    "title": "Irregular Convolutional Auto-Encoder on Point Clouds",
    "author": [
      "Zhang Yuhui",
      "Greg Gutmann",
      "Konagaya Akihiko"
    ],
    "abstract": "We proposed a novel graph convolutional neural network that could construct a coarse, sparse latent point cloud from a dense, raw point cloud. With a novel non-isotropic convolution operation defined on irregular geometries, the model then can reconstruct the original point cloud from this latent cloud with fine details. Furthermore, we proposed that it is even possible to perform particle simulation using the latent cloud encoded from some simulated particle cloud (e.g. fluids), to accelerate the particle simulation process. Our model has been tested on ShapeNetCore dataset for Auto-Encoding with a limited latent dimension and tested on a synthesis dataset for fluids simulation. We also compare the model with other state-of-the-art models, and several visualizations were done to intuitively understand the model.",
    "lastUpdated": "2019-10-07T09:24:08Z",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1910.02686v1"
  },
  {
    "title": "Conditional Invertible Flow for Point Cloud Generation",
    "author": [
      "Michał Stypułkowski",
      "Maciej Zamorski",
      "Maciej Zięba",
      "Jan Chorowski"
    ],
    "abstract": "This paper focuses on a novel generative approach for 3D point clouds that makes use of invertible flow-based models. The main idea of the method is to treat a point cloud as a probability density in 3D space that is modeled using a cloud-specific neural network. To capture the similarity between point clouds we rely on parameter sharing among networks, with each cloud having only a small embedding vector that defines it. We use invertible flows networks to generate the individual point clouds, and to regularize the embedding vectors. We evaluate the generative capabilities of the model both in qualitative and quantitative manner.",
    "lastUpdated": "2019-10-16T13:47:05Z",
    "category": [
      "cs.LG",
      "cs.CV",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1910.07344v1"
  },
  {
    "title": "SRINet: Learning Strictly Rotation-Invariant Representations for Point Cloud Classification and Segmentation",
    "author": [
      "Xiao Sun",
      "Zhouhui Lian",
      "Jianguo Xiao"
    ],
    "abstract": "Point cloud analysis has drawn broader attentions due to its increasing demands in various fields. Despite the impressive performance has been achieved on several databases, researchers neglect the fact that the orientation of those point cloud data is aligned. Varying the orientation of point cloud may lead to the degradation of performance, restricting the capacity of generalizing to real applications where the prior of orientation is often unknown. In this paper, we propose the point projection feature, which is invariant to the rotation of the input point cloud. A novel architecture is designed to mine features of different levels. We adopt a PointNet-based backbone to extract global feature for point cloud, and the graph aggregation operation to perceive local shape structure. Besides, we introduce an efficient key point descriptor to assign each point with different response and help recognize the overall geometry. Mathematical analyses and experimental results demonstrate that the proposed method can extract strictly rotation-invariant representations for point cloud recognition and segmentation without data augmentation, and outperforms other state-of-the-art methods.",
    "lastUpdated": "2019-11-06T02:08:03Z",
    "category": [
      "cs.CV",
      "eess.IV"
    ],
    "url": "http://arxiv.org/abs/1911.02163v1"
  },
  {
    "title": "Morphing and Sampling Network for Dense Point Cloud Completion",
    "author": [
      "Minghua Liu",
      "Lu Sheng",
      "Sheng Yang",
      "Jing Shao",
      "Shi-Min Hu"
    ],
    "abstract": "3D point cloud completion, the task of inferring the complete geometric shape from a partial point cloud, has been attracting attention in the community. For acquiring high-fidelity dense point clouds and avoiding uneven distribution, blurred details, or structural loss of existing methods' results, we propose a novel approach to complete the partial point cloud in two stages. Specifically, in the first stage, the approach predicts a complete but coarse-grained point cloud with a collection of parametric surface elements. Then, in the second stage, it merges the coarse-grained prediction with the input point cloud by a novel sampling algorithm. Our method utilizes a joint loss function to guide the distribution of the points. Extensive experiments verify the effectiveness of our method and demonstrate that it outperforms the existing methods in both the Earth Mover's Distance (EMD) and the Chamfer Distance (CD).",
    "lastUpdated": "2019-11-30T22:52:54Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1912.00280v1"
  },
  {
    "title": "Development of trust based access control models using fuzzy logic in cloud computing",
    "author": [
      "Abhishek Kesarwani",
      "Pabitra Mohan Khilar"
    ],
    "abstract": "Cloud computing is the technology that provides different types of services as a useful resource on the Internet. Resource trust value will help the cloud users to select the services of a cloud provider for processing and storing their essential information. Also, service providers can give access to users based on trust value to secure cloud resources from malicious users. In this paper, trust models are proposed, which comes under the subjective trust model based on the behavior of user and service provider to calculate the trust values. The trust is fuzzy, which motivated us to apply fuzzy logic for calculating the trust values of the cloud users and service providers in the cloud environment. We use a Mamdani fuzzy method with gauss membership function for fuzzification and triangular membership function for defuzzification. Parameters such as performance and elasticity are taken for trust evaluation of the resource. The attributes for calculating performance are workload and response time. And for calculating elasticity, we have taken scalability, availability, security, and usability. The fuzzy C-means clustering is applied to parameters for evaluating the trust value of users such as bad requests, bogus requests, unauthorized requests, and total requests.",
    "lastUpdated": "2019-11-21T06:10:53Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1912.01709v1"
  },
  {
    "title": "On the Security of A Remote Cloud Storage Integrity Checking Protocol",
    "author": [
      "Faen Zhang",
      "Xinyu Fan",
      "Pengcheng Zhou",
      "Wenfeng Zhou"
    ],
    "abstract": "Data security and privacy is an important but challenging problem in cloud computing. One of the security concerns from cloud users is how to efficiently verify the integrity of their data stored on the cloud server. Third Party Auditing (TPA) is a new technique proposed in recent years to achieve this goal. In a recent paper (IEEE Transactions on Computers 62(2): 362-375 (2013)), Wang et al. proposed a highly efficient and scalable TPA protocol and also a Zero Knowledge Public Auditing protocol which can prevent offline guessing attacks. However, in this paper, we point out several security weaknesses in Wang et al's protocols: first, we show that an attacker can arbitrarily modify the cloud data without being detected by the auditor in the integrity checking process, and the attacker can achieve this goal even without knowing the content of the cloud data or any verification metadata maintained by the cloud server; secondly, we show that the Zero Knowledge Public Auditing protocol cannot achieve its design goal, that is to prevent offline guessing attacks.",
    "lastUpdated": "2019-12-01T17:16:35Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1912.02089v1"
  },
  {
    "title": "Is Big Data Performance Reproducible in Modern Cloud Networks?",
    "author": [
      "Alexandru Uta",
      "Alexandru Custura",
      "Dmitry Duplyakin",
      "Ivo Jimenez",
      "Jan Rellermeyer",
      "Carlos Maltzahn",
      "Robert Ricci",
      "Alexandru Iosup"
    ],
    "abstract": "Performance variability has been acknowledged as a problem for over a decade by cloud practitioners and performance engineers. Yet, our survey of top systems conferences reveals that the research community regularly disregards variability when running experiments in the cloud. Focusing on networks, we assess the impact of variability on cloud-based big-data workloads by gathering traces from mainstream commercial clouds and private research clouds. Our data collection consists of millions of datapoints gathered while transferring over 9 petabytes of data. We characterize the network variability present in our data and show that, even though commercial cloud providers implement mechanisms for quality-of-service enforcement, variability still occurs, and is even exacerbated by such mechanisms and service provider policies. We show how big-data workloads suffer from significant slowdowns and lack predictability and replicability, even when state-of-the-art experimentation techniques are used. We provide guidelines for practitioners to reduce the volatility of big data performance, making experiments more repeatable.",
    "lastUpdated": "2019-12-19T15:05:30Z",
    "category": [
      "cs.PF",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1912.09256v1"
  },
  {
    "title": "Fair Auction and Trade Framework for Cloud VM Allocation based on Blockchain",
    "author": [
      "Zhili Chen",
      "Wei Ding",
      "Yan Xu",
      "Miaomiao Tian",
      "Hong Zhong"
    ],
    "abstract": "Cloud auctions provide cost-effective strategies for cloud VM allocation. Most existing cloud auctions simply assume that the auctioneer is trustable, and thus the fairness of auctions can be easily achieved. However, in fact, such a trustable auctioneer may not exist, and the fairness is non-trivial to guarantee. In this work, for the first time, we propose a decentralized cloud VM auction and trade framework based on blockchain. We realize both auction fairness and trade fairness among participants (e.g., cloud provider and cloud users) in this system, which guarantees the interest of each party will not suffer any loss as long as it follows the protocol. Furthermore, we implement our system through the local blockchain and Ethereum official test blockchain, carry out experimental simulations, and demonstrate the feasibility of our system.",
    "lastUpdated": "2020-01-03T09:54:27Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/2001.00771v1"
  },
  {
    "title": "Hypergraph Spectral Analysis and Processing in 3D Point Cloud",
    "author": [
      "Songyang Zhang",
      "Shuguang Cui",
      "Zhi Ding"
    ],
    "abstract": "Along with increasingly popular virtual reality applications, the three-dimensional (3D) point cloud has become a fundamental data structure to characterize 3D objects and surroundings. To process 3D point clouds efficiently, a suitable model for the underlying structure and outlier noises is always critical. In this work, we propose a hypergraph-based new point cloud model that is amenable to efficient analysis and processing. We introduce tensor-based methods to estimate hypergraph spectrum components and frequency coefficients of point clouds in both ideal and noisy settings. We establish an analytical connection between hypergraph frequencies and structural features. We further evaluate the efficacy of hypergraph spectrum estimation in two common point cloud applications of sampling and denoising for which also we elaborate specific hypergraph filter design and spectral properties. The empirical performance demonstrates the strength of hypergraph signal processing as a tool in 3D point clouds and the underlying properties.",
    "lastUpdated": "2020-01-08T05:30:16Z",
    "category": [
      "eess.SP",
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2001.02384v1"
  },
  {
    "title": "ContainerStress: Autonomous Cloud-Node Scoping Framework for Big-Data ML Use Cases",
    "author": [
      "Guang Chao Wang",
      "Kenny Gross",
      "Akshay Subramaniam"
    ],
    "abstract": "Deploying big-data Machine Learning (ML) services in a cloud environment presents a challenge to the cloud vendor with respect to the cloud container configuration sizing for any given customer use case. OracleLabs has developed an automated framework that uses nested-loop Monte Carlo simulation to autonomously scale any size customer ML use cases across the range of cloud CPU-GPU \"Shapes\" (configurations of CPUs and/or GPUs in Cloud containers available to end customers). Moreover, the OracleLabs and NVIDIA authors have collaborated on a ML benchmark study which analyzes the compute cost and GPU acceleration of any ML prognostic algorithm and assesses the reduction of compute cost in a cloud container comprising conventional CPUs and NVIDIA GPUs.",
    "lastUpdated": "2020-03-18T01:51:42Z",
    "category": [
      "cs.DC",
      "cs.LG",
      "cs.PF",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2003.08011v1"
  },
  {
    "title": "MNEW: Multi-domain Neighborhood Embedding and Weighting for Sparse Point Clouds Segmentation",
    "author": [
      "Yang Zheng",
      "Izzat H. Izzat",
      "Sanling Song"
    ],
    "abstract": "Point clouds have been widely adopted in 3D semantic scene understanding. However, point clouds for typical tasks such as 3D shape segmentation or indoor scenario parsing are much denser than outdoor LiDAR sweeps for the application of autonomous driving perception. Due to the spatial property disparity, many successful methods designed for dense point clouds behave depreciated effectiveness on the sparse data. In this paper, we focus on the semantic segmentation task of sparse outdoor point clouds. We propose a new method called MNEW, including multi-domain neighborhood embedding, and attention weighting based on their geometry distance, feature similarity, and neighborhood sparsity. The network architecture inherits PointNet which directly process point clouds to capture pointwise details and global semantics, and is improved by involving multi-scale local neighborhoods in static geometry domain and dynamic feature space. The distance/similarity attention and sparsity-adapted weighting mechanism of MNEW enable its capability for a wide range of data sparsity distribution. With experiments conducted on virtual and real KITTI semantic datasets, MNEW achieves the top performance for sparse point clouds, which is important to the application of LiDAR-based automated driving perception.",
    "lastUpdated": "2020-04-05T18:02:07Z",
    "category": [
      "cs.CV",
      "cs.LG",
      "eess.IV"
    ],
    "url": "http://arxiv.org/abs/2004.03401v1"
  },
  {
    "title": "Reusing empirical knowledge during cloud computing adoption",
    "author": [
      "Mahdi Fahmideh",
      "Ghassan Beydoun"
    ],
    "abstract": "Moving legacy software systems to cloud platforms is an ever popular option. But, such an endeavour may not be hazard-free and demands a proper understanding of requirements and risks involved prior to taking any actions. The time is indeed ripe to undertake a realistic view of what migrating systems to the cloud may offer, an understanding of exceptional situations causing system quality goal failure, and insights on countermeasures. The cloud migration body of knowledge, although is useful, is dispersed over the current literature. It is hard for busy practitioners to digest, synthesize, and harness this body of knowledge into practice in a scenario of integrating legacy systems with cloud services. We address this issue by creating an innovative synergy between the approaches evidence-based software engineering and goal-oriented modelling. We develop an evidential repository of commonly occurred obstacles and platform agnostic resolution tactics related to making systems cloud-enabled. The repository is further utilized during the systematic goal-obstacle elaboration of given cloud migration scenarios. The applicability of the proposed framework is also demonstrated.",
    "lastUpdated": "2020-04-17T02:25:36Z",
    "category": [
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/2004.11268v1"
  },
  {
    "title": "3D Object Detection Method Based on YOLO and K-Means for Image and Point Clouds",
    "author": [
      "Xuanyu Yin",
      "Yoko Sasaki",
      "Weimin Wang",
      "Kentaro Shimizu"
    ],
    "abstract": "Lidar based 3D object detection and classification tasks are essential for autonomous driving(AD). A lidar sensor can provide the 3D point cloud data reconstruction of the surrounding environment. However, real time detection in 3D point clouds still needs a strong algorithmic. This paper proposes a 3D object detection method based on point cloud and image which consists of there parts.(1)Lidar-camera calibration and undistorted image transformation. (2)YOLO-based detection and PointCloud extraction, (3)K-means based point cloud segmentation and detection experiment test and evaluation in depth image. In our research, camera can capture the image to make the Real-time 2D object detection by using YOLO, we transfer the bounding box to node whose function is making 3d object detection on point cloud data from Lidar. By comparing whether 2D coordinate transferred from the 3D point is in the object bounding box or not can achieve High-speed 3D object recognition function in GPU. The accuracy and precision get imporved after k-means clustering in point cloud. The speed of our detection method is a advantage faster than PointNet.",
    "lastUpdated": "2020-04-21T04:32:36Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2005.02132v1"
  },
  {
    "title": "Launching Stealth Attacks using Cloud",
    "author": [
      "Moitrayee Chatterjee",
      "Prerit Datta",
      "Faranak Abri",
      "Akbar Siami Namin",
      "Keith S. Jones"
    ],
    "abstract": "Cloud computing offers users scalable platforms and low resource cost. At the same time, the off-site location of the resources of this service model makes it more vulnerable to certain types of adversarial actions. Cloud computing has not only gained major user base, but also, it has the features that attackers can leverage to remain anonymous and stealth. With convenient access to data and technology, cloud has turned into an attack platform among other utilization. This paper reports our study to show that cyber attackers heavily abuse the public cloud platforms to setup their attack environments and launch stealth attacks. The paper first reviews types of attacks launched through cloud environment. It then reports case studies through which the processes of launching cyber attacks using clouds are demonstrated.",
    "lastUpdated": "2020-06-14T14:20:13Z",
    "category": [
      "cs.CR",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/2006.07908v1"
  },
  {
    "title": "Cloud detection in Landsat-8 imagery in Google Earth Engine based on a deep neural network",
    "author": [
      "Zhixiang Yin",
      "Feng Ling",
      "Giles M. Foody",
      "Xinyan Li",
      "Yun Du"
    ],
    "abstract": "Google Earth Engine (GEE) provides a convenient platform for applications based on optical satellite imagery of large areas. With such data sets, the detection of cloud is often a necessary prerequisite step. Recently, deep learning-based cloud detection methods have shown their potential for cloud detection but they can only be applied locally, leading to inefficient data downloading time and storage problems. This letter proposes a method to directly perform cloud detection in Landsat-8 imagery in GEE based on deep learning (DeepGEE-CD). A deep neural network (DNN) was first trained locally, and then the trained DNN was deployed in the JavaScript client of GEE. An experiment was undertaken to validate the proposed method with a set of Landsat-8 images and the results show that DeepGEE-CD outperformed the widely used function of mask (Fmask) algorithm. The proposed DeepGEE-CD approach can accurately detect cloud in Landsat-8 imagery without downloading it, making it a promising method for routine cloud detection of Landsat-8 imagery in GEE.",
    "lastUpdated": "2020-10-01T13:40:47Z",
    "category": [
      "eess.IV",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2006.10358v2"
  },
  {
    "title": "A Cloud Computing Capability Model for Large-Scale Semantic Annotation",
    "author": [
      "Oluwasegun Adedugbe",
      "Elhadj Benkhelifa"
    ],
    "abstract": "Semantic technologies are designed to facilitate context-awareness for web content, enabling machines to understand and process them. However, this has been faced with several challenges, such as disparate nature of existing solutions and lack of scalability in proportion to web scale. With a holistic perspective to web content semantic annotation, this paper focuses on leveraging cloud computing for these challenges. To achieve this, a set of requirements towards holistic semantic annotation on the web is defined and mapped with cloud computing mechanisms to facilitate them. Technical specification for the requirements is critically reviewed and examined against each of the cloud computing mechanisms, in relation to their technical functionalities. Hence, a mapping is established if the cloud computing mechanism's functionalities proffer a solution for implementation of a requirement's technical specification. The result is a cloud computing capability model for holistic semantic annotation which presents an approach towards delivering large scale semantic annotation on the web via a cloud platform.",
    "lastUpdated": "2020-06-24T17:23:06Z",
    "category": [
      "cs.CY",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/2006.13893v1"
  },
  {
    "title": "DeepCLR: Correspondence-Less Architecture for Deep End-to-End Point Cloud Registration",
    "author": [
      "Markus Horn",
      "Nico Engel",
      "Vasileios Belagiannis",
      "Michael Buchholz",
      "Klaus Dietmayer"
    ],
    "abstract": "This work addresses the problem of point cloud registration using deep neural networks. We propose an approach to predict the alignment between two point clouds with overlapping data content, but displaced origins. Such point clouds originate, for example, from consecutive measurements of a LiDAR mounted on a moving platform. The main difficulty in deep registration of raw point clouds is the fusion of template and source point cloud. Our proposed architecture applies flow embedding to tackle this problem, which generates features that describe the motion of each template point. These features are then used to predict the alignment in an end-to-end fashion without extracting explicit point correspondences between both input clouds. We rely on the KITTI odometry and ModelNet40 datasets for evaluating our method on various point distributions. Our approach achieves state-of-the-art accuracy and the lowest run-time of the compared methods.",
    "lastUpdated": "2021-01-13T10:04:51Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2007.11255v2"
  },
  {
    "title": "Cloud Transformers",
    "author": [
      "Kirill Mazur",
      "Victor Lempitsky"
    ],
    "abstract": "We present a new versatile building block for deep point cloud processing architectures. This building block combines the ideas of spatial transformers and multi-view CNNs with the efficiency of standard convolutional layers in two and three-dimensional dense grids. The new block operates via multiple parallel heads, whereas each head differentiably rasterizes feature representations of individual points into a low-dimensional space, and then uses dense convolution to propagate information across points. The results of the processing of individual heads are then combined together resulting in the update of point features. Using the new block, we build architectures for both discriminative (point cloud segmentation, point cloud classification) and generative (point cloud inpainting and image-based point cloud reconstruction) tasks. The resulting architectures invariably achieve state-of-the-art performance for these tasks, demonstrating the versatility and universality of the new block for point cloud processing.",
    "lastUpdated": "2020-12-09T22:04:58Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2007.11679v2"
  },
  {
    "title": "The Impact of Distance on Performance and Scalability of Distributed Database Systems in Hybrid Clouds",
    "author": [
      "Yaser Mansouri",
      "M. Ali Babar"
    ],
    "abstract": "The increasing need for managing big data has led the emergence of advanced database management systems. There has been increased efforts aimed at evaluating the performance and scalability of NoSQL and Relational databases hosted by either private or public cloud datacenters. However, there has been little work on evaluating the performance and scalability of these databases in hybrid clouds, where the distance between private and public cloud datacenters can be one of the key factors that can affect their performance. Hence, in this paper, we present a detailed evaluation of throughput, scalability, and VMs size vs. VMs number for six modern databases in a hybrid cloud, consisting of a private cloud in Adelaide and Azure based datacenter in Sydney, Mumbai, and Virginia regions. Based on results, as the distance between private and public clouds increases, the throughput performance of most databases reduces. Second, MongoDB obtains the best throughput performance, followed by MySQL C luster, whilst Cassandra exposes the most fluctuation in through performance. Third, vertical scalability improves the throughput of databases more than the horizontal scalability. Forth, exploiting bigger VMs rather than more VMs with less cores can increase throughput performance for Cassandra, Riak, and Redis.",
    "lastUpdated": "2020-07-31T03:36:58Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/2007.15826v1"
  },
  {
    "title": "Refinement of Predicted Missing Parts Enhance Point Cloud Completion",
    "author": [
      "Alexis Mendoza",
      "Alexander Apaza",
      "Ivan Sipiran",
      "Cristian Lopez"
    ],
    "abstract": "Point cloud completion is the task of predicting complete geometry from partial observations using a point set representation for a 3D shape. Previous approaches propose neural networks to directly estimate the whole point cloud through encoder-decoder models fed by the incomplete point set. By predicting the complete model, the current methods compute redundant information because the output also contains the known incomplete input geometry. This paper proposes an end-to-end neural network architecture that focuses on computing the missing geometry and merging the known input and the predicted point cloud. Our method is composed of two neural networks: the missing part prediction network and the merging-refinement network. The first module focuses on extracting information from the incomplete input to infer the missing geometry. The second module merges both point clouds and improves the distribution of the points. Our experiments on ShapeNet dataset show that our method outperforms the state-of-the-art methods in point cloud completion. The code of our methods and experiments is available in \\url{https://github.com/ivansipiran/Refinement-Point-Cloud-Completion}.",
    "lastUpdated": "2020-10-08T22:01:23Z",
    "category": [
      "cs.CV",
      "cs.GR"
    ],
    "url": "http://arxiv.org/abs/2010.04278v1"
  },
  {
    "title": "PointManifold: Using Manifold Learning for Point Cloud Classification",
    "author": [
      "Dinghao Yang",
      "Wei Gao"
    ],
    "abstract": "In this paper, we propose a point cloud classification method based on graph neural network and manifold learning. Different from the conventional point cloud analysis methods, this paper uses manifold learning algorithms to embed point cloud features for better considering the geometric continuity on the surface. Then, the nature of point cloud can be acquired in low dimensional space, and after being concatenated with features in the original three-dimensional (3D)space, both the capability of feature representation and the classification network performance can be improved. We pro-pose two manifold learning modules, where one is based on locally linear embedding algorithm, and the other is a non-linear projection method based on neural network architecture. Both of them can obtain better performances than the state-of-the-art baseline. Afterwards, the graph model is constructed by using the k nearest neighbors algorithm, where the edge features are effectively aggregated for the implementation of point cloud classification. Experiments show that the proposed point cloud classification methods obtain the mean class accuracy (mA) of 90.2% and the overall accuracy (oA)of 93.2%, which reach competitive performances compared with the existing state-of-the-art related methods.",
    "lastUpdated": "2020-10-16T06:32:05Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2010.07215v2"
  },
  {
    "title": "Graphite: GRAPH-Induced feaTure Extraction for Point Cloud Registration",
    "author": [
      "Mahdi Saleh",
      "Shervin Dehghani",
      "Benjamin Busam",
      "Nassir Navab",
      "Federico Tombari"
    ],
    "abstract": "3D Point clouds are a rich source of information that enjoy growing popularity in the vision community. However, due to the sparsity of their representation, learning models based on large point clouds is still a challenge. In this work, we introduce Graphite, a GRAPH-Induced feaTure Extraction pipeline, a simple yet powerful feature transform and keypoint detector. Graphite enables intensive down-sampling of point clouds with keypoint detection accompanied by a descriptor. We construct a generic graph-based learning scheme to describe point cloud regions and extract salient points. To this end, we take advantage of 6D pose information and metric learning to learn robust descriptions and keypoints across different scans. We Reformulate the 3D keypoint pipeline with graph neural networks which allow efficient processing of the point set while boosting its descriptive power which ultimately results in more accurate 3D registrations. We demonstrate our lightweight descriptor on common 3D descriptor matching and point cloud registration benchmarks and achieve comparable results with the state of the art. Describing 100 patches of a point cloud and detecting their keypoints takes only ~0.018 seconds with our proposed network.",
    "lastUpdated": "2020-10-18T19:41:09Z",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2010.09079v1"
  },
  {
    "title": "Anomaly Detection in a Large-scale Cloud Platform",
    "author": [
      "Mohammad Saiful Islam",
      "William Pourmajidi",
      "Lei Zhang",
      "John Steinbacher",
      "Tony Erwin",
      "Andriy Miranskyy"
    ],
    "abstract": "Cloud computing is ubiquitous: more and more companies are moving the workloads into the Cloud. However, this rise in popularity challenges Cloud service providers, as they need to monitor the quality of their ever-growing offerings effectively. To address the challenge, we designed and implemented an automated monitoring system for the IBM Cloud Platform. This monitoring system utilizes deep learning neural networks to detect anomalies in near-real-time in multiple Platform components simultaneously. After running the system for a year, we observed that the proposed solution frees the DevOps team's time and human resources from manually monitoring thousands of Cloud components. Moreover, it increases customer satisfaction by reducing the risk of Cloud outages. In this paper, we share our solutions' architecture, implementation notes, and best practices that emerged while evolving the monitoring system. They can be leveraged by other researchers and practitioners to build anomaly detectors for complex systems.",
    "lastUpdated": "2020-10-21T12:58:36Z",
    "category": [
      "cs.DC",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2010.10966v1"
  },
  {
    "title": "Enhancing Cloud Storage with Shareable Instances for Social Computing",
    "author": [
      "Ying Mao",
      "Peizhao Hu"
    ],
    "abstract": "Cloud storage plays an important role in social computing. This paper aims to develop a cloud storage management system for mobile devices to support an extended set of file operations. Because of the limit of storage, bandwidth, power consumption, and other resource restrictions, most existing cloud storage apps for smartphones do not keep local copies of files. This efficient design, however, limits the application capacities. In this paper, we attempt to extend the available file operations for cloud storage service to better serve smartphone users. We develop an efficient and secure file management system, Skyfiles, to support more advanced file operations. The basic idea of our design is to utilize cloud instances to assist file operations. Particularly, Skyfiles supports downloading, compressing, encrypting, and converting operations, as well as file transfer between two smartphone users' cloud storage spaces. In addition, we propose a protocol for users to share their idle instances. All file operations supported by Skyfiles can be efficiently and securely accomplished with either a self-created instance or shared instance.",
    "lastUpdated": "2020-10-26T02:52:43Z",
    "category": [
      "cs.DC",
      "cs.PF"
    ],
    "url": "http://arxiv.org/abs/2010.13296v1"
  },
  {
    "title": "Video Big Data Analytics in the Cloud: Research Issues and Challenges",
    "author": [
      "Aftab Alam",
      "Shah Khalid",
      "Muhammad Numan Khan",
      "Tariq Habib Afridi",
      "Irfan Ullah",
      "Young-Koo Lee"
    ],
    "abstract": "On the rise of distributed computing technologies, video big data analytics in the cloud have attracted researchers and practitioners' attention. The current technology and market trends demand an efficient framework for video big data analytics. However, the current work is too limited to provide an architecture on video big data analytics in the cloud, including managing and analyzing video big data, the challenges, and opportunities. This study proposes a service-oriented layered reference architecture for intelligent video big data analytics in the cloud. Finally, we identify and articulate several open research issues and challenges, which have been raised by the deployment of big data technologies in the cloud for video big data analytics. This paper provides the research studies and technologies advancing video analyses in the era of big data and cloud computing. This is the first study that presents the generalized view of the video big data analytics in the cloud to the best of our knowledge.",
    "lastUpdated": "2020-11-05T07:58:19Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/2011.02694v1"
  },
  {
    "title": "Multiscale Point Cloud Geometry Compression",
    "author": [
      "Jianqiang Wang",
      "Dandan Ding",
      "Zhu Li",
      "Zhan Ma"
    ],
    "abstract": "Recent years have witnessed the growth of point cloud based applications because of its realistic and fine-grained representation of 3D objects and scenes. However, it is a challenging problem to compress sparse, unstructured, and high-precision 3D points for efficient communication. In this paper, leveraging the sparsity nature of point cloud, we propose a multiscale end-to-end learning framework which hierarchically reconstructs the 3D Point Cloud Geometry (PCG) via progressive re-sampling. The framework is developed on top of a sparse convolution based autoencoder for point cloud compression and reconstruction. For the input PCG which has only the binary occupancy attribute, our framework translates it to a downscaled point cloud at the bottleneck layer which possesses both geometry and associated feature attributes. Then, the geometric occupancy is losslessly compressed using an octree codec and the feature attributes are lossy compressed using a learned probabilistic context model.Compared to state-of-the-art Video-based Point Cloud Compression (V-PCC) and Geometry-based PCC (G-PCC) schemes standardized by the Moving Picture Experts Group (MPEG), our method achieves more than 40% and 70% BD-Rate (Bjontegaard Delta Rate) reduction, respectively. Its encoding runtime is comparable to that of G-PCC, which is only 1.5% of V-PCC.",
    "lastUpdated": "2020-11-07T16:11:16Z",
    "category": [
      "eess.IV",
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2011.03799v1"
  },
  {
    "title": "Managing Latency in Edge-Cloud Environment",
    "author": [
      "Lubomír Bulej",
      "Tomáš Bureš",
      "Adam Filandr",
      "Petr Hnětynka",
      "Iveta Hnětynkova",
      "Jan Pacovský",
      "Gabor Sandor",
      "Ilias Gerostathopoulos"
    ],
    "abstract": "Modern Cyber-physical Systems (CPS) include applications like smart traffic, smart agriculture, smart power grid, etc. Commonly, these systems are distributed and composed of end-user applications and microservices that typically run in the cloud. The connection with the physical world, which is inherent to CPS, brings the need to operate and respond in real-time. As the cloud becomes part of the computation loop, the real-time requirements have to be also reflected by the cloud. In this paper, we present an approach that provides soft real-time guarantees on the response time of services running in cloud and edge-cloud (i.e., cloud geographically close to the end-user), where these services are developed in high-level programming languages. In particular, we elaborate a method that allows us to predict the upper bound of the response time of a service when sharing the same computer with other services. Importantly, as our approach focuses on minimizing the impact on the developer of such services, it does not require any special programming model nor limits usage of common libraries, etc.",
    "lastUpdated": "2020-11-23T14:52:43Z",
    "category": [
      "cs.DC",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/2011.11450v1"
  },
  {
    "title": "Nudge Attacks on Point-Cloud DNNs",
    "author": [
      "Yiren Zhao",
      "Ilia Shumailov",
      "Robert Mullins",
      "Ross Anderson"
    ],
    "abstract": "The wide adaption of 3D point-cloud data in safety-critical applications such as autonomous driving makes adversarial samples a real threat. Existing adversarial attacks on point clouds achieve high success rates but modify a large number of points, which is usually difficult to do in real-life scenarios. In this paper, we explore a family of attacks that only perturb a few points of an input point cloud, and name them nudge attacks. We demonstrate that nudge attacks can successfully flip the results of modern point-cloud DNNs. We present two variants, gradient-based and decision-based, showing their effectiveness in white-box and grey-box scenarios. Our extensive experiments show nudge attacks are effective at generating both targeted and untargeted adversarial point clouds, by changing a few points or even a single point from the entire point-cloud input. We find that with a single point we can reliably thwart predictions in 12--80% of cases, whereas 10 points allow us to further increase this to 37--95%. Finally, we discuss the possible defenses against such attacks, and explore their limitations.",
    "lastUpdated": "2020-11-22T18:04:02Z",
    "category": [
      "cs.CR",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2011.11637v1"
  },
  {
    "title": "A Survey on Blockchain & Cloud Integration",
    "author": [
      "Soumik Sarker",
      "Arnob Kumar Saha",
      "Md Sadek Ferdous"
    ],
    "abstract": "Blockchain is one of the emerging technologies with the potential to disrupt many application domains. Cloud is an on-demand service paradigm facilitating the availability of shared resources for data storage and computation. In recent years, the integration of blockchain and cloud has received significant attention for ensuring efficiency, transparency, security and even for offering better cloud services in the form of novel service models. In order to exploit the full potential of blockchain-cloud integration, it is essential to have a clear understanding on the existing works within this domain. To facilitate this, there have been several survey papers, however, none of them covers the aspect of blockchain-cloud integration from a service-oriented perspective. This paper aims to fulfil this gap by providing a service oriented review of blockchain-cloud integration. Indeed, in this survey, we explore different service models into which blockchain has been integrated. For each service model, we review the existing works and present a comparative analysis so as to offer a clear and concise view in each category.",
    "lastUpdated": "2020-12-04T15:04:27Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/2012.02644v1"
  },
  {
    "title": "PointCutMix: Regularization Strategy for Point Cloud Classification",
    "author": [
      "Jinlai Zhang",
      "Lvjie Chen",
      "Bo Ouyang",
      "Binbin Liu",
      "Jihong Zhu",
      "Yujing Chen",
      "Yanmei Meng",
      "Danfeng Wu"
    ],
    "abstract": "3D point cloud analysis has received increasing attention in recent years, however, the diversity and availability of point cloud datasets are still limited. We therefore present PointCutMix, a simple but effective method for augmentation in point cloud. In our method, after finding the optimal assignment between two point clouds, we replace some points in one point cloud by its counterpart point in another point cloud. Our strategy consistently and significantly improves the performance across various models and datasets. Surprisingly, when it is used as a defense method, it shows far superior performance to the SOTA defense algorithm. The code is available at:https://github.com/cuge1995/PointCutMix",
    "lastUpdated": "2021-01-05T11:39:06Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2101.01461v1"
  },
  {
    "title": "Cloud Computing: Exploring the scope",
    "author": [
      "Abhinav Pandey",
      "Akash Pandey",
      "Ankit Tandon",
      "Brajesh Kr Maurya",
      "Upendra Kushwaha",
      "Dr. Madhvendra Mishra",
      "Vijayshree Tiwari"
    ],
    "abstract": "Cloud computing refers to a paradigm shift to overall IT solutions while raising the accessibility, scalability and effectiveness through its enabling technologies. However, migrated cloud platforms and services cost benefits as well as performances are neither clear nor summarized. Globalization and the recessionary economic times have not only raised the bar of a better IT delivery models but also have given access to technology enabled services via internet. Cloud computing has vast potential in terms of lean Retail methodologies that can minimize the operational cost by using the third party based IT capabilities, as a service. It will not only increase the ROI but will also help in lowering the total cost of ownership. In this paper we have tried to compare the cloud computing cost benefits with the actual premise cost which an organization incurs normally. However, in spite of the cost benefits, many IT professional believe that the latest model i.e. \"cloud computing\" has risks and security concerns. This report demonstrates how to answer the following questions: (1) Idea behind cloud computing. (2) Monetary cost benefits of using cloud with respect to traditional premise computing. (3) What are the various security issues? We have tried to find out the cost benefit by comparing the Microsoft Azure cloud cost with the prevalent premise cost.",
    "lastUpdated": "2010-05-20T19:26:07Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1005.1904v3"
  },
  {
    "title": "Managing Clouds in Cloud Platforms",
    "author": [
      "Kamal A. Ahmat",
      "Hassan Gobjuka"
    ],
    "abstract": "Managing cloud services is a fundamental challenge in todays virtualized environments. These challenges equally face both providers and consumers of cloud services. The issue becomes even more challenging in virtualized environments that support mobile clouds. Cloud computing platforms such as Amazon EC2 provide customers with flexible, on demand resources at low cost. However, they fail to provide seamless infrastructure management and monitoring capabilities that many customers may need. For instance, Amazon EC2 doesn't fully support cloud services automated discovery and it requires a private set of authentication credentials. Salesforce.com, on the other hand, do not provide monitoring access to their underlying systems. Moreover, these systems fail to provide infrastructure monitoring of heterogenous and legacy systems that don't support agents. In this work, we explore how to build a cloud management system that combines heterogeneous management of virtual resources with comprehensive management of physical devices. We propose an initial prototype for automated cloud management and monitoring framework. Our ultimate goal is to develop a framework that have the capability of automatically tracking configuration and relationships while providing full event management, measuring performance and testing thresholds, and measuring availability consistently. Armed with such a framework, operators can make better decisions quickly and more efficiently.",
    "lastUpdated": "2010-08-29T03:35:24Z",
    "category": [
      "cs.DC",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1008.4900v1"
  },
  {
    "title": "A New Trusted and Collaborative Agent Based Approach for Ensuring Cloud Security",
    "author": [
      "Shantanu Pal",
      "Sunirmal Khatua",
      "Nabendu Chaki",
      "Sugata Sanyal"
    ],
    "abstract": "In order to determine the user's trust is a growing concern for ensuring privacy and security in a cloud computing environment. In cloud, user's data is stored in one or more remote server(s) which poses more security challenges for the system. One of the most important concerns is to protect user's sensitive information from other users and hackers that may cause data leakage in cloud storage. Having this security challenge in mind, this paper focuses on the development of a more secure cloud environment, to determine the trust of the service requesting authorities by using a novel VM (Virtual Machine) monitoring system. Moreover, this research aims towards proposing a new trusted and collaborative agent-based two-tier framework, titled WAY (Who Are You?), to protect cloud resources. The framework can be used to provide security in network, infrastructure, as well as data storage in a heterogeneous cloud platform. If the trust updating policy is based on network activities, then the framework can provide network security. Similarly, it provides storage security by monitoring unauthorized access activities by the Cloud Service Users (CSU). Infrastructure security can be provided by monitoring the use of privileged instructions within the isolated VMs. The uniqueness of the proposed security solution lies in the fact that it ensures security and privacy both at the service provider level as well as at the user level in a cloud environment.",
    "lastUpdated": "2011-08-20T08:20:47Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1108.4100v1"
  },
  {
    "title": "Cloud Computing framework for Computer Vision Research:An Introduction",
    "author": [
      "Yu Zhou"
    ],
    "abstract": "Cloud computing offers the potential to help scientists to process massive number of computing resources often required in machine learning application such as computer vision problems. This proposal would like to show that which benefits can be obtained from cloud in order to help medical image analysis users (including scientists, clinicians, and research institutes). As security and privacy of algorithms are important for most of algorithms inventors, these algorithms can be hidden in a cloud to allow the users to use the algorithms as a package without any access to see/change their inside. In another word, in the user part, users send their images to the cloud and configure the algorithm via an interface. In the cloud part, the algorithms are applied to this image and the results are returned back to the user. My proposal has two parts: (1) investigate the potential of cloud computing for computer vision problems and (2) study the components of a proposed cloud-based framework for medical image analysis application and develop them (depending on the length of the internship). The investigation part will involve a study on several aspects of the problem including security, usability (for medical end users of the service), appropriate programming abstractions for vision problems, scalability and resource requirements. In the second part of this proposal I am going to thoroughly study of the proposed framework components and their relations and develop them. The proposed cloud-based framework includes an integrated environment to enable scientists and clinicians to access to the previous and current medical image analysis algorithms using a handful user interface without any access to the algorithm codes and procedures.",
    "lastUpdated": "2013-02-06T11:41:26Z",
    "category": [
      "cs.CV",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1302.1326v1"
  },
  {
    "title": "Cloud Security Challenges: Investigating Policies, Standards, and Guidelines in a Fortune 500 Organization",
    "author": [
      "George Grispos",
      "William Bradley Glisson",
      "Tim Storer"
    ],
    "abstract": "Cloud computing is quickly becoming pervasive in today's globally integrated networks. The cloud offers organizations opportunities to potentially deploy software and data solutions that are accessible through numerous mechanisms, in a multitude of settings, at a reduced cost with increased reliability and scalability. The increasingly pervasive and ubiquitous nature of the cloud creates an environment that is potentially conducive to security risks. While previous discussions have focused on security and privacy issues in the cloud from the end-users perspective, minimal empirical research has been conducted from the perspective of a corporate environment case study. This paper presents the results of an initial case study identifying real-world information security documentation issues for a Global Fortune 500 organization, should the organization decide to implement cloud computing services in the future. The paper demonstrates the importance of auditing policies, standards and guidelines applicable to cloud computing environments along with highlighting potential corporate concerns. The results from this case study has revealed that from the 1123 'relevant' statements found in the organization's security documentation, 175 statements were considered to be 'inadequate' for cloud computing. Furthermore, the paper provides a foundation for future analysis and research regarding implementation concerns for corporate cloud computing applications and services",
    "lastUpdated": "2013-06-11T10:18:02Z",
    "category": [
      "cs.CR",
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1306.2477v1"
  },
  {
    "title": "Cloud Template, a Big Data Solution",
    "author": [
      "Mehdi Bahrami"
    ],
    "abstract": "Today cloud computing has become as a new concept for hosting and delivering different services over the Internet for big data solutions. Cloud computing is attractive to different business owners of both small and enterprise as it eliminates the requirement for users to plan ahead for provisioning, and allows enterprises to start from the small and increase resources only when there is a rise in service demand. Despite the fact that cloud computing offers huge opportunities to the IT industry, the development of cloud computing technology is currently has several issues. This study presents an idea for introducing cloud templates which will be used for analyzing, designing, developing and implementing cloud computing systems. We will present a template based design for cloud computing systems, highlighting its key concepts, architectural principles and state of the art implementation, as well as research challenges and future work requirements. The aim of this idea is to provide a better understanding of the design challenges of cloud computing and identify important research directions in this big data increasingly important area. We will describe a series of studies by which we and other researchers have assessed the effectiveness of these techniques in practical situations. Finally, in this study we will show how this idea could be implemented in a practical and useful way in industry.",
    "lastUpdated": "2013-08-05T00:15:39Z",
    "category": [
      "cs.DC",
      "cs.NI",
      "cs.SE",
      "cs.SI"
    ],
    "url": "http://arxiv.org/abs/1307.4716v2"
  },
  {
    "title": "Continuous Double Auction Mechanism and Bidding Strategies in Cloud Computing Markets",
    "author": [
      "Xuelin Shi",
      "Ke Xu",
      "JiangChuan Liu",
      "Yong Wang"
    ],
    "abstract": "Cloud computing has been an emerging model which aims at allowing customers to utilize computing resources hosted by Cloud Service Providers (CSPs). More and more consumers rely on CSPs to supply computing and storage service on the one hand, and CSPs try to attract consumers on favorable terms on the other. In such competitive cloud computing markets, pricing policies are critical to market efficiency. While CSPs often publish their prices and charge users according to the amount of resources they consume, auction mechanism is rarely applied. In fact a feasible auction mechanism is the most effective method for allocation of resources, especially double auction is more efficient and flexible for it enables buyers and sellers to enter bids and offers simultaneously. In this paper we bring up an electronic auction platform for cloud, and a cloud Continuous Double Auction (CDA) mechanism is formulated to match orders and facilitate trading based on the platform. Some evaluating criteria are defined to analyze the efficiency of markets and strategies. Furthermore, the selection of bidding strategies for the auction plays a very important role for each player to maximize its own profit, so we developed a novel bidding strategy for cloud CDA, BH-strategy, which is a two-stage game bidding strategy. At last we designed three simulation scenarios to compare the performance of our strategy with other dominating bidding strategies and proved that BH-strategy has better performance on surpluses, successful transactions and market efficiency. In addition, we discussed that our cloud CDA mechanism is feasible for cloud computing resource allocation.",
    "lastUpdated": "2013-07-23T13:28:56Z",
    "category": [
      "cs.DC",
      "cs.GT"
    ],
    "url": "http://arxiv.org/abs/1307.6066v1"
  },
  {
    "title": "Determinants of a Successful Migration to Cloud Computing in Iranian Telecommunication Industry",
    "author": [
      "Azadeh Erfan"
    ],
    "abstract": "Although the research support for Cloud Computing (CC) is still developing, the concept of this paper has provided comprehensive frameworks for a successful migration to cloud computing (SMCC) in telecommunication industry in Iran. Using an academic orientation, the conceptual research is focusing on the determinants of a successful migration from legacy to cloud computing. The study attempts to reveal the constructive effects and deconstructive defects of migration to cloud computing with a close regard into prior literature and practical practices all around the world. Conceptual frameworks are deducted from the literature and Telco's revolutionary movements toward cloud computing. The confirmatory quantitative approach tries to verify or reject the validity of determinants of successful migration. The study reports that there are some success and failure factors which are influencing a successful migration of data centres and servers of Iranian Telecommunication to the cloud. Considering these approved factors before any migration decision would be valuable for engaged project members and finally for Telecommunication organization. This paper can be used as reliable model for any migration beforehand taking any action. Enforcing proper determinants in accordance with the prior success stories and academia viewpoints in Telecommunication industry in Iran as a first mover research in this field provides a precious insight for policy and decision makers to change their mindset and grant a proper space for cloud computing to grow in this industry due to its advantages. Obviously, like any other big Telco in the world, Iranian Telco might start cloud projects to sustain its presence in the global market.",
    "lastUpdated": "2013-10-28T09:35:40Z",
    "category": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1310.7353v1"
  },
  {
    "title": "An Overview of the Commercial Cloud Monitoring Tools: Research Dimensions, Design Issues, and State-of-the-Art",
    "author": [
      "Khalid Alhamazani",
      "Rajiv Ranjan",
      "Karan Mitra",
      "Fethi Rabhi",
      "Samee Ullah Khan",
      "Adnene Guabtni",
      "Vasudha Bhatnagar"
    ],
    "abstract": "Cloud monitoring activity involves dynamically tracking the Quality of Service (QoS) parameters related to virtualized resources (e.g., VM, storage, network, appliances, etc.), the physical resources they share, the applications running on them and data hosted on them. Applications and resources configuration in cloud computing environment is quite challenging considering a large number of heterogeneous cloud resources. Further, considering the fact that at each point of time, there will be a different and specific cloud service which may be massively required. Hence, cloud monitoring tools can assist a cloud providers or application developers in: (i) keeping their resources and applications operating at peak efficiency; (ii) detecting variations in resource and application performance; (iii) accounting the Service Level Agreement (SLA) violations of certain QoS parameters; and (iv) tracking the leave and join operations of cloud resources due to failures and other dynamic configuration changes. In this paper, we identify and discuss the major research dimensions and design issues related to engineering cloud monitoring tools. We further discuss how aforementioned research dimensions and design issues are handled by current academic research as well as by commercial monitoring tools.",
    "lastUpdated": "2013-12-20T22:54:23Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1312.6170v1"
  },
  {
    "title": "A systematic literature review of cloud computing in eHealth",
    "author": [
      "Yan Hu",
      "Guohua Bai"
    ],
    "abstract": "Cloud computing in eHealth is an emerging area for only few years. There needs to identify the state of the art and pinpoint challenges and possible directions for researchers and applications developers. Based on this need, we have conducted a systematic review of cloud computing in eHealth. We searched ACM Digital Library, IEEE Xplore, Inspec, ISI Web of Science and Springer as well as relevant open-access journals for relevant articles. A total of 237 studies were first searched, of which 44 papers met the Include Criteria. The studies identified three types of studied areas about cloud computing in eHealth, namely (1) cloud-based eHealth framework design (n=13); (2) applications of cloud computing (n=17); and (3) security or privacy control mechanisms of healthcare data in the cloud (n=14). Most of the studies in the review were about designs and concept-proof. Only very few studies have evaluated their research in the real world, which may indicate that the application of cloud computing in eHealth is still very immature. However, our presented review could pinpoint that a hybrid cloud platform with mixed access control and security protection mechanisms will be a main research area for developing citizen centred home-based healthcare applications.",
    "lastUpdated": "2014-12-08T09:42:41Z",
    "category": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1412.2494v1"
  },
  {
    "title": "An Effective Framework for Managing University Data using a Cloud based Environment",
    "author": [
      "Kashish Ara Shakil",
      "Shuchi Sethi",
      "Mansaf Alam"
    ],
    "abstract": "Management of data in education sector particularly management of data for big universities with several employees, departments and students is a very challenging task. There are also problems such as lack of proper funds and manpower for management of such data in universities. Education sector can easily and effectively take advantage of cloud computing skills for management of data. It can enhance the learning experience as a whole and can add entirely new dimensions to the way in which education is imbibed. Several benefits of Cloud computing such as monetary benefits, environmental benefits and remote data access for management of data such as university database can be used in education sector. Therefore, in this paper we have proposed an effective framework for managing university data using a cloud based environment. We have also proposed cloud data management simulator: a new simulation framework which demonstrates the applicability of cloud in the current education sector. The framework consists of a cloud developed for processing a universities database which consists of staff and students. It has the following features (i) support for modeling cloud computing infrastructure, which includes data centers containing university database; (ii) a user friendly interface; (iii) flexibility to switch between the different types of users; and (iv) virtualized access to cloud data.",
    "lastUpdated": "2015-01-28T10:37:33Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1501.07056v1"
  },
  {
    "title": "Making Availability as a Service in the Clouds",
    "author": [
      "Pengfei Chen",
      "Yong Qi",
      "Peipei Wang",
      "Li Su",
      "Xinyi Li"
    ],
    "abstract": "Cloud computing has achieved great success in modern IT industry as an excellent computing paradigm due to its flexible management and elastic resource sharing. To date, cloud computing takes an irrepalceable position in our socioeconomic system and influences almost every aspect of our daily life. However, it is still in its infancy, many problems still exist.Besides the hotly-debated security problem, availability is also an urgent issue.With the limited power of availability mechanisms provided in present cloud platform, we can hardly get detailed availability information of current applications such as the root causes of availability problem,mean time to failure, etc. Thus a new mechanism based on deep avaliability analysis is neccessary and benificial.Following the prevalent terminology 'XaaS',this paper proposes a new win-win concept for cloud users and providers in term of 'Availability as a Service' (abbreviated as 'AaaS').The aim of 'AaaS' is to provide comprehensive and aimspecific runtime avaliabilty analysis services for cloud users by integrating plent of data-driven and modeldriven approaches. To illustrate this concept, we realize a prototype named 'EagleEye' with all features of 'AaaS'. By subscribing corresponding services in 'EagleEye', cloud users could get specific availability information of their applications deployed in cloud platform. We envision this new kind of service will be merged into the cloud management mechanism in the near future.",
    "lastUpdated": "2015-03-15T13:06:10Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1503.04422v1"
  },
  {
    "title": "Medusa: An Efficient Cloud Fault-Tolerant MapReduce",
    "author": [
      "Pedro A. R. S. Costa",
      "Xiao Bai",
      "Fernando M. V. Ramos",
      "Miguel Correia"
    ],
    "abstract": "Applications such as web search and social networking have been moving from centralized to decentralized cloud architectures to improve their scalability. MapReduce, a programming framework for processing large amounts of data using thousands of machines in a single cloud, also needs to be scaled out to multiple clouds to adapt to this evolution. The challenge of building a multi-cloud distributed architecture is substantial. Notwithstanding, the ability to deal with the new types of faults introduced by such setting, such as the outage of a whole datacenter or an arbitrary fault caused by a malicious cloud insider, increases the endeavor considerably. In this paper we propose Medusa, a platform that allows MapReduce computations to scale out to multiple clouds and tolerate several types of faults. Our solution fulfills four objectives. First, it is transparent to the user, who writes her typical MapReduce application without modification. Second, it does not require any modification to the widely used Hadoop framework. Third, the proposed system goes well beyond the fault-tolerance offered by MapReduce to tolerate arbitrary faults, cloud outages, and even malicious faults caused by corrupt cloud insiders. Fourth, it achieves this increased level of fault tolerance at reasonable cost. We performed an extensive experimental evaluation in the ExoGENI testbed, demonstrating that our solution significantly reduces execution time when compared to traditional methods that achieve the same level of resilience.",
    "lastUpdated": "2015-11-23T12:02:43Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1511.07185v1"
  },
  {
    "title": "TwinCloud: Secure Cloud Sharing Without Explicit Key Management",
    "author": [
      "Kemal Bicakci",
      "Davut Deniz Yavuz",
      "Sezin Gurkan"
    ],
    "abstract": "With the advent of cloud technologies, there is a growing number of easy-to-use services to store files and share them with other cloud users. By providing security features, cloud service providers try to encourage users to store personal files or corporate documents on their servers. However, their server-side encryption solutions are not satisfactory when the server itself is not trusted. Although, there are several client-side solutions to provide security for cloud sharing, they are not used extensively because of usability issues in key management. In this paper, we propose TwinCloud which is an innovative solution with the goal of providing a secure system to users without compromising the usability of cloud sharing. TwinCloud achieves this by bringing a novel solution to the complex key exchange problem and by providing a simple and practical approach to store and share files by hiding all the cryptographic and key-distribution operations from users. Serving as a gateway, TwinCloud uses two or more cloud providers to store the encryption keys and encrypted files in separate clouds which ease the secure sharing without a need for trust to either of the cloud service providers with the assumption that they do not collude with each other. We implemented TwinCloud as a lightweight application and make it available as open-source. The results of our usability study show the prospect of the secure sharing solution of TwinCloud.",
    "lastUpdated": "2016-07-13T05:40:31Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1606.04705v2"
  },
  {
    "title": "Secure Cloud Storage Protocols with Data Dynamics Using Secure Network Coding Techniques",
    "author": [
      "Binanda Sengupta",
      "Akanksha Dixit",
      "Sushmita Ruj"
    ],
    "abstract": "In the age of cloud computing, cloud users with limited storage can outsource their data to remote servers. These servers, in lieu of monetary benefits, offer retrievability of their clients' data at any point of time. Secure cloud storage protocols enable a client to check integrity of outsourced data. In this work, we explore the possibility of constructing a secure cloud storage for dynamic data by leveraging the algorithms involved in secure network coding. We show that some of the secure network coding schemes can be used to construct efficient secure cloud storage protocols for dynamic data, and we construct such a protocol (DSCS I) based on a secure network coding protocol. To the best of our knowledge, DSCS I is the first secure cloud storage protocol for dynamic data constructed using secure network coding techniques which is secure in the standard model. Although generic dynamic data support arbitrary insertions, deletions and modifications, append-only data find numerous applications in the real world. We construct another secure cloud storage protocol (DSCS II) specific to append-only data -- that overcomes some limitations of DSCS I. Finally, we provide prototype implementations for DSCS I and DSCS II in order to evaluate their performance.",
    "lastUpdated": "2020-06-07T05:38:55Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1612.08029v7"
  },
  {
    "title": "An Enhanced BPSO based Approach for Service Placement in Hybrid Cloud",
    "author": [
      "Wissem Abbes",
      "Zied Kechaou",
      "Adel M. Alimi"
    ],
    "abstract": "Due to the challenges of competition and the rapidly evolving market, companies need to be innovative and agile, particularly in regard of web applications as used by customers. Nowadays, hybrid cloud stands as an attractive solution as organizations tend to use a combination of private and public cloud implementations, in accordance with their appropriate needs to profitably apply the available resources and speed of execution. In such a case, deploying the new applications would certainly entail opting for placing and consecrating some components to the private cloud option, while reserving some others to the public cloud option. In this respect, our primary goal in this paper consists in minimizing the extra costs likely to be incurred by applying the public cloud related options, along with those costs involved in maintaining communication between the private cloud system and the public cloud framework. As for our second targeted objective, it lies in reducing the decision process relating to the execution time, necessary for selecting the optimal service placement solution. For this purpose, a novel Binary Particle Swarm Optimization (BPSO) based approach is proposed, useful for an effective service placement optimization within hybrid cloud to take place. Using a real benchmark, the experimental results appear to reveal that our proposed approach reached results that outperform those documented in the state of the art both in terms of cost and time.",
    "lastUpdated": "2018-06-10T22:08:02Z",
    "category": [
      "cs.DC",
      "cs.NE"
    ],
    "url": "http://arxiv.org/abs/1806.05971v1"
  },
  {
    "title": "An Elastic Middleware Platform for Concurrent and Distributed Cloud and MapReduce Simulations",
    "author": [
      "Pradeeban Kathiravelu"
    ],
    "abstract": "Cloud Computing researches involve a tremendous amount of entities such as users, applications, and virtual machines. Due to the limited access and often variable availability of such resources, researchers have their prototypes tested against the simulation environments, opposed to the real cloud environments. Existing cloud simulation environments such as CloudSim and EmuSim are executed sequentially, where a more advanced cloud simulation tool could be created extending them, leveraging the latest technologies as well as the availability of multi-core computers and the clusters in the research laboratories. While computing has been evolving with multi-core programming, MapReduce paradigms, and middleware platforms, cloud and MapReduce simulations still fail to exploit these developments themselves. This research develops Cloud2Sim, which tries to fill the gap between the simulations and the actual technology that they are trying to simulate. First, Cloud2Sim provides a concurrent and distributed cloud simulator, by extending CloudSim cloud simulator, using Hazelcast in-memory key-value store. Then, it also provides a quick assessment to MapReduce implementations of Hazelcast and Infinispan, adaptively distributing the execution to a cluster, providing means of simulating MapReduce executions. The dynamic scaler solution scales out the cloud and MapReduce simulations to multiple nodes running Hazelcast and Infinispan, based on load. The distributed execution model and adaptive scaling solution could be leveraged as a general purpose auto scaler middleware for a multi-tenanted deployment.",
    "lastUpdated": "2016-01-15T16:04:02Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1601.03980v1"
  },
  {
    "title": "A coarse-to-fine algorithm for registration in 3D street-view cross-source point clouds",
    "author": [
      "Xiaoshui Huang",
      "Jian Zhang",
      "Qiang Wu",
      "Lixin Fan",
      "Chun Yuan"
    ],
    "abstract": "With the development of numerous 3D sensing technologies, object registration on cross-source point cloud has aroused researchers' interests. When the point clouds are captured from different kinds of sensors, there are large and different kinds of variations. In this study, we address an even more challenging case in which the differently-source point clouds are acquired from a real street view. One is produced directly by the LiDAR system and the other is generated by using VSFM software on image sequence captured from RGB cameras. When it confronts to large scale point clouds, previous methods mostly focus on point-to-point level registration, and the methods have many limitations.The reason is that the least mean error strategy shows poor ability in registering large variable cross-source point clouds. In this paper, different from previous ICP-based methods, and from a statistic view, we propose a effective coarse-to-fine algorithm to detect and register a small scale SFM point cloud in a large scale Lidar point cloud. Seen from the experimental results, the model can successfully run on LiDAR and SFM point clouds, hence it can make a contribution to many applications, such as robotics and smart city development.",
    "lastUpdated": "2016-10-24T08:22:32Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1610.07324v1"
  },
  {
    "title": "ERA: A Framework for Economic Resource Allocation for the Cloud",
    "author": [
      "Moshe Babaioff",
      "Yishay Mansour",
      "Noam Nisan",
      "Gali Noti",
      "Carlo Curino",
      "Nar Ganapathy",
      "Ishai Menache",
      "Omer Reingold",
      "Moshe Tennenholtz",
      "Erez Timnat"
    ],
    "abstract": "Cloud computing has reached significant maturity from a systems perspective, but currently deployed solutions rely on rather basic economics mechanisms that yield suboptimal allocation of the costly hardware resources. In this paper we present Economic Resource Allocation (ERA), a complete framework for scheduling and pricing cloud resources, aimed at increasing the efficiency of cloud resources usage by allocating resources according to economic principles. The ERA architecture carefully abstracts the underlying cloud infrastructure, enabling the development of scheduling and pricing algorithms independently of the concrete lower-level cloud infrastructure and independently of its concerns. Specifically, ERA is designed as a flexible layer that can sit on top of any cloud system and interfaces with both the cloud resource manager and with the users who reserve resources to run their jobs. The jobs are scheduled based on prices that are dynamically calculated according to the predicted demand. Additionally, ERA provides a key internal API to pluggable algorithmic modules that include scheduling, pricing and demand prediction. We provide a proof-of-concept software and demonstrate the effectiveness of the architecture by testing ERA over both public and private cloud systems -- Azure Batch of Microsoft and Hadoop/YARN. A broader intent of our work is to foster collaborations between economics and system communities. To that end, we have developed a simulation platform via which economics and system experts can test their algorithmic implementations.",
    "lastUpdated": "2017-02-23T17:54:28Z",
    "category": [
      "cs.GT",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1702.07311v1"
  },
  {
    "title": "StackInsights: Cognitive Learning for Hybrid Cloud Readiness",
    "author": [
      "Mu Qiao",
      "Luis Bathen",
      "Simon-Pierre Génot",
      "Sunhwan Lee",
      "Ramani Routray"
    ],
    "abstract": "Hybrid cloud is an integrated cloud computing environment utilizing a mix of public cloud, private cloud, and on-premise traditional IT infrastructures. Workload awareness, defined as a detailed full range understanding of each individual workload, is essential in implementing the hybrid cloud. While it is critical to perform an accurate analysis to determine which workloads are appropriate for on-premise deployment versus which workloads can be migrated to a cloud off-premise, the assessment is mainly performed by rule or policy based approaches. In this paper, we introduce StackInsights, a novel cognitive system to automatically analyze and predict the cloud readiness of workloads for an enterprise. Our system harnesses the critical metrics across the entire stack: 1) infrastructure metrics, 2) data relevance metrics, and 3) application taxonomy, to identify workloads that have characteristics of a) low sensitivity with respect to business security, criticality and compliance, and b) low response time requirements and access patterns. Since the capture of the data relevance metrics involves an intrusive and in-depth scanning of the content of storage objects, a machine learning model is applied to perform the business relevance classification by learning from the meta level metrics harnessed across stack. In contrast to traditional methods, StackInsights significantly reduces the total time for hybrid cloud readiness assessment by orders of magnitude.",
    "lastUpdated": "2017-12-16T20:14:53Z",
    "category": [
      "cs.LG",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1712.06015v1"
  },
  {
    "title": "Pervasive Cloud Controller for Geotemporal Inputs",
    "author": [
      "Dražen Lučanin",
      "Ivona Brandic"
    ],
    "abstract": "The rapid cloud computing growth has turned data center energy consumption into a global problem. At the same time, modern cloud providers operate multiple geographically-distributed data centers. Distributed data center infrastructure changes the rules of cloud control, as energy costs depend on current regional electricity prices and temperatures. Furthermore, to account for emerging technologies surrounding the cloud ecosystem, a maintainable control solution needs to be forward-compatible. Existing cloud controllers are focused on VM consolidation methods suitable only for a single data center or consider migration just in case of workload peaks, not accounting for all the aspects of geographically distributed data centers. In this paper, we propose a pervasive cloud controller for dynamic resource reallocation adapting to volatile time- and location-dependent factors, while considering the QoS impact of too frequent migrations and the data quality limits of time series forecasting methods. The controller is designed with extensible decision support components. We evaluate it in a simulation using historical traces of electricity prices and temperatures. By optimising for these additional factors, we estimate 28.6% energy cost savings compared to baseline dynamic VM consolidation. We provide a range of guidelines for cloud providers, showing the environment conditions necessary to achieve significant cost savings and we validate the controller's extensibility.",
    "lastUpdated": "2018-09-16T08:50:50Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1809.05838v1"
  },
  {
    "title": "Performance Analysis and Modeling of Video Transcoding Using Heterogeneous Cloud Services",
    "author": [
      "Xiangbo Li",
      "Mohsen Amini Salehi",
      "Yamini Joshi",
      "Mahmoud Darwich",
      "Brad Landreneau",
      "Magdy Bayoumi"
    ],
    "abstract": "High-quality video streaming, either in form of Video-On-Demand (VOD) or live streaming, usually requires converting (ie, transcoding) video streams to match the characteristics of viewers' devices (eg, in terms of spatial resolution or supported formats). Considering the computational cost of the transcoding operation and the surge in video streaming demands, Streaming Service Providers (SSPs) are becoming reliant on cloud services to guarantee Quality of Service (QoS) of streaming for their viewers. Cloud providers offer heterogeneous computational services in form of different types of Virtual Machines (VMs) with diverse prices. Effective utilization of cloud services for video transcoding requires detailed performance analysis of different video transcoding operations on the heterogeneous cloud VMs. In this research, for the first time, we provide a thorough analysis of the performance of the video stream transcoding on heterogeneous cloud VMs. Providing such analysis is crucial for efficient prediction of transcoding time on heterogeneous VMs and for the functionality of any scheduling methods tailored for video transcoding. Based upon the findings of this analysis and by considering the cost difference of heterogeneous cloud VMs, in this research, we also provide a model to quantify the degree of suitability of each cloud VM type for various transcoding tasks. The provided model can supply resource (VM) provisioning methods with accurate performance and cost trade-offs to efficiently utilize cloud services for video streaming.",
    "lastUpdated": "2018-09-18T04:47:43Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1809.06529v1"
  },
  {
    "title": "Practical Shape Analysis and Segmentation Methods for Point Cloud Models",
    "author": [
      "Reed M. Williams",
      "Horea T. Ilieş"
    ],
    "abstract": "Current point cloud processing algorithms do not have the capability to automatically extract semantic information from the observed scenes, except in very specialized cases. Furthermore, existing mesh analysis paradigms cannot be directly employed to automatically perform typical shape analysis tasks directly on point cloud models. We present a potent framework for shape analysis, similarity, and segmentation of noisy point cloud models for real objects of engineering interest, models that may be incomplete. The proposed framework relies on spectral methods and the heat diffusion kernel to construct compact shape signatures, and we show that the framework supports a variety of clustering techniques that have traditionally been applied only on mesh models. We developed and implemented one practical and convergent estimate of the Laplace-Beltrami operator for point clouds as well as a number of clustering techniques adapted to work directly on point clouds to produce geometric features of engineering interest. The key advantage of this framework is that it supports practical shape analysis capabilities that operate directly on point cloud models of objects without requiring surface reconstruction or global meshing. We show that the proposed technique is robust against typical noise present in possibly incomplete point clouds, and segment point clouds scanned by depth cameras (e.g. Kinect) into semantically-meaningful sub-shapes.",
    "lastUpdated": "2018-10-25T15:38:30Z",
    "category": [
      "cs.CG",
      "cs.CV",
      "cs.GR",
      "J.6; I.4.6; I.5.3; I.3.5"
    ],
    "url": "http://arxiv.org/abs/1810.10933v1"
  },
  {
    "title": "Adversarial Examples Versus Cloud-based Detectors: A Black-box Empirical Study",
    "author": [
      "Xurong Li",
      "Shouling Ji",
      "Meng Han",
      "Juntao Ji",
      "Zhenyu Ren",
      "Yushan Liu",
      "Chunming Wu"
    ],
    "abstract": "Deep learning has been broadly leveraged by major cloud providers, such as Google, AWS and Baidu, to offer various computer vision related services including image classification, object identification, illegal image detection, etc. While recent works extensively demonstrated that deep learning classification models are vulnerable to adversarial examples, cloud-based image detection models, which are more complicated than classifiers, may also have similar security concern but not get enough attention yet. In this paper, we mainly focus on the security issues of real-world cloud-based image detectors. Specifically, (1) based on effective semantic segmentation, we propose four attacks to generate semantics-aware adversarial examples via only interacting with black-box APIs; and (2) we make the first attempt to conduct an extensive empirical study of black-box attacks against real-world cloud-based image detectors. Through the comprehensive evaluations on five major cloud platforms: AWS, Azure, Google Cloud, Baidu Cloud, and Alibaba Cloud, we demonstrate that our image processing based attacks can reach a success rate of approximately 100%, and the semantic segmentation based attacks have a success rate over 90% among different detection services, such as violence, politician, and pornography detection. We also proposed several possible defense strategies for these security challenges in the real-life situation.",
    "lastUpdated": "2019-09-14T14:30:25Z",
    "category": [
      "cs.CV",
      "cs.CR",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1901.01223v4"
  },
  {
    "title": "Towards Collaborative Intelligence Friendly Architectures for Deep Learning",
    "author": [
      "Amir Erfan Eshratifar",
      "Amirhossein Esmaili",
      "Massoud Pedram"
    ],
    "abstract": "Modern mobile devices are equipped with high-performance hardware resources such as graphics processing units (GPUs), making the end-side intelligent services more feasible. Even recently, specialized silicons as neural engines are being used for mobile devices. However, most mobile devices are still not capable of performing real-time inference using very deep models. Computations associated with deep models for today's intelligent applications are typically performed solely on the cloud. This cloud-only approach requires significant amounts of raw data to be uploaded to the cloud over the mobile wireless network and imposes considerable computational and communication load on the cloud server. Recent studies have shown that the latency and energy consumption of deep neural networks in mobile applications can be notably reduced by splitting the workload between the mobile device and the cloud. In this approach, referred to as collaborative intelligence, intermediate features computed on the mobile device are offloaded to the cloud instead of the raw input data of the network, reducing the size of the data needed to be sent to the cloud. In this paper, we design a new collaborative intelligence friendly architecture by introducing a unit responsible for reducing the size of the feature data needed to be offloaded to the cloud to a greater extent, where this unit is placed after a selected layer of a deep model. Our proposed method, across different wireless networks, achieves on average 53x improvements for end-to-end latency and 68x improvements for mobile energy consumption compared to the status quo cloud-only approach for ResNet-50, while the accuracy loss is less than 2%.",
    "lastUpdated": "2019-02-01T01:37:57Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1902.00147v1"
  },
  {
    "title": "Adversarial Attack and Defense on Point Sets",
    "author": [
      "Qiang Zhang",
      "Jiancheng Yang",
      "Rongyao Fang",
      "Bingbing Ni",
      "Jinxian Liu",
      "Qi Tian"
    ],
    "abstract": "Emergence of the utility of 3D point cloud data in safety-critical vision tasks (e.g., ADAS) urges researchers to pay more attention to the robustness of 3D representations and deep networks. To this end, we develop an attack and defense scheme, dedicated to 3D point cloud data, for preventing 3D point clouds from manipulated as well as pursuing noise-tolerable 3D representation. A set of novel 3D point cloud attack operations are proposed via pointwise gradient perturbation and adversarial point attachment / detachment. We then develop a flexible perturbation-measurement scheme for 3D point cloud data to detect potential attack data or noisy sensing data. Notably, the proposed defense methods are even effective to detect the adversarial point clouds generated by a proof-of-concept attack directly targeting the defense. Transferability of adversarial attacks between several point cloud networks is addressed, and we propose an momentum-enhanced pointwise gradient to improve the attack transferability. We further analyze the transferability from adversarial point clouds to grid CNNs and the inverse. Extensive experimental results on common point cloud benchmarks demonstrate the validity of the proposed 3D attack and defense framework.",
    "lastUpdated": "2020-10-08T16:13:03Z",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1902.10899v3"
  },
  {
    "title": "3D Dynamic Point Cloud Denoising via Spatial-Temporal Graph Learning",
    "author": [
      "Wei Hu",
      "Qianjiang Hu",
      "Zehua Wang",
      "Xiang Gao"
    ],
    "abstract": "The prevalence of accessible depth sensing and 3D laser scanning techniques has enabled the convenient acquisition of 3D dynamic point clouds, which provide efficient representation of arbitrarily-shaped objects in motion. Nevertheless, dynamic point clouds are often perturbed by noise due to hardware, software or other causes. While a plethora of methods have been proposed for static point cloud denoising, few efforts are made for the denoising of dynamic point clouds with varying number of irregularly-sampled points in each frame. In this paper, we represent dynamic point clouds naturally on graphs and address the denoising problem by inferring the underlying graph via spatio-temporal graph learning, exploiting both the intra-frame similarity and inter-frame consistency. Firstly, assuming the availability of a relevant feature vector per node, we pose spatial-temporal graph learning as optimizing a Mahalanobis distance metric $\\mathbf{M}$, which is formulated as the minimization of graph Laplacian regularizer. Secondly, to ease the optimization of the symmetric and positive definite metric matrix $\\mathbf{M}$, we decompose it into $\\mathbf{M}=\\mathbf{R}^{\\top}\\mathbf{R}$ and solve $\\mathbf{R}$ instead via proximal gradient. Finally, based on the spatial-temporal graph learning, we formulate dynamic point cloud denoising as the joint optimization of the desired point cloud and underlying spatio-temporal graph, which leverages both intra-frame affinities and inter-frame consistency and is solved via alternating minimization. Experimental results show that the proposed method significantly outperforms independent denoising of each frame from state-of-the-art static point cloud denoising approaches.",
    "lastUpdated": "2020-04-08T04:06:17Z",
    "category": [
      "cs.CV",
      "cs.MM"
    ],
    "url": "http://arxiv.org/abs/1904.12284v2"
  },
  {
    "title": "SAASQUAL: A Quality Model For Evaluating SaaS on The Cloud Computing Environment",
    "author": [
      "Dhanamma Jagli",
      "Seema Purohit",
      "N. Subhash Chandra"
    ],
    "abstract": "Cloud computing is a Technology that has come out in the last decade and that is transforming the IT industry in huge. The Cloud computing is playing a vital role as a backbone component of the Internet of Things (IoT). In a Cloud Computing scenario, cloud services are accessible via Internet. Cloud computing is providing ondemand resources like Infrastructure, platform, and software as it is do not pay to possess the software itself but rather to use it. Pay for use concept is very attractive, hence many organizations are adopting the SaaS model drastically. Even though, each customer is unique and leads to unique variation in the requirements of the software. the SaaS is generally press into service and it yields advantages to service providers and service customers. More and more SaaS services are emerging, how to select qualified service is key problem for customers. Present quality models are not sufficient to evaluate SaaS selection on the cloud due to its tremendous increasing in the use. A quality model can be used to represent, evaluate, and differentiate the quality of the SaaS providers. In this paper, a new quality model proposed and named SAASQUAL for cloud software services.This model is based on different attributes of quality software, quality service and metrics that measure software quality and service quality in order to evaluate potential software as a service on the cloud.",
    "lastUpdated": "2019-05-25T06:11:21Z",
    "category": [
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/1905.10531v1"
  },
  {
    "title": "NPTC-net: Narrow-Band Parallel Transport Convolutional Neural Network on Point Clouds",
    "author": [
      "Pengfei Jin",
      "Tianhao Lai",
      "Rongjie Lai",
      "Bin Dong"
    ],
    "abstract": "Convolution plays a crucial role in various applications in signal and image processing, analysis and recognition. It is also the main building block of convolution neural networks (CNNs). Designing appropriate convolution neural networks on manifold-structured point clouds can inherit and empower recent advances of CNNs to analyzing and processing point cloud data. However, one of the major challenges is to define a proper way to \"sweep\" filters through the point cloud as a natural generalization of the planar convolution and to reflect the point cloud's geometry at the same time. In this paper, we consider generalizing convolution by adapting parallel transport on the point cloud. Inspired by a triangulated surface based method [Stefan C. Schonsheck, Bin Dong, and Rongjie Lai, arXiv:1805.07857.], we propose the Narrow-Band Parallel Transport Convolution (NPTC) using a specifically defined connection on a voxelized narrow-band approximation of point cloud data. With that, we further propose a deep convolutional neural network based on NPTC (called NPTC-net) for point cloud classification and segmentation. Comprehensive experiments show that the proposed NPTC-net achieves similar or better results than current state-of-the-art methods on point clouds classification and segmentation.",
    "lastUpdated": "2019-09-25T14:30:41Z",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1905.12218v2"
  },
  {
    "title": "Video-based compression for plenoptic point clouds",
    "author": [
      "Li Li",
      "Zhu Li",
      "Shan Liu",
      "Houqiang Li"
    ],
    "abstract": "The plenoptic point cloud that has multiple colors from various directions, is a more complete representation than the general point cloud that usually has only one color. It is more realistic but also brings a larger volume of data that needs to be compressed efficiently. The state-of-the-art method to compress the plenoptic point cloud is an extension of the region-based adaptive hierarchical transform (RAHT). As far as we can see, in addition to RAHT, the video-based point cloud compression (V-PCC) is also an efficient point cloud compression method. However, to the best of our knowledge, no works have used a video-based solution to compress the plenoptic point cloud yet. In this paper, we first extend the V-PCC to support the plenoptic point cloud compression by generating multiple attribute videos. Then based on the observation that these videos from multiple views have very high correlations, we propose encoding them using multiview high efficiency video coding. We further propose a block-based padding method that unifies the unoccupied attribute pixels from different views to reduce their bit cost. The proposed algorithms are implemented in the V-PCC reference software. The experimental results show that the proposed algorithms can bring significant bitrate savings compared with the state-of-the-art method for plenoptic point cloud compression.",
    "lastUpdated": "2019-11-04T17:36:30Z",
    "category": [
      "eess.IV",
      "cs.MM"
    ],
    "url": "http://arxiv.org/abs/1911.01355v1"
  },
  {
    "title": "Folding-based compression of point cloud attributes",
    "author": [
      "Maurice Quach",
      "Giuseppe Valenzise",
      "Frederic Dufaux"
    ],
    "abstract": "Existing techniques to compress point cloud attributes leverage either geometric or video-based compression tools. We explore a radically different approach inspired by recent advances in point cloud representation learning. Point clouds can be interpreted as 2D manifolds in 3D space. Specifically, we fold a 2D grid onto a point cloud and we map attributes from the point cloud onto the folded 2D grid using a novel optimized mapping method. This mapping results in an image, which opens a way to apply existing image processing techniques on point cloud attributes. However, as this mapping process is lossy in nature, we propose several strategies to refine it so that attributes can be mapped to the 2D grid with minimal distortion. Moreover, this approach can be flexibly applied to point cloud patches in order to better adapt to local geometric complexity. In this work, we consider point cloud attribute compression; thus, we compress this image with a conventional 2D image codec. Our preliminary results show that the proposed folding-based coding scheme can already reach performance similar to the latest MPEG Geometry-based PCC (G-PCC) codec.",
    "lastUpdated": "2020-06-22T07:17:57Z",
    "category": [
      "eess.IV",
      "cs.CV",
      "cs.GR",
      "cs.LG",
      "eess.SP",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2002.04439v3"
  },
  {
    "title": "Dynamic Point Cloud Denoising via Manifold-to-Manifold Distance",
    "author": [
      "Wei Hu",
      "Qianjiang Hu",
      "Zehua Wang",
      "Xiang Gao"
    ],
    "abstract": "3D dynamic point clouds provide a natural discrete representation of real-world objects or scenes in motion, with a wide range of applications in immersive telepresence, autonomous driving, surveillance, \\etc. Nevertheless, dynamic point clouds are often perturbed by noise due to hardware, software or other causes. While a plethora of methods have been proposed for static point cloud denoising, few efforts are made for the denoising of dynamic point clouds, which is quite challenging due to the irregular sampling patterns both spatially and temporally. In this paper, we represent dynamic point clouds naturally on spatial-temporal graphs, and exploit the temporal consistency with respect to the underlying surface (manifold). In particular, we define a manifold-to-manifold distance and its discrete counterpart on graphs to measure the variation-based intrinsic distance between surface patches in the temporal domain, provided that graph operators are discrete counterparts of functionals on Riemannian manifolds. Then, we construct the spatial-temporal graph connectivity between corresponding surface patches based on the temporal distance and between points in adjacent patches in the spatial domain. Leveraging the initial graph representation, we formulate dynamic point cloud denoising as the joint optimization of the desired point cloud and underlying graph representation, regularized by both spatial smoothness and temporal consistency. We reformulate the optimization and present an efficient algorithm. Experimental results show that the proposed method significantly outperforms independent denoising of each frame from state-of-the-art static point cloud denoising approaches, on both Gaussian noise and simulated LiDAR noise.",
    "lastUpdated": "2020-10-28T12:53:04Z",
    "category": [
      "eess.IV",
      "cs.CV",
      "cs.LG",
      "cs.MM"
    ],
    "url": "http://arxiv.org/abs/2003.08355v3"
  },
  {
    "title": "On Coordination of Smart Grid and Cooperative Cloud Providers",
    "author": [
      "Monireh Mohebbi Moghaddam",
      "Mohammad Hossein Manshaei",
      "Mehdi Naderi Soorki",
      "Walid Saad",
      "Maziar Goudarzi",
      "Dusit Niyato"
    ],
    "abstract": "Cooperative cloud providers in the form of cloud federations can potentially reduce their energy costs by exploiting electricity price fluctuations across different locations. In this environment, on the one hand, the electricity price has a significant influence on the federations formed, and, thus, on the profit earned by the cloud providers, and on the other hand, the cloud cooperation has an inevitable impact on the performance of the smart grid. In this regard, the interaction between independent cloud providers and the smart grid is modeled as a two-stage Stackelberg game interleaved with a coalitional game in this paper. In this game, in the first stage the smart grid, as a leader chooses a proper electricity pricing mechanism to maximize its own profit. In the second stage, cloud providers cooperatively manage their workload to minimize their electricity costs. Given the dynamic of cloud providers in the federation formation process, an optimization model based on a constrained Markov decision process (CMDP) has been used by the smart grid to achieve the optimal policy. Numerical results show that the proposed solution yields around 28% and 29% profit improvement on average for the smart grid, and the cloud providers, respectively, compared to the noncooperative scheme",
    "lastUpdated": "2020-03-30T17:56:33Z",
    "category": [
      "cs.NI",
      "cs.GT"
    ],
    "url": "http://arxiv.org/abs/2003.13675v1"
  },
  {
    "title": "SK-Net: Deep Learning on Point Cloud via End-to-end Discovery of Spatial Keypoints",
    "author": [
      "Weikun Wu",
      "Yan Zhang",
      "David Wang",
      "Yunqi Lei"
    ],
    "abstract": "Since the PointNet was proposed, deep learning on point cloud has been the concentration of intense 3D research. However, existing point-based methods usually are not adequate to extract the local features and the spatial pattern of a point cloud for further shape understanding. This paper presents an end-to-end framework, SK-Net, to jointly optimize the inference of spatial keypoint with the learning of feature representation of a point cloud for a specific point cloud task. One key process of SK-Net is the generation of spatial keypoints (Skeypoints). It is jointly conducted by two proposed regulating losses and a task objective function without knowledge of Skeypoint location annotations and proposals. Specifically, our Skeypoints are not sensitive to the location consistency but are acutely aware of shape. Another key process of SK-Net is the extraction of the local structure of Skeypoints (detail feature) and the local spatial pattern of normalized Skeypoints (pattern feature). This process generates a comprehensive representation, pattern-detail (PD) feature, which comprises the local detail information of a point cloud and reveals its spatial pattern through the part district reconstruction on normalized Skeypoints. Consequently, our network is prompted to effectively understand the correlation between different regions of a point cloud and integrate contextual information of the point cloud. In point cloud tasks, such as classification and segmentation, our proposed method performs better than or comparable with the state-of-the-art approaches. We also present an ablation study to demonstrate the advantages of SK-Net.",
    "lastUpdated": "2020-03-31T08:15:40Z",
    "category": [
      "cs.CV",
      "cs.LG",
      "eess.IV"
    ],
    "url": "http://arxiv.org/abs/2003.14014v1"
  },
  {
    "title": "Generative PointNet: Energy-Based Learning on Unordered Point Sets for 3D Generation, Reconstruction and Classification",
    "author": [
      "Jianwen Xie",
      "Yifei Xu",
      "Zilong Zheng",
      "Song-Chun Zhu",
      "Ying Nian Wu"
    ],
    "abstract": "We propose a generative model of unordered point sets, such as point clouds, in the forms of an energy-based model, where the energy function is parameterized by an input-permutation-invariant bottom-up neural network. The energy function learns a coordinate encoding of each point and then aggregates all individual point features into energy for the whole point cloud. We show that our model can be derived from the discriminative PointNet. The model can be trained by MCMC-based maximum likelihood learning (as well as its variants), without the help of any assisting networks like those in GANs and VAEs. Unlike most point cloud generator that relys on hand-crafting distance metrics, our model does not rely on hand-crafting distance metric for point cloud generation, because it synthesizes point clouds by matching observed examples in terms of statistical property defined by the energy function. Furthermore, we can learn a short-run MCMC toward the energy-based model as a flow-like generator for point cloud reconstruction and interpretation. The learned point cloud representation can be also useful for point cloud classification. Experiments demonstrate the advantages of the proposed generative model of point clouds.",
    "lastUpdated": "2020-04-02T23:08:10Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2004.01301v1"
  },
  {
    "title": "Point Cloud Completion by Skip-attention Network with Hierarchical Folding",
    "author": [
      "Xin Wen",
      "Tianyang Li",
      "Zhizhong Han",
      "Yu-Shen Liu"
    ],
    "abstract": "Point cloud completion aims to infer the complete geometries for missing regions of 3D objects from incomplete ones. Previous methods usually predict the complete point cloud based on the global shape representation extracted from the incomplete input. However, the global representation often suffers from the information loss of structure details on local regions of incomplete point cloud. To address this problem, we propose Skip-Attention Network (SA-Net) for 3D point cloud completion. Our main contributions lie in the following two-folds. First, we propose a skip-attention mechanism to effectively exploit the local structure details of incomplete point clouds during the inference of missing parts. The skip-attention mechanism selectively conveys geometric information from the local regions of incomplete point clouds for the generation of complete ones at different resolutions, where the skip-attention reveals the completion process in an interpretable way. Second, in order to fully utilize the selected geometric information encoded by skip-attention mechanism at different resolutions, we propose a novel structure-preserving decoder with hierarchical folding for complete shape generation. The hierarchical folding preserves the structure of complete point cloud generated in upper layer by progressively detailing the local regions, using the skip-attentioned geometry at the same resolution. We conduct comprehensive experiments on ShapeNet and KITTI datasets, which demonstrate that the proposed SA-Net outperforms the state-of-the-art point cloud completion methods.",
    "lastUpdated": "2020-05-18T14:10:05Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2005.03871v2"
  },
  {
    "title": "Performance Evaluation of Fuzzy Integrated Firewall Model for Hybrid Cloud based on Packet Utilization",
    "author": [
      "Ziaur Rahman",
      "Asma Islam Swapna",
      "Habibur Rahman Habib",
      "Akramuzzaman Shaoun"
    ],
    "abstract": "Cloud computing is one of the highly flexible, confidential and easily accessible medium of platforms and provides powerful service for sharing information over the Internet. Cloud security has become an emerging issue as network manager eventually encounter its data protection, vulnerability during information exchange on the cloud system. We can protect our data from unwanted access on a hybrid cloud through controlling the respective firewall of the network. But, the firewall has already proved its weakness as it is unable to ensure multi-layered, secured accessibility of the cloud network. Efficient packet utilization sometimes causes high response time in accessing hybrid cloud. In this paper, a Cloud Model with Hybrid functionality and a secure Fuzzy Integrated Firewall for that Hybrid Cloud is proposed and thereby evaluated for the performance in traffic response. Experimental result illustrated that having a fuzzified firewall gives high point-to-point packet utilization decreasing the response time than a conventional firewall. Results from this research work will highly be implemented in transplanting artificial intelligence in future Internet of Things (IoT).",
    "lastUpdated": "2020-06-21T05:12:52Z",
    "category": [
      "cs.NI",
      "C.2.1"
    ],
    "url": "http://arxiv.org/abs/2006.12736v1"
  },
  {
    "title": "A Benchmarking Framework for Interactive 3D Applications in the Cloud",
    "author": [
      "Tianyi Liu",
      "Sen He",
      "Sunzhou Huang",
      "Danny Tsang",
      "Lingjia Tang",
      "Jason Mars",
      "Wei Wang"
    ],
    "abstract": "With the growing popularity of cloud gaming and cloud virtual reality (VR), interactive 3D applications have become a major type of workloads for the cloud. However, despite their growing importance, there is limited public research on how to design cloud systems to efficiently support these applications, due to the lack of an open and reliable research infrastructure, including benchmarks and performance analysis tools. The challenges of generating human-like inputs under various system/application randomness and dissecting the performance of complex graphics systems make it very difficult to design such an infrastructure. In this paper, we present the design of a novel cloud graphics rendering research infrastructure, Pictor. Pictor employs AI to mimic human interactions with complex 3D applications. It can also provide in-depth performance measurements for the complex software and hardware stack used for cloud 3D graphics rendering. With Pictor, we designed a benchmark suite with six interactive 3D applications. Performance analyses were conducted with these benchmarks to characterize 3D applications in the cloud and reveal new performance bottlenecks. To demonstrate the effectiveness of Pictor, we also implemented two optimizations to address two performance bottlenecks discovered in a state-of-the-art cloud 3D-graphics rendering system, which improved the frame rate by 57.7% on average.",
    "lastUpdated": "2020-08-02T16:06:12Z",
    "category": [
      "cs.DC",
      "cs.GR"
    ],
    "url": "http://arxiv.org/abs/2006.13378v2"
  },
  {
    "title": "Point Set Voting for Partial Point Cloud Analysis",
    "author": [
      "Junming Zhang",
      "Weijia Chen",
      "Yuping Wang",
      "Ram Vasudevan",
      "Matthew Johnson-Roberson"
    ],
    "abstract": "The continual improvement of 3D sensors has driven the development of algorithms to perform point cloud analysis. In fact, techniques for point cloud classification and segmentation have in recent years achieved incredible performance driven in part by leveraging large synthetic datasets. Unfortunately these same state-of-the-art approaches perform poorly when applied to incomplete point clouds. This limitation of existing algorithms is particularly concerning since point clouds generated by 3D sensors in the real world are usually incomplete due to perspective view or occlusion by other objects. This paper proposes a general model for partial point clouds analysis wherein the latent feature encoding a complete point clouds is inferred by applying a local point set voting strategy. In particular, each local point set constructs a vote that corresponds to a distribution in the latent space, and the optimal latent feature is the one with the highest probability. This approach ensures that any subsequent point cloud analysis is robust to partial observation while simultaneously guaranteeing that the proposed model is able to output multiple possible results. This paper illustrates that this proposed method achieves state-of-the-art performance on shape classification, part segmentation and point cloud completion.",
    "lastUpdated": "2021-01-02T17:37:19Z",
    "category": [
      "cs.CV",
      "cs.RO"
    ],
    "url": "http://arxiv.org/abs/2007.04537v2"
  },
  {
    "title": "Mesorasi: Architecture Support for Point Cloud Analytics via Delayed-Aggregation",
    "author": [
      "Yu Feng",
      "Boyuan Tian",
      "Tiancheng Xu",
      "Paul Whatmough",
      "Yuhao Zhu"
    ],
    "abstract": "Point cloud analytics is poised to become a key workload on battery-powered embedded and mobile platforms in a wide range of emerging application domains, such as autonomous driving, robotics, and augmented reality, where efficiency is paramount. This paper proposes Mesorasi, an algorithm-architecture co-designed system that simultaneously improves the performance and energy efficiency of point cloud analytics while retaining its accuracy. Our extensive characterizations of state-of-the-art point cloud algorithms show that, while structurally reminiscent of convolutional neural networks (CNNs), point cloud algorithms exhibit inherent compute and memory inefficiencies due to the unique characteristics of point cloud data. We propose delayed-aggregation, a new algorithmic primitive for building efficient point cloud algorithms. Delayed-aggregation hides the performance bottlenecks and reduces the compute and memory redundancies by exploiting the approximately distributive property of key operations in point cloud algorithms. Delayed-aggregation let point cloud algorithms achieve 1.6x speedup and 51.1% energy reduction on a mobile GPU while retaining the accuracy (-0.9% loss to 1.2% gains). To maximize the algorithmic benefits, we propose minor extensions to contemporary CNN accelerators, which can be integrated into a mobile Systems-on-a-Chip (SoC) without modifying other SoC components. With additional hardware support, Mesorasi achieves up to 3.6x speedup.",
    "lastUpdated": "2020-08-16T18:11:19Z",
    "category": [
      "cs.CV",
      "cs.AR"
    ],
    "url": "http://arxiv.org/abs/2008.06967v1"
  },
  {
    "title": "Machine Learning Algorithms for Active Monitoring of High Performance Computing as a Service (HPCaaS) Cloud Environments",
    "author": [
      "Gianluca Longoni",
      "Ryan LaMothe",
      "Jeremy Teuton",
      "Mark Greaves",
      "Nicole Nichols",
      "William Smith"
    ],
    "abstract": "Cloud computing provides ubiquitous and on-demand access to vast reconfigurable resources that can meet any computational need. Many service models are available, but the Infrastructure as a Service (IaaS) model is particularly suited to operate as a high performance computing (HPC) platform, by networking large numbers of cloud computing nodes. We used the Pacific Northwest National Laboratory (PNNL) cloud computing environment to perform our experiments. A number of cloud computing providers such as Amazon Web Services, Microsoft Azure, or IBM Cloud, offer flexible and scalable computing resources. This paper explores the viability identifying types of engineering applications running on a cloud infrastructure configured as an HPC platform using privacy preserving features as input to statistical models. The engineering applications considered in this work include MCNP6, a radiation transport code developed by Los Alamos National Laboratory, OpenFOAM, an open source computational fluid dynamics code, and CADO-NFS, a numerical implementation of the general number field sieve algorithm used for prime number factorization. Our experiments use the OpenStack cloud management tool to create a cloud HPC environment and the privacy preserving Ceilometer billing meters as classification features to demonstrate identification of these applications.",
    "lastUpdated": "2020-09-26T01:29:19Z",
    "category": [
      "cs.DC",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2009.12498v1"
  },
  {
    "title": "3D Object Classification on Partial Point Clouds: A Practical Perspective",
    "author": [
      "Zelin Xu",
      "Ke Chen",
      "Tong Zhang",
      "C. L. Philip Chen",
      "Kui Jia"
    ],
    "abstract": "A point cloud is a popular shape representation adopted in 3D object classification, which covers the whole surface of an object and is usually well aligned. However, such an assumption can be invalid in practice, as point clouds collected in real-world scenarios are typically scanned from visible object parts observed under arbitrary SO(3) viewpoint, which are thus incomplete due to self and inter-object occlusion. In light of this, this paper introduces a practical setting to classify partial point clouds of object instances under any poses. Compared to the classification of complete object point clouds, such a problem is made more challenging in view of geometric similarities of local shape across object classes and intra-class dissimilarities of geometries restricted by their observation view. We consider that specifying the location of partial point clouds on their object surface is essential to alleviate suffering from the aforementioned challenges, which can be solved via an auxiliary task of 6D object pose estimation. To this end, a novel algorithm in an alignment-classification manner is proposed in this paper, which consists of an alignment module predicting object pose for the rigid transformation of visible point clouds to their canonical pose and a typical point classifier such as PointNet++ and DGCNN. Experiment results on the popular ModelNet40 and ScanNet datasets, which are adapted to a single-view partial setting, demonstrate the proposed method can outperform three alternative schemes extended from representative point cloud classifiers for complete point clouds.",
    "lastUpdated": "2020-12-23T02:59:10Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2012.10042v2"
  },
  {
    "title": "PhoenixCloud: Provisioning Resources for Heterogeneous Workloads in Cloud Computing",
    "author": [
      "Jianfeng Zhan",
      "Lei Wang",
      "Weisong Shi",
      "Shimin Gong",
      "Xiutao Zang"
    ],
    "abstract": "As more and more service providers choose Cloud platforms, which is provided by third party resource providers, resource providers needs to provision resources for heterogeneous workloads in different Cloud scenarios. Taking into account the dramatic differences of heterogeneous workloads, can we coordinately provision resources for heterogeneous workloads in Cloud computing? In this paper we focus on this important issue, which is investigated by few previous work. Our contributions are threefold: (1) we respectively propose a coordinated resource provisioning solution for heterogeneous workloads in two typical Cloud scenarios: first, a large organization operates a private Cloud for two heterogeneous workloads; second, a large organization or two service providers running heterogeneous workloads revert to a public Cloud; (2) we build an agile system PhoenixCloud that enables a resource provider to create coordinated runtime environments on demand for heterogeneous workloads when they are consolidated on a Cloud site; and (3) A comprehensive evaluation has been performed in experiments. For two typical heterogeneous workload traces: parallel batch jobs and Web services, our experiments show that: a) in a private Cloud scenario, when the throughput is almost same like that of a dedicated cluster system, our solution decreases the configuration size of a cluster by about 40%; b) in a public Cloud scenario, our solution decreases not only the total resource consumption, but also the peak resource consumption maximally to 31% with respect to that of EC2 +RightScale solution.",
    "lastUpdated": "2010-07-20T23:58:31Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1006.1401v2"
  },
  {
    "title": "A Declarative Recommender System for Cloud Infrastructure Services Selection",
    "author": [
      "Miranda Zhang",
      "Rajiv Ranjan",
      "Surya Nepal",
      "Michael Menzel",
      "Armin Haller"
    ],
    "abstract": "The cloud infrastructure services landscape advances steadily leaving users in the agony of choice...",
    "lastUpdated": "2012-11-29T09:54:30Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1210.2047v2"
  },
  {
    "title": "Virtual Laboratories in Cloud Infrastructure of Educational Institutions",
    "author": [
      "Evgeniy Pluzhnik",
      "Evgeny Nikulchev"
    ],
    "abstract": "Modern educational institutions widely used virtual laboratories and cloud technologies. In practice must deal with security, processing speed and other tasks. The paper describes the experience of the construction of an experimental stand cloud computing and network management. Models and control principles set forth herein.",
    "lastUpdated": "2014-09-14T17:53:49Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1409.4082v1"
  },
  {
    "title": "Cloud for Gaming",
    "author": [
      "Gabriele D'Angelo",
      "Stefano Ferretti",
      "Moreno Marzolla"
    ],
    "abstract": "Cloud for Gaming refers to the use of cloud computing technologies to build large-scale gaming infrastructures, with the goal of improving scalability and responsiveness, improve the user's experience and enable new business models.",
    "lastUpdated": "2016-05-17T13:23:08Z",
    "category": [
      "cs.DC",
      "cs.MM",
      "C.2.4; I.6.8"
    ],
    "url": "http://arxiv.org/abs/1505.02435v2"
  },
  {
    "title": "Emerging Cloud Computing Security Threats",
    "author": [
      "Kamal Ahmat"
    ],
    "abstract": "Cloud computing is one of the latest emerging innovations of the modern internet and technological landscape. With everyone from the White house to major online technological leaders like Amazon and Google using or offering cloud computing services it is truly presents itself as an exciting and innovative method to store and use data on the internet.",
    "lastUpdated": "2015-12-05T20:55:58Z",
    "category": [
      "cs.OH"
    ],
    "url": "http://arxiv.org/abs/1512.01701v1"
  },
  {
    "title": "An Approach for Design Parameter Optimization of the Triangle Cloud Control System",
    "author": [
      "UnSun Pak",
      "YongNam Sin",
      "GyongIl Ryang"
    ],
    "abstract": "In this paper, we have proposed the optimization approach of design parameter of generalized cloud control system by hybrid chaos optimization approach. The approach determined the off-line parameters of the cloud control system by the chaos approach and on-line by gradient approach.",
    "lastUpdated": "2015-12-16T04:41:17Z",
    "category": [
      "cs.SY"
    ],
    "url": "http://arxiv.org/abs/1512.05047v1"
  },
  {
    "title": "Development of System Architecture for E-Government Cloud Platforms",
    "author": [
      "M. Aubakirov",
      "E. Nikulchev"
    ],
    "abstract": "Requirements and criteria for selection of cloud platform and platform visualization are stated by which optimal cloud products will be chosen for the Republic of Kazakhstan e-Government considering quality-price ratio, and also the framework of information and communication architecture will be introduced.",
    "lastUpdated": "2016-03-21T20:06:37Z",
    "category": [
      "cs.CY",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1603.08297v1"
  },
  {
    "title": "A Consumer-Centric Market for Database Computation in the Cloud",
    "author": [
      "Yue Wang",
      "Alexandra Meliou",
      "Gerome Miklau"
    ],
    "abstract": "The availability of public computing resources in the cloud has revolutionized data analysis, but requesting cloud resources often involves complex decisions for consumers. Under the current pricing mechanisms, cloud service providers offer several service options and charge consumers based on the resources they use. Before they can decide which cloud resources to request, consumers have to estimate the completion time and cost of their computational tasks for different service options and possibly for different service providers. This estimation is challenging even for expert cloud users. We propose a new market-based framework for pricing computational tasks in the cloud. Our framework introduces an agent between consumers and cloud providers. The agent takes data and computational tasks from users, estimates time and cost for evaluating the tasks, and returns to consumers contracts that specify the price and completion time. Our framework can be applied directly to existing cloud markets without altering the way cloud providers offer and price services. In addition, it simplifies cloud use for consumers by allowing them to compare contracts, rather than choose resources directly. We present design, analytical, and algorithmic contributions focusing on pricing computation contracts, analyzing their properties, and optimizing them in complex workflows. We conduct an experimental evaluation of our market framework over a real-world cloud service and demonstrate empirically that our market ensures three key properties: competitiveness, fairness, and resilience. Finally, we present a fine-grained pricing mechanism for complex workflows and show that it can increase agent profits by more than an order of magnitude in some cases.",
    "lastUpdated": "2017-06-16T20:40:04Z",
    "category": [
      "cs.DB",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1609.02104v6"
  },
  {
    "title": "cSELENE: Privacy Preserving Query Retrieval System on Heterogeneous Cloud Data",
    "author": [
      "Diyah Puspitaningrum"
    ],
    "abstract": "While working in collaborative team elsewhere sometimes the federated (huge) data are from heterogeneous cloud vendors. It is not only about the data privacy concern but also about how can those federated data can be querying from cloud directly in fast and securely way. Previous solution offered hybrid cloud between public and trusted private cloud. Another previous solution used encryption on MapReduce framework. But the challenge is we are working on heterogeneous clouds. In this paper, we present a novel technique for querying with privacy concern. Since we take execution time into account, our basic idea is to use the data mining model by partitioning the federated databases in order to reduce the search and query time. By using model of the database it means we use only the summary or the very characteristic patterns of the database. Modeling is the Preserving Privacy Stage I, since by modeling the data is being symbolized. We implement encryption on the database as preserving privacy Stage II. Our system, called \"cSELENE\" (stands for \"cloud SELENE\"), is designed to handle federated data on heterogeneous clouds: AWS, Microsoft Azure, and Google Cloud Platform with MapReduce technique. In this paper we discuss preserving-privacy system and threat model, the format of federated data, the parallel programming (GPU programming and shared/memory systems), the parallel and secure algorithm for data mining model in distributed cloud, the cloud infrastructure/architecture, and the UIX design of the cSELENE system. Other issues such as incremental method and the secure design of cloud architecture system (Virtual Machines across platform design) are still open to discuss. Our experiments should demonstrate the validity and practicality of the proposed high performance computing scheme.",
    "lastUpdated": "2018-05-02T07:29:34Z",
    "category": [
      "cs.DB",
      "cs.IR",
      "68P20 Information storage and retrieval",
      "H.3.3"
    ],
    "url": "http://arxiv.org/abs/1805.01275v1"
  },
  {
    "title": "Does The Cloud Need Stabilizing?",
    "author": [
      "Murat Demirbas",
      "Aleksey Charapko",
      "Ailidani Ailijiang"
    ],
    "abstract": "The last decade has witnessed rapid proliferation of cloud computing. While even the smallest distributed programs (with 3-5 actions) produce many unanticipated error cases due to concurrency involved, it seems short of a miracle these web-services are able to operate at those vast scales. In this paper, we explore the factors that contribute most to the high-availability of cloud computing services and examine where self-stabilization could fit in that picture.",
    "lastUpdated": "2018-06-08T15:09:21Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1806.03210v1"
  },
  {
    "title": "Information Retrieval in the Cloud",
    "author": [
      "Jochen L. Leidner"
    ],
    "abstract": "There has been a recent trend to migrate IT infrastructure into the cloud. In this paper, we discuss the impact of this trend on searching for textual and other data, i.e. the distributed indexing and retrieval of information, from an organizational context. Keywords: information retrieval (IR); federated search; cloud search.",
    "lastUpdated": "2018-07-01T02:36:24Z",
    "category": [
      "cs.IR",
      "cs.CY",
      "H.3.0; C.2.4"
    ],
    "url": "http://arxiv.org/abs/1807.00257v1"
  },
  {
    "title": "Linux-Tomcat Application Performance on Amazon AWS",
    "author": [
      "Neil J. Gunther",
      "Mohit Chawla"
    ],
    "abstract": "The need for Linux system administrators to do performance management has returned with a vengeance. Why? The cloud. Resource consumption in the cloud is all about pay-as-you-go. This article shows you how performance models can find the most cost-effective deployment of an application on Amazon's cloud.",
    "lastUpdated": "2018-11-29T17:41:05Z",
    "category": [
      "cs.PF",
      "cs.DC",
      "B.8.2; C.4; C.2.4; C.5.5; D.4.8"
    ],
    "url": "http://arxiv.org/abs/1811.12341v1"
  },
  {
    "title": "Big Data in Cloud Computing Review and Opportunities",
    "author": [
      "Manoj Muniswamaiah",
      "Tilak Agerwala",
      "Charles Tappert"
    ],
    "abstract": "Big Data is used in decision making process to gain useful insights hidden in the data for business and engineering. At the same time it presents challenges in processing, cloud computing has helped in advancement of big data by providing computational, networking and storage capacity. This paper presents the review, opportunities and challenges of transforming big data using cloud computing resources.",
    "lastUpdated": "2019-12-17T17:23:36Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1912.10821v1"
  },
  {
    "title": "An IoT Platform-as-a-service for NFV Based -- Hybrid Cloud / Fog Systems",
    "author": [
      "Carla Mouradian",
      "Fereshteh Ebrahimnezhad",
      "Yassine Jebbar",
      "Jasmeen Kaur Ahluwalia",
      "Seyedeh Negar Afrasiabi",
      "Roch H. Glitho",
      "Ashok Moghe"
    ],
    "abstract": "Cloud computing, despite its inherent advantages (e.g., resource efficiency) still faces several challenges. the wide are network used to connect the cloud to end-users could cause high latency, which may not be tolerable for some applications, especially Internet of Things (IoT applications. Fog computing can reduce this latency by extending the traditional cloud architecture to the edge of the network and by enabling the deployment of some application components on fog nodes. Application providers use Platform-as-a-Service (PaaS) to provision (i.e., develop, deploy, manage, and orchestrate) applications in cloud. However, existing PaaS solutions (including IoT PaaS) usually focus on cloud and do not enable provisioning of applications with components spanning cloud and fog. provisioning such applications require novel functions, such as application graph generation, that are absent from existing PaaS. Furthermore, several functions offered by existing PaaS (e.g., publication/discovery) need to be significantly extended in order to fit in a hybrid cloud/fog environment. In this paper, we propose a novel architecture for PaaS for hybrid cloud/fog system. It is IoT use case-driven, and its applications' components are implemented as Virtual Network Functions (VNFs) with execution sequences modeled s graphs with sub-structures such as selection and loops. It automates the provisioning of applications with components spanning cloud and fog. In addition, it enables the discovery of existing cloud and fog nodes and generates application graphs. A proof of concept is built based on Cloudify open source. Feasibility is demonstrated by evaluating its performance when PaaS modules and application components are placed in clouds and fogs in different geographical locations.",
    "lastUpdated": "2020-01-17T18:42:02Z",
    "category": [
      "cs.DC",
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/2001.07497v1"
  },
  {
    "title": "Safer in the Clouds (Extended Abstract)",
    "author": [
      "Chiara Bodei",
      "Viet Dung Dinh",
      "Gian Luigi Ferrari"
    ],
    "abstract": "We outline the design of a framework for modelling cloud computing systems.The approach is based on a declarative programming model which takes the form of a lambda-calculus enriched with suitable mechanisms to express and enforce application-level security policies governing usages of resources available in the clouds. We will focus on the server side of cloud systems, by adopting a pro-active approach, where explicit security policies regulate server's behaviour.",
    "lastUpdated": "2010-10-27T05:04:22Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1010.5568v1"
  },
  {
    "title": "Survey on Improved Scheduling in Hadoop MapReduce in Cloud Environments",
    "author": [
      "B. Thirumala Rao",
      "L. S. S. Reddy"
    ],
    "abstract": "Cloud Computing is emerging as a new computational paradigm shift. Hadoop-MapReduce has become a powerful Computation Model for processing large data on distributed commodity hardware clusters such as Clouds. In all Hadoop implementations, the default FIFO scheduler is available where jobs are scheduled in FIFO order with support for other priority based schedulers also. In this paper we study various scheduler improvements possible with Hadoop and also provided some guidelines on how to improve the scheduling in Hadoop in Cloud Environments.",
    "lastUpdated": "2012-07-03T19:01:26Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1207.0780v1"
  },
  {
    "title": "Increasing Security in Cloud Environment",
    "author": [
      "Priyanka Naik",
      "Sugata Sanyal"
    ],
    "abstract": "The concept of cloud computing was introduced to meet the increase in demand for new application for a project, and to provide a large storage facility whenever or wherever a user needs it. The cloud system facility helped many industries as well as individual users to get authentic software at a very low cost. But with this new system comes the major concern of security, as the connection to the cloud is through the web and the data and application availability need to be handled for each client. The paper describes the various security measures that can be added in isolation or in combination for securing data transmission, server and client.",
    "lastUpdated": "2013-01-02T16:59:22Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1301.0315v1"
  },
  {
    "title": "Towards Securing APIs in Cloud Computing",
    "author": [
      "Kumar Gunjan",
      "R. K. Tiwari",
      "G. Sahoo"
    ],
    "abstract": "Every organisation today wants to adopt cloud computing paradigm and leverage its various advantages. Today everyone is aware of its characteristics which have made it so popular and how it can help the organisations focus on their core activities leaving all IT services development and maintenance to the cloud service providers. Application Programming Interfaces (APIs) act as the interface between the CSPs and the consumers. This paper proposes an improved access control mechanism for securing the Cloud APIs.",
    "lastUpdated": "2013-07-25T07:41:44Z",
    "category": [
      "cs.DC",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1307.6649v1"
  },
  {
    "title": "N2Sky - Neural Networks as Services in the Clouds",
    "author": [
      "Erich Schikuta",
      "Erwin Mann"
    ],
    "abstract": "We present the N2Sky system, which provides a framework for the exchange of neural network specific knowledge, as neural network paradigms and objects, by a virtual organization environment. It follows the sky computing paradigm delivering ample resources by the usage of federated Clouds. N2Sky is a novel Cloud-based neural network simulation environment, which follows a pure service oriented approach. The system implements a transparent environment aiming to enable both novice and experienced users to do neural network research easily and comfortably. N2Sky is built using the RAVO reference architecture of virtual organizations which allows itself naturally integrating into the Cloud service stack (SaaS, PaaS, and IaaS) of service oriented architectures.",
    "lastUpdated": "2014-01-10T21:09:36Z",
    "category": [
      "cs.NE",
      "H.3.5; I.2"
    ],
    "url": "http://arxiv.org/abs/1401.2468v1"
  },
  {
    "title": "Improving Hard Disk Contention-based Covert Channel in Cloud Computing Environment",
    "author": [
      "Bartosz Lipinski",
      "Wojciech Mazurczyk",
      "Krzysztof Szczypiorski"
    ],
    "abstract": "Steganographic methods allow the covert exchange of secret data between parties aware of the procedure. The cloud computing environment is a new and hot target for steganographers, and currently not many solutions have been proposed. This paper proposes CloudSteg which is a steganographic method that allows the creation of a covert channel based on hard disk contention between the two cloud instances that reside on the same physical machine. Experimental results conducted using open source cloud environment OpenStack, show that CloudSteg is able to achieve a bandwidth of about 0.1 bps which is 1000 times higher than is known from the state-of-the-art version.",
    "lastUpdated": "2014-02-02T20:01:30Z",
    "category": [
      "cs.CR",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1402.0239v1"
  },
  {
    "title": "Optimal Control of Applications for Hybrid Cloud Services",
    "author": [
      "Evgeniy Pluzhnik",
      "Evgeniy Nikulchev",
      "Simon Payain"
    ],
    "abstract": "Development of cloud computing enables to move Big Data in the hybrid cloud services. This requires research of all processing systems and data structures for provide QoS. Due to the fact that there are many bottlenecks requires monitoring and control system when performing a query. The models and optimization criteria for the design of systems in a hybrid cloud infrastructures are created. In this article suggested approaches and the results of this build.",
    "lastUpdated": "2014-02-19T13:49:50Z",
    "category": [
      "cs.DC",
      "cs.SY"
    ],
    "url": "http://arxiv.org/abs/1402.4662v1"
  },
  {
    "title": "Secure Cloud Computing through Homomorphic Encryption",
    "author": [
      "Maha Tebaa",
      "Said El Hajji"
    ],
    "abstract": "Go to the cloud, has always been the dream of man. Cloud Computing offers a number of benefits and services to its customers who pay the use of hardware and software resources (servers hosted in data centers, applications, software...) on demand which they can access via internet without the need of expensive computers or a large storage system capacity and without paying any equipment maintenance fees. But these cloud providers must provide guarantees on the protection of privacy and sensitive data stored in their data centers shared between multiple clients using the concept of virtualization.",
    "lastUpdated": "2014-09-02T19:10:02Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1409.0829v1"
  },
  {
    "title": "Practical and Legal Challenges of Cloud Investigations",
    "author": [
      "Joshua I. James",
      "Yunsik Jang"
    ],
    "abstract": "An area presenting new opportunities for both legitimate business, as well as criminal organizations, is Cloud computing. This work gives a strong background in current digital forensic science, as well as a basic understanding of the goal of Law Enforcement when conducting digital forensic investigations. These concepts are then applied to digital forensic investigation of cloud environments in both theory and practice, and supplemented with current literature on the subject. Finally, legal challenges with digital forensic investigations in cloud environments are discussed.",
    "lastUpdated": "2015-02-04T09:13:42Z",
    "category": [
      "cs.CY",
      "K.4.1; K.4.2"
    ],
    "url": "http://arxiv.org/abs/1502.01133v1"
  },
  {
    "title": "Toward A Collection of Cloud Integration Patterns",
    "author": [
      "Daniel Ritter",
      "Stefanie Rinderle-Ma"
    ],
    "abstract": "Cloud computing is one of the most exciting IT trends nowadays. It poses several challenges on application integration with respect to, for example, security. In this work we collect and categorize several new integration patterns and pattern solutions with a focus on cloud integration requirements. Their evidence and examples are based on extensive literature and system reviews.",
    "lastUpdated": "2017-03-11T12:05:27Z",
    "category": [
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/1511.09250v4"
  },
  {
    "title": "Cloud Cognitive Radio HetNets with Limited Feedback",
    "author": [
      "Sandeep Babasaheb Dhavane",
      "Mohammed Zafar Ali Khan"
    ],
    "abstract": "In this paper we propose a cloud based interweave cognitive radio HetNets which combines gain of cloud based radio that is increased rate for cell edge users and better spectral efficiency of cognitive radio. Simulation results for limited feedback shows approximately 100 % increase in rate for primary while 300 % for secondary cell edge users with same outage in cloud over conventional cognitive radio network.",
    "lastUpdated": "2016-05-19T15:39:40Z",
    "category": [
      "cs.IT",
      "cs.NI",
      "math.IT"
    ],
    "url": "http://arxiv.org/abs/1604.05964v2"
  },
  {
    "title": "Security checklist for IaaS cloud deployments",
    "author": [
      "M. Héder",
      "F. Bisztray",
      "Gy. Lakatos",
      "G. Malasits",
      "P. Ormos",
      "E. Prunk-Éger",
      "J. Rigó",
      "Sz. Tenczer",
      "E. Rigó"
    ],
    "abstract": "In this article, we provide a cloud-security checklist for IaaS cloud deployments. The elements of the checklist are established by surveying the related literature on cloud-threat models and various security recommendations. We define the elements of the list on a level of abstraction that helps keep the size of the list manageable while preserving the list's practical applicability.",
    "lastUpdated": "2016-08-31T09:39:53Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1608.08787v1"
  },
  {
    "title": "Cloud Dictionary: Sparse Coding and Modeling for Point Clouds",
    "author": [
      "Or Litany",
      "Tal Remez",
      "Alex Bronstein"
    ],
    "abstract": "With the development of range sensors such as LIDAR and time-of-flight cameras, 3D point cloud scans have become ubiquitous in computer vision applications, the most prominent ones being gesture recognition and autonomous driving. Parsimony-based algorithms have shown great success on images and videos where data points are sampled on a regular Cartesian grid. We propose an adaptation of these techniques to irregularly sampled signals by using continuous dictionaries. We present an example application in the form of point cloud denoising.",
    "lastUpdated": "2017-03-20T19:45:44Z",
    "category": [
      "cs.CV",
      "cs.GR"
    ],
    "url": "http://arxiv.org/abs/1612.04956v2"
  },
  {
    "title": "Executing Bag of Distributed Tasks on Virtually Unlimited Cloud Resources",
    "author": [
      "Long Thai",
      "Blesson Varghese",
      "Adam Barker"
    ],
    "abstract": "Bag-of-Distributed-Tasks (BoDT) application is the collection of identical and independent tasks each of which requires a piece of input data located around the world. As a result, Cloud computing offers an ef- fective way to execute BoT application as it not only consists of multiple geographically distributed data centres but also allows a user to pay for what she actually uses only. In this paper, BoDT on the Cloud using virtually unlimited cloud resources. A heuristic algorithm is proposed to find an execution plan that takes budget constraints into account. Compared with other approaches, with the same given budget, our algorithm is able to reduce the overall execution time up to 50%.",
    "lastUpdated": "2015-06-01T17:57:09Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1506.00590v1"
  },
  {
    "title": "Challenges to be addressed for realising an Ephemeral Cloud Federation",
    "author": [
      "Emanuele Carlini",
      "Massimo Coppola",
      "Patrizio Dazzi",
      "Matteo Mordacchini"
    ],
    "abstract": "This paper sketches the challenges to address to realise a support able to achieve an Ephemeral Cloud Federation, an innovative cloud computing paradigm that enables the exploitation of a dynamic, personalised and context-aware set of resources. The aim of the Ephemeral Federation is to answer to the need of combining private data-centres with both federation of cloud providers and the resource on the edge of the network. The goal of the Ephemeral Federation is to deliver a context-aware and personalised federations of computational, data and network resources, able to manage their heterogeneity in a highly distributed deployment, which can dynamically bring data and computation close to the final user.",
    "lastUpdated": "2016-10-24T11:38:34Z",
    "category": [
      "cs.DC",
      "C.1.4"
    ],
    "url": "http://arxiv.org/abs/1610.07371v1"
  },
  {
    "title": "3D Fully Convolutional Network for Vehicle Detection in Point Cloud",
    "author": [
      "Bo Li"
    ],
    "abstract": "2D fully convolutional network has been recently successfully applied to object detection from images. In this paper, we extend the fully convolutional network based detection techniques to 3D and apply it to point cloud data. The proposed approach is verified on the task of vehicle detection from lidar point cloud for autonomous driving. Experiments on the KITTI dataset shows a significant performance improvement over the previous point cloud based detection approaches.",
    "lastUpdated": "2017-01-16T05:56:01Z",
    "category": [
      "cs.CV",
      "cs.RO"
    ],
    "url": "http://arxiv.org/abs/1611.08069v2"
  },
  {
    "title": "Security Management Model in Cloud Computing Environment",
    "author": [
      "Seyed Hossein Ahmadpanah"
    ],
    "abstract": "In the cloud computing environment, cloud virtual machine (VM) will be more and more the number of virtual machine security and management faced giant Challenge. In order to address security issues cloud computing virtualization environment, this paper presents a virtual machine based on efficient and dynamic deployment VM security management model state migration and scheduling, study of which virtual machine security architecture, based on AHP (Analytic Hierarchy Process) virtual machine deployment and scheduling method, based on CUSUM (Cumulative Sum) DDoS attack detection algorithm, and the above-described method for functional testing and validation.",
    "lastUpdated": "2016-11-27T19:09:27Z",
    "category": [
      "cs.NI",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1611.08889v1"
  },
  {
    "title": "Comparative benchmarking of cloud computing vendors with High Performance Linpack",
    "author": [
      "Mohammad Mohammadi",
      "Timur Bazhirov"
    ],
    "abstract": "We present a comparative analysis of the maximum performance achieved by the Linpack benchmark on compute intensive hardware publicly available from multiple cloud providers. We study both performance within a single compute node, and speedup for distributed memory calculations with up to 32 nodes or at least 512 computing cores. We distinguish between hyper-threaded and non-hyper-threaded scenarios and estimate the performance per single computing core. We also compare results with a traditional supercomputing system for reference. Our findings provide a way to rank the cloud providers and demonstrate the viability of the cloud for high performance computing applications.",
    "lastUpdated": "2017-02-09T20:11:26Z",
    "category": [
      "cs.PF",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1702.02968v1"
  },
  {
    "title": "Denoising a Point Cloud for Surface Reconstruction",
    "author": [
      "Siu-Wing Cheng",
      "Man-Kit Lau"
    ],
    "abstract": "Surface reconstruction from an unorganized point cloud is an important problem due to its widespread applications. White noise, possibly clustered outliers, and noisy perturbation may be generated when a point cloud is sampled from a surface. Most existing methods handle limited amount of noise. We develop a method to denoise a point cloud so that the users can run their surface reconstruction codes or perform other analyses afterwards. Our experiments demonstrate that our method is computationally efficient and it has significantly better noise handling ability than several existing surface reconstruction codes.",
    "lastUpdated": "2017-11-10T06:39:53Z",
    "category": [
      "cs.GR"
    ],
    "url": "http://arxiv.org/abs/1704.04038v2"
  },
  {
    "title": "Artificial life, complex systems and cloud computing: a short review",
    "author": [
      "Juan-Julián Merelo-Guervós"
    ],
    "abstract": "Cloud computing is the prevailing mode of designing, creating and deploying complex applications nowadays. Its underlying assumptions include distributed computing, but also new concepts that need to be incorporated in the different fields. In this short paper we will make a review of how the world of cloud computing has intersected the complex systems and artificial life field, and how it has been used as inspiration for new models or implementation of new and powerful algorithms",
    "lastUpdated": "2017-09-02T18:05:13Z",
    "category": [
      "cs.DC",
      "cs.NE"
    ],
    "url": "http://arxiv.org/abs/1710.02553v1"
  },
  {
    "title": "When Cars Meet Distributed Computing: Data Storage as an Example",
    "author": [
      "Lewis Tseng",
      "Takamasa Higuchi",
      "Onur Altintas"
    ],
    "abstract": "As cars are ubiquitous they could play a major role in a next generation communication and computation framework. In the last years, the development of vehicle-to-vehicle communication and vehicle-to-infrastructure communication took huge steps forward and therefore gives us the tools to build \"mobile computing service\" on cars equipped with computation capabilities. Recently, several groups of researchers independently proposed the design of \"vehicular clouds\" that materializes the concept. In this paper, we introduce a new paradigm of the vehicular clouds, followed by a case study of data storage on top of the proposed cloud. Finally, we present several challenges and opportunities in the intersection of vehicular clouds and distributed computing.",
    "lastUpdated": "2017-11-06T16:57:03Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1711.02014v1"
  },
  {
    "title": "Hidden Markov Random Field Iterative Closest Point",
    "author": [
      "John Stechschulte",
      "Christoffer Heckman"
    ],
    "abstract": "When registering point clouds resolved from an underlying 2-D pixel structure, such as those resulting from structured light and flash LiDAR sensors, or stereo reconstruction, it is expected that some points in one cloud do not have corresponding points in the other cloud, and that these would occur together, such as along an edge of the depth map. In this work, a hidden Markov random field model is used to capture this prior within the framework of the iterative closest point algorithm. The EM algorithm is used to estimate the distribution parameters and the hidden component memberships. Experiments are presented demonstrating that this method outperforms several other outlier rejection methods when the point clouds have low or moderate overlap.",
    "lastUpdated": "2017-11-07T23:12:26Z",
    "category": [
      "cs.CV",
      "cs.RO"
    ],
    "url": "http://arxiv.org/abs/1711.05864v1"
  },
  {
    "title": "Using JSON-LD to Compose Different IoT and Cloud Services",
    "author": [
      "Darko Andročec"
    ],
    "abstract": "Internet of things and cloud computing are in the widespread use today, and often work together to accomplish complex business task and use cases. This paper propose the framework and its practical implementation to compose different things as services and cloud services. The ontology based approach and JSON-LD was used to semantically annotate both types of services, and enable the mechanism to semi-automatically compose these services. The use case and proof-of-concept application that use the proposed theoretical approach is also described in this work.",
    "lastUpdated": "2018-09-21T09:31:39Z",
    "category": [
      "cs.SE",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1809.08233v1"
  },
  {
    "title": "Automatic normal orientation in point clouds of building interiors",
    "author": [
      "Sebastian Ochmann",
      "Reinhard Klein"
    ],
    "abstract": "Orienting surface normals correctly and consistently is a fundamental problem in geometry processing. Applications such as visualization, feature detection, and geometry reconstruction often rely on the availability of correctly oriented normals. Many existing approaches for automatic orientation of normals on meshes or point clouds make severe assumptions on the input data or the topology of the underlying object which are not applicable to real-world measurements of urban scenes. In contrast, our approach is specifically tailored to the challenging case of unstructured indoor point cloud scans of multi-story, multi-room buildings. We evaluate the correctness and speed of our approach on multiple real-world point cloud datasets.",
    "lastUpdated": "2019-04-10T10:27:13Z",
    "category": [
      "cs.GR"
    ],
    "url": "http://arxiv.org/abs/1901.06487v2"
  },
  {
    "title": "NeuralSampler: Euclidean Point Cloud Auto-Encoder and Sampler",
    "author": [
      "Edoardo Remelli",
      "Pierre Baque",
      "Pascal Fua"
    ],
    "abstract": "Most algorithms that rely on deep learning-based approaches to generate 3D point sets can only produce clouds containing fixed number of points. Furthermore, they typically require large networks parameterized by many weights, which makes them hard to train. In this paper, we propose an auto-encoder architecture that can both encode and decode clouds of arbitrary size and demonstrate its effectiveness at upsampling sparse point clouds. Interestingly, we can do so using less than half as many parameters as state-of-the-art architectures while still delivering better performance. We will make our code base fully available.",
    "lastUpdated": "2019-01-27T15:38:49Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1901.09394v1"
  },
  {
    "title": "Cloud Futurology",
    "author": [
      "Blesson Varghese",
      "Philipp Leitner",
      "Suprio Ray",
      "Kyle Chard",
      "Adam Barker",
      "Yehia Elkhatib",
      "Herry Herry",
      "Cheol-Ho Hong",
      "Jeremy Singer",
      "Fung Po Tso",
      "Eiko Yoneki",
      "Mohamed-Faten Zhani"
    ],
    "abstract": "The Cloud has become integral to most Internet-based applications and user gadgets. This article provides a brief history of the Cloud and presents a researcher's view of the prospects for innovating at the infrastructure, middleware, and application and delivery levels of the already crowded Cloud computing stack.",
    "lastUpdated": "2019-02-10T19:37:24Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1902.03656v1"
  },
  {
    "title": "Cloud-Based Autonomous Indoor Navigation: A Case Study",
    "author": [
      "Uthman Baroudi",
      "M. Alharbi",
      "K. Alhouty",
      "H. Baafeef",
      "K. Alofi"
    ],
    "abstract": "In this case study, we design, integrate and implement a cloud-enabled autonomous robotic navigation system. The system has the following features: map generation and robot coordination via cloud service and video streaming to allow online monitoring and control in case of emergency. The system has been tested to generate a map for a long corridor using two modes: manual and autonomous. The autonomous mode has shown more accurate map. In addition, the field experiments confirm the benefit of offloading the heavy computation to the cloud by significantly shortening the time required to build the map.",
    "lastUpdated": "2019-02-21T13:56:31Z",
    "category": [
      "cs.RO",
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1902.08052v1"
  },
  {
    "title": "Benefits of AWS in Modern Cloud",
    "author": [
      "Sourav Mukherjee"
    ],
    "abstract": "This article gives an overview of the benefits of AWS in the modern cloud. Cloud computing is performing well in todays World and boosting the ability to use the internet more than ever. Cloud computing gradually developed a method to use the benefits of it in most of the organizations. It is very demanding in all businesses tasked with improving the quality of service reducing costs as the organization pays for the service only what they consume based on the incoming and outgoing traffic.",
    "lastUpdated": "2019-03-18T19:48:39Z",
    "category": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1903.03219v2"
  },
  {
    "title": "Towards a Security-Aware Benchmarking Framework for Function-as-a-Service",
    "author": [
      "Roland Pellegrini",
      "Igor Ivkic",
      "Markus Tauber"
    ],
    "abstract": "In a world, where complexity increases on a daily basis the Function-as-a-Service (FaaS) cloud model seams to take countermeasures. In comparison to other cloud models, the fast evolving FaaS increasingly abstracts the underlying infrastructure and refocuses on the application logic. This trend brings huge benefits in application and performance but comes with difficulties for benchmarking cloud applications. In this position paper, we present an initial investigation of benchmarking FaaS in close to reality production systems. Furthermore, we outline the architectural design including the necessary benchmarking metrics. We also discuss the possibility of using the proposed framework for identifying security vulnerabilities.",
    "lastUpdated": "2019-05-15T10:14:12Z",
    "category": [
      "cs.SE",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1905.07228v1"
  },
  {
    "title": "SARSA(0) Reinforcement Learning over Fully Homomorphic Encryption",
    "author": [
      "Jihoon Suh",
      "Takashi Tanaka"
    ],
    "abstract": "We consider a cloud-based control architecture in which the local plants outsource the control synthesis task to the cloud. In particular, we consider a cloud-based reinforcement learning (RL), where updating the value function is outsourced to the cloud. To achieve confidentiality, we implement computations over Fully Homomorphic Encryption (FHE). We use a CKKS encryption scheme and a modified SARSA(0) reinforcement learning to incorporate the encryption-induced delays. We then give a convergence result for the delayed updated rule of SARSA(0) with a blocking mechanism. We finally present a numerical demonstration via implementing on a classical pole-balancing problem.",
    "lastUpdated": "2020-02-02T23:12:42Z",
    "category": [
      "eess.SY",
      "cs.CR",
      "cs.SY"
    ],
    "url": "http://arxiv.org/abs/2002.00506v1"
  },
  {
    "title": "Intrinsic Point Cloud Interpolation via Dual Latent Space Navigation",
    "author": [
      "Marie-Julie Rakotosaona",
      "Maks Ovsjanikov"
    ],
    "abstract": "We present a learning-based method for interpolating and manipulating 3D shapes represented as point clouds, that is explicitly designed to preserve intrinsic shape properties. Our approach is based on constructing a dual encoding space that enables shape synthesis and, at the same time, provides links to the intrinsic shape information, which is typically not available on point cloud data. Our method works in a single pass and avoids expensive optimization, employed by existing techniques. Furthermore, the strong regularization provided by our dual latent space approach also helps to improve shape recovery in challenging settings from noisy point clouds across different datasets. Extensive experiments show that our method results in more realistic and smoother interpolations compared to baselines.",
    "lastUpdated": "2020-04-03T16:28:55Z",
    "category": [
      "cs.CV",
      "cs.GR"
    ],
    "url": "http://arxiv.org/abs/2004.01661v1"
  },
  {
    "title": "Exosphere -- Bringing The Cloud Closer",
    "author": [
      "Julian L. Pistorius",
      "Chris Martin",
      "Sanjana Sudarshan",
      "David S. LeBauer"
    ],
    "abstract": "Exosphere provides researcher-friendly software for managing computing workloads on OpenStack cloud infrastructure. Exosphere is a user-friendly alternative to Horizon, the default OpenStack graphical interface. Exosphere can be used with most research cloud infrastructure, requiring near-zero custom integration work.",
    "lastUpdated": "2020-10-13T22:36:17Z",
    "category": [
      "cs.DC",
      "cs.HC",
      "H.5.2; C.2.4; H.1.2; D.4.7; D.1.1; D.2.2"
    ],
    "url": "http://arxiv.org/abs/2008.10640v2"
  },
  {
    "title": "Deep Learning for 3D Point Cloud Understanding: A Survey",
    "author": [
      "Haoming Lu",
      "Humphrey Shi"
    ],
    "abstract": "The development of practical applications, such as autonomous driving and robotics, has brought increasing attention to 3D point cloud understanding. While deep learning has achieved remarkable success on image-based tasks, there are many unique challenges faced by deep neural networks in processing massive, unstructured and noisy 3D points. To demonstrate the latest progress of deep learning for 3D point cloud understanding, this paper summarizes recent remarkable research contributions in this area from several different directions (classification, segmentation, detection, tracking, flow estimation, registration, augmentation and completion), together with commonly used datasets, metrics and state-of-the-art performances. More information regarding this survey can be found at: https://github.com/SHI-Labs/3D-Point-Cloud-Learning.",
    "lastUpdated": "2020-09-18T16:34:12Z",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2009.08920v1"
  },
  {
    "title": "Towards Runtime Verification via Event Stream Processing in Cloud Computing Infrastructures",
    "author": [
      "Domenico Cotroneo",
      "Luigi De Simone",
      "Pietro Liguori",
      "Roberto Natella",
      "Angela Scibelli"
    ],
    "abstract": "Software bugs in cloud management systems often cause erratic behavior, hindering detection, and recovery of failures. As a consequence, the failures are not timely detected and notified, and can silently propagate through the system. To face these issues, we propose a lightweight approach to runtime verification, for monitoring and failure detection of cloud computing systems. We performed a preliminary evaluation of the proposed approach in the OpenStack cloud management platform, an \"off-the-shelf\" distributed system, showing that the approach can be applied with high failure detection coverage.",
    "lastUpdated": "2020-10-13T18:03:41Z",
    "category": [
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/2010.06607v1"
  },
  {
    "title": "Point Cloud Registration Based on Consistency Evaluation of Rigid Transformation in Parameter Space",
    "author": [
      "Masaki Yoshii",
      "Ikuko Shimizu"
    ],
    "abstract": "We can use a method called registration to integrate some point clouds that represent the shape of the real world. In this paper, we propose highly accurate and stable registration method. Our method detects keypoints from point clouds and generates triplets using multiple descriptors. Furthermore, our method evaluates the consistency of rigid transformation parameters of each triplet with histograms and obtains the rigid transformation between the point clouds. In the experiment of this paper, our method had minimul errors and no major failures. As a result, we obtained sufficiently accurate and stable registration results compared to the comparative methods.",
    "lastUpdated": "2020-11-10T10:13:15Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2011.05014v1"
  },
  {
    "title": "A deep network approach to multitemporal cloud detection",
    "author": [
      "Devis Tuia",
      "Benjamin Kellenberger",
      "Adrian Pérez-Suay",
      "Gustau Camps-Valls"
    ],
    "abstract": "We present a deep learning model with temporal memory to detect clouds in image time series acquired by the Seviri imager mounted on the Meteosat Second Generation (MSG) satellite. The model provides pixel-level cloud maps with related confidence and propagates information in time via a recurrent neural network structure. With a single model, we are able to outline clouds along all year and during day and night with high accuracy.",
    "lastUpdated": "2020-12-09T08:58:36Z",
    "category": [
      "physics.ao-ph",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2012.10393v1"
  },
  {
    "title": "Distributed Double Machine Learning with a Serverless Architecture",
    "author": [
      "Malte S. Kurz"
    ],
    "abstract": "Serverless cloud computing is predicted to be the dominating and default architecture of cloud computing in the coming decade (Berkley View on Serverless Computing, 2019). In this paper we explore serverless cloud computing for double machine learning. Being based on repeated cross-fitting, double machine learning is particularly well suited to exploit the enormous elasticity of serverless computing. It allows to get fast on-demand estimations without additional cloud maintenance effort. We provide a prototype implementation DoubleML-Serverless written in Python that implements the estimation of double machine learning models with the serverless computing platform AWS Lambda and demonstrate its utility with a case study.",
    "lastUpdated": "2021-01-11T16:58:30Z",
    "category": [
      "cs.DC",
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2101.04025v1"
  },
  {
    "title": "Video Big Data Analytics in the Cloud: A Reference Architecture, Survey, Opportunities, and Open Research Issues",
    "author": [
      "Aftab Alam",
      "Irfan Ullah",
      "Young-Koo Lee"
    ],
    "abstract": "The proliferation of multimedia devices over the Internet of Things (IoT) generates an unprecedented amount of data. Consequently, the world has stepped into the era of big data. Recently, on the rise of distributed computing technologies, video big data analytics in the cloud has attracted the attention of researchers and practitioners. The current technology and market trends demand an efficient framework for video big data analytics. However, the current work is too limited to provide a complete survey of recent research work on video big data analytics in the cloud, including the management and analysis of a large amount of video data, the challenges, opportunities, and promising research directions. To serve this purpose, we present this study, which conducts a broad overview of the state-of-the-art literature on video big data analytics in the cloud. It also aims to bridge the gap among large-scale video analytics challenges, big data solutions, and cloud computing. In this study, we clarify the basic nomenclatures that govern the video analytics domain and the characteristics of video big data while establishing its relationship with cloud computing. We propose a service-oriented layered reference architecture for intelligent video big data analytics in the cloud. Then, a comprehensive and keen review has been conducted to examine cutting-edge research trends in video big data analytics. Finally, we identify and articulate several open research issues and challenges, which have been raised by the deployment of big data technologies in the cloud for video big data analytics. To the best of our knowledge, this is the first study that presents the generalized view of the video big data analytics in the cloud. This paper provides the research studies and technologies advancing video analyses in the era of big data and cloud computing.",
    "lastUpdated": "2020-11-16T09:21:53Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/2011.07807v1"
  },
  {
    "title": "InterCloud: Utility-Oriented Federation of Cloud Computing Environments for Scaling of Application Services",
    "author": [
      "Rajkumar Buyya",
      "Rajiv Ranjan",
      "Rodrigo N. Calheiros"
    ],
    "abstract": "Cloud computing providers have setup several data centers at different geographical locations over the Internet in order to optimally serve needs of their customers around the world. However, existing systems do not support mechanisms and policies for dynamically coordinating load distribution among different Cloud-based data centers in order to determine optimal location for hosting application services to achieve reasonable QoS levels. Further, the Cloud computing providers are unable to predict geographic distribution of users consuming their services, hence the load coordination must happen automatically, and distribution of services must change in response to changes in the load. To counter this problem, we advocate creation of federated Cloud computing environment (InterCloud) that facilitates just-in-time, opportunistic, and scalable provisioning of application services, consistently achieving QoS targets under variable workload, resource and network conditions. The overall goal is to create a computing environment that supports dynamic expansion or contraction of capabilities (VMs, services, storage, and database) for handling sudden variations in service demands. This paper presents vision, challenges, and architectural elements of InterCloud for utility-oriented federation of Cloud computing environments. The proposed InterCloud environment supports scaling of applications across multiple vendor clouds. We have validated our approach by conducting a set of rigorous performance evaluation study using the CloudSim toolkit. The results demonstrate that federated Cloud computing model has immense potential as it offers significant performance gains as regards to response time and cost saving under dynamic workload scenarios.",
    "lastUpdated": "2010-03-20T10:54:43Z",
    "category": [
      "cs.DC",
      "C.2.4"
    ],
    "url": "http://arxiv.org/abs/1003.3920v1"
  },
  {
    "title": "Energy-Efficient Management of Data Center Resources for Cloud Computing: A Vision, Architectural Elements, and Open Challenges",
    "author": [
      "Rajkumar Buyya",
      "Anton Beloglazov",
      "Jemal Abawajy"
    ],
    "abstract": "Cloud computing is offering utility-oriented IT services to users worldwide. Based on a pay-as-you-go model, it enables hosting of pervasive applications from consumer, scientific, and business domains. However, data centers hosting Cloud applications consume huge amounts of energy, contributing to high operational costs and carbon footprints to the environment. Therefore, we need Green Cloud computing solutions that can not only save energy for the environment but also reduce operational costs. This paper presents vision, challenges, and architectural elements for energy-efficient management of Cloud computing environments. We focus on the development of dynamic resource provisioning and allocation algorithms that consider the synergy between various data center infrastructures (i.e., the hardware, power units, cooling and software), and holistically work to boost data center energy efficiency and performance. In particular, this paper proposes (a) architectural principles for energy-efficient management of Clouds; (b) energy-efficient resource allocation policies and scheduling algorithms considering quality-of-service expectations, and devices power usage characteristics; and (c) a novel software technology for energy-efficient management of Clouds. We have validated our approach by conducting a set of rigorous performance evaluation study using the CloudSim toolkit. The results demonstrate that Cloud computing model has immense potential as it offers significant performance gains as regards to response time and cost saving under dynamic workload scenarios.",
    "lastUpdated": "2010-06-02T06:45:07Z",
    "category": [
      "cs.DC",
      "C.2.4"
    ],
    "url": "http://arxiv.org/abs/1006.0308v1"
  },
  {
    "title": "Aneka Cloud Application Platform and Its Integration with Windows Azure",
    "author": [
      "Yi Wei",
      "Karthik Sukumar",
      "Christian Vecchiola",
      "Dileban Karunamoorthy",
      "Rajkumar Buyya"
    ],
    "abstract": "Aneka is an Application Platform-as-a-Service (Aneka PaaS) for Cloud Computing. It acts as a framework for building customized applications and deploying them on either public or private Clouds. One of the key features of Aneka is its support for provisioning resources on different public Cloud providers such as Amazon EC2, Windows Azure and GoGrid. In this chapter, we will present Aneka platform and its integration with one of the public Cloud infrastructures, Windows Azure, which enables the usage of Windows Azure Compute Service as a resource provider of Aneka PaaS. The integration of the two platforms will allow users to leverage the power of Windows Azure Platform for Aneka Cloud Computing, employing a large number of compute instances to run their applications in parallel. Furthermore, customers of the Windows Azure platform can benefit from the integration with Aneka PaaS by embracing the advanced features of Aneka in terms of multiple programming models, scheduling and management services, application execution services, accounting and pricing services and dynamic provisioning services. Finally, in addition to the Windows Azure Platform we will illustrate in this chapter the integration of Aneka PaaS with other public Cloud platforms such as Amazon EC2 and GoGrid, and virtual machine management platforms such as Xen Server. The new support of provisioning resources on Windows Azure once again proves the adaptability, extensibility and flexibility of Aneka.",
    "lastUpdated": "2011-03-14T06:38:11Z",
    "category": [
      "cs.DC",
      "C.1.4"
    ],
    "url": "http://arxiv.org/abs/1103.2590v1"
  },
  {
    "title": "Secured Data Consistency and Storage Way in Untrusted Cloud using Server Management Algorithm",
    "author": [
      "C. Dinesh"
    ],
    "abstract": "It is very challenging part to keep safely all required data that are needed in many applications for user in cloud. Storing our data in cloud may not be fully trustworthy. Since client doesn't have copy of all stored data, he has to depend on Cloud Service Provider. But dynamic data operations, Read-Solomon and verification token construction methods don't tell us about total storage capacity of server allocated space before and after the data addition in cloud. So we have to introduce a new proposed system of efficient storage measurement and space comparison algorithm with time management for measuring the total allocated storage area before and after the data insertion in cloud. So by using our proposed scheme, the value or weight of stored data before and after is measured by client with specified time in cloud storage area with accuracy. And here we also have proposed the multi-server restore point in server failure condition. If there occurs any server failure, by using this scheme the data can be recovered automatically in cloud server. Our proposed scheme efficiently checks space for the in-outsourced data to maintain integrity. Here the TPA necessarily doesn't have the delegation to audit user's data.",
    "lastUpdated": "2011-11-10T08:05:38Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1111.2412v1"
  },
  {
    "title": "AnonyControl: Control Cloud Data Anonymously with Multi-Authority Attribute-Based Encryption",
    "author": [
      "Taeho Jung",
      "Xiang-Yang Li",
      "Zhiguo Wan",
      "Meng Wan"
    ],
    "abstract": "Cloud computing is a revolutionary computing paradigm which enables flexible, on-demand and low-cost usage of computing resources. However, those advantages, ironically, are the causes of security and privacy problems, which emerge because the data owned by different users are stored in some cloud servers instead of under their own control. To deal with security problems, various schemes based on the Attribute- Based Encryption (ABE) have been proposed recently. However, the privacy problem of cloud computing is yet to be solved. This paper presents an anonymous privilege control scheme AnonyControl to address the user and data privacy problem in a cloud. By using multiple authorities in cloud computing system, our proposed scheme achieves anonymous cloud data access, finegrained privilege control, and more importantly, tolerance to up to (N -2) authority compromise. Our security and performance analysis show that AnonyControl is both secure and efficient for cloud computing environment.",
    "lastUpdated": "2013-04-11T16:55:49Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1206.2657v6"
  },
  {
    "title": "Streamforce: outsourcing access control enforcement for stream data to the clouds",
    "author": [
      "Tien Tuan Anh Dinh",
      "Anwitaman Datta"
    ],
    "abstract": "As tremendous amount of data being generated everyday from human activity and from devices equipped with sensing capabilities, cloud computing emerges as a scalable and cost-effective platform to store and manage the data. While benefits of cloud computing are numerous, security concerns arising when data and computation are outsourced to a third party still hinder the complete movement to the cloud. In this paper, we focus on the problem of data privacy on the cloud, particularly on access controls over stream data. The nature of stream data and the complexity of sharing data make access control a more challenging issue than in traditional archival databases. We present Streamforce - a system allowing data owners to securely outsource their data to the cloud. The owner specifies fine-grained policies which are enforced by the cloud. The latter performs most of the heavy computations, while learning nothing about the data. To this end, we employ a number of encryption schemes, including deterministic encryption, proxy-based attribute based encryption and sliding-window encryption. In Streamforce, access control policies are modeled as secure continuous queries, which entails minimal changes to existing stream processing engines, and allows for easy expression of a wide-range of policies. In particular, Streamforce comes with a number of secure query operators including Map, Filter, Join and Aggregate. Finally, we implement Streamforce over an open source stream processing engine (Esper) and evaluate its performance on a cloud platform. The results demonstrate practical performance for many real-world applications, and although the security overhead is visible, Streamforce is highly scalable.",
    "lastUpdated": "2013-05-28T11:05:07Z",
    "category": [
      "cs.DB",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1305.6146v2"
  },
  {
    "title": "DCaaS: Data Consistency as a Service for Managing Data Uncertainty on the Clouds",
    "author": [
      "Islam Elgedawy"
    ],
    "abstract": "Ensuring data correctness over partitioned distributed database systems is a classical problem. Classical solutions proposed to solve this problem are mainly adopting locking or blocking techniques. These techniques are not suitable for cloud environments as they produce terrible response times; due to the long latency and faultiness of wide area network connections among cloud datacenters. One way to improve performance is to restrict access of users-bases to specific datacenters and avoid data sharing between datacenters. However, conflicts might appear when data is replicated between datacenters; nevertheless change propagation timeliness is not guaranteed. Such problems created data uncertainty on cloud environments. Managing data uncertainty is one of the main obstacles for supporting global distributed transactions on the clouds. To overcome this problem, this paper proposes an quota-based approach for managing data uncertainty on the clouds that guarantees global data correctness without global locking or blocking. To decouple service developers from the hassles of managing data uncertainty, we propose to use a new platform service (i.e. Data Consistency as a Service (DCaaS)) to encapsulate the proposed approach. DCaaS service also ensures SaaS services cloud portability, as it works as a cloud adapter between SaaS service instances. Experiments show that proposed approach realized by the DCaaS service provides much better response time when compared with classical locking and blocking techniques.",
    "lastUpdated": "2013-06-03T14:46:08Z",
    "category": [
      "cs.DC",
      "68Q85"
    ],
    "url": "http://arxiv.org/abs/1306.0441v1"
  },
  {
    "title": "Secure k-Nearest Neighbor Query over Encrypted Data in Outsourced Environments",
    "author": [
      "Yousef Elmehdwi",
      "Bharath K. Samanthula",
      "Wei Jiang"
    ],
    "abstract": "For the past decade, query processing on relational data has been studied extensively, and many theoretical and practical solutions to query processing have been proposed under various scenarios. With the recent popularity of cloud computing, users now have the opportunity to outsource their data as well as the data management tasks to the cloud. However, due to the rise of various privacy issues, sensitive data (e.g., medical records) need to be encrypted before outsourcing to the cloud. In addition, query processing tasks should be handled by the cloud; otherwise, there would be no point to outsource the data at the first place. To process queries over encrypted data without the cloud ever decrypting the data is a very challenging task. In this paper, we focus on solving the k-nearest neighbor (kNN) query problem over encrypted database outsourced to a cloud: a user issues an encrypted query record to the cloud, and the cloud returns the k closest records to the user. We first present a basic scheme and demonstrate that such a naive solution is not secure. To provide better security, we propose a secure kNN protocol that protects the confidentiality of the data, user's input query, and data access patterns. Also, we empirically analyze the efficiency of our protocols through various experiments. These results indicate that our secure protocol is very efficient on the user end, and this lightweight scheme allows a user to use any mobile device to perform the kNN query.",
    "lastUpdated": "2013-07-18T03:36:20Z",
    "category": [
      "cs.CR",
      "D.4.6; E.3"
    ],
    "url": "http://arxiv.org/abs/1307.4824v1"
  },
  {
    "title": "Accelerating R-based Analytics on the Cloud",
    "author": [
      "Ishan Patel",
      "Andrew Rau-Chaplin",
      "Blesson Varghese"
    ],
    "abstract": "This paper addresses how the benefits of cloud-based infrastructure can be harnessed for analytical workloads. Often the software handling analytical workloads is not developed by a professional programmer, but on an ad hoc basis by Analysts in high-level programming environments such as R or Matlab. The goal of this research is to allow Analysts to take an analytical job that executes on their personal workstations, and with minimum effort execute it on cloud infrastructure and manage both the resources and the data required by the job. If this can be facilitated gracefully, then the Analyst benefits from on-demand resources, low maintenance cost and scalability of computing resources, all of which are offered by the cloud. In this paper, a Platform for Parallel R-based Analytics on the Cloud (P2RAC) that is placed between an Analyst and a cloud infrastructure is proposed and implemented. P2RAC offers a set of command-line tools for managing the resources, such as instances and clusters, the data and the execution of the software on the Amazon Elastic Computing Cloud infrastructure. Experimental studies are pursued using two parallel problems and the results obtained confirm the feasibility of employing P2RAC for solving large-scale analytical problems on the cloud.",
    "lastUpdated": "2013-08-13T08:58:24Z",
    "category": [
      "cs.DC",
      "cs.CE",
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/1308.2787v1"
  },
  {
    "title": "On Optimal and Fair Service Allocation in Mobile Cloud Computing",
    "author": [
      "M. Reza Rahimi",
      "Nalini Venkatasubramanian",
      "Sharad Mehrotra",
      "Athanasios V. Vasilakos"
    ],
    "abstract": "This paper studies the optimal and fair service allocation for a variety of mobile applications (single or group and collaborative mobile applications) in mobile cloud computing. We exploit the observation that using tiered clouds, i.e. clouds at multiple levels (local and public) can increase the performance and scalability of mobile applications. We proposed a novel framework to model mobile applications as a location-time workflows (LTW) of tasks; here users mobility patterns are translated to mobile service usage patterns. We show that an optimal mapping of LTWs to tiered cloud resources considering multiple QoS goals such application delay, device power consumption and user cost/price is an NP-hard problem for both single and group-based applications. We propose an efficient heuristic algorithm called MuSIC that is able to perform well (73% of optimal, 30% better than simple strategies), and scale well to a large number of users while ensuring high mobile application QoS. We evaluate MuSIC and the 2-tier mobile cloud approach via implementation (on real world clouds) and extensive simulations using rich mobile applications like intensive signal processing, video streaming and multimedia file sharing applications. Our experimental and simulation results indicate that MuSIC supports scalable operation (100+ concurrent users executing complex workflows) while improving QoS. We observe about 25% lower delays and power (under fixed price constraints) and about 35% decrease in price (considering fixed delay) in comparison to only using the public cloud. Our studies also show that MuSIC performs quite well under different mobility patterns, e.g. random waypoint and Manhattan models.",
    "lastUpdated": "2013-08-20T19:36:58Z",
    "category": [
      "cs.DC",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1308.4391v1"
  },
  {
    "title": "Reducing Failure Probability of cloud storage services using Multi-Clouds",
    "author": [
      "Veena Rawat"
    ],
    "abstract": "Any information is valuable as long as it has related data. If related data are not put together, the information is meaningless as unrelated data has no value. The mapped information is required only by authenticated users. So there is no necessity to store related information together. If the relations of a database are fragmented into chunks and these chunks are stored at different cloud service providers, it could prevent from any privacy breach and the data stored will be secure. It would also reduce the data transfer costs as the entire data is not always required, for e.g. during updates. Also, instead of storage of chunks at a single CSP, if each chunk or fragment is stored at multiple CSPs it ensures availability and also permits concurrent access. Additionally, it would prevent financial loss during cloud outages and also prevent data lock-in. Replicating data chunks at multiple clouds situated at geographically different locations would also have an additional decrease in response time. The work attempts to select multiple cloud service providers within a given budget so as to ensure maximum availability of data. The entire data can be stored at each of the data centers selected depending on the budget when there is no security or privacy issue. Data can also be stored in chunks by replicating each data chunk at two or more cloud service providers. Different chunks can be replicated at different service providers. The work also attempts to select various cloud service providers to ensure maximum valid data chunks within a given budget.",
    "lastUpdated": "2013-10-18T05:42:43Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1310.4919v1"
  },
  {
    "title": "An Auction-driven Self-organizing Cloud Delivery Model",
    "author": [
      "Dan C. Marinescu",
      "Ashkan Paya",
      "John P. Morrison",
      "Philip Healy"
    ],
    "abstract": "The three traditional cloud delivery models -- IaaS, PaaS, and SaaS -- constrain access to cloud resources by hiding their raw functionality and forcing us to use them indirectly via a restricted set of actions. Can we introduce a new delivery model, and, at the same time, support improved security, a higher degree of assurance, find relatively simple solutions to the hard cloud resource management problems, eliminate some of the inefficiencies related to resource virtualization, allow the assembly of clouds of clouds, and, last but not least, minimize the number of interoperability standards? We sketch a self-organizing architecture for very large compute clouds composed of many-core processors and heterogeneous coprocessors. We discuss how self-organization will address each of the challenges described above. The approach is {\\em bid-centric}. The system of heterogeneous cloud resources is dynamically, and autonomically, configured to bid to meet the needs identified in a high-level task or service specification. When the task is completed, or the service is retired, the resources are released for subsequent reuse. Our approach mimics the process followed by individual researchers who, in response to a call for proposals released by a funding agency, organize themselves in groups of various sizes and specialities. If the bid is successful, then the group carries out the proposed work and releases the results. After the work is completed, individual researchers in the group disperse, possibly joining other groups or submitting individual bids in response to other proposals. Similar protocols are common to other human activities such as procurement management.",
    "lastUpdated": "2013-12-10T23:39:15Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1312.2998v1"
  },
  {
    "title": "Application of Selective Algorithm for Effective Resource Provisioning in Cloud Computing Environment",
    "author": [
      "Mayanka Katyal",
      "Atul Mishra"
    ],
    "abstract": "Modern day continued demand for resource hungry services and applications in IT sector has led to development of Cloud computing. Cloud computing environment involves high cost infrastructure on one hand and need high scale computational resources on the other hand. These resources need to be provisioned (allocation and scheduling) to the end users in most efficient manner so that the tremendous capabilities of cloud are utilized effectively and efficiently. In this paper we discuss a selective algorithm for allocation of cloud resources to end-users on-demand basis. This algorithm is based on min-min and max-min algorithms. These are two conventional task scheduling algorithm. The selective algorithm uses certain heuristics to select between the two algorithms so that overall makespan of tasks on the machines is minimized. The tasks are scheduled on machines in either space shared or time shared manner. We evaluate our provisioning heuristics using a cloud simulator, called CloudSim. We also compared our approach to the statistics obtained when provisioning of resources was done in First-Cum-First- Serve(FCFS) manner. The experimental results show that overall makespan of tasks on given set of VMs minimizes significantly in different scenarios.",
    "lastUpdated": "2014-03-12T12:50:04Z",
    "category": [
      "cs.DC",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1403.2914v1"
  },
  {
    "title": "Near-Optimal Virtual Machine Packing Based on Resource Requirement of Service Demands Using Pattern Clustering",
    "author": [
      "Yaghoob Siahmargooei",
      "Mohammad Kazem Akbari",
      "Seyyed Alireza Hashemi Golpayegani",
      "Saeed Sharifian"
    ],
    "abstract": "Upon the expansion of Cloud Computing and the positive outlook of organizations with regard to the movements towards using cloud computing and their expanding utilization of such valuable processing method, as well as the solutions provided by the cloud infrastructure providers with regard to the reduction of the costs of processing resources, the problem of organizing resources in a cloud environment gained a high importance. One of the major preoccupations of the minds of cloud infrastructure clients is their lack of knowledge on the quantity of their required processing resources in different periods of time. The managers and technicians are trying to make the most use of scalability and the flexibility of the resources in cloud computing. The main challenge is with calculating the amount of the required processing resources per moment with regard to the quantity of incoming requests of the service. Through deduction of the accurate amount of these items, one can have an accurate estimation of the requests per moment. This paper aims at introducing a model for automatic scaling of the cloud resources that would reduce the cost of renting the resources for the clients of cloud infrastructure. Thus, first we start with a thorough explanation of the proposal and the major components of the model. Then through calculating the incomings of the model through clustering and introducing the way that each of these components work in different phases,...",
    "lastUpdated": "2014-06-27T19:56:15Z",
    "category": [
      "cs.DC",
      "cs.NI",
      "cs.PF"
    ],
    "url": "http://arxiv.org/abs/1406.7285v1"
  },
  {
    "title": "Analyzing Cryptographic Algorithms for Secure Cloud Network",
    "author": [
      "Vineet Kumar Singh",
      "Maitreyee Dutta"
    ],
    "abstract": "Pay as per usage concept of Cloud computing has brought revolutionary changes in the information technology world.",
    "lastUpdated": "2014-07-06T17:54:01Z",
    "category": [
      "cs.DC",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1407.1520v1"
  },
  {
    "title": "Software-Defined Cloud Computing: Architectural Elements and Open Challenges",
    "author": [
      "Rajkumar Buyya",
      "Rodrigo N. Calheiros",
      "Jungmin Son",
      "Amir Vahid Dastjerdi",
      "Young Yoon"
    ],
    "abstract": "The variety of existing cloud services creates a challenge for service providers to enforce reasonable Software Level Agreements (SLA) stating the Quality of Service (QoS) and penalties in case QoS is not achieved. To avoid such penalties at the same time that the infrastructure operates with minimum energy and resource wastage, constant monitoring and adaptation of the infrastructure is needed. We refer to Software-Defined Cloud Computing, or simply Software-Defined Clouds (SDC), as an approach for automating the process of optimal cloud configuration by extending virtualization concept to all resources in a data center. An SDC enables easy reconfiguration and adaptation of physical resources in a cloud infrastructure, to better accommodate the demand on QoS through a software that can describe and manage various aspects comprising the cloud environment. In this paper, we present an architecture for SDCs on data centers with emphasis on mobile cloud applications. We present an evaluation, showcasing the potential of SDC in two use cases-QoS-aware bandwidth allocation and bandwidth-aware, energy-efficient VM placement-and discuss the research challenges and opportunities in this emerging area.",
    "lastUpdated": "2015-02-19T00:21:43Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1408.6891v2"
  },
  {
    "title": "Migrating to Cloud-Native Architectures Using Microservices: An Experience Report",
    "author": [
      "Armin Balalaie",
      "Abbas Heydarnoori",
      "Pooyan Jamshidi"
    ],
    "abstract": "Migration to the cloud has been a popular topic in industry and academia in recent years. Despite many benefits that the cloud presents, such as high availability and scalability, most of the on-premise application architectures are not ready to fully exploit the benefits of this environment, and adapting them to this environment is a non-trivial task. Microservices have appeared recently as novel architectural styles that are native to the cloud. These cloud-native architectures can facilitate migrating on-premise architectures to fully benefit from the cloud environments because non-functional attributes, like scalability, are inherent in this style. The existing approaches on cloud migration does not mostly consider cloud-native architectures as their first-class citizens. As a result, the final product may not meet its primary drivers for migration. In this paper, we intend to report our experience and lessons learned in an ongoing project on migrating a monolithic on-premise software architecture to microservices. We concluded that microservices is not a one-fit-all solution as it introduces new complexities to the system, and many factors, such as distribution complexities, should be considered before adopting this style. However, if adopted in a context that needs high flexibility in terms of scalability and availability, it can deliver its promised benefits.",
    "lastUpdated": "2015-07-29T16:52:39Z",
    "category": [
      "cs.SE",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1507.08217v1"
  },
  {
    "title": "Spherical Conformal Parameterization of Genus-0 Point Clouds for Meshing",
    "author": [
      "Gary Pui-Tung Choi",
      "Kin Tat Ho",
      "Lok Ming Lui"
    ],
    "abstract": "Point cloud is the most fundamental representation of 3D geometric objects. Analyzing and processing point cloud surfaces is important in computer graphics and computer vision. However, most of the existing algorithms for surface analysis require connectivity information. Therefore, it is desirable to develop a mesh structure on point clouds. This task can be simplified with the aid of a parameterization. In particular, conformal parameterizations are advantageous in preserving the geometric information of the point cloud data. In this paper, we extend a state-of-the-art spherical conformal parameterization algorithm for genus-0 closed meshes to the case of point clouds, using an improved approximation of the Laplace-Beltrami operator on data points. Then, we propose an iterative scheme called the North-South reiteration for achieving a spherical conformal parameterization. A balancing scheme is introduced to enhance the distribution of the spherical parameterization. High quality triangulations and quadrangulations can then be built on the point clouds with the aid of the parameterizations. Also, the meshes generated are guaranteed to be genus-0 closed meshes. Moreover, using our proposed spherical conformal parameterization, multilevel representations of point clouds can be easily constructed. Experimental results demonstrate the effectiveness of our proposed framework.",
    "lastUpdated": "2016-03-16T08:47:28Z",
    "category": [
      "cs.CG",
      "cs.CV",
      "cs.GR",
      "math.DG"
    ],
    "url": "http://arxiv.org/abs/1508.07569v3"
  },
  {
    "title": "Investigations into Elasticity in Cloud Computing",
    "author": [
      "Rui Han"
    ],
    "abstract": "The pay-as-you-go model supported by existing cloud infrastructure providers is appealing to most application service providers to deliver their applications in the cloud. Within this context, elasticity of applications has become one of the most important features in cloud computing. This elasticity enables real-time acquisition/release of compute resources to meet application performance demands. In this thesis we investigate the problem of delivering cost-effective elasticity services for cloud applications. Traditionally, the application level elasticity addresses the question of how to scale applications up and down to meet their performance requirements, but does not adequately address issues relating to minimising the costs of using the service. With this current limitation in mind, we propose a scaling approach that makes use of cost-aware criteria to detect the bottlenecks within multi-tier cloud applications, and scale these applications only at bottleneck tiers to reduce the costs incurred by consuming cloud infrastructure resources. Our approach is generic for a wide class of multi-tier applications, and we demonstrate its effectiveness by studying the behaviour of an example electronic commerce site application. Furthermore, we consider the characteristics of the algorithm for implementing the business logic of cloud applications, and investigate the elasticity at the algorithm level: when dealing with large-scale data under resource and time constraints, the algorithm's output should be elastic with respect to the resource consumed. We propose a novel framework to guide the development of elastic algorithms that adapt to the available budget while guaranteeing the quality of output result, e.g. prediction accuracy for classification tasks, improves monotonically with the used budget.",
    "lastUpdated": "2015-11-15T03:38:55Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1511.04651v1"
  },
  {
    "title": "Desktop to Cloud Migration of Scientific Computing Experiments",
    "author": [
      "Satish Narayana Srirama",
      "Pelle Jakovits",
      "Vladislav Ivaništšev"
    ],
    "abstract": "Scientific computing applications usually need huge amounts of computational power. The cloud provides interesting high-performance computing solutions, with its promise of virtually infinite resources on demand. However, migrating scientific computing problems to clouds and the re-creation of software environment on the vendor-supplied OS and cloud instances is often a laborious task. It is also assumed that the scientist who is performing the experiments has significant knowledge of computer science, cloud computing and the migration procedure, which is often not true. Considering these obstacles, we have designed a tool suite that migrates the complete software environment directly to the cloud. The developed desktop-to-cloud-migration (D2CM) tool supports transformation and migration of virtual machine images, reusable deployment description and life-cycle management for applications to be hosted on Amazon Cloud or compatible infrastructure such as Eucalyptus. The paper also presents an electrochemical case study and computational experiments targeted at designing modern supercapacitors. These experiments have extensively used the tool in drawing domain specific results. Detailed analysis of the case showed that D2CM tool not only simplifies the migration procedure for the scientists, but also helps them in optimizing the calculations and compute clusters, by providing them a new dimension -- cost-to-value of computational experiments.",
    "lastUpdated": "2015-11-25T14:54:46Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1511.08078v1"
  },
  {
    "title": "Multi-Cloud Resource Provisioning with Aneka: A Unified and Integrated Utilisation of Microsoft Azure and Amazon EC2 Instances",
    "author": [
      "Rajkumar Buyya",
      "Diana Barreto"
    ],
    "abstract": "Many vendors are offering computing services on subscription basis via Infrastructure-as-a-Service (IaaS) model. Users can acquire resources from different providers and get the best of each of them to run their applications. However, deploying applications in multi-cloud environments is a complex task. Therefore, application platforms are needed to help developers to succeed. Aneka is one such platform that supports developers to program and deploy distributed applications in multi-cloud environments. It can be used to provision resources from different cloud providers and can be configured to request resources dynamically according to the needs of specific applications. This paper presents extensions incorporated in Aneka to support the deployment of applications in multi-cloud environments. The first extension shows the flexibility of Aneka architecture to add cloud providers. Specifically, we describe the addition of Microsoft Azure IaaS cloud provider. We also discuss the inclusion of public IPs to communicate resources located in different networks and the functionality of using PowerShell to automatize installation of Aneka on remote resources. We demonstrate how an application composed of independent tasks improves its total execution time when it is deployed in the multi-cloud environment created by Aneka using resources provisioned from Azure and EC2.",
    "lastUpdated": "2015-11-28T01:06:11Z",
    "category": [
      "cs.DC",
      "C.2.4"
    ],
    "url": "http://arxiv.org/abs/1511.08857v1"
  },
  {
    "title": "Query Processing For The Internet-of-Things: Coupling Of Device Energy Consumption And Cloud Infrastructure Billing",
    "author": [
      "Francesco Renna",
      "Joseph Doyle",
      "Vasileios Giotsas",
      "Yiannis Andreopoulos"
    ],
    "abstract": "Audio/visual recognition and retrieval applications have recently garnered significant attention within Internet-of-Things (IoT) oriented services, given that video cameras and audio processing chipsets are now ubiquitous even in low-end embedded systems. In the most typical scenario for such services, each device extracts audio/visual features and compacts them into feature descriptors, which comprise media queries. These queries are uploaded to a remote cloud computing service that performs content matching for classification or retrieval applications. Two of the most crucial aspects for such services are: (i) controlling the device energy consumption when using the service; (ii) reducing the billing cost incurred from the cloud infrastructure provider. In this paper we derive analytic conditions for the optimal coupling between the device energy consumption and the incurred cloud infrastructure billing. Our framework encapsulates: the energy consumption to produce and transmit audio/visual queries, the billing rates of the cloud infrastructure, the number of devices concurrently connected to the same cloud server, and the statistics of the query data production volume per device. Our analytic results are validated via a deployment with: (i) the device side comprising compact image descriptors (queries) computed on Beaglebone Linux embedded platforms and transmitted to Amazon Web Services (AWS) Simple Storage Service; (ii) the cloud side carrying out image similarity detection via AWS Elastic Compute Cloud (EC2) spot instances, with the AWS Auto Scaling being used to control the number of instances according to the demand.",
    "lastUpdated": "2016-02-10T12:32:27Z",
    "category": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1602.03350v1"
  },
  {
    "title": "Media Query Processing For The Internet-of-Things: Coupling Of Device Energy Consumption And Cloud Infrastructure Billing",
    "author": [
      "Francesco Renna",
      "Joseph Doyle",
      "Vasileios Giotsas",
      "Yiannis Andreopoulos"
    ],
    "abstract": "Audio/visual recognition and retrieval applications have recently garnered significant attention within Internet-of-Things (IoT) oriented services, given that video cameras and audio processing chipsets are now ubiquitous even in low-end embedded systems. In the most typical scenario for such services, each device extracts audio/visual features and compacts them into feature descriptors, which comprise media queries. These queries are uploaded to a remote cloud computing service that performs content matching for classification or retrieval applications. Two of the most crucial aspects for such services are: (i) controlling the device energy consumption when using the service; (ii) reducing the billing cost incurred from the cloud infrastructure provider. In this paper we derive analytic conditions for the optimal coupling between the device energy consumption and the incurred cloud infrastructure billing. Our framework encapsulates: the energy consumption to produce and transmit audio/visual queries, the billing rates of the cloud infrastructure, the number of devices concurrently connected to the same cloud server, {the query volume constraint of each cluster of devices,} and the statistics of the query data production volume per device. Our analytic results are validated via a deployment with: (i) the device side comprising compact image descriptors (queries) computed on Beaglebone Linux embedded platforms and transmitted to Amazon Web Services (AWS) Simple Storage Service; (ii) the cloud side carrying out image similarity detection via AWS Elastic Compute Cloud (EC2) instances, with the AWS Auto Scaling being used to control the number of instances according to the demand.",
    "lastUpdated": "2016-08-02T18:40:03Z",
    "category": [
      "cs.MM",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1608.00925v1"
  },
  {
    "title": "A Survey on the Adoption of Cloud Computing in Education Sector",
    "author": [
      "Rania Almajalid"
    ],
    "abstract": "Education is a key factor in ensuring economic growth, especially for countries with growing economies. Today, students have become more technologically savvy as teaching and learning uses more advance technology day in, day out. Due to virtualize resources through the Internet, as well as dynamic scalability, cloud computing has continued to be adopted by more organizations. Despite the looming financial crisis, there has been increasing pressure for educational institutions to deliver better services using minimal resources. Leaning institutions, both public and private can utilize the potential advantage of cloud computing to ensure high quality service regardless of the minimal resources available. Cloud computing is taking a center stage in academia because of its various benefits. Various learning institutions use different cloud-based applications provided by the service providers to ensure that their students and other users can perform both academic as well as business-related tasks. Thus, this research will seek to establish the benefits associated with the use of cloud computing in learning institutions. The solutions provided by the cloud technology ensure that the research and development, as well as the teaching is more sustainable and efficient, thus positively influencing the quality of learning and teaching within educational institutions. This has led to various learning institutions adopting cloud technology as a solution to various technological challenges they face on a daily routine.",
    "lastUpdated": "2017-06-04T19:44:29Z",
    "category": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1706.01136v1"
  },
  {
    "title": "Boosting Metrics for Cloud Services Evaluation -- The Last Mile of Using Benchmark Suites",
    "author": [
      "Zheng Li",
      "Liam O'Brien",
      "Rainbow Cai",
      "He Zhang"
    ],
    "abstract": "Benchmark suites are significant for evaluating various aspects of Cloud services from a holistic view. However, there is still a gap between using benchmark suites and achieving holistic impression of the evaluated Cloud services. Most Cloud service evaluation work intended to report individual benchmarking results without delivering summary measures. As a result, it could be still hard for customers with such evaluation reports to understand an evaluated Cloud service from a global perspective. Inspired by the boosting approaches to machine learning, we proposed the concept Boosting Metrics to represent all the potential approaches that are able to integrate a suite of benchmarking results. This paper introduces two types of preliminary boosting metrics, and demonstrates how the boosting metrics can be used to supplement primary measures of individual Cloud service features. In particular, boosting metrics can play a summary Response role in applying experimental design to Cloud services evaluation. Although the concept Boosting Metrics was refined based on our work in the Cloud Computing domain, we believe it can be easily adapted to the evaluation work of other computing paradigms.",
    "lastUpdated": "2017-08-04T08:25:15Z",
    "category": [
      "cs.DC",
      "cs.PF"
    ],
    "url": "http://arxiv.org/abs/1708.01414v1"
  },
  {
    "title": "Deep Scattering: Rendering Atmospheric Clouds with Radiance-Predicting Neural Networks",
    "author": [
      "Simon Kallweit",
      "Thomas Müller",
      "Brian McWilliams",
      "Markus Gross",
      "Jan Novák"
    ],
    "abstract": "We present a technique for efficiently synthesizing images of atmospheric clouds using a combination of Monte Carlo integration and neural networks. The intricacies of Lorenz-Mie scattering and the high albedo of cloud-forming aerosols make rendering of clouds---e.g. the characteristic silverlining and the \"whiteness\" of the inner body---challenging for methods based solely on Monte Carlo integration or diffusion theory. We approach the problem differently. Instead of simulating all light transport during rendering, we pre-learn the spatial and directional distribution of radiant flux from tens of cloud exemplars. To render a new scene, we sample visible points of the cloud and, for each, extract a hierarchical 3D descriptor of the cloud geometry with respect to the shading location and the light source. The descriptor is input to a deep neural network that predicts the radiance function for each shading configuration. We make the key observation that progressively feeding the hierarchical descriptor into the network enhances the network's ability to learn faster and predict with high accuracy while using few coefficients. We also employ a block design with residual connections to further improve performance. A GPU implementation of our method synthesizes images of clouds that are nearly indistinguishable from the reference solution within seconds interactively. Our method thus represents a viable solution for applications such as cloud design and, thanks to its temporal stability, also for high-quality production of animated content.",
    "lastUpdated": "2017-09-15T21:40:02Z",
    "category": [
      "cs.LG",
      "cs.GR",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1709.05418v1"
  },
  {
    "title": "Towards Mission-Critical Control at the Edge and Over 5G",
    "author": [
      "Per Skarin",
      "William Tärneberg",
      "Karl-Erik Årzen",
      "Maria Kihl"
    ],
    "abstract": "With the emergence of industrial IoT and cloud computing, and the advent of 5G and edge clouds, there are ambitious expectations on elasticity, economies of scale, and fast time to market for demanding use cases in the next generation of ICT networks. Responsiveness and reliability of wireless communication links and services in the cloud are set to improve significantly as the concept of edge clouds is becoming more prevalent. To enable industrial uptake we must provide cloud capacity in the networks but also a sufficient level of simplicity and self-sustainability in the software platforms. In this paper, we present a research test-bed built to study mission-critical control over the distributed edge cloud. We evaluate system properties using a conventional control application in the form of a Model Predictive Controller. Our cloud platform provides the means to continuously operate our mission-critical application while seamlessly relocating computations across geographically dispersed compute nodes. Through our use of 5G wireless radio, we allow for mobility and reliably provide compute resources with low latency, at the edge. The primary contribution of this paper is a state-of-the art, fully operational test-bed showing the potential for merged IoT, 5G, and cloud. We also provide an evaluation of the system while operating a mission-critical application and provide an outlook on a novel research direction.",
    "lastUpdated": "2018-06-18T08:25:56Z",
    "category": [
      "cs.SY",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1803.02123v2"
  },
  {
    "title": "iSTRICT: An Interdependent Strategic Trust Mechanism for the Cloud-Enabled Internet of Controlled Things",
    "author": [
      "Jeffrey Pawlick",
      "Juntao Chen",
      "Quanyan Zhu"
    ],
    "abstract": "The cloud-enabled Internet of controlled things (IoCT) envisions a network of sensors, controllers, and actuators connected through a local cloud in order to intelligently control physical devices. Because cloud services are vulnerable to advanced persistent threats (APTs), each device in the IoCT must strategically decide whether to trust cloud services that may be compromised. In this paper, we present iSTRICT, an interdependent strategic trust mechanism for the cloud-enabled IoCT. iSTRICT is composed of three interdependent layers. In the cloud layer, iSTRICT uses FlipIt games to conceptualize APTs. In the communication layer, it captures the interaction between devices and the cloud using signaling games. In the physical layer, iSTRICT uses optimal control to quantify the utilities in the higher level games. Best response dynamics link the three layers in an overall \"game-of-games,\" for which the outcome is captured by a concept called Gestalt Nash equilibrium (GNE). We prove the existence of a GNE under a set of natural assumptions and develop an adaptive algorithm to iteratively compute the equilibrium. Finally, we apply iSTRICT to trust management for autonomous vehicles that rely on measurements from remote sources. We show that strategic trust in the communication layer achieves a worst-case probability of compromise for any attack and defense costs in the cyber layer.",
    "lastUpdated": "2018-11-15T14:13:16Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1805.00403v2"
  },
  {
    "title": "Big Data Analytics-Enhanced Cloud Computing: Challenges, Architectural Elements, and Future Directions",
    "author": [
      "Rajkumar Buyya",
      "Kotagiri Ramamohanarao",
      "Chris Leckie",
      "Rodrigo N. Calheiros",
      "Amir Vahid Dastjerdi",
      "Steve Versteeg"
    ],
    "abstract": "The emergence of cloud computing has made dynamic provisioning of elastic capacity to applications on-demand. Cloud data centers contain thousands of physical servers hosting orders of magnitude more virtual machines that can be allocated on demand to users in a pay-as-you-go model. However, not all systems are able to scale up by just adding more virtual machines. Therefore, it is essential, even for scalable systems, to project workloads in advance rather than using a purely reactive approach. Given the scale of modern cloud infrastructures generating real time monitoring information, along with all the information generated by operating systems and applications, this data poses the issues of volume, velocity, and variety that are addressed by Big Data approaches. In this paper, we investigate how utilization of Big Data analytics helps in enhancing the operation of cloud computing environments. We discuss diverse applications of Big Data analytics in clouds, open issues for enhancing cloud operations via Big Data analytics, and architecture for anomaly detection and prevention in clouds along with future research directions.",
    "lastUpdated": "2015-10-22T04:07:55Z",
    "category": [
      "cs.DC",
      "C.1.4; C.2.4"
    ],
    "url": "http://arxiv.org/abs/1510.06486v1"
  },
  {
    "title": "Cloud Kotta: Enabling Secure and Scalable Data Analytics in the Cloud",
    "author": [
      "Yadu N. Babuji",
      "Kyle Chard",
      "Aaron Gerow",
      "Eamon Duede"
    ],
    "abstract": "Distributed communities of researchers rely increasingly on valuable, proprietary, or sensitive datasets. Given the growth of such data, especially in fields new to data-driven, computationally intensive research like the social sciences and humanities, coupled with what are often strict and complex data-use agreements, many research communities now require methods that allow secure, scalable and cost-effective storage and analysis. Here we present CLOUD KOTTA: a cloud-based data management and analytics framework. CLOUD KOTTA delivers an end-to-end solution for coordinating secure access to large datasets, and an execution model that provides both automated infrastructure scaling and support for executing analytics near to the data. CLOUD KOTTA implements a fine-grained security model ensuring that only authorized users may access, analyze, and download protected data. It also implements automated methods for acquiring and configuring low-cost storage and compute resources as they are needed. We present the architecture and implementation of CLOUD KOTTA and demonstrate the advantages it provides in terms of increased performance and flexibility. We show that CLOUD KOTTA's elastic provisioning model can reduce costs by up to 16x when compared with statically provisioned models.",
    "lastUpdated": "2016-10-18T19:07:46Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1610.03108v2"
  },
  {
    "title": "An Approach to Controller Design Based on the Generalized Cloud Model",
    "author": [
      "UnSun Pak",
      "YongChol Sin",
      "ChungJin Kwak",
      "GyongIl Ryang"
    ],
    "abstract": "In this paper, an approach to controller design based on the cloud models, without using the analog plant model is presented.",
    "lastUpdated": "2017-02-10T07:25:28Z",
    "category": [
      "cs.SY"
    ],
    "url": "http://arxiv.org/abs/1702.03083v1"
  },
  {
    "title": "Integration of QoS aspects in the Cloud Computing Research and Selection System",
    "author": [
      "Manar Abourezq",
      "Abdellah Idrissi"
    ],
    "abstract": "Cloud Computing is a business model revolution more than a technological one. It capitalized on various technologies that have proved themselves and reshaped the use of computers by replacing their local use by a centralized one where shared resources are stored and managed by a third-party in a way transparent to end-users. With this new use came new needs and one of them is the need to search through Cloud services and select the ones that meet certain requirements. To address this need, we have developed, in a previous work, the Cloud Service Research and Selection System (CSRSS) which aims to allow Cloud users to search through Cloud services in the database and find the ones that match their requirements. It is based on the Skyline and ELECTRE IS. In this paper, we improve the system by introducing 7 new dimensions related to QoS constraints. Our work's main contribution is conceiving an Agent that uses both the Skyline and an outranking method, called ELECTREIsSkyline, to determine which Cloud services meet better the users' requirements while respecting QoS properties. We programmed and tested this method for a total of 10 dimensions and for 50 000 cloud services. The first results are very promising and show the effectiveness of our approach.",
    "lastUpdated": "2015-12-27T20:51:34Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1702.04966v1"
  },
  {
    "title": "An Efficient Framework for Information Security in Cloud Computing Using Auditing Algorithm Shell (AAS)",
    "author": [
      "M. Omer Mushtaq",
      "Furrakh Shahzad",
      "M. Owais Tariq",
      "Mahina Riaz",
      "Bushra Majeed"
    ],
    "abstract": "There is a dynamic escalation and extension in the new infrastructure, educating personnel and licensing new computer programs in the field of IT, due to the emergence of Cloud Computing (CC) paradigm. It has become a quick growing segment of IT business in last couple of years. However, due to the rapid growth of data, people and IT firms, the issue of information security is getting more complex. One of the major concerns of the user is, at what degree the data is safe on Cloud? In spite of all promotional material encompassing the cloud, consortium customers are not willing to shift their business on the cloud. Data security is the major problem which has limited the scope of cloud computing. In new cloud computing infrastructure, the techniques such as the Strong Secure Shell and Encryption are deployed to guarantee the authenticity of the user through logs systems. The vendors utilize these logs to analyze and view their data. Therefore, this implementation is not enough to ensure security, privacy and authoritative use of the data. This paper introduces quad layered framework for data security, data privacy, data breaches and process associated aspects. Using this layered architecture we have preserved the secrecy of confidential information and tried to build the trust of user on cloud computing. This layered framework prevents the confidential information by multiple means i.e. Secure Transmission of Data, Encrypted Data and its Processing, Database Secure Shell and Internal/external log Auditing.",
    "lastUpdated": "2017-02-23T09:06:07Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1702.07140v1"
  },
  {
    "title": "HPC Cloud for Scientific and Business Applications: Taxonomy, Vision, and Research Challenges",
    "author": [
      "Marco A. S. Netto",
      "Rodrigo N. Calheiros",
      "Eduardo R. Rodrigues",
      "Renato L. F. Cunha",
      "Rajkumar Buyya"
    ],
    "abstract": "High Performance Computing (HPC) clouds are becoming an alternative to on-premise clusters for executing scientific applications and business analytics services. Most research efforts in HPC cloud aim to understand the cost-benefit of moving resource-intensive applications from on-premise environments to public cloud platforms. Industry trends show hybrid environments are the natural path to get the best of the on-premise and cloud resources---steady (and sensitive) workloads can run on on-premise resources and peak demand can leverage remote resources in a pay-as-you-go manner. Nevertheless, there are plenty of questions to be answered in HPC cloud, which range from how to extract the best performance of an unknown underlying platform to what services are essential to make its usage easier. Moreover, the discussion on the right pricing and contractual models to fit small and large users is relevant for the sustainability of HPC clouds. This paper brings a survey and taxonomy of efforts in HPC cloud and a vision on what we believe is ahead of us, including a set of research challenges that, once tackled, can help advance businesses and scientific discoveries. This becomes particularly relevant due to the fast increasing wave of new HPC applications coming from big data and artificial intelligence.",
    "lastUpdated": "2018-02-02T13:42:19Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1710.08731v3"
  },
  {
    "title": "A Game-theoretic Framework for Revenue Sharing in Edge-Cloud Computing System",
    "author": [
      "Zhi Cao",
      "Honggang Zhang",
      "Benyuan Liu",
      "Bo Sheng"
    ],
    "abstract": "We introduce a game-theoretic framework to ex- plore revenue sharing in an Edge-Cloud computing system, in which computing service providers at the edge of the Internet (edge providers) and computing service providers at the cloud (cloud providers) co-exist and collectively provide computing resources to clients (e.g., end users or applications) at the edge. Different from traditional cloud computing, the providers in an Edge-Cloud system are independent and self-interested. To achieve high system-level efficiency, the manager of the system adopts a task distribution mechanism to maximize the total revenue received from clients and also adopts a revenue sharing mechanism to split the received revenue among computing servers (and hence service providers). Under those system-level mechanisms, service providers attempt to game with the system in order to maximize their own utilities, by strategically allocating their resources (e.g., computing servers). Our framework models the competition among the providers in an Edge-Cloud system as a non-cooperative game. Our simulations and experiments on an emulation system have shown the existence of Nash equilibrium in such a game. We find that revenue sharing mechanisms have a significant impact on the system-level efficiency at Nash equilibria, and surprisingly the revenue sharing mechanism based directly on actual contributions can result in significantly worse system efficiency than Shapley value sharing mechanism and Ortmann proportional sharing mechanism. Our framework provides an effective economics approach to understanding and designing efficient Edge-Cloud computing systems.",
    "lastUpdated": "2018-10-05T03:12:57Z",
    "category": [
      "cs.GT",
      "cs.DC",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1711.10102v2"
  },
  {
    "title": "JointDNN: An Efficient Training and Inference Engine for Intelligent Mobile Cloud Computing Services",
    "author": [
      "Amir Erfan Eshratifar",
      "Mohammad Saeed Abrishami",
      "Massoud Pedram"
    ],
    "abstract": "Deep learning models are being deployed in many mobile intelligent applications. End-side services, such as intelligent personal assistants, autonomous cars, and smart home services often employ either simple local models on the mobile or complex remote models on the cloud. However, recent studies have shown that partitioning the DNN computations between the mobile and cloud can increase the latency and energy efficiencies. In this paper, we propose an efficient, adaptive, and practical engine, JointDNN, for collaborative computation between a mobile device and cloud for DNNs in both inference and training phase. JointDNN not only provides an energy and performance efficient method of querying DNNs for the mobile side but also benefits the cloud server by reducing the amount of its workload and communications compared to the cloud-only approach. Given the DNN architecture, we investigate the efficiency of processing some layers on the mobile device and some layers on the cloud server. We provide optimization formulations at layer granularity for forward- and backward-propagations in DNNs, which can adapt to mobile battery limitations and cloud server load constraints and quality of service. JointDNN achieves up to 18 and 32 times reductions on the latency and mobile energy consumption of querying DNNs compared to the status-quo approaches, respectively.",
    "lastUpdated": "2020-02-04T20:53:08Z",
    "category": [
      "cs.DC",
      "cs.AI",
      "cs.LG",
      "cs.PF"
    ],
    "url": "http://arxiv.org/abs/1801.08618v2"
  },
  {
    "title": "Detecting Comma-shaped Clouds for Severe Weather Forecasting using Shape and Motion",
    "author": [
      "Xinye Zheng",
      "Jianbo Ye",
      "Yukun Chen",
      "Stephen Wistar",
      "Jia Li",
      "Jose A. Piedra-Fernández",
      "Michael A. Steinberg",
      "James Z. Wang"
    ],
    "abstract": "Meteorologists use shapes and movements of clouds in satellite images as indicators of several major types of severe storms. Satellite imaginary data are in increasingly higher resolution, both spatially and temporally, making it impossible for humans to fully leverage the data in their forecast. Automatic satellite imagery analysis methods that can find storm-related cloud patterns as soon as they are detectable are in demand. We propose a machine learning and pattern recognition based approach to detect \"comma-shaped\" clouds in satellite images, which are specific cloud distribution patterns strongly associated with the cyclone formulation. In order to detect regions with the targeted movement patterns, our method is trained on manually annotated cloud examples represented by both shape and motion-sensitive features. Sliding windows in different scales are used to ensure that dense clouds will be captured, and we implement effective selection rules to shrink the region of interest among these sliding windows. Finally, we evaluate the method on a hold-out annotated comma-shaped cloud dataset and cross-match the results with recorded storm events in the severe weather database. The validated utility and accuracy of our method suggest a high potential for assisting meteorologists in weather forecasting.",
    "lastUpdated": "2018-12-13T18:27:28Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1802.08937v3"
  },
  {
    "title": "A LiDAR Point Cloud Generator: from a Virtual World to Autonomous Driving",
    "author": [
      "Xiangyu Yue",
      "Bichen Wu",
      "Sanjit A. Seshia",
      "Kurt Keutzer",
      "Alberto L. Sangiovanni-Vincentelli"
    ],
    "abstract": "3D LiDAR scanners are playing an increasingly important role in autonomous driving as they can generate depth information of the environment. However, creating large 3D LiDAR point cloud datasets with point-level labels requires a significant amount of manual annotation. This jeopardizes the efficient development of supervised deep learning algorithms which are often data-hungry. We present a framework to rapidly create point clouds with accurate point-level labels from a computer game. The framework supports data collection from both auto-driving scenes and user-configured scenes. Point clouds from auto-driving scenes can be used as training data for deep learning algorithms, while point clouds from user-configured scenes can be used to systematically test the vulnerability of a neural network, and use the falsifying examples to make the neural network more robust through retraining. In addition, the scene images can be captured simultaneously in order for sensor fusion tasks, with a method proposed to do automatic calibration between the point clouds and captured scene images. We show a significant improvement in accuracy (+9%) in point cloud segmentation by augmenting the training dataset with the generated synthesized data. Our experiments also show by testing and retraining the network using point clouds from user-configured scenes, the weakness/blind spots of the neural network can be fixed.",
    "lastUpdated": "2018-03-31T01:32:11Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1804.00103v1"
  },
  {
    "title": "A Two-Stage Auction Mechanism for Cloud Resource Allocation",
    "author": [
      "Seyyedali Hosseinalipour",
      "Huaiyu Dai"
    ],
    "abstract": "With the recent growth in the size of cloud computing business, handling the interactions between customers and cloud providers has become more challenging. Auction theory has been proposed to model these interactions due to its simplicity and a good match with real-world scenarios. In this paper, we consider cloud of clouds networks (CCNs) with different types of servers along with customers with heterogeneous demands. For each CCN, a CCN manager is designated to handle the cloud resources. A comprehensive framework is introduced in which the process of resource gathering and allocation is addressed via two stages, where the first stage models the interactions between customers and CCN managers, and the second stage examines the interactions between CCN managers and private cloud providers (CPs). For the first stage, an options-based sequential auction (OBSA) is adapted to the examined market, which is capable of providing truthfulness as the dominant strategy and resolving the entrance time problem. An analytical foundation for OBSAs is presented and multiple performance metrics are derived. For the second stage, two parallel markets are assumed: flat-price and auction-based market. A theoretical framework for market analysis is provided and the bidding behavior of CCN managers is described.",
    "lastUpdated": "2018-10-29T15:36:12Z",
    "category": [
      "cs.DC",
      "cs.GT"
    ],
    "url": "http://arxiv.org/abs/1807.04214v2"
  },
  {
    "title": "A Fog Robotic System for Dynamic Visual Servoing",
    "author": [
      "Nan Tian",
      "Jinfa Chen",
      "Mas Ma",
      "Robert Zhang",
      "Bill Huang",
      "Ken Goldberg",
      "Somayeh Sojoudi"
    ],
    "abstract": "Cloud Robotics is a paradigm where distributed robots are connected to cloud services via networks to access unlimited computation power, at the cost of network communication. However, due to limitations such as network latency and variability, it is difficult to control dynamic, human compliant service robots directly from the cloud. In this work, by leveraging asynchronous protocol with a heartbeat signal, we combine cloud robotics with a smart edge device to build a Fog Robotic system. We use the system to enable robust teleoperation of a dynamic self-balancing robot from the cloud. We first use the system to pick up boxes from static locations, a task commonly performed in warehouse logistics. To make cloud teleoperation more efficient, we deploy image based visual servoing (IBVS) to perform box pickups automatically. Visual feedbacks, including apriltag recognition and tracking, are performed in the cloud to emulate a Fog Robotic object recognition system for IBVS. We demonstrate the feasibility of real-time dynamic automation system using this cloud-edge hybrid, which opens up possibilities of deploying dynamic robotic control with deep-learning recognition systems in Fog Robotics. Finally, we show that Fog Robotics enables the self-balancing service robot to pick up a box automatically from a person under unstructured environments.",
    "lastUpdated": "2018-09-16T07:58:09Z",
    "category": [
      "cs.RO",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1809.06716v1"
  },
  {
    "title": "Local Frequency Interpretation and Non-Local Self-Similarity on Graph for Point Cloud Inpainting",
    "author": [
      "Zeqing Fu",
      "Wei Hu",
      "Zongming Guo"
    ],
    "abstract": "As 3D scanning devices and depth sensors mature, point clouds have attracted increasing attention as a format for 3D object representation, with applications in various fields such as tele-presence, navigation and heritage reconstruction. However, point clouds usually exhibit holes of missing data, mainly due to the limitation of acquisition techniques and complicated structure. Further, point clouds are defined on irregular non-Euclidean domains, which is challenging to address especially with conventional signal processing tools. Hence, leveraging on recent advances in graph signal processing, we propose an efficient point cloud inpainting method, exploiting both the local smoothness and the non-local self-similarity in point clouds. Specifically, we first propose a frequency interpretation in graph nodal domain, based on which we introduce the local graph-signal smoothness prior in order to describe the local smoothness of point clouds. Secondly, we explore the characteristics of non-local self-similarity, by globally searching for the most similar area to the missing region. The similarity metric between two areas is defined based on the direct component and the anisotropic graph total variation of normals in each area. Finally, we formulate the hole-filling step as an optimization problem based on the selected most similar area and regularized by the graph-signal smoothness prior. Besides, we propose voxelization and automatic hole detection methods for the point cloud prior to inpainting. Experimental results show that the proposed approach outperforms four competing methods significantly, both in objective and subjective quality.",
    "lastUpdated": "2018-09-28T13:08:49Z",
    "category": [
      "cs.CV",
      "cs.MM"
    ],
    "url": "http://arxiv.org/abs/1810.03973v1"
  },
  {
    "title": "Super-pixel cloud detection using Hierarchical Fusion CNN",
    "author": [
      "Han Liu",
      "Dan Zeng",
      "Qi Tian"
    ],
    "abstract": "Cloud detection plays a very important role in the process of remote sensing images. This paper designs a super-pixel level cloud detection method based on convolutional neural network (CNN) and deep forest. Firstly, remote sensing images are segmented into super-pixels through the combination of SLIC and SEEDS. Structured forests is carried out to compute edge probability of each pixel, based on which super-pixels are segmented more precisely. Segmented super-pixels compose a super-pixel level remote sensing database. Though cloud detection is essentially a binary classification problem, our database is labeled into four categories: thick cloud, cirrus cloud, building and other culture, to improve the generalization ability of our proposed models. Secondly, super-pixel level database is used to train our cloud detection models based on CNN and deep forest. Considering super-pixel level remote sensing images contain less semantic information compared with general object classification database, we propose a Hierarchical Fusion CNN (HFCNN). It takes full advantage of low-level features like color and texture information and is more applicable to cloud detection task. In test phase, every super-pixel in remote sensing images is classified by our proposed models and then combined to recover final binary mask by our proposed distance metric, which is used to determine ambiguous super-pixels. Experimental results show that, compared with conventional methods, HFCNN can achieve better precision and recall.",
    "lastUpdated": "2018-10-19T04:37:46Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1810.08352v1"
  },
  {
    "title": "CPAR: Cloud-Assisted Privacy-preserving Image Annotation with Randomized KD-Forest",
    "author": [
      "Yifan Tian",
      "Yantian Hou",
      "Jiawei Yuan"
    ],
    "abstract": "With the explosive growth in the number of pictures taken by smartphones, organizing and searching pictures has become important tasks. To efficiently fulfill these tasks, the key enabler is annotating images with proper keywords, with which keyword-based searching and organizing become available for images. Currently, smartphones usually synchronize photo albums with cloud storage platforms, and have their images annotated with the help of cloud computing. However, the \"offloading-to-cloud\" solution may cause privacy breach, since photos from smart photos contain various sensitive information. For privacy protection, existing research made effort to support cloud-based image annotation on encrypted images by utilizing cryptographic primitives. Nevertheless, for each annotation, it requires the cloud to perform linear checking on the large-scale encrypted dataset with high computational cost. This paper proposes a cloud-assisted privacy-preserving image annotation with randomized kd-forest, namely CPAR. With CPAR, users are able to automatically assign keywords to their images by leveraging the power of cloud with privacy protected. CPAR proposes a novel privacy-preserving randomized kd-forest structure, which significantly improves the annotation performance compared with existing research. Thorough analysis is carried out to demonstrate the security of CPAR. Experimental evaluation on the well-known IAPR TC-12 dataset validates the efficiency and effectiveness of CPAR.",
    "lastUpdated": "2019-02-12T18:52:10Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1811.04195v2"
  },
  {
    "title": "Evaluation of Energy-efficient VM Consolidation for Cloud Based Data Center - Revisited",
    "author": [
      "Nasrin Akhter",
      "Mohamed Othman",
      "Ranesh Kumar Naha"
    ],
    "abstract": "In this paper, a re-evaluation undertaken for dynamic VM consolidation problem and optimal online deterministic algorithms for the single VM migration in an experimental environment. We proceeded to focus on energy and performance trade-off by planet lab workload traces, which consists of a thousand Planetlab VMs with widespread simulation environments. All experiments are done in a simulated cloud environment by the CloudSim simulation tool. A new paradigm of utility-oriented IT services is cloud computing, which offers a pay-as-you-go model. In recent years, there has been increasing interest among many users from business, scientific, engineering and educational territories in cloud computing. There is increasing concern that high energy consumption issues are a disadvantage for various institutions. However, so far too little attention has been given to the various methods to reduce energy consumption in cloud environments while ensuring performance. Besides the evaluation of energy-efficient data center management algorithms in the cloud, we proposed a further research directed toward the development of energy efficient algorithms. By the experimental evaluation of the current proposal for the competitive analysis of dynamic VM consolidation and optimal online deterministic algorithms for the single VM migration, we found different results for different algorithm combinations. Cloud-based data centers` consume massive energy, which has a negative effect on the environment and operational cost, this work contributes to the energy consumption reduction in the cloud environment.",
    "lastUpdated": "2018-12-15T08:43:36Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1812.06255v1"
  },
  {
    "title": "Energy-aware virtual machine selection method for cloud data center resource allocation",
    "author": [
      "Nasrin Akhter",
      "Mohamed Othman",
      "Ranesh Kumar Naha"
    ],
    "abstract": "Saving energy is an important issue for cloud providers to reduce energy cost in a data center. With the increasing popularity of cloud computing, it is time to examine various energy reduction methods for which energy consumption could be reduced and lead us to green cloud computing. In this paper, our aim is to propose a virtual machine selection algorithm to improve the energy efficiency of a cloud data center. We are also presenting experimental results of the proposed algorithm in a cloud computing based simulation environment. The proposed algorithm dynamically took the virtual machines' allocation, deallocation, and reallocation action to the physical server. However, it depends on the load and heuristics based on the analysis placement of a virtual machine which is decided over time. From the results obtained from the simulation, we have found that our proposed virtual machine selection algorithm reduces the total energy consumption by 19% compared to the existing one. Therefore, the energy consumption cost of a cloud data center reduces and also lowers the carbon footprint. Simulation-based experimental results show that the proposed heuristics which are based on resource provisioning algorithms reduce the energy consumption of the cloud data center and decrease the virtual machine's migration rate.",
    "lastUpdated": "2018-12-20T06:29:12Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1812.08375v1"
  },
  {
    "title": "PointWise: An Unsupervised Point-wise Feature Learning Network",
    "author": [
      "Matan Shoef",
      "Sharon Fogel",
      "Daniel Cohen-Or"
    ],
    "abstract": "We present a novel approach to learning a point-wise, meaningful embedding for point-clouds in an unsupervised manner, through the use of neural-networks. The domain of point-cloud processing via neural-networks is rapidly evolving, with novel architectures and applications frequently emerging. Within this field of research, the availability and plethora of unlabeled point-clouds as well as their possible applications make finding ways of characterizing this type of data appealing. Though significant advancement was achieved in the realm of unsupervised learning, its adaptation to the point-cloud representation is not trivial. Previous research focuses on the embedding of entire point-clouds representing an object in a meaningful manner. We present a deep learning framework to learn point-wise description from a set of shapes without supervision. Our approach leverages self-supervision to define a relevant loss function to learn rich per-point features. We train a neural-network with objectives based on context derived directly from the raw data, with no added annotation. We use local structures of point-clouds to incorporate geometric information into each point's latent representation. In addition to using local geometric information, we encourage adjacent points to have similar representations and vice-versa, creating a smoother, more descriptive representation. We demonstrate the ability of our method to capture meaningful point-wise features through three applications. By clustering the learned embedding space, we perform unsupervised part-segmentation on point clouds. By calculating euclidean distance in the latent space we derive semantic point-analogies. Finally, by retrieving nearest-neighbors in our learned latent space we present meaningful point-correspondence within and among point-clouds.",
    "lastUpdated": "2019-03-10T14:18:11Z",
    "category": [
      "cs.GR"
    ],
    "url": "http://arxiv.org/abs/1901.04544v2"
  },
  {
    "title": "Virtual Machines Embedding for Cloud PON AWGR and Server Based Data Centres",
    "author": [
      "Randa A. T. Alani",
      "Taisir E. H. El-Gorashi",
      "Jaafar M. H. Elmirghani"
    ],
    "abstract": "In this study, we investigate the embedding of various cloud applications in PON AWGR and Server Based Data Centres.",
    "lastUpdated": "2019-04-05T21:57:20Z",
    "category": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1904.03298v1"
  },
  {
    "title": "Reproducible Workflow on a Public Cloud for Computational Fluid Dynamics",
    "author": [
      "Olivier Mesnard",
      "Lorena A. Barba"
    ],
    "abstract": "In a new effort to make our research transparent and reproducible by others, we developed a workflow to run and share computational studies on the public cloud Microsoft Azure. It uses Docker containers to create an image of the application software stack. We also adopt several tools that facilitate creating and managing virtual machines on compute nodes and submitting jobs to these nodes. The configuration files for these tools are part of an expanded \"reproducibility package\" that includes workflow definitions for cloud computing, in addition to input files and instructions. This facilitates re-creating the cloud environment to re-run the computations under the same conditions. Although cloud providers have improved their offerings, many researchers using high-performance computing (HPC) are still skeptical about cloud computing. Thus, we ran benchmarks for tightly coupled applications to confirm that the latest HPC nodes of Microsoft Azure are indeed a viable alternative to traditional on-site HPC clusters. We also show that cloud offerings are now adequate to complete computational fluid dynamics studies with in-house research software that uses parallel computing with GPUs. Finally, we share with the community what we have learned from nearly two years of using Azure cloud to enhance transparency and reproducibility in our computational simulations.",
    "lastUpdated": "2019-09-25T18:59:13Z",
    "category": [
      "cs.CE",
      "physics.comp-ph"
    ],
    "url": "http://arxiv.org/abs/1904.07981v3"
  },
  {
    "title": "Adaptive Hierarchical Down-Sampling for Point Cloud Classification",
    "author": [
      "Ehsan Nezhadarya",
      "Ehsan Taghavi",
      "Ryan Razani",
      "Bingbing Liu",
      "Jun Luo"
    ],
    "abstract": "While several convolution-like operators have recently been proposed for extracting features out of point clouds, down-sampling an unordered point cloud in a deep neural network has not been rigorously studied. Existing methods down-sample the points regardless of their importance for the output. As a result, some important points in the point cloud may be removed, while less valuable points may be passed to the next layers. In contrast, adaptive down-sampling methods sample the points by taking into account the importance of each point, which varies based on the application, task and training data. In this paper, we propose a permutation-invariant learning-based adaptive down-sampling layer, called Critical Points Layer (CPL), which reduces the number of points in an unordered point cloud while retaining the important points. Unlike most graph-based point cloud down-sampling methods that use $k$-NN search algorithm to find the neighbouring points, CPL is a global down-sampling method, rendering it computationally very efficient. The proposed layer can be used along with any graph-based point cloud convolution layer to form a convolutional neural network, dubbed CP-Net in this paper. We introduce a CP-Net for $3$D object classification that achieves the best accuracy for the ModelNet$40$ dataset among point cloud-based methods, which validates the effectiveness of the CPL.",
    "lastUpdated": "2020-05-22T20:50:01Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1904.08506v2"
  },
  {
    "title": "RL-GAN-Net: A Reinforcement Learning Agent Controlled GAN Network for Real-Time Point Cloud Shape Completion",
    "author": [
      "Muhammad Sarmad",
      "Hyunjoo Jenny Lee",
      "Young Min Kim"
    ],
    "abstract": "We present RL-GAN-Net, where a reinforcement learning (RL) agent provides fast and robust control of a generative adversarial network (GAN). Our framework is applied to point cloud shape completion that converts noisy, partial point cloud data into a high-fidelity completed shape by controlling the GAN. While a GAN is unstable and hard to train, we circumvent the problem by (1) training the GAN on the latent space representation whose dimension is reduced compared to the raw point cloud input and (2) using an RL agent to find the correct input to the GAN to generate the latent space representation of the shape that best fits the current input of incomplete point cloud. The suggested pipeline robustly completes point cloud with large missing regions. To the best of our knowledge, this is the first attempt to train an RL agent to control the GAN, which effectively learns the highly nonlinear mapping from the input noise of the GAN to the latent space of point cloud. The RL agent replaces the need for complex optimization and consequently makes our technique real time. Additionally, we demonstrate that our pipelines can be used to enhance the classification accuracy of point cloud with missing data.",
    "lastUpdated": "2019-04-28T11:08:04Z",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1904.12304v1"
  },
  {
    "title": "SeeMoRe: A Fault-Tolerant Protocol for Hybrid Cloud Environments",
    "author": [
      "Mohammad Javad Amiri",
      "Sujaya Maiyya",
      "Divyakant Agrawal",
      "Amr El Abbadi"
    ],
    "abstract": "Large scale data management systems utilize State Machine Replication to provide fault tolerance and to enhance performance. Fault-tolerant protocols are extensively used in the distributed database infrastructure of large enterprises such as Google, Amazon, and Facebook, as well as permissioned blockchain systems like IBM's Hyperledger Fabric. However, and in spite of years of intensive research, existing fault-tolerant protocols do not adequately address all the characteristics of distributed system applications. In particular, hybrid cloud environments consisting of private and public clouds are widely used by enterprises. However, fault-tolerant protocols have not been adapted for such environments. In this paper, we introduce SeeMoRe, a hybrid State Machine Replication protocol to handle both crash and malicious failures in a public/private cloud environment. SeeMoRe considers a private cloud consisting of nonmalicious nodes (either correct or crash) and a public cloud with both Byzantine faulty and correct nodes. SeeMoRe has three different modes which can be used depending on the private cloud load and the communication latency between the public and the private cloud. We also introduce a dynamic mode switching technique to transition from one mode to another. Furthermore, we evaluate SeeMoRe using a series of benchmarks. The experiments reveal that SeeMoRe's performance is close to the state of the art crash fault-tolerant protocols while tolerating malicious failures.",
    "lastUpdated": "2019-06-18T23:45:35Z",
    "category": [
      "cs.DC",
      "cs.DB"
    ],
    "url": "http://arxiv.org/abs/1906.07850v1"
  },
  {
    "title": "PointFlow: 3D Point Cloud Generation with Continuous Normalizing Flows",
    "author": [
      "Guandao Yang",
      "Xun Huang",
      "Zekun Hao",
      "Ming-Yu Liu",
      "Serge Belongie",
      "Bharath Hariharan"
    ],
    "abstract": "As 3D point clouds become the representation of choice for multiple vision and graphics applications, the ability to synthesize or reconstruct high-resolution, high-fidelity point clouds becomes crucial. Despite the recent success of deep learning models in discriminative tasks of point clouds, generating point clouds remains challenging. This paper proposes a principled probabilistic framework to generate 3D point clouds by modeling them as a distribution of distributions. Specifically, we learn a two-level hierarchy of distributions where the first level is the distribution of shapes and the second level is the distribution of points given a shape. This formulation allows us to both sample shapes and sample an arbitrary number of points from a shape. Our generative model, named PointFlow, learns each level of the distribution with a continuous normalizing flow. The invertibility of normalizing flows enables the computation of the likelihood during training and allows us to train our model in the variational inference framework. Empirically, we demonstrate that PointFlow achieves state-of-the-art performance in point cloud generation. We additionally show that our model can faithfully reconstruct point clouds and learn useful representations in an unsupervised manner. The code will be available at https://github.com/stevenygd/PointFlow.",
    "lastUpdated": "2019-09-02T12:11:36Z",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1906.12320v3"
  },
  {
    "title": "Edge Computing for User-Centric Secure Search on Cloud-Based Encrypted Big Data",
    "author": [
      "Sahan Ahmad",
      "SM Zobaed",
      "Raju Gottumukkala",
      "Mohsen Amini Salehi"
    ],
    "abstract": "Cloud service providers offer a low-cost and convenient solution to host unstructured data. However, cloud services act as third-party solutions and do not provide control of the data to users. This has raised security and privacy concerns for many organizations (users) with sensitive data to utilize cloud-based solutions. User-side encryption can potentially address these concerns by establishing user-centric cloud services and granting data control to the user. Nonetheless, user-side encryption limits the ability to process (e.g., search) encrypted data on the cloud. Accordingly, in this research, we provide a framework that enables processing (in particular, searching) of encrypted multi-organizational (i.e., multi-source) big data without revealing the data to cloud provider. Our framework leverages locality feature of edge computing to offer a user-centric search ability in a real-time manner. In particular, the edge system intelligently predicts the user's search pattern and prunes the multi-source big data search space to reduce the search time. The pruning system is based on efficient sampling from the clustered big dataset on the cloud. For each cluster, the pruning system dynamically samples appropriate number of terms based on the user's search tendency, so that the cluster is optimally represented. We developed a prototype of a user-centric search system and evaluated it against multiple datasets. Experimental results demonstrate 27% improvement in the pruning quality and search accuracy.",
    "lastUpdated": "2019-08-10T02:19:37Z",
    "category": [
      "cs.CR",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1908.03668v1"
  },
  {
    "title": "LDLS: 3-D Object Segmentation Through Label Diffusion From 2-D Images",
    "author": [
      "Brian H. Wang",
      "Wei-Lun Chao",
      "Yan Wang",
      "Bharath Hariharan",
      "Kilian Q. Weinberger",
      "Mark Campbell"
    ],
    "abstract": "Object segmentation in three-dimensional (3-D) point clouds is a critical task for robots capable of 3-D perception. Despite the impressive performance of deep learning-based approaches on object segmentation in 2-D images, deep learning has not been applied nearly as successfully for 3-D point cloud segmentation. Deep networks generally require large amounts of labeled training data, which are readily available for 2-D images but are difficult to produce for 3-D point clouds. In this letter, we present Label Diffusion Lidar Segmentation (LDLS), a novel approach for 3-D point cloud segmentation, which leverages 2-D segmentation of an RGB image from an aligned camera to avoid the need for training on annotated 3-D data. We obtain 2-D segmentation predictions by applying Mask-RCNN to the RGB image, and then link this image to a 3-D lidar point cloud by building a graph of connections among 3-D points and 2-D pixels. This graph then directs a semi-supervised label diffusion process, where the 2-D pixels act as source nodes that diffuse object label information through the 3-D point cloud, resulting in a complete 3-D point cloud segmentation. We conduct empirical studies on the KITTI benchmark dataset and on a mobile robot, demonstrating wide applicability and superior performance of LDLS compared with the previous state of the art in 3-D point cloud segmentation, without any need for either 3-D training data or fine tuning of the 2-D image segmentation model.",
    "lastUpdated": "2019-10-30T16:11:23Z",
    "category": [
      "eess.IV",
      "cs.CV",
      "cs.RO"
    ],
    "url": "http://arxiv.org/abs/1910.13955v1"
  },
  {
    "title": "Spectral-GANs for High-Resolution 3D Point-cloud Generation",
    "author": [
      "Sameera Ramasinghe",
      "Salman Khan",
      "Nick Barnes",
      "Stephen Gould"
    ],
    "abstract": "Point-clouds are a popular choice for vision and graphics tasks due to their accurate shape description and direct acquisition from range-scanners. This demands the ability to synthesize and reconstruct high-quality point-clouds. Current deep generative models for 3D data generally work on simplified representations (e.g., voxelized objects) and cannot deal with the inherent redundancy and irregularity in point-clouds. A few recent efforts on 3D point-cloud generation offer limited resolution and their complexity grows with the increase in output resolution. In this paper, we develop a principled approach to synthesize 3D point-clouds using a spectral-domain Generative Adversarial Network (GAN). Our spectral representation is highly structured and allows us to disentangle various frequency bands such that the learning task is simplified for a GAN model. As compared to spatial-domain generative approaches, our formulation allows us to generate arbitrary number of points high-resolution point-clouds with minimal computational overhead. Furthermore, we propose a fully differentiable block to transform from {the} spectral to the spatial domain and back, thereby allowing us to integrate knowledge from well-established spatial models. We demonstrate that Spectral-GAN performs well for point-cloud generation task. Additionally, it can learn {a} highly discriminative representation in an unsupervised fashion and can be used to accurately reconstruct 3D objects.",
    "lastUpdated": "2020-07-19T08:50:33Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1912.01800v2"
  },
  {
    "title": "H2O-Cloud: A Resource and Quality of Service-Aware Task Scheduling Framework for Warehouse-Scale Data Centers -- A Hierarchical Hybrid DRL (Deep Reinforcement Learning) based Approach",
    "author": [
      "Mingxi Cheng",
      "Ji Li",
      "Paul Bogdan",
      "Shahin Nazarian"
    ],
    "abstract": "Cloud computing has attracted both end-users and Cloud Service Providers (CSPs) in recent years. Improving resource utilization rate (RUtR), such as CPU and memory usages on servers, while maintaining Quality-of-Service (QoS) is one key challenge faced by CSPs with warehouse-scale data centers. Prior works proposed various algorithms to reduce energy cost or to improve RUtR, which either lack the fine-grained task scheduling capabilities, or fail to take a comprehensive system model into consideration. This article presents H2O-Cloud, a Hierarchical and Hybrid Online task scheduling framework for warehouse-scale CSPs, to improve resource usage effectiveness while maintaining QoS. H2O-Cloud is highly scalable and considers comprehensive information such as various workload scenarios, cloud platform configurations, user request information and dynamic pricing model. The hierarchy and hybridity of the framework, combined with its deep reinforcement learning (DRL) engines, enable H2O-Cloud to efficiently start on-the-go scheduling and learning in an unpredictable environment without pre-training. Our experiments confirm the high efficiency of the proposed H2O-Cloud when compared to baseline approaches, in terms of energy and cost while maintaining QoS. Compared with a state-of-the-art DRL-based algorithm, H2O-Cloud achieves up to 201.17% energy cost efficiency improvement, 47.88% energy efficiency improvement and 551.76% reward rate improvement.",
    "lastUpdated": "2020-02-12T01:38:04Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1912.10808v3"
  },
  {
    "title": "Energy Efficient Algorithms based on VM Consolidation for Cloud Computing: Comparisons and Evaluations",
    "author": [
      "Qiheng Zhou",
      "Minxian Xu",
      "Sukhpal Singh Gill",
      "Chengxi Gao",
      "Wenhong Tian",
      "Chengzhong Xu",
      "Rajkumar Buyya"
    ],
    "abstract": "Cloud Computing paradigm has revolutionized IT industry and be able to offer computing as the fifth utility. With the pay-as-you-go model, cloud computing enables to offer the resources dynamically for customers anytime. Drawing the attention from both academia and industry, cloud computing is viewed as one of the backbones of the modern economy. However, the high energy consumption of cloud data centers contributes to high operational costs and carbon emission to the environment. Therefore, Green cloud computing is required to ensure energy efficiency and sustainability, which can be achieved via energy efficient techniques. One of the dominant approaches is to apply energy efficient algorithms to optimize resource usage and energy consumption. Currently, various virtual machine consolidation-based energy efficient algorithms have been proposed to reduce the energy of cloud computing environment. However, most of them are not compared comprehensively under the same scenario, and their performance is not evaluated with the same experimental settings. This makes users hard to select the appropriate algorithm for their objectives. To provide insights for existing energy efficient algorithms and help researchers to choose the most suitable algorithm, in this paper, we compare several state-of-the-art energy efficient algorithms in depth from multiple perspectives, including architecture, modelling and metrics. In addition, we also implement and evaluate these algorithms with the same experimental settings in CloudSim toolkit. The experimental results show the performance comparison of these algorithms with comprehensive results. Finally, detailed discussions of these algorithms are provided.",
    "lastUpdated": "2020-02-12T09:18:01Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/2002.04860v1"
  },
  {
    "title": "Model-based Joint Bit Allocation between Geometry and Color for Video-based 3D Point Cloud Compression",
    "author": [
      "Qi Liu",
      "Hui Yuan",
      "Junhui Hou",
      "Raouf Hamzaoui",
      "Honglei Su"
    ],
    "abstract": "Rate distortion optimization plays a very important role in image/video coding. But for 3D point cloud, this problem has not been investigated. In this paper, the rate and distortion characteristics of 3D point cloud are investigated in detail, and a typical and challenging rate distortion optimization problem is solved for 3D point cloud. Specifically, since the quality of the reconstructed 3D point cloud depends on both the geometry and color distortions, we first propose analytical rate and distortion models for the geometry and color information in video-based 3D point cloud compression platform, and then solve the joint bit allocation problem for geometry and color based on the derived models. To maximize the reconstructed quality of 3D point cloud, the bit allocation problem is formulated as a constrained optimization problem and solved by an interior point method. Experimental results show that the rate-distortion performance of the proposed solution is close to that obtained with exhaustive search but at only 0.68% of its time complexity. Moreover, the proposed rate and distortion models can also be used for the other rate-distortion optimization problems (such as prediction mode decision) and rate control technologies for 3D point cloud coding in the future.",
    "lastUpdated": "2020-03-27T16:00:47Z",
    "category": [
      "eess.IV",
      "cs.MM",
      "cs.SY",
      "eess.SY"
    ],
    "url": "http://arxiv.org/abs/2002.10798v2"
  },
  {
    "title": "Multi-Path Region Mining For Weakly Supervised 3D Semantic Segmentation on Point Clouds",
    "author": [
      "Jiacheng Wei",
      "Guosheng Lin",
      "Kim-Hui Yap",
      "Tzu-Yi Hung",
      "Lihua Xie"
    ],
    "abstract": "Point clouds provide intrinsic geometric information and surface context for scene understanding. Existing methods for point cloud segmentation require a large amount of fully labeled data. Using advanced depth sensors, collection of large scale 3D dataset is no longer a cumbersome process. However, manually producing point-level label on the large scale dataset is time and labor-intensive. In this paper, we propose a weakly supervised approach to predict point-level results using weak labels on 3D point clouds. We introduce our multi-path region mining module to generate pseudo point-level label from a classification network trained with weak labels. It mines the localization cues for each class from various aspects of the network feature using different attention modules. Then, we use the point-level pseudo labels to train a point cloud segmentation network in a fully supervised manner. To the best of our knowledge, this is the first method that uses cloud-level weak labels on raw 3D space to train a point cloud semantic segmentation network. In our setting, the 3D weak labels only indicate the classes that appeared in our input sample. We discuss both scene- and subcloud-level weakly labels on raw 3D point cloud data and perform in-depth experiments on them. On ScanNet dataset, our result trained with subcloud-level labels is compatible with some fully supervised methods.",
    "lastUpdated": "2020-03-29T14:13:29Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2003.13035v1"
  },
  {
    "title": "GRNet: Gridding Residual Network for Dense Point Cloud Completion",
    "author": [
      "Haozhe Xie",
      "Hongxun Yao",
      "Shangchen Zhou",
      "Jiageng Mao",
      "Shengping Zhang",
      "Wenxiu Sun"
    ],
    "abstract": "Estimating the complete 3D point cloud from an incomplete one is a key problem in many vision and robotics applications. Mainstream methods (e.g., PCN and TopNet) use Multi-layer Perceptrons (MLPs) to directly process point clouds, which may cause the loss of details because the structural and context of point clouds are not fully considered. To solve this problem, we introduce 3D grids as intermediate representations to regularize unordered point clouds. We therefore propose a novel Gridding Residual Network (GRNet) for point cloud completion. In particular, we devise two novel differentiable layers, named Gridding and Gridding Reverse, to convert between point clouds and 3D grids without losing structural information. We also present the differentiable Cubic Feature Sampling layer to extract features of neighboring points, which preserves context information. In addition, we design a new loss function, namely Gridding Loss, to calculate the L1 distance between the 3D grids of the predicted and ground truth point clouds, which is helpful to recover details. Experimental results indicate that the proposed GRNet performs favorably against state-of-the-art methods on the ShapeNet, Completion3D, and KITTI benchmarks.",
    "lastUpdated": "2020-07-20T11:22:05Z",
    "category": [
      "cs.CV",
      "cs.LG",
      "eess.IV"
    ],
    "url": "http://arxiv.org/abs/2006.03761v4"
  },
  {
    "title": "Economic and Business Dimensions Cloud Computing and Electricity: Beyond the Utility Model",
    "author": [
      "Erik Brynjolfsson",
      "Paul Hofmann",
      "John Jordan"
    ],
    "abstract": "An overly simplistic reliance on the utility model risks blinding us to the real opportunities and challenges of cloud computing.",
    "lastUpdated": "2020-06-07T19:40:39Z",
    "category": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2006.04244v1"
  },
  {
    "title": "Reproducible and Portable Workflows for Scientific Computing and HPC in the Cloud",
    "author": [
      "Peter Vaillancourt",
      "Bennett Wineholt",
      "Brandon Barker",
      "Plato Deliyannis",
      "Jackie Zheng",
      "Akshay Suresh",
      "Adam Brazier",
      "Rich Knepper",
      "Rich Wolski"
    ],
    "abstract": "The increasing availability of cloud computing services for science has changed the way scientific code can be developed, deployed, and run. Many modern scientific workflows are capable of running on cloud computing resources. Consequently, there is an increasing interest in the scientific computing community in methods, tools, and implementations that enable moving an application to the cloud and simplifying the process, and decreasing the time to meaningful scientific results. In this paper, we have applied the concepts of containerization for portability and multi-cloud automated deployment with industry-standard tools to three scientific workflows. We show how our implementations provide reduced complexity to portability of both the applications themselves, and their deployment across private and public clouds. Each application has been packaged in a Docker container with its dependencies and necessary environment setup for production runs. Terraform and Ansible have been used to automate the provisioning of compute resources and the deployment of each scientific application in a Multi-VM cluster. Each application has been deployed on the AWS and Aristotle Cloud Federation platforms. Variation in data management constraints, Multi-VM MPI communication, and embarrassingly parallel instance deployments were all explored and reported on. We thus present a sample of scientific workflows that can be simplified using the tools and our proposed implementation to deploy and run in a variety of cloud environments.",
    "lastUpdated": "2020-06-09T02:29:53Z",
    "category": [
      "cs.DC",
      "cs.SE",
      "J.2; C.2.4; H.3.4; I.0"
    ],
    "url": "http://arxiv.org/abs/2006.05016v1"
  },
  {
    "title": "An energy efficient service composition mechanism using a hybrid meta-heuristic algorithm in a mobile cloud environment",
    "author": [
      "Godar J. Ibrahim",
      "Tarik A. Rashid",
      "Mobayode O. Akinsolu"
    ],
    "abstract": "By increasing mobile devices in technology and human life, using a runtime and mobile services has gotten more complex along with the composition of a large number of atomic services. Different services are provided by mobile cloud components to represent the non-functional properties as Quality of Service (QoS), which is applied by a set of standards. On the other hand, the growth of the energy-source heterogeneity in mobile clouds is an emerging challenge according to the energy-saving problem in mobile nodes. To mobile cloud service composition as an NP-Hard problem, an efficient selection method should be taken by problem using optimal energy-aware methods that can extend the deployment and interoperability of mobile cloud components. Also, an energy-aware service composition mechanism is required to preserve high energy saving scenarios for mobile cloud components. In this paper, an energy-aware mechanism is applied to optimize mobile cloud service composition using a hybrid Shuffled Frog Leaping Algorithm and Genetic Algorithm (SFGA). Experimental results capture that the proposed mechanism improves the feasibility of the service composition with minimum energy consumption, response time, and cost for mobile cloud components against some current algorithms.",
    "lastUpdated": "2020-05-19T21:38:55Z",
    "category": [
      "cs.NI",
      "cs.NE"
    ],
    "url": "http://arxiv.org/abs/2006.16771v1"
  },
  {
    "title": "Towards Tracking Data Flows in Cloud Architectures",
    "author": [
      "Immanuel Kunz",
      "Valentina Casola",
      "Angelika Schneider",
      "Christian Banse",
      "Julian Schütte"
    ],
    "abstract": "As cloud services become central in an increasing number of applications, they process and store more personal and business-critical data. At the same time, privacy and compliance regulations such as GDPR, the EU ePrivacy regulation, PCI, and the upcoming EU Cybersecurity Act raise the bar for secure processing and traceability of critical data. Especially the demand to provide information about existing data records of an individual and the ability to delete them on demand is central in privacy regulations. Common to these requirements is that cloud providers must be able to track data as it flows across the different services to ensure that it never moves outside of the legitimate realm, and it is known at all times where a specific copy of a record that belongs to a specific individual or business process is located. However, current cloud architectures do neither provide the means to holistically track data flows across different services nor to enforce policies on data flows. In this paper, we point out the deficits in the data flow tracking functionalities of major cloud providers by means of a set of practical experiments. We then generalize from these experiments introducing a generic architecture that aims at solving the problem of cloud-wide data flow tracking and show how it can be built in a Kubernetes-based prototype implementation.",
    "lastUpdated": "2020-07-10T07:31:47Z",
    "category": [
      "cs.CR",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/2007.05212v1"
  },
  {
    "title": "Global Context Aware Convolutions for 3D Point Cloud Understanding",
    "author": [
      "Zhiyuan Zhang",
      "Binh-Son Hua",
      "Wei Chen",
      "Yibin Tian",
      "Sai-Kit Yeung"
    ],
    "abstract": "Recent advances in deep learning for 3D point clouds have shown great promises in scene understanding tasks thanks to the introduction of convolution operators to consume 3D point clouds directly in a neural network. Point cloud data, however, could have arbitrary rotations, especially those acquired from 3D scanning. Recent works show that it is possible to design point cloud convolutions with rotation invariance property, but such methods generally do not perform as well as translation-invariant only convolution. We found that a key reason is that compared to point coordinates, rotation-invariant features consumed by point cloud convolution are not as distinctive. To address this problem, we propose a novel convolution operator that enhances feature distinction by integrating global context information from the input point cloud to the convolution. To this end, a globally weighted local reference frame is constructed in each point neighborhood in which the local point set is decomposed into bins. Anchor points are generated in each bin to represent global shape features. A convolution can then be performed to transform the points and anchor features into final rotation-invariant features. We conduct several experiments on point cloud classification, part segmentation, shape retrieval, and normals estimation to evaluate our convolution, which achieves state-of-the-art accuracy under challenging rotations.",
    "lastUpdated": "2020-08-07T04:33:27Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2008.02986v1"
  },
  {
    "title": "PointMixup: Augmentation for Point Clouds",
    "author": [
      "Yunlu Chen",
      "Vincent Tao Hu",
      "Efstratios Gavves",
      "Thomas Mensink",
      "Pascal Mettes",
      "Pengwan Yang",
      "Cees G. M. Snoek"
    ],
    "abstract": "This paper introduces data augmentation for point clouds by interpolation between examples. Data augmentation by interpolation has shown to be a simple and effective approach in the image domain. Such a mixup is however not directly transferable to point clouds, as we do not have a one-to-one correspondence between the points of two different objects. In this paper, we define data augmentation between point clouds as a shortest path linear interpolation. To that end, we introduce PointMixup, an interpolation method that generates new examples through an optimal assignment of the path function between two point clouds. We prove that our PointMixup finds the shortest path between two point clouds and that the interpolation is assignment invariant and linear. With the definition of interpolation, PointMixup allows to introduce strong interpolation-based regularizers such as mixup and manifold mixup to the point cloud domain. Experimentally, we show the potential of PointMixup for point cloud classification, especially when examples are scarce, as well as increased robustness to noise and geometric transformations to points. The code for PointMixup and the experimental details are publicly available.",
    "lastUpdated": "2020-08-14T13:57:20Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2008.06374v1"
  },
  {
    "title": "Classification and understanding of cloud structures via satellite images with EfficientUNet",
    "author": [
      "Tashin Ahmed",
      "Noor Hossain Nuri Sabab"
    ],
    "abstract": "Climate change has been a common interest and the forefront of crucial political discussion and decision-making for many years. Shallow clouds play a significant role in understanding the Earth's climate, but they are challenging to interpret and represent in a climate model. By classifying these cloud structures, there is a better possibility of understanding the physical structures of the clouds, which would improve the climate model generation, resulting in a better prediction of climate change or forecasting weather update. Clouds organise in many forms, which makes it challenging to build traditional rule-based algorithms to separate cloud features. In this paper, classification of cloud organization patterns was performed using a new scaled-up version of Convolutional Neural Network (CNN) named as EfficientNet as the encoder and UNet as decoder where they worked as feature extractor and reconstructor of fine grained feature map and was used as a classifier, which will help experts to understand how clouds will shape the future climate. By using a segmentation model in a classification task, it was shown that with a good encoder alongside UNet, it is possible to obtain good performance from this dataset. Dice coefficient has been used for the final evaluation metric, which gave the score of 66.26% and 66.02% for public and private leaderboard on Kaggle competition respectively.",
    "lastUpdated": "2020-09-27T19:50:05Z",
    "category": [
      "eess.IV",
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2009.12931v1"
  },
  {
    "title": "Resource Management Schemes for Cloud-Native Platforms with Computing Containers of Docker and Kubernetes",
    "author": [
      "Ying Mao",
      "Yuqi Fu",
      "Suwen Gu",
      "Sudip Vhaduri",
      "Long Cheng",
      "Qingzhi Liu"
    ],
    "abstract": "Businesses have made increasing adoption and incorporation of cloud technology into internal processes in the last decade. The cloud-based deployment provides on-demand availability without active management. More recently, the concept of cloud-native application has been proposed and represents an invaluable step toward helping organizations develop software faster and update it more frequently to achieve dramatic business outcomes. Cloud-native is an approach to build and run applications that exploit the cloud computing delivery model's advantages. It is more about how applications are created and deployed than where. The container-based virtualization technology, such as Docker and Kubernetes, serves as the foundation for cloud-native applications. This paper investigates the performance of two popular computational-intensive applications, big data, and deep learning, in a cloud-native environment. We analyze the system overhead and resource usage for these applications. Through extensive experiments, we show that the completion time reduces by up to 79.4% by changing the default setting and increases by up to 96.7% due to different resource management schemes on two platforms. Additionally, the resource release is delayed by up to 116.7% across different systems. Our work can guide developers, administrators, and researchers to better design and deploy their applications by selecting and configuring a hosting platform.",
    "lastUpdated": "2020-10-20T15:13:25Z",
    "category": [
      "cs.DC",
      "cs.PF"
    ],
    "url": "http://arxiv.org/abs/2010.10350v1"
  },
  {
    "title": "LG-GAN: Label Guided Adversarial Network for Flexible Targeted Attack of Point Cloud-based Deep Networks",
    "author": [
      "Hang Zhou",
      "Dongdong Chen",
      "Jing Liao",
      "Weiming Zhang",
      "Kejiang Chen",
      "Xiaoyi Dong",
      "Kunlin Liu",
      "Gang Hua",
      "Nenghai Yu"
    ],
    "abstract": "Deep neural networks have made tremendous progress in 3D point-cloud recognition. Recent works have shown that these 3D recognition networks are also vulnerable to adversarial samples produced from various attack methods, including optimization-based 3D Carlini-Wagner attack, gradient-based iterative fast gradient method, and skeleton-detach based point-dropping. However, after a careful analysis, these methods are either extremely slow because of the optimization/iterative scheme, or not flexible to support targeted attack of a specific category. To overcome these shortcomings, this paper proposes a novel label guided adversarial network (LG-GAN) for real-time flexible targeted point cloud attack. To the best of our knowledge, this is the first generation based 3D point cloud attack method. By feeding the original point clouds and target attack label into LG-GAN, it can learn how to deform the point clouds to mislead the recognition network into the specific label only with a single forward pass. In detail, LGGAN first leverages one multi-branch adversarial network to extract hierarchical features of the input point clouds, then incorporates the specified label information into multiple intermediate features using the label encoder. Finally, the encoded features will be fed into the coordinate reconstruction decoder to generate the target adversarial sample. By evaluating different point-cloud recognition models (e.g., PointNet, PointNet++ and DGCNN), we demonstrate that the proposed LG-GAN can support flexible targeted attack on the fly while guaranteeing good attack performance and higher efficiency simultaneously.",
    "lastUpdated": "2020-11-01T17:17:10Z",
    "category": [
      "cs.CV",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/2011.00566v1"
  },
  {
    "title": "MoNet: Motion-based Point Cloud Prediction Network",
    "author": [
      "Fan Lu",
      "Guang Chen",
      "Yinlong Liu",
      "Zhijun Li",
      "Sanqing Qu",
      "Tianpei Zou"
    ],
    "abstract": "Predicting the future can significantly improve the safety of intelligent vehicles, which is a key component in autonomous driving. 3D point clouds accurately model 3D information of surrounding environment and are crucial for intelligent vehicles to perceive the scene. Therefore, prediction of 3D point clouds has great significance for intelligent vehicles, which can be utilized for numerous further applications. However, due to point clouds are unordered and unstructured, point cloud prediction is challenging and has not been deeply explored in current literature. In this paper, we propose a novel motion-based neural network named MoNet. The key idea of the proposed MoNet is to integrate motion features between two consecutive point clouds into the prediction pipeline. The introduction of motion features enables the model to more accurately capture the variations of motion information across frames and thus make better predictions for future motion. In addition, content features are introduced to model the spatial content of individual point clouds. A recurrent neural network named MotionRNN is proposed to capture the temporal correlations of both features. Besides, we propose an attention-based motion align module to address the problem of missing motion features in the inference pipeline. Extensive experiments on two large scale outdoor LiDAR datasets demonstrate the performance of the proposed MoNet. Moreover, we perform experiments on applications using the predicted point clouds and the results indicate the great application potential of the proposed method.",
    "lastUpdated": "2020-11-21T15:43:31Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2011.10812v1"
  },
  {
    "title": "R-AGNO-RPN: A LIDAR-Camera Region Deep Network for Resolution-Agnostic Detection",
    "author": [
      "Ruddy Théodose",
      "Dieumet Denis",
      "Thierry Chateau",
      "Vincent Frémont",
      "Paul Checchin"
    ],
    "abstract": "Current neural networks-based object detection approaches processing LiDAR point clouds are generally trained from one kind of LiDAR sensors. However, their performances decrease when they are tested with data coming from a different LiDAR sensor than the one used for training, i.e., with a different point cloud resolution. In this paper, R-AGNO-RPN, a region proposal network built on fusion of 3D point clouds and RGB images is proposed for 3D object detection regardless of point cloud resolution. As our approach is designed to be also applied on low point cloud resolutions, the proposed method focuses on object localization instead of estimating refined boxes on reduced data. The resilience to low-resolution point cloud is obtained through image features accurately mapped to Bird's Eye View and a specific data augmentation procedure that improves the contribution of the RGB images. To show the proposed network's ability to deal with different point clouds resolutions, experiments are conducted on both data coming from the KITTI 3D Object Detection and the nuScenes datasets. In addition, to assess its performances, our method is compared to PointPillars, a well-known 3D detection network. Experimental results show that even on point cloud data reduced by $80\\%$ of its original points, our method is still able to deliver relevant proposals localization.",
    "lastUpdated": "2020-12-10T15:22:58Z",
    "category": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "url": "http://arxiv.org/abs/2012.05740v1"
  },
  {
    "title": "Analyzing the Performance of Smart Industry 4.0 Applications on Cloud Computing Systems",
    "author": [
      "Razin Farhan Hussain",
      "Alireza Pakravan",
      "Mohsen Amini Salehi"
    ],
    "abstract": "Cloud-based Deep Neural Network (DNN) applications that make latency-sensitive inference are becoming an indispensable part of Industry 4.0. Due to the multi-tenancy and resource heterogeneity, both inherent to the cloud computing environments, the inference time of DNN-based applications are stochastic. Such stochasticity, if not captured, can potentially lead to low Quality of Service (QoS) or even a disaster in critical sectors, such as Oil and Gas industry. To make Industry 4.0 robust, solution architects and researchers need to understand the behavior of DNN-based applications and capture the stochasticity exists in their inference times. Accordingly, in this study, we provide a descriptive analysis of the inference time from two perspectives. First, we perform an application-centric analysis and statistically model the execution time of four categorically different DNN applications on both Amazon and Chameleon clouds. Second, we take a resource-centric approach and analyze a rate-based metric in form of Million Instruction Per Second (MIPS) for heterogeneous machines in the cloud. This non-parametric modeling, achieved via Jackknife and Bootstrap re-sampling methods, provides the confidence interval of MIPS for heterogeneous cloud machines. The findings of this research can be helpful for researchers and cloud solution architects to develop solutions that are robust against the stochastic nature of the inference time of DNN applications in the cloud and can offer a higher QoS to their users and avoid unintended outcomes.",
    "lastUpdated": "2020-12-11T00:18:05Z",
    "category": [
      "cs.DC",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2012.06054v1"
  },
  {
    "title": "Green IT as a tool for design cloud-oriented sustainable learning environment of a higher education institution",
    "author": [
      "Tetiana Vakaliuk",
      "Dmitry Antoniuk",
      "Andrii Morozov",
      "Mariia Medvedieva",
      "Mykhailo Medvediev"
    ],
    "abstract": "The paper proposes the use of green IT as a tool for designing a cloud-oriented sustainable learning environment for a higher education institution. The article substantiates the expediency of designing such an environment as a prerequisite for the sustainable development of Ukraine. It is established that one of the goals of Ukraine's sustainable development for 2030 is to provide fair quality education and to promote lifelong learning opportunities for all. Green IT is a set of approaches related to sustainable computing and information technology. The work of foreign scientists was analyzed, which considered the issues of designing the learning environment using green computing. As a result, Cloud LMS has been established that cloud LMS is a type of green IT and can serve as a tool for designing a cloud-oriented sustainable learning environment of a higher education institution. A model of a cloud-oriented sustainable learning environment of a higher education institution using cloud LMS is proposed. The application of a cloud-oriented sustainable learning environment will provide such capabilities: keep electronic journals; use on-line services; conduct correspondence, assessment of knowledge on-line; and more. And all of the above is the key to a sustainable development of the learning environment.",
    "lastUpdated": "2020-12-10T14:25:01Z",
    "category": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/2012.07744v1"
  },
  {
    "title": "Cloud removal in remote sensing images using generative adversarial networks and SAR-to-optical image translation",
    "author": [
      "Faramarz Naderi Darbaghshahi",
      "Mohammad Reza Mohammadi",
      "Mohsen Soryani"
    ],
    "abstract": "Satellite images are often contaminated by clouds. Cloud removal has received much attention due to the wide range of satellite image applications. As the clouds thicken, the process of removing the clouds becomes more challenging. In such cases, using auxiliary images such as near-infrared or synthetic aperture radar (SAR) for reconstructing is common. In this study, we attempt to solve the problem using two generative adversarial networks (GANs). The first translates SAR images into optical images, and the second removes clouds using the translated images of prior GAN. Also, we propose dilated residual inception blocks (DRIBs) instead of vanilla U-net in the generator networks and use structural similarity index measure (SSIM) in addition to the L1 Loss function. Reducing the number of downsamplings and expanding receptive fields by dilated convolutions increase the quality of output images. We used the SEN1-2 dataset to train and test both GANs, and we made cloudy images by adding synthetic clouds to optical images. The restored images are evaluated with PSNR and SSIM. We compare the proposed method with state-of-the-art deep learning models and achieve more accurate results in both SAR-to-optical translation and cloud removal parts.",
    "lastUpdated": "2020-12-22T17:19:14Z",
    "category": [
      "eess.IV",
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2012.12180v1"
  },
  {
    "title": "Market-Oriented Cloud Computing: Vision, Hype, and Reality for Delivering IT Services as Computing Utilities",
    "author": [
      "Rajkumar Buyya",
      "Chee Shin Yeo",
      "Srikumar Venugopal"
    ],
    "abstract": "This keynote paper: presents a 21st century vision of computing; identifies various computing paradigms promising to deliver the vision of computing utilities; defines Cloud computing and provides the architecture for creating market-oriented Clouds by leveraging technologies such as VMs; provides thoughts on market-based resource management strategies that encompass both customer-driven service management and computational risk management to sustain SLA-oriented resource allocation; presents some representative Cloud platforms especially those developed in industries along with our current work towards realising market-oriented resource allocation of Clouds by leveraging the 3rd generation Aneka enterprise Grid technology; reveals our early thoughts on interconnecting Clouds for dynamically creating an atmospheric computing environment along with pointers to future community research; and concludes with the need for convergence of competing IT paradigms for delivering our 21st century vision.",
    "lastUpdated": "2008-08-26T17:16:11Z",
    "category": [
      "cs.DC",
      "C.2.4"
    ],
    "url": "http://arxiv.org/abs/0808.3558v1"
  },
  {
    "title": "Cloud Migration: A Case Study of Migrating an Enterprise IT System to IaaS",
    "author": [
      "Ali Khajeh-Hosseini",
      "David Greenwood",
      "Ian Sommerville"
    ],
    "abstract": "This case study illustrates the potential benefits and risks associated with the migration of an IT system in the oil & gas industry from an in-house data center to Amazon EC2 from a broad variety of stakeholder perspectives across the enterprise, thus transcending the typical, yet narrow, financial and technical analysis offered by providers. Our results show that the system infrastructure in the case study would have cost 37% less over 5 years on EC2, and using cloud computing could have potentially eliminated 21% of the support calls for this system. These findings seem significant enough to call for a migration of the system to the cloud but our stakeholder impact analysis revealed that there are significant risks associated with this. Whilst the benefits of using the cloud are attractive, we argue that it is important that enterprise decision-makers consider the overall organizational implications of the changes brought about with cloud computing to avoid implementing local optimizations at the cost of organization-wide performance.",
    "lastUpdated": "2010-02-18T11:25:49Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1002.3492v1"
  },
  {
    "title": "MalStone: Towards A Benchmark for Analytics on Large Data Clouds",
    "author": [
      "Collin Bennett",
      "Robert L. Grossman",
      "David Locke",
      "Jonathan Seidman",
      "Steve Vejcik"
    ],
    "abstract": "Developing data mining algorithms that are suitable for cloud computing platforms is currently an active area of research, as is developing cloud computing platforms appropriate for data mining. Currently, the most common benchmark for cloud computing is the Terasort (and related) benchmarks. Although the Terasort Benchmark is quite useful, it was not designed for data mining per se. In this paper, we introduce a benchmark called MalStone that is specifically designed to measure the performance of cloud computing middleware that supports the type of data intensive computing common when building data mining models. We also introduce MalGen, which is a utility for generating data on clouds that can be used with MalStone.",
    "lastUpdated": "2010-07-07T23:26:22Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1007.1261v1"
  },
  {
    "title": "Mapping Cloud Computing onto Useful e-Governance",
    "author": [
      "Ajay Prasad",
      "Sandeep Chaurasia",
      "Arjun Singh",
      "Deepak Gour"
    ],
    "abstract": "Most of the services viewed in context to grid and cloud computing are mostly confined to services that are available for intellectual purposes. The grid or cloud computing are large scale distributed systems. The essence of large scale distribution can only be realized if the services are rendered to common man. The only organization which has exposure to almost every single resident is the respective governments in every country. As the size of population increases so the need for a larger purview arises. The problem of having a large purview can be solved by means of large scale grid for online services. The government services can be rendered through fully customized Service-oriented Clouds. In this paper we are presenting tight similarities between generic government functioning and the service oriented grid/cloud approach. Also, we will discuss the major issues in establishing services oriented grids for governmental organization.",
    "lastUpdated": "2010-09-13T07:36:47Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1009.2314v1"
  },
  {
    "title": "Accomplish the Application Area in Cloud Computing",
    "author": [
      "Nidhi Bansal",
      "Amit Awasthi"
    ],
    "abstract": "In the cloud computing application area of accomplish, we find the fact that cloud computing covers a lot of areas are its main asset. At a top level, it is an approach to IT where many users, some even from different companies get access to shared IT resources such as servers, routers and various file extensions, instead of each having their own dedicated servers. This offers many advantages like lower costs and higher efficiency. Unfortunately there have been some high profile incidents where some of the largest cloud providers have had outages and even lost data, and this underscores that it is important to have backup, security and disaster recovery capabilities. In education field, it gives better choice and flexibility to IT departments than others. The platform and applications you use can be on-premises, off-premises, or a combination of both, depending on your academic organization's needs. With cloud computing in education, you get powerful software and massive computing resources where and when you need them. Use cloud services to best combine: *On-demand computing and storage. *A familiar development experience with on-demand scalability. *Online services for anywhere, anytime access to powerful web-based tools.",
    "lastUpdated": "2012-03-10T05:47:22Z",
    "category": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1203.2231v1"
  },
  {
    "title": "Cloud Computing Through Mobile-Learning",
    "author": [
      "N. Mallikharjuna Rao",
      "C. Sasidhar",
      "V. Sathyendra Kumar"
    ],
    "abstract": "Cloud computing is the new technology that has various advantages and it is an adoptable technology in this present scenario. The main advantage of the cloud computing is that this technology reduces the cost effectiveness for the implementation of the Hardware, software and License for all. This is the better peak time to analyze the cloud and its implementation and better use it for the development of the quality and low cost education for all over the world. In this paper, we discuss how to influence on cloud computing and influence on this technology to take education to a wider mass of students over the country. We believe cloud computing will surely improve the current system of education and improve quality at an affordable cost.",
    "lastUpdated": "2012-04-07T05:15:47Z",
    "category": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1204.1594v1"
  },
  {
    "title": "Tripod of Requirements in Horizontal Heterogeneous Mobile Cloud Computing",
    "author": [
      "Zohreh Sanaei",
      "Saeid Abolfazli",
      "Abdullah Gani",
      "Rashid Hafeez Khokhar"
    ],
    "abstract": "Recent trend of mobile computing is emerging toward executing resource-intensive applications in mobile devices regardless of underlying resource restrictions (e.g. limited processor and energy) that necessitate imminent technologies. Prosperity of cloud computing in stationary computers breeds Mobile Cloud Computing (MCC) technology that aims to augment computing and storage capabilities of mobile devices besides conserving energy. However, MCC is more heterogeneous and unreliable (due to wireless connectivity) compare to cloud computing. Problems like variations in OS, data fragmentation, and security and privacy discourage and decelerate implementation and pervasiveness of MCC. In this paper, we describe MCC as a horizontal heterogeneous ecosystem and identify thirteen critical metrics and approaches that influence on mobile-cloud solutions and success of MCC. We divide them into three major classes, namely ubiquity, trust, and energy efficiency and devise a tripod of requirements in MCC. Our proposed tripod shows that success of MCC is achievable by reducing mobility challenges (e.g. seamless connectivity, fragmentation), increasing trust, and enhancing energy efficiency.",
    "lastUpdated": "2012-05-15T03:29:23Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1205.3247v1"
  },
  {
    "title": "Research On Mobile Cloud Computing: Review, Trend, And Perspectives",
    "author": [
      "Han Qi",
      "Abdullah Gani"
    ],
    "abstract": "Mobile Cloud Computing (MCC) which combines mobile computing and cloud computing, has become one of the industry buzz words and a major discussion thread in the IT world since 2009. As MCC is still at the early stage of development, it is necessary to grasp a thorough understanding of the technology in order to point out the direction of future research. With the latter aim, this paper presents a review on the background and principle of MCC, characteristics, recent research work, and future research trends. A brief account on the background of MCC: from mobile computing to cloud computing is presented and then followed with a discussion on characteristics and recent research work. It then analyses the features and infrastructure of mobile cloud computing. The rest of the paper analyses the challenges of mobile cloud computing, summary of some research projects related to this area, and points out promising future research directions.",
    "lastUpdated": "2012-06-06T03:53:39Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1206.1118v1"
  },
  {
    "title": "Using Open Standards for Interoperability - Issues, Solutions, and Challenges facing Cloud Computing",
    "author": [
      "Piyush Harsh",
      "Florian Dudouet",
      "Roberto G. Cascella",
      "Yvon Jégou",
      "Christine Morin"
    ],
    "abstract": "Virtualization offers several benefits for optimal resource utilization over traditional non-virtualized server farms. With improvements in internetworking technologies and increase in network bandwidth speeds, a new era of computing has been ushered in, that of grids and clouds. With several commercial cloud providers coming up, each with their own APIs, application description formats, and varying support for SLAs, vendor lock-in has become a serious issue for end users. This article attempts to describe the problem, issues, possible solutions and challenges in achieving cloud interoperability. These issues will be analyzed in the ambit of the European project Contrail that is trying to adopt open standards with available virtualization solutions to enhance users' trust in the clouds by attempting to prevent vendor lock-ins, supporting and enforcing SLAs together with adequate data protection for sensitive data.",
    "lastUpdated": "2012-07-25T10:54:08Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1207.5949v1"
  },
  {
    "title": "WiSANCloud: a set of UML-based specifications for the integration of Wireless Sensor and Actor Networks (WSANs) with the Cloud Computing",
    "author": [
      "Priscill Orue-Esquivel",
      "Bartolomé Rubio"
    ],
    "abstract": "Giving the current trend to combine the advantages of Wireless Sensor and Actor Networks (WSANs)with the Cloud Computing technology, this work proposes a set of specifications, based on the Unified Modeling Language - UML, in order to provide the general framework for the design of the integration of said components. One of the keys of the integration is the architecture of the WSAN, due to its structural relationship with the Cloud in the definition of the combination. Regarding the standard applied in the integration, UML and its subset, Systems Modeling Language - SysML, are proposed by the Object Management Group - OMG to deal with cloud applications; so, this indicates the starting point of the process of the design of specifications for WSAN-Cloud integration. Based on the current state of UML tools for analysis and design, there are several aspects to take into account in order to define the integration process.",
    "lastUpdated": "2012-11-20T11:41:10Z",
    "category": [
      "cs.SE",
      "cs.DC",
      "68M99"
    ],
    "url": "http://arxiv.org/abs/1211.4720v1"
  },
  {
    "title": "CloudSVM : Training an SVM Classifier in Cloud Computing Systems",
    "author": [
      "F. Ozgur Catak",
      "M. Erdal Balaban"
    ],
    "abstract": "In conventional method, distributed support vector machines (SVM) algorithms are trained over pre-configured intranet/internet environments to find out an optimal classifier. These methods are very complicated and costly for large datasets. Hence, we propose a method that is referred as the Cloud SVM training mechanism (CloudSVM) in a cloud computing environment with MapReduce technique for distributed machine learning applications. Accordingly, (i) SVM algorithm is trained in distributed cloud storage servers that work concurrently; (ii) merge all support vectors in every trained cloud node; and (iii) iterate these two steps until the SVM converges to the optimal classifier function. Large scale data sets are not possible to train using SVM algorithm on a single computer. The results of this study are important for training of large scale data sets for machine learning applications. We provided that iterative training of splitted data set in cloud computing environment using SVM will converge to a global optimal classifier in finite iteration size.",
    "lastUpdated": "2013-01-01T13:20:27Z",
    "category": [
      "cs.LG",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1301.0082v1"
  },
  {
    "title": "Toward the Automatic Generation of a Semantic VRML Model from Unorganized 3D Point Clouds",
    "author": [
      "Helmi Ben Hmida",
      "Christophe Cruz",
      "Christophe Nicolle",
      "Frank Boochs"
    ],
    "abstract": "This paper presents our experience regarding the creation of 3D semantic facility model out of unorganized 3D point clouds. Thus, a knowledge-based detection approach of objects using the OWL ontology language is presented. This knowledge is used to define SWRL detection rules. In addition, the combination of 3D processing built-ins and topological Built-Ins in SWRL rules aims at combining geometrical analysis of 3D point clouds and specialist's knowledge. This combination allows more flexible and intelligent detection and the annotation of objects contained in 3D point clouds. The created WiDOP prototype takes a set of 3D point clouds as input, and produces an indexed scene of colored objects visualized within VRML language as output. The context of the study is the detection of railway objects materialized within the Deutsche Bahn scene such as signals, technical cupboards, electric poles, etc. Therefore, the resulting enriched and populated domain ontology, that contains the annotations of objects in the point clouds, is used to feed a GIS system.",
    "lastUpdated": "2013-01-21T08:17:15Z",
    "category": [
      "cs.CG",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/1301.5349v1"
  },
  {
    "title": "Enhanced Security for Cloud Storage using File Encryption",
    "author": [
      "Debajyoti Mukhopadhyay",
      "Gitesh Sonawane",
      "Parth Sarthi Gupta",
      "Sagar Bhavsar",
      "Vibha Mittal"
    ],
    "abstract": "Cloud computing is a term coined to a network that offers incredible processing power, a wide array of storage space and unbelievable speed of computation. Social media channels, corporate structures and individual consumers are all switching to the magnificent world of cloud computing. The flip side to this coin is that with cloud storage emerges the security issues of confidentiality, data integrity and data availability. Since the cloud is a mere collection of tangible super computers spread across the world, authentication and authorization for data access is more than a necessity. Our work attempts to overcome these security threats. The proposed methodology suggests the encryption of the files to be uploaded on the cloud. The integrity and confidentiality of the data uploaded by the user is ensured doubly by not only encrypting it but also providing access to the data only on successful authentication.",
    "lastUpdated": "2013-03-28T09:20:54Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1303.7075v1"
  },
  {
    "title": "A Paradigm for the Application of Cloud Computing in Mobile Intelligent Tutoring Systems",
    "author": [
      "Hossein Movafegh Ghadirli",
      "Maryam Rastgarpour"
    ],
    "abstract": "Nowadays, with the rapid growth of cloud computing, many industries are going to move their computing activities to clouds. Researchers of virtual learning are also looking for the ways to use clouds through mobile platforms. This paper offers a model to accompany the benefits of \"Mobile Intelligent Learning\" technology and \"Cloud Computing\". The architecture of purposed system is based on multi-layer architecture of Mobile Cloud Computing. Despite the existing challenges, the system has increased the life of mobile device battery. It will raise working memory capacity and processing capacity of the educational system in addition to the greater advantage of the educational system. The proposed system allows the users to enjoy an intelligent learning every-time and every-where, reduces training costs and hardware dependency, and increases consistency, efficiency, and data reliability.",
    "lastUpdated": "2013-04-15T10:40:42Z",
    "category": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1304.4047v1"
  },
  {
    "title": "Trust Management Model for Cloud Computing Environment",
    "author": [
      "Somesh Kumar Prajapati",
      "Suvamoy Changder",
      "Anirban Sarkar"
    ],
    "abstract": "Software as a service or (SaaS) is a new software development and deployment paradigm over the cloud and offers Information Technology services dynamically as \"on-demand\" basis over the internet. Trust is one of the fundamental security concepts on storing and delivering such services. In general, trust factors are integrated into such existent security frameworks in order to add a security level to entities collaborations through the trust relationship. However, deploying trust factor in the secured cloud environment are more complex engineering task due to the existence of heterogeneous types of service providers and consumers. In this paper, a formal trust management model has been introduced to manage the trust and its properties for SaaS in cloud computing environment. The model is capable to represent the direct trust, recommended trust, reputation etc. formally. For the analysis of the trust properties in the cloud environment, the proposed approach estimates the trust value and uncertainty of each peer by computing decay function, number of positive interactions, reputation factor and satisfaction level for the collected information.",
    "lastUpdated": "2013-04-19T05:38:13Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1304.5313v1"
  },
  {
    "title": "An Auction Mechanism for Resource Allocation in Mobile Cloud Computing Systems",
    "author": [
      "Yang Zhang",
      "Dusit Niyato",
      "Ping Wang"
    ],
    "abstract": "A mobile cloud computing system is composed of heterogeneous services and resources to be allocated by the cloud service provider to mobile cloud users. On one hand, some of these resources are substitutable (e.g., users can use storage from different places) that they have similar functions to the users. On the other hand, some resources are complementary that the user will need them as a bundle (e.g., users need both wireless connection and storage for online photo posting). In this paper, we first model the resource allocation process of a mobile cloud computing system as an auction mechanism with premium and discount factors. The premium and discount factors indicate complementary and substitutable relations among cloud resources provided by the service provider. Then, we analyze the individual rationality and incentive compatibility (truthfulness) properties of the users in the proposed auction mechanism. The optimal solutions of the resource allocation and cost charging schemes in the auction mechanism is discussed afterwards.",
    "lastUpdated": "2013-04-23T06:11:12Z",
    "category": [
      "cs.DC",
      "cs.GT"
    ],
    "url": "http://arxiv.org/abs/1304.6176v1"
  },
  {
    "title": "TCloud: A Dynamic Framework and Policies for Access Control across Multiple Domains in Cloud Computing",
    "author": [
      "Sultan Ullah",
      "Zheng Xuefeng",
      "Zhou Feng"
    ],
    "abstract": "In a cloud computing environment, access control policy is an effective means of fortification cloud users and cloud resources services against security infringements. Based on analysis of current cloud computing security characteristics, the preamble of the concept of trust, role-based access control policy, combined with the characteristics of the cloud computing environment, there are multiple security management domains, so a new cross domain framework is for access control is proposed which is based on trust. It will establish and calculate the degree of trust in the single as well as multiple domains. Role Based Access Control is used for the implementation of the access control policies in a single domain environment with the introduction of the trust concept. In multiple domains the access control will be based on the conversion of roles. On the basis of trust, and role based access control model, a new novel framework of flexible cross domain access control framework is presented. The role assignment and conversion will take place dynamically.",
    "lastUpdated": "2013-04-10T09:16:17Z",
    "category": [
      "cs.DC",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1305.2865v1"
  },
  {
    "title": "Secure Authentication of Cloud Data Mining API",
    "author": [
      "Rohit Bhadauria",
      "Rajdeep Borgohain",
      "Abirlal Biswas",
      "Sugata Sanyal"
    ],
    "abstract": "Cloud computing is a revolutionary concept that has brought a paradigm shift in the IT world. This has made it possible to manage and run businesses without even setting up an IT infrastructure. It offers multi-fold benefits to the users moving to a cloud, while posing unknown security and privacy issues. User authentication is one such growing concern and is greatly needed in order to ensure privacy and security in a cloud computing environment. This paper discusses the security at different levels viz. network, application and virtualization, in a cloud computing environment. A security framework based on one-time pass key mechanism has been proposed. The uniqueness of the proposed security protocol lies in the fact, that it provides security to both the service providers as well the users in a highly conflicting cloud environment.",
    "lastUpdated": "2013-08-04T16:22:30Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1308.0824v1"
  },
  {
    "title": "A Survey of Current Trends in Distributed, Grid and Cloud Computing",
    "author": [
      "Gaurav Mittal",
      "Dr. Nishtha Kesswani",
      "Kuldeep Goswami"
    ],
    "abstract": "Through the 1990s to 2012 the internet changed the world of computing drastically. It started its journey with parallel computing after it advanced to distributed computing and further to grid computing. And in present scenario it creates a new world which is pronounced as a Cloud Computing [1]. These all three terms have different meanings. Cloud computing is based on backward computing schemes like cluster computing, distributed computing, grid computing and utility computing. The basic concept of cloud computing is virtualization. It provides virtual hardware and software resources to various requesting programs. This paper gives a detailed description about cluster computing, grid computing and cloud computing and gives an insight of some implementations of the same. We try to list the inspirations for the advent of all these technologies. We also account for some present scenario faults of grid computing and also discuss new cloud computing projects which are being managed by the Government of India for learning. The paper also reviews the existing work and covers (analytically), to some extent, some innovative ideas that can be implemented.",
    "lastUpdated": "2013-08-08T10:23:09Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1308.1806v1"
  },
  {
    "title": "RBioCloud: A Light-weight Framework for Bioconductor and R-based Jobs on the Cloud",
    "author": [
      "Ishan Patel",
      "Blesson Varghese",
      "Adam Barker"
    ],
    "abstract": "Large-scale ad hoc analytics of genomic data is popular using the R-programming language supported by 671 software packages provided by Bioconductor. More recently, analytical jobs are benefitting from on-demand computing and storage, their scalability and their low maintenance cost, all of which are offered by the cloud. While Biologists and Bioinformaticists can take an analytical job and execute it on their personal workstations, it remains challenging to seamlessly execute the job on the cloud infrastructure without extensive knowledge of the cloud dashboard. How analytical jobs can not only with minimum effort be executed on the cloud, but also how both the resources and data required by the job can be managed is explored in this paper. An open-source light-weight framework for executing R-scripts using Bioconductor packages, referred to as `RBioCloud', is designed and developed. RBioCloud offers a set of simple command-line tools for managing the cloud resources, the data and the execution of the job. Three biological test cases validate the feasibility of RBioCloud. The framework is publicly available from http://www.rbiocloud.com.",
    "lastUpdated": "2013-08-09T09:20:02Z",
    "category": [
      "cs.DC",
      "cs.CE",
      "cs.PF",
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/1308.2058v1"
  },
  {
    "title": "Security Issues on Cloud Computing",
    "author": [
      "Harit Shah",
      "Sharma Shankar Anandane",
      "Shrikanth"
    ],
    "abstract": "The Cloud Computing concept offers dynamically scalable resources provisioned as a service over the Internet.Economic benefits are the main driver for the Cloud, since it promises the reduction of capital expenditure and operational expenditure.In order for this to become reality, however, there are still some challenges to be solved. Amongst these are security and trust issues, since the user data has to be released to the Cloud and thus leaves the protection sphere of the data owner. Most of the discussions on these topics are mainly driven by arguments related to organisational means. This paper focuses on various security issues arising from the usage of Cloud services and especially by the rapid development of Cloud computing arena. It also discusses basic security model followed by various High Level Security threats in the industry.",
    "lastUpdated": "2013-08-27T21:08:52Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1308.5996v1"
  },
  {
    "title": "Securing Software as a Service Model of Cloud Computing: Issues and Solutions",
    "author": [
      "Rashmi Rai",
      "G. Sahoo",
      "S. Mehfuz"
    ],
    "abstract": "Cloud computing, undoubtedly, has become the buzzword in the IT industry today. Looking at the potential impact it has on numerous business applications as well as in our everyday life, it can certainly be said that this disruptive technology is here to stay. Many of the features that make cloud computing attractive, have not just challenged the existing security system, but have also revealed new security issues. This paper provides an insightful analysis of the existing status on cloud computing security issues based on a detailed survey carried by the author. It also makes an attempt to describe the security challenges in Software as a Service (SaaS) model of cloud computing and also endeavors to provide future security research directions.",
    "lastUpdated": "2013-09-10T09:23:16Z",
    "category": [
      "cs.DC",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1309.2426v1"
  },
  {
    "title": "Analysis of Scientific Cloud Computing requirements",
    "author": [
      "Álvaro López García",
      "Enol Fernández del Castillo"
    ],
    "abstract": "While the requirements of enterprise and web applications have driven the development of Cloud computing, some of its key features, such as customized environments and rapid elasticity, could also benefit scientific applications. However, neither virtualization techniques nor Cloud-like access to resources is common in scientific computing centers due to the negative perception of the impact that virtualization techniques introduce. In this paper we discuss the feasibility of the IaaS cloud model to satisfy some of the computational science requirements and the main drawbacks that need to be addressed by cloud resource providers so that the maximum benefit can be obtained from a given cloud infrastructure.",
    "lastUpdated": "2015-06-22T12:55:31Z",
    "category": [
      "cs.DC",
      "cs.CE"
    ],
    "url": "http://arxiv.org/abs/1309.6109v2"
  },
  {
    "title": "Network Traffic Adaptation For Cloud Games",
    "author": [
      "Richard Ewelle Ewelle",
      "Abdelkader Gouaïch",
      "Yannick Francillette",
      "Ghulam Mahdi"
    ],
    "abstract": "With the arrival of cloud technology, game accessibility and ubiquity have a bright future; Games can be hosted in a centralize server and accessed through the Internet by a thin client on a wide variety of devices with modest capabilities: cloud gaming. However, current cloud gaming systems have very strong requirements in terms of network resources, thus reducing the accessibility and ubiquity of cloud games, because devices with little bandwidth and people located in area with limited and unstable network connectivity, cannot take advantage of these cloud services. In this paper we present an adaptation technique inspired by the level of detail (LoD) approach in 3D graphics. It delivers multiple platform accessibility and network adaptability, while improving user's quality of experience (QoE) by reducing the impact of poor and unstable network parameters (delay, packet loss, jitter) on game interactivity. We validate our approach using a prototype game in a controlled environment and characterize the user QoE in a pilot experiment. The results show that the proposed framework provides a significant QoE enhancement.",
    "lastUpdated": "2013-11-14T00:17:27Z",
    "category": [
      "cs.NI",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1311.3348v1"
  },
  {
    "title": "Agent Based Negotiation using Cloud - an Approach in E-Commerce",
    "author": [
      "Amruta More",
      "Sheetal Vij",
      "Debajyoti Mukhopadhyay"
    ],
    "abstract": "Cloud computing allows subscription based access to computing. It also allows storage services over Internet. Automated Negotiation is becoming an emerging, and important area in the field of Multi Agent Systems in ECommerce. Multi Agent based negotiation system is necessary to increase the efficiency of E-negotiation process. Cloud computing provides security and privacy to the user data and low maintenance costs. We propose a Negotiation system using cloud. In this system, all product information and multiple agent details are stored on cloud. Both parties select their agents through cloud for negotiation. Agent acts as a negotiator. Agents have users details and their requirements for a particular product. Using users requirement, agents negotiate on some issues such as price, volume, duration, quality and so on. After completing negotiation process, agents give feedback to the user about whether negotiation is successful or not. This negotiation system is dynamic in nature and increases the agents with the increase in participating user.",
    "lastUpdated": "2013-11-25T08:42:59Z",
    "category": [
      "cs.MA"
    ],
    "url": "http://arxiv.org/abs/1311.6233v1"
  },
  {
    "title": "On-Demand Grid Provisioning Using Cloud Infrastructures and Related Virtualization Tools: A Survey and Taxonomy",
    "author": [
      "Shafii Muhammad Abdulhamid",
      "Muhammad Shafie Abd Latiff",
      "Mohammed Bakri Bashir"
    ],
    "abstract": "Recent researches have shown that grid resources can be accessed by client on-demand, with the help of virtualization technology in the Cloud. The virtual machines hosted by the hypervisors are being utilized to build the grid network within the cloud environment. The aim of this study is to survey some concepts used for the on-demand grid provisioning using Infrastructure as a Service Cloud and the taxonomy of its related components. This paper, discusses the different approaches for on-demand grid using infrastructural Cloud, the issues it tries to address and the implementation tools. The paper also, proposed an extended classification for the virtualization technology used and a new classification for the Grid-Cloud integration which was based on the architecture, communication flow and the user demand for the Grid resources. This survey, tools and taxonomies presented here will contribute as a guide in the design of future architectures for further researches.",
    "lastUpdated": "2014-02-04T11:27:56Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1402.0696v1"
  },
  {
    "title": "An EMUSIM Technique and its Components in Cloud Computing- A Review",
    "author": [
      "Dr. Rahul Malhotra",
      "Prince Jain"
    ],
    "abstract": "Recent efforts to design and develop Cloud technologies focus on defining novel methods, policies and mechanisms for efficiently managing Cloud infrastructures. One key challenge potential Cloud customers have before renting resources is to know how their services will behave in a set of resources and the costs involved when growing and shrinking their resource pool. Most of the studies in this area rely on simulation-based experiments, which consider simplified modeling of applications and computing environment. In order to better predict service's behavior on Cloud platforms, an integrated architecture that is based on both simulation and emulation. The proposed architecture, named EMUSIM, automatically extracts information from application behavior via emulation and then uses this information to generate the corresponding simulation model. This paper presents brief overview of the EMUSIM technique and its components. The work in this paper focuses on architecture and operation details of Automated Emulation Framework (AEF), QAppDeployer and proposes Cloud Sim Application for Simulation techniques.",
    "lastUpdated": "2014-02-09T10:10:48Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1402.1932v1"
  },
  {
    "title": "On Cloud-based Oversubscription",
    "author": [
      "Rachel Householder",
      "Scott Arnold",
      "Robert Green"
    ],
    "abstract": "Rising trends in the number of customers turning to the cloud for their computing needs has made effective resource allocation imperative for cloud service providers. In order to maximize profits and reduce waste, providers have started to explore the role of oversubscribing cloud resources. However, the benefits of cloud-based oversubscription are not without inherent risks. This paper attempts to unveil the incentives, risks, and techniques behind oversubscription in a cloud infrastructure. Additionally, an overview of the current research that has been completed on this highly relevant topic is reviewed, and suggestions are made regarding potential avenues for future work.",
    "lastUpdated": "2014-03-05T16:15:00Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1402.4758v2"
  },
  {
    "title": "Efficient and Reliable Hybrid Cloud Architechture for Big Data",
    "author": [
      "Narzu Tarannum",
      "Nova Ahmed"
    ],
    "abstract": "The objective of our paper is to propose a Cloud computing framework which is feasible and necessary for handling huge data. In our prototype system we considered national ID database structure of Bangladesh which is prepared by election commission of Bangladesh. Using this database we propose an interactive graphical user interface for Bangladeshi People Search (BDPS) that use a hybrid structure of cloud computing handled by apache Hadoop where database is implemented by HiveQL. The infrastructure divides into two parts: locally hosted cloud which is based on Eucalyptus and the remote cloud which is implemented on well-known Amazon Web Service (AWS). Some common problems of Bangladesh aspect which includes data traffic congestion, server time out and server down issue is also discussed.",
    "lastUpdated": "2014-01-09T12:46:41Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1405.5200v1"
  },
  {
    "title": "Crypto multi tenant: an environment of secure computing using cloud sql",
    "author": [
      "Parul Kashyap",
      "Rahul Singh"
    ],
    "abstract": "In our proposed work we mainly focus on data security of tenants so that only the authorized user can access the data. To provide this feature we use encryption and decryption process of data so that the only legal tenant can access their particular data. Hence, for security related to data of tenants we implement AES (advanced encryption standard) using cloud SQL. The result obtained from experimental methodology proved that AES gives protection for the data stored in the cloud. We make use of AES algorithm and Google App Engine to supply secured data storage, efficiency, assure availability in the condition of cloud denial-of-service attacks and data security in the cloud. This Approach is basically implemented by tenants who are going to store their data in the cloud.",
    "lastUpdated": "2014-06-18T11:15:33Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1406.4681v1"
  },
  {
    "title": "Securing Cloud from Cloud Drain",
    "author": [
      "Niva Das",
      "Tanmoy Sarkar"
    ],
    "abstract": "Today, in the world of communication, connected systems is growing at a rapid pace. To accommodate this growth the need for computational power and storage is also increasing at a similar rate. Companies are investing a large amount of resources in buying, maintaining and ensuring availability of the system to their customers. To mitigate these issues, cloud computing is playing a major role.The underlying concept of cloud computing dates back to the 50's but the term entering into widespread usage can be traced to 2006 when Amazon.com announced the Elastic Compute Cloud.In this paper, we will discuss about cloud security approaches. We have used the term Cloud-Drain to define data leakage in case of security compromise.",
    "lastUpdated": "2014-09-29T18:02:29Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1407.6482v3"
  },
  {
    "title": "Cloud WorkBench - Infrastructure-as-Code Based Cloud Benchmarking",
    "author": [
      "Joel Scheuner",
      "Philipp Leitner",
      "Jurgen Cito",
      "Harald Gall"
    ],
    "abstract": "To optimally deploy their applications, users of Infrastructure-as-a-Service clouds are required to evaluate the costs and performance of different combinations of cloud configurations to find out which combination provides the best service level for their specific application. Unfortunately, benchmarking cloud services is cumbersome and error-prone. In this paper, we propose an architecture and concrete implementation of a cloud benchmarking Web service, which fosters the definition of reusable and representative benchmarks. In distinction to existing work, our system is based on the notion of Infrastructure-as-Code, which is a state of the art concept to define IT infrastructure in a reproducible, well-defined, and testable way. We demonstrate our system based on an illustrative case study, in which we measure and compare the disk IO speeds of different instance and storage types in Amazon EC2.",
    "lastUpdated": "2014-08-20T09:04:57Z",
    "category": [
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/1408.4565v1"
  },
  {
    "title": "Modeling Cloud Architectures as Interactive Systems",
    "author": [
      "Antonio Navarro Perez",
      "Bernhard Rumpe"
    ],
    "abstract": "The development and maintenance of cloud software is complicated by complex but crucial technological requirements that are tightly coupled with each other and with the softwares actual business functionality. Consequently, the complexity of design, implementation, deployment, and maintenance activities increases. We present an architecture description language that raises the level of technological abstraction by modeling cloud software as interactive systems. We show how its models correspond to an architecture style that particularly meets the requirements of cloud-based cyber-physical systems. The result provides a basis for an architecture-driven model-based methodology for engineering cloud software.",
    "lastUpdated": "2014-08-25T09:44:00Z",
    "category": [
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/1408.5705v1"
  },
  {
    "title": "Pouring Cloud Virtualization Security Inside Out",
    "author": [
      "Yasir Shoaib",
      "Olivia Das"
    ],
    "abstract": "In this article, virtualization security concerns in the cloud computing domain are reviewed. The focus is toward virtual machine (VM) security where attacks and vulnerabilities such as VM escape, VM hopping, cross-VM side-channel, VM-based rootkits (VMBRs), VM mobility, and VM remote are mentioned and discussed according to their relevance in the clouds. For each attack we outline how they affect the security of cloud systems. Countermeasures and security measures to detect or prevent them through techniques such as VM detection, GuardHype, VM introspection, VM image scanning, etc. are also discussed. Through the surveyed work we present a classification of VM threats within the clouds. Finally, we include our observations and those of other researchers on this matter of cloud virtualization security.",
    "lastUpdated": "2014-11-14T01:14:58Z",
    "category": [
      "cs.CR",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1411.3771v1"
  },
  {
    "title": "Developing a SAAS-Cloud Integrated Development Environment (IDE) for C, C++, and Java",
    "author": [
      "A. B. Mutiara",
      "R. Refianti",
      "B. A. Witono"
    ],
    "abstract": "Cloud era brought revolution of computerization world. People could access their data from anywhere and anytime with different devices. One of the cloud's model is Software as a Service, which capable to provide applications that run on a cloud infrastructure.An IDE (Integrated Development Environment) is the most popular tool to develop application in the network or single computer development. By installing IDE in each computer of the network could causes the lot of time and budget spending. The objective of the research is developing an efficient cloud based IDE. The IDE could compile the code which sent from client browser through SaaS IDE to the server and send it back to the client. The method that used in the research is the System Development Life-Cycle: Waterfall and Unified Model Language as system designing tool. The research successfully produced the cloud-based SaaS IDE with excellent result from several testing in local network and internet.",
    "lastUpdated": "2014-11-19T09:55:44Z",
    "category": [
      "cs.SE",
      "D.2.2"
    ],
    "url": "http://arxiv.org/abs/1411.5161v1"
  },
  {
    "title": "User-driven Privacy Enforcement for Cloud-based Services in the Internet of Things",
    "author": [
      "Martin Henze",
      "Lars Hermerschmidt",
      "Daniel Kerpen",
      "Roger Häußling",
      "Bernhard Rumpe",
      "Klaus Wehrle"
    ],
    "abstract": "Internet of Things devices are envisioned to penetrate essentially all aspects of life, including homes and urbanspaces, in use cases such as health care, assisted living, and smart cities. One often proposed solution for dealing with the massive amount of data collected by these devices and offering services on top of them is the federation of the Internet of Things and cloud computing. However, user acceptance of such systems is a critical factor that hinders the adoption of this promising approach due to severe privacy concerns. We present UPECSI, an approach for user-driven privacy enforcement for cloud-based services in the Internet of Things to address this critical factor. UPECSI enables enforcement of all privacy requirements of the user once her sensitive data leaves the border of her network, provides a novel approach for the integration of privacy functionality into the development process of cloud-based services, and offers the user an adaptable and transparent configuration of her privacy requirements. Hence, UPECSI demonstrates an approach for realizing user-accepted cloud services in the Internet of Things.",
    "lastUpdated": "2014-12-09T14:02:52Z",
    "category": [
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/1412.3325v1"
  },
  {
    "title": "Decoding the Text Encoding",
    "author": [
      "Fereshteh Sadeghi",
      "Hamid Izadinia"
    ],
    "abstract": "Word clouds and text visualization is one of the recent most popular and widely used types of visualizations. Despite the attractiveness and simplicity of producing word clouds, they do not provide a thorough visualization for the distribution of the underlying data. Therefore, it is important to redesign word clouds for improving their design choices and to be able to do further statistical analysis on data. In this paper we have proposed a fully automatic redesigning algorithm for word cloud visualization. Our proposed method is able to decode an input word cloud visualization and provides the raw data in the form of a list of (word, value) pairs. To the best of our knowledge our work is the first attempt to extract raw data from word cloud visualization. We have tested our proposed method both qualitatively and quantitatively. The results of our experiments show that our algorithm is able to extract the words and their weights effectively with considerable low error rate.",
    "lastUpdated": "2014-12-16T04:34:16Z",
    "category": [
      "cs.HC"
    ],
    "url": "http://arxiv.org/abs/1412.6079v1"
  },
  {
    "title": "Crowdsourced Live Streaming over the Cloud",
    "author": [
      "Fei Chen",
      "Cong Zhang",
      "Feng Wang",
      "Jiangchuan Liu"
    ],
    "abstract": "Empowered by today's rich tools for media generation and distribution, and the convenient Internet access, crowdsourced streaming generalizes the single-source streaming paradigm by including massive contributors for a video channel. It calls a joint optimization along the path from crowdsourcers, through streaming servers, to the end-users to minimize the overall latency. The dynamics of the video sources, together with the globalized request demands and the high computation demand from each sourcer, make crowdsourced live streaming challenging even with powerful support from modern cloud computing. In this paper, we present a generic framework that facilitates a cost-effective cloud service for crowdsourced live streaming. Through adaptively leasing, the cloud servers can be provisioned in a fine granularity to accommodate geo-distributed video crowdsourcers. We present an optimal solution to deal with service migration among cloud instances of diverse lease prices. It also addresses the location impact to the streaming quality. To understand the performance of the proposed strategies in the realworld, we have built a prototype system running over the planetlab and the Amazon/Microsoft Cloud. Our extensive experiments demonstrate that the effectiveness of our solution in terms of deployment cost and streaming quality.",
    "lastUpdated": "2015-02-23T04:44:02Z",
    "category": [
      "cs.MM",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1502.06314v1"
  },
  {
    "title": "CloudTree: A Library to Extend Cloud Services for Trees",
    "author": [
      "Yun Tian",
      "Bojian Xu",
      "Yanqing Ji",
      "Jesse Scholer"
    ],
    "abstract": "In this work, we propose a library that enables on a cloud the creation and management of tree data structures from a cloud client. As a proof of concept, we implement a new cloud service CloudTree. With CloudTree, users are able to organize big data into tree data structures of their choice that are physically stored in a cloud. We use caching, prefetching, and aggregation techniques in the design and implementation of CloudTree to enhance performance. We have implemented the services of Binary Search Trees (BST) and Prefix Trees as current members in CloudTree and have benchmarked their performance using the Amazon Cloud. The idea and techniques in the design and implementation of a BST and prefix tree is generic and thus can also be used for other types of trees such as B-tree, and other link-based data structures such as linked lists and graphs. Preliminary experimental results show that CloudTree is useful and efficient for various big data applications.",
    "lastUpdated": "2015-04-30T21:59:29Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1505.00043v1"
  },
  {
    "title": "Survey on security issues in file management in cloud computing environment",
    "author": [
      "Udit Gupta"
    ],
    "abstract": "Cloud computing has pervaded through every aspect of Information technology in past decade. It has become easier to process plethora of data, generated by various devices in real time, with the advent of cloud networks. The privacy of users data is maintained by data centers around the world and hence it has become feasible to operate on that data from lightweight portable devices. But with ease of processing comes the security aspect of the data. One such security aspect is secure file transfer either internally within cloud or externally from one cloud network to another. File management is central to cloud computing and it is paramount to address the security concerns which arise out of it. This survey paper aims to elucidate the various protocols which can be used for secure file transfer and analyze the ramifications of using each protocol.",
    "lastUpdated": "2015-06-20T06:02:10Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1505.00729v2"
  },
  {
    "title": "Factors Influencing the Adoption of Cloud Incident Handling Strategy: A Preliminary Study in Malaysia",
    "author": [
      "Nurul Hidayah Ab Rahman",
      "Kim-Kwang Raymond Choo"
    ],
    "abstract": "This study seeks to understand the factors influencing the adoption of an incident handling strategy by organisational cloud service users. We propose a conceptual model that draws upon the Situation Awareness (SA) model and Protection Motivation Theory (PMT) to guide this research. 40 organisational cloud service users in Malaysia were surveyed. We also conduct face-to-face interviews with participants from four of the organisations. Findings from the study indicate that four PMT factors (Perceived Vulnerability, Self-Efficacy, Response Efficacy, and Perceived Severity) have a significantly influence on the adoption of cloud incident handling strategy within the organisations. We, therefore, suggest a successful adoption cloud incident handling strategy by organisational cloud service users involves the nexus between these four PMT factors. We also outline future research required to validate the model.",
    "lastUpdated": "2015-05-12T08:42:28Z",
    "category": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1505.02908v1"
  },
  {
    "title": "Request Prediction in Cloud with a Cyclic Window Learning Algorithm",
    "author": [
      "Min Sang Yoon",
      "Ahmed E. Kamal",
      "Zhengyuan Zhu"
    ],
    "abstract": "Automatic resource scaling is one advantage of Cloud systems. Cloud systems are able to scale the number of physical machines depending on user requests. Therefore, accurate request prediction brings a great improvement in Cloud systems' performance. If we can make accurate requests prediction, the appropriate number of physical machines that can accommodate predicted amount of requests can be activated and Cloud systems will save more energy by preventing excessive activation of physical machines. Also, Cloud systems can implement advanced load distribution with accurate requests prediction. We propose an algorithm that predicts a probability distribution parameters of requests for each time interval. Maximum Likelihood Estimation (MLE) and Local Linear Regression (LLR) are used to implement this algorithm. An evaluation of the proposed algorithm is performed with the Google cluster-trace data. The prediction is implemented about the number of task arrivals, CPU requests, and memory requests. Then the accuracy of prediction is measured with Mean Absolute Percentage Error (MAPE).",
    "lastUpdated": "2015-07-09T04:43:57Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1507.02372v1"
  },
  {
    "title": "Hyper Heterogeneous Cloud-based IMS Software Architecture: A Proof-of-Concept and Empirical Analysis",
    "author": [
      "Pascal Potvin",
      "Hanen Garcia Gamardo",
      "Kim-Khoa Nguyen",
      "Mohamed Cheriet"
    ],
    "abstract": "The IP Multimedia Subsystem (IMS) defined by the 3GPP has been mainly developed and deployed by telephony vendors on vendor-specific hardware. Recent advances in Network Function Virtualisation (NFV) technology paved the way for virtualized hardware and telephony function elasticity. As such, Telecom vendors have started to embrace the cloud as a deployment platform, usually selecting a privileged virtualization platform. Operators would like to deploy telecom functionality on their already existing IT cloud platforms. Achieving such flexibility would require the telecom vendors to adopt a software architecture allowing deployment on many cloud platforms or even heterogeneous cloud platforms. We propose a distributed software architecture enabling the deployment of a single software version on multiple cloud platforms thus allowing for a solution-based deployment. We also present a prototype we developed to study the characteristics of this architecture.",
    "lastUpdated": "2015-09-18T15:34:21Z",
    "category": [
      "cs.DC",
      "C.2.4; D.1.3; D.2.11"
    ],
    "url": "http://arxiv.org/abs/1507.04039v2"
  },
  {
    "title": "Budget Constrained Execution of Multiple Bag-of-Tasks Applications on the Cloud",
    "author": [
      "Long Thai",
      "Blesson Varghese",
      "Adam Barker"
    ],
    "abstract": "Optimising the execution of Bag-of-Tasks (BoT) applications on the cloud is a hard problem due to the trade- offs between performance and monetary cost. The problem can be further complicated when multiple BoT applications need to be executed. In this paper, we propose and implement a heuristic algorithm that schedules tasks of multiple applications onto different cloud virtual machines in order to maximise performance while satisfying a given budget constraint. Current approaches are limited in task scheduling since they place a limit on the number of cloud resources that can be employed by the applications. However, in the proposed algorithm there are no such limits, and in comparison with other approaches, the algorithm on average achieves an improved performance of 10%. The experimental results also highlight that the algorithm yields consistent performance even with low budget constraints which cannot be achieved by competing approaches.",
    "lastUpdated": "2015-07-20T12:25:54Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1507.05467v1"
  },
  {
    "title": "An SLA-based Advisor for Placement of HPC Jobs on Hybrid Clouds",
    "author": [
      "Kiran Mantripragada",
      "Leonardo P. Tizzei",
      "Alecio P. D. Binotto",
      "Marco A. S. Netto"
    ],
    "abstract": "Several scientific and industry applications require High Performance Computing (HPC) resources to process and/or simulate complex models. Not long ago, companies, research institutes, and universities used to acquire and maintain on-premise computer clusters; but, recently, cloud computing has emerged as an alternative for a subset of HPC applications. This poses a challenge to end-users, who have to decide where to run their jobs: on local clusters or burst to a remote cloud service provider. While current research on HPC cloud has focused on comparing performance of on-premise clusters against cloud resources, we build on top of existing efforts and introduce an advisory service to help users make this decision considering the trade-offs of resource costs, performance, and availability on hybrid clouds. We evaluated our service using a real test-bed with a seismic processing application based on Full Waveform Inversion; a technique used by geophysicists in the oil & gas industry and earthquake prediction. We also discuss how the advisor can be used for other applications and highlight the main lessons learned constructing this service to reduce costs and turnaround times.",
    "lastUpdated": "2015-07-20T12:41:32Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1507.05472v1"
  },
  {
    "title": "RC3E: Provision and Management of Reconfigurable Hardware Accelerators in a Cloud Environment",
    "author": [
      "Oliver Knodel",
      "Rainer G. Spallek"
    ],
    "abstract": "Heterogeneous systems consisting of general-purpose processors and different types of hardware accelerators are becoming more and more common in HPC systems. Especially FPGAs provide a promising opportunity to improve both performance and energy efficiency of such systems. Adding FPGAs to clouds or data centers allows easy access to such reconfigurable resources. In this paper we present our cloud service models and cloud hypervisor called RC3E, which integrates virtualized FPGA-based hardware accelerators into a cloud environment. With our hardware and software framework, multiple (virtual) user designs can be executed on a single physical FPGA device. We demonstrate the performance of our approach by implementing up to four virtual user cores on a single device and present future perspectives for FPGAs in cloud-based data environments.",
    "lastUpdated": "2015-08-27T13:05:24Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1508.06843v1"
  },
  {
    "title": "Brewing Analytics Quality for Cloud Performance",
    "author": [
      "Li Chen",
      "Pooja Jain",
      "Kingsum Chow",
      "Emad Guirguis",
      "Tony Wu"
    ],
    "abstract": "Cloud computing has become increasingly popular. Many options of cloud deployments are available. Testing cloud performance would enable us to choose a cloud deployment based on the requirements. In this paper, we present an innovative process, implemented in software, to allow us to assess the quality of the cloud performance data. The process combines performance data from multiple machines, spanning across user experience data, workload performance metrics, and readily available system performance data. Furthermore, we discuss the major challenges of bringing raw data into tidy data formats in order to enable subsequent analysis, and describe how our process has several layers of assessment to validate the quality of the data processing procedure. We present a case study to demonstrate the effectiveness of our proposed process, and conclude our paper with several future research directions worth investigating.",
    "lastUpdated": "2015-08-31T23:55:54Z",
    "category": [
      "cs.PF",
      "cs.DC",
      "stat.AP"
    ],
    "url": "http://arxiv.org/abs/1509.00095v1"
  },
  {
    "title": "Factors influencing risk acceptance of Cloud Computing services in the UK Government",
    "author": [
      "Gianfranco Elena",
      "Christopher W. Johnson"
    ],
    "abstract": "Cloud Computing services are increasingly being made available by the UK Government through the Government digital marketplace to reduce costs and improve IT efficiency; however, little is known about factors influencing the decision-making process to adopt cloud services within the UK Government. This research aims to develop a theoretical framework to understand risk perception and risk acceptance of cloud computing services. Study subjects (N=24) were recruited from three UK Government organizations to attend a semi- structured interview. Transcribed texts were analyzed using the approach termed interpretive phenomenological analysis. Results showed that the most important factors influencing risk acceptance of cloud services are: perceived benefits and opportunities, organization risk culture and perceived risks. We focused on perceived risks and perceived security concerns. Based on these results, we suggest a number of implications for risk managers, policy makers and cloud service providers.",
    "lastUpdated": "2015-09-22T09:57:54Z",
    "category": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1509.06533v1"
  },
  {
    "title": "The Cloud Needs a Reputation System",
    "author": [
      "Murad Kablan",
      "Carlee Joe-Won",
      "Sangtae Ha",
      "Hani Jamjoom",
      "Eric Keller"
    ],
    "abstract": "Today's cloud apps are built from many diverse services that are managed by different parties. At the same time, these parties, which consume and/or provide services, continue to rely on arcane static security and entitlements models. In this paper, we introduce Seit, an inter-tenant framework that manages the interactions between cloud services. Seit is a software-defined reputation-based framework. It consists of two primary components: (1) a set of integration and query interfaces that can be easily integrated into cloud and service providers' management stacks, and (2) a controller that maintains reputation information using a mechanism that is adaptive to the highly dynamic environment of the cloud. We have fully implemented Seit, and integrated it into an SDN controller, a load balancer, a cloud service broker, an intrusion detection system, and a monitoring framework. We evaluate the efficacy of Seit using both an analytical model and a Mininet-based emulated environment. Our analytical model validate the isolation and stability properties of Seit. Using our emulated environment, we show that Seit can provide improved security by isolating malicious tenants, reduced costs by adapting the infrastructure without compromising security, and increased revenues for high quality service providers by enabling reputation to impact discovery.",
    "lastUpdated": "2015-09-30T08:13:35Z",
    "category": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1509.09057v1"
  },
  {
    "title": "Robustness enhancement of cloud computing network based on coupled networks model",
    "author": [
      "Zibin Su",
      "Jing Yuan"
    ],
    "abstract": "As a novel technology, cloud computing attracts more and more people including technology enthusiasts and malicious users. Different from the classical network architecture, cloud environment has many its own features which make the traditional defense mechanism invalid. To make the network more robust against a malicious attack, we introduce a new method to mitigate this risk efficiently and systematically. In this paper, we first propose a coupled networks model which adequately considers the interactions between physical layer and virtual layer in a practical cloud computing environment. Based on this new model and our systematical method, we show that with the addition of protection of some specific nodes in the network structure, the robustness of cloud computing's network can be significantly improved whereas their functionality remains unchanged. Our results demonstrate that our new method can effectively settle the hard problems which cloud computing now is facing without much cost.",
    "lastUpdated": "2015-12-09T05:41:34Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1512.02756v1"
  },
  {
    "title": "Forensic Acquisition of Cloud Drives",
    "author": [
      "Vassil Roussev",
      "Andres Barreto",
      "Irfan Ahmed"
    ],
    "abstract": "Cloud computing and cloud storage services, in particular, pose a new challenge to digital forensic investigations. Currently, evidence acquisition for such services still follows the traditional method of collecting artifacts on a client device. This approach requires labor-intensive reverse engineering efforts, and ultimately results in an acquisition that is inherently incomplete. Specifically, it makes the incorrect assumption that all storage content for an account is fully replicated on the client; further, there are no means to acquire historical data in the form of document revisions, nor is there a way to acquire cloud-native artifacts, such as Google Docs. In this work, we introduce the concept of API-based evidence acquisition for cloud services, which addresses these concerns by utilizing the officially supported API of the service. To demonstrate the utility of this approach, we present a proof-of-concept acquisition tool, kumodd, which can acquire evidence from four major cloud drive providers: Google Drive, Microsoft OneDrive, Dropbox, and Box. The implementation provides both command-line and web user interfaces, and can be readily incorporated into established forensic processes.",
    "lastUpdated": "2016-01-26T06:07:39Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1603.06542v1"
  },
  {
    "title": "Design and implementation of the advanced cloud privacy threat modeling",
    "author": [
      "Ali Gholami",
      "Anna-Sara Lind",
      "Jane Reichel",
      "Jan-Eric Litton",
      "Ake Edlund",
      "Erwin Laure"
    ],
    "abstract": "Privacy-preservation for sensitive data has become a challenging issue in cloud computing. Threat modeling as a part of requirements engineering in secure software development provides a structured approach for identifying attacks and proposing countermeasures against the exploitation of vulnerabilities in a system . This paper describes an extension of Cloud Privacy Threat Modeling (CPTM) methodology for privacy threat modeling in relation to processing sensitive data in cloud computing environments. It describes the modeling methodology that involved applying Method Engineering to specify characteristics of a cloud privacy threat modeling methodology, different steps in the proposed methodology and corresponding products. In addition, a case study has been implemented as a proof of concept to demonstrate the usability of the proposed methodology. We believe that the extended methodology facilitates the application of a privacy-preserving cloud software development approach from requirements engineering to design.",
    "lastUpdated": "2016-04-03T18:27:37Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1604.00666v1"
  },
  {
    "title": "Color-based Segmentation of Sky/Cloud Images From Ground-based Cameras",
    "author": [
      "Soumyabrata Dev",
      "Yee Hui Lee",
      "Stefan Winkler"
    ],
    "abstract": "Sky/cloud images captured by ground-based cameras (a.k.a. whole sky imagers) are increasingly used nowadays because of their applications in a number of fields, including climate modeling, weather prediction, renewable energy generation, and satellite communications. Due to the wide variety of cloud types and lighting conditions in such images, accurate and robust segmentation of clouds is challenging. In this paper, we present a supervised segmentation framework for ground-based sky/cloud images based on a systematic analysis of different color spaces and components, using partial least squares (PLS) regression. Unlike other state-of-the-art methods, our proposed approach is entirely learning-based and does not require any manually-defined parameters. In addition, we release the Singapore Whole Sky IMaging SEGmentation Database (SWIMSEG), a large database of annotated sky/cloud images, to the research community.",
    "lastUpdated": "2016-06-12T06:17:10Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1606.03669v1"
  },
  {
    "title": "An Approach for Parallel Genetic Algorithms in the Cloud using Software Containers",
    "author": [
      "Pasquale Salza",
      "Filomena Ferrucci"
    ],
    "abstract": "Genetic Algorithms (GAs) are a powerful technique to address hard optimisation problems. However, scalability issues might prevent them from being applied to real-world problems. Exploiting parallel GAs in the cloud might be an affordable approach to get time efficient solutions that benefit of the appealing features of the cloud, such as scalability, reliability, fault-tolerance and cost-effectiveness. Nevertheless, distributed computation is very prone to cause considerable overhead for communication and making GAs distributed in an on-demand fashion is not trivial. Aiming to keep under control the communication overhead and support GAs developers in the construction and deployment of parallel GAs in the cloud, in this paper we propose an approach to distribute GAs using the global parallelisation model, exploiting software containers and their cloud orchestration. We also devised a conceptual workflow covering each cloud GAs distribution phase, from resources allocation to actual deployment and execution, in a DevOps fashion.",
    "lastUpdated": "2016-06-22T14:32:34Z",
    "category": [
      "cs.NE",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1606.06961v1"
  },
  {
    "title": "IoT Cloud-based Distribution System State Estimation: Virtual Objects and Context-Awareness",
    "author": [
      "Alessio Meloni",
      "Paolo Attilio Pegoraro",
      "Luigi Atzori",
      "Paolo Castello",
      "Sara Sulis"
    ],
    "abstract": "This paper presents an IoT cloud-based state estimation system for distribution networks in which the PMUs (Phasor Measurement Units) are virtualized with respect to the physical devices. In the considered system only application level entities are put in the cloud, whereas virtualized PMUs are running in the communication network edge (i.e. closer to the physical objects) in order to have a certain degree of local logic, which allows to implement a bandwidth-efficient and smart data transmission to the involved applications in the cloud. The major contributions of the paper are the following: we demonstrate that a cloud-based architecture is capable of achieving the QoS level required by the specific state estimation application; we show that implementing a certain local logic for data transmission in the cloud, the result of the state estimation is not degraded with respect to the case of an estimation that takes place frequently at fixed intervals; we show the results in terms of latency and reduced network load for a reference smart grid network.",
    "lastUpdated": "2016-06-29T11:09:28Z",
    "category": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1606.09043v1"
  },
  {
    "title": "Auto-scaling Web Applications in Clouds: A Taxonomy and Survey",
    "author": [
      "Chenhao Qu",
      "Rodrigo N. Calheiros",
      "Rajkumar Buyya"
    ],
    "abstract": "Web application providers have been migrating their applications to cloud data centers, attracted by the emerging cloud computing paradigm. One of the appealing features of the cloud is elasticity. It allows cloud users to acquire or release computing resources on-demand, which enables web application providers to automatically scale the resources provisioned to their applications without human intervention under a dynamic workload to minimize resource cost while satisfying Quality of Service (QoS) requirements. In this paper, we comprehensively analyze the challenges that remain in auto-scaling web applications in clouds and review the developments in this field. We present a taxonomy of auto-scalers according to the identified challenges and key properties. We analyze the surveyed works and map them to the taxonomy to identify the weaknesses in this field. Moreover, based on the analysis, we propose new future directions that can be explored in this area.",
    "lastUpdated": "2017-09-14T16:19:03Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1609.09224v6"
  },
  {
    "title": "Managing Usability and Reliability Aspects in Cloud Computing",
    "author": [
      "Maria Spichkova",
      "Heinz W. Schmidt",
      "Ian E. Thomas",
      "Iman I. Yusuf",
      "Steve Androulakis",
      "Grischa R. Meyer"
    ],
    "abstract": "Cloud computing provides a great opportunity for scientists, as it enables large-scale experiments that cannot are too long to run on local desktop machines. Cloud-based computations can be highly parallel, long running and data-intensive, which is desirable for many kinds of scientific experiments. However, to unlock this power, we need a user-friendly interface and an easy-to-use methodology for conducting these experiments. For this reason, we introduce here a formal model of a cloud-based platform and the corresponding open-source implementation. The proposed solution allows to conduct experiments without having a deep technical understanding of cloud-computing, HPC, fault tolerance, or data management in order to leverage the benefits of cloud computing. In the current version, we have focused on biophysics and structural chemistry experiments, based on the analysis of big data from synchrotrons and atomic force microscopy. The domain experts noted the time savings for computing and data management, as well as user-friendly interface.",
    "lastUpdated": "2016-12-06T05:58:40Z",
    "category": [
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/1612.01675v1"
  },
  {
    "title": "Spontaneous Proximity Clouds: Making Mobile Devices to Collaborate for Resource and Data Sharing",
    "author": [
      "Roya Golchay",
      "Frédéric Le Mouël",
      "Julien Ponge",
      "Nicolas Stouls"
    ],
    "abstract": "The base motivation of Mobile Cloud Computing was empowering mobile devices by application offloading onto powerful cloud resources. However, this goal can't entirely be reached because of the high offloading cost imposed by the long physical distance between the mobile device and the cloud. To address this issue, we propose an application offloading onto a nearby mobile cloud composed of the mobile devices in the vicinity-a Spontaneous Proximity Cloud. We introduce our proposed dynamic, ant-inspired, bi-objective offloading middleware-ACOMMA, and explain its extension to perform a close mobile application offloading. With the learning-based offloading decision-making process of ACOMMA, combined to the collaborative resource sharing, the mobile devices can cooperate for decision cache sharing. We evaluate the performance of ACOMMA in collaborative mode with real benchmarks Face Recognition and Monte-Carlo algorithms-and achieve 50% execution time gain.",
    "lastUpdated": "2016-11-03T10:29:30Z",
    "category": [
      "cs.NI",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1612.02468v1"
  },
  {
    "title": "Homomorphic Encryption Experiments on IBM's Cloud Quantum Computing Platform",
    "author": [
      "He-Liang Huang",
      "You-Wei Zhao",
      "Tan Li",
      "Feng-Guang Li",
      "Yu-Tao Du",
      "Xiang-Qun Fu",
      "Shuo Zhang",
      "Xiang Wang",
      "Wan-Su Bao"
    ],
    "abstract": "Quantum computing has undergone rapid development in recent years. Owing to limitations on scalability, personal quantum computers still seem slightly unrealistic in the near future. The first practical quantum computer for ordinary users is likely to be on the cloud. However, the adoption of cloud computing is possible only if security is ensured. Homomorphic encryption is a cryptographic protocol that allows computation to be performed on encrypted data without decrypting them, so it is well suited to cloud computing. Here, we first applied homomorphic encryption on IBM's cloud quantum computer platform. In our experiments, we successfully implemented a quantum algorithm for linear equations while protecting our privacy. This demonstration opens a feasible path to the next stage of development of cloud quantum information technology.",
    "lastUpdated": "2017-07-02T04:08:24Z",
    "category": [
      "cs.CR",
      "physics.data-an"
    ],
    "url": "http://arxiv.org/abs/1612.02886v2"
  },
  {
    "title": "Catalyzing Cloud-Fog Interoperation in 5G Wireless Networks: An SDN Approach",
    "author": [
      "Peng Yang",
      "Ning Zhang",
      "Yuanguo Bi",
      "Li Yu",
      "Xuemin",
      "Shen"
    ],
    "abstract": "The piling up storage and compute stacks in cloud data center are expected to accommodate the majority of internet traffic in the future. However, as the number of mobile devices significantly increases, getting massive data into and out of the cloud wirelessly inflicts high pressure on the bandwidth, and meanwhile induces unpredictable latency. Fog computing, which advocates extending clouds to network edge, guarantees low latency and location-aware service provisioning. In this article, we consider fog computing as an ideal complement rather than a substitute of cloud computing, and we propose a software defined networking (SDN) enabled framework for cloud-fog interoperation, aiming at improving quality of experience and optimizing network resource usage. Two case studies are provided to illuminate the feasibility and advantage of the proposed framework. At last, potential research issues are presented for further investigation.",
    "lastUpdated": "2016-12-15T22:21:37Z",
    "category": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1612.05291v1"
  },
  {
    "title": "H-infinity Filtering for Cloud-Aided Semi-active Suspension with Delayed Information",
    "author": [
      "Zhaojian Li",
      "Ilya Kolmanovsky",
      "Ella Atkins",
      "Jianbo Lu",
      "Dimitar Filev"
    ],
    "abstract": "This chapter presents an H-infinity filtering framework for cloud-aided semiactive suspension system with time-varying delays. In this system, road profile information is downloaded from a cloud database to facilitate onboard estimation of suspension states. Time-varying data transmission delays are considered and assumed to be bounded. A quarter-car linear suspension model is used and an H-infinity filter is designed with both onboard sensor measurements and delayed road profile information from the cloud. The filter design procedure is designed based on linear matrix inequalities (LMIs). Numerical simulation results are reported that illustrates the fusion of cloud-based and on-board information that can be achieved in Vehicleto- Cloud-to-Vehicle (V2C2V) implementation.",
    "lastUpdated": "2017-01-10T18:18:19Z",
    "category": [
      "cs.SY"
    ],
    "url": "http://arxiv.org/abs/1701.02714v1"
  },
  {
    "title": "Using Multiple Seasonal Holt-Winters Exponential Smoothing to Predict Cloud Resource Provisioning",
    "author": [
      "Ashraf A. Shahin"
    ],
    "abstract": "Elasticity is one of the key features of cloud computing that attracts many SaaS providers to minimize their services' cost. Cost is minimized by automatically provision and release computational resources depend on actual computational needs. However, delay of starting up new virtual resources can cause Service Level Agreement violation. Consequently, predicting cloud resources provisioning gains a lot of attention to scale computational resources in advance. However, most of current approaches do not consider multi-seasonality in cloud workloads. This paper proposes cloud resource provisioning prediction algorithm based on Holt-Winters exponential smoothing method. The proposed algorithm extends Holt-Winters exponential smoothing method to model cloud workload with multi-seasonal cycles. Prediction accuracy of the proposed algorithm has been improved by employing Artificial Bee Colony algorithm to optimize its parameters. Performance of the proposed algorithm has been evaluated and compared with double and triple exponential smoothing methods. Our results have shown that the proposed algorithm outperforms other methods.",
    "lastUpdated": "2017-01-12T10:48:37Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1701.03296v1"
  },
  {
    "title": "Privacy Protection for Mobile Cloud Data: A Network Coding Approach",
    "author": [
      "Yu-Jia Chen",
      "Li-Chun Wang"
    ],
    "abstract": "Taking into account of both the huge computing power of intruders and untrusted cloud servers, we develop an enhanced secure pseudonym scheme to protect the privacy of mobile cloud data. To face the huge computing power challenge, we develop an unconditionally secure lightweight network coding pseudonym scheme. For the privacy issue of untrusted cloud server, we further design a two tier network coding to decouple the stored mobile cloud data from the owner pseudonyms. Therefore, our proposed network coding based pseudonym scheme can simultaneously defend against attackers from both outside and inside. We implement our proposed two-tier light-weight network coding mechanism in a group location based service (LBS) using untrusted cloud database. Compared to computationally secure Hash-based pseudonym, our proposed scheme is not only unconditionally secure, but also can reduce more than 90 percent of processing time as well as 10 percent of energy consumption.",
    "lastUpdated": "2017-01-11T14:58:38Z",
    "category": [
      "cs.CR",
      "cs.IT",
      "math.IT"
    ],
    "url": "http://arxiv.org/abs/1701.07075v1"
  },
  {
    "title": "A review on cloud robotics based frameworks to solve simultaneous localization and mapping (slam) problem",
    "author": [
      "Rajesh Doriya",
      "Paresh Sao",
      "Vinit Payal",
      "Vibhav Anand",
      "Pavan Chakraborty"
    ],
    "abstract": "Cloud Robotics is one of the emerging area of robotics. It has created a lot of attention due to its direct practical implications on Robotics. In Cloud Robotics, the concept of cloud computing is used to offload computational extensive jobs of the robots to the cloud. Apart from this, additional functionalities can also be offered on run to the robots on demand. Simultaneous Localization and Mapping (SLAM) is one of the computational intensive algorithm in robotics used by robots for navigation and map building in an unknown environment. Several Cloud based frameworks are proposed specifically to address the problem of SLAM, DAvinCi, Rapyuta and C2TAM are some of those framework. In this paper, we presented a detailed review of all these framework implementation for SLAM problem.",
    "lastUpdated": "2017-01-29T22:27:15Z",
    "category": [
      "cs.RO"
    ],
    "url": "http://arxiv.org/abs/1701.08444v1"
  },
  {
    "title": "Foveated Video Streaming for Cloud Gaming",
    "author": [
      "Gazi Illahi",
      "Matti Siekkinen",
      "Enrico Masala"
    ],
    "abstract": "Good user experience with interactive cloud-based multimedia applications, such as cloud gaming and cloud-based VR, requires low end-to-end latency and large amounts of downstream network bandwidth at the same time. In this paper, we present a foveated video streaming system for cloud gaming. The system adapts video stream quality by adjusting the encoding parameters on the fly to match the player's gaze position. We conduct measurements with a prototype that we developed for a cloud gaming system in conjunction with eye tracker hardware. Evaluation results suggest that such foveated streaming can reduce bandwidth requirements by even more than 50% depending on parametrization of the foveated video coding and that it is feasible from the latency perspective.",
    "lastUpdated": "2017-06-15T10:14:25Z",
    "category": [
      "cs.MM"
    ],
    "url": "http://arxiv.org/abs/1706.04804v1"
  },
  {
    "title": "Cost-Based Assessment of Partitioning Algorithms of Agent-Based Systems on Hybrid Cloud Environments",
    "author": [
      "Chahrazed Labba",
      "Narjès Bellamine Ben Saoud"
    ],
    "abstract": "Distributing agent-based simulators reveals many challenges while deploying them on a hybrid cloud infrastructure. In fact, a researcher's main motivations by running simulations on hybrid clouds, are reaching more scalable systems as well as reducing monetary costs. Indeed, hybrid cloud environment, despite providing scalability and effective control over proper data, requires an efficient deployment strategy combining both an efficient partitioning mechanism and cost savings. In this paper, we propose a cost deployment model dedicated to distributed agent-based simulation systems. This cost model, combining general performance partitioning criteria as well as monetary costs, is used to evaluate cluster and grid based partitioning algorithms on hybrid cloud environments. The first experimental results show that, for a given agent-based model, a good partitioning method used with the suitable hybrid cloud environment lead to an efficient and economic deployment.",
    "lastUpdated": "2017-09-17T19:36:48Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1709.05708v1"
  },
  {
    "title": "SO-Net: Self-Organizing Network for Point Cloud Analysis",
    "author": [
      "Jiaxin Li",
      "Ben M. Chen",
      "Gim Hee Lee"
    ],
    "abstract": "This paper presents SO-Net, a permutation invariant architecture for deep learning with orderless point clouds. The SO-Net models the spatial distribution of point cloud by building a Self-Organizing Map (SOM). Based on the SOM, SO-Net performs hierarchical feature extraction on individual points and SOM nodes, and ultimately represents the input point cloud by a single feature vector. The receptive field of the network can be systematically adjusted by conducting point-to-node k nearest neighbor search. In recognition tasks such as point cloud reconstruction, classification, object part segmentation and shape retrieval, our proposed network demonstrates performance that is similar with or better than state-of-the-art approaches. In addition, the training speed is significantly faster than existing point cloud recognition networks because of the parallelizability and simplicity of the proposed architecture. Our code is available at the project website. https://github.com/lijx10/SO-Net",
    "lastUpdated": "2018-03-27T02:59:48Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1803.04249v4"
  },
  {
    "title": "An Efficient Secure Distributed Cloud Storage for Append-only Data",
    "author": [
      "Binanda Sengupta",
      "Nishant Nikam",
      "Sushmita Ruj",
      "Srinivasan Narayanamurthy",
      "Siddhartha Nandi"
    ],
    "abstract": "Cloud computing enables users (clients) to outsource large volume of their data to cloud servers. Secure distributed cloud storage schemes ensure that multiple servers store these data in a reliable and untampered fashion. We propose an idea to construct such a scheme for static data by encoding data blocks (using error-correcting codes) and then attaching authentication information (tags) to these encoded blocks. We identify some challenges while extending this idea to accommodate append-only data. Then, we propose our secure distributed cloud storage scheme for append-only data that addresses the challenges efficiently. The main advantage of our scheme is that it enables the servers to update the parity blocks themselves. Moreover, the client need not download any data (or parity) block to update the tags of the modified parity blocks residing on the servers. Finally, we analyze the security and performance of our scheme.",
    "lastUpdated": "2018-06-03T13:42:04Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1805.02970v3"
  },
  {
    "title": "Cloud-Edge Non-Orthogonal Transmission for Fog Networks with Delayed CSI at the Cloud",
    "author": [
      "Jingjing Zhang",
      "Osvaldo Simeone"
    ],
    "abstract": "In a Fog Radio Access Network (F-RAN), the cloud processor (CP) collects channel state information (CSI) from the edge nodes (ENs) over fronthaul links. As a result, the CSI at the cloud is generally affected by an error due to outdating. In this work, the problem of content delivery based on fronthaul transmission and edge caching is studied from an information-theoretic perspective in the high signal-to-noise ratio (SNR) regime. For the set-up under study, under the assumption of perfect CSI, prior work has shown the (approximate or exact) optimality of a scheme in which the ENs transmit information received from the cloud and cached contents over orthogonal resources. In this work, it is demonstrated that a non-orthogonal transmission scheme is able to substantially improve the latency performance in the presence of imperfect CSI at the cloud.",
    "lastUpdated": "2018-05-25T08:16:55Z",
    "category": [
      "cs.IT",
      "math.IT"
    ],
    "url": "http://arxiv.org/abs/1805.10024v1"
  },
  {
    "title": "The Architectural Implications of Microservices in the Cloud",
    "author": [
      "Yu Gan",
      "Christina Delimitrou"
    ],
    "abstract": "Cloud services have recently undergone a shift from monolithic applications to microservices, with hundreds or thousands of loosely-coupled microservices comprising the end-to-end application. Microservices present both opportunities and challenges when optimizing for quality of service (QoS) and cloud utilization. In this paper we explore the implications cloud microservices have on system bottlenecks, and datacenter server design. We first present and characterize an end-to-end application built using tens of popular open-source microservices that implements a movie renting and streaming service, and is modular and extensible. We then use the end-to-end service to study the scalability and performance bottlenecks of microservices, and highlight implications they have on the design of datacenter hardware. Specifically, we revisit the long-standing debate of brawny versus wimpy cores in the context of microservices, we quantify the I-cache pressure they introduce, and measure the time spent in computation versus communication between microservices over RPCs. As more cloud applications switch to this new programming model, it is increasingly important to revisit the assumptions we have previously used to build and manage cloud systems.",
    "lastUpdated": "2018-05-25T20:19:50Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1805.10351v1"
  },
  {
    "title": "Cloud Computing Future Framework for e-management of NGO's",
    "author": [
      "Harjit Singh Lamba",
      "Gurdev Singh"
    ],
    "abstract": "Cloud computing is an emerging new computing paradigm for delivering computing services. This computing approach relies on a number of existing technologies, e.g., the Internet, virtualization, grid computing, Web services, etc. Cloud Computing aims to provide scalable and inexpensive on-demand computing infrastructures with good quality of service levels. It represents a shift away from computing as a product that is purchased, to computing as a service that is delivered to consumers from the cloud. It helps an organization in saving costs and creating new business opportunities.This paper provides a framework, Education Cloud for the e- management of NGO's. The Education Cloud can transform a nonprofit, or an entire sector of nonprofits, achieves its mission and creates lasting impact in its communities. This paper also presents the case study of Kalgidhar trust, Baru Sahib, Himachal Pradesh, NGO which is using the education as the tool to solve the social issues.",
    "lastUpdated": "2011-07-16T10:16:36Z",
    "category": [
      "cs.OH"
    ],
    "url": "http://arxiv.org/abs/1107.3217v1"
  },
  {
    "title": "Modeling and Analysis of Converged Network-Cloud Services",
    "author": [
      "Eduardo Hargreaves",
      "Paulo H De Aguiar Rodrigues",
      "Daniel S. Menasché"
    ],
    "abstract": "Networks connecting distributed cloud services through multiple data centers are called cloud networks. These types of networks play a crucial role in cloud computing and a holistic performance evaluation is essential before planning a converged network-cloud environment. We analyze a specific case where some resources can be centralized in one datacenter or distributed among multiple data centers. The economy of scale in centralizing resources in a sin- gle pool of resources can be overcome by an increase in communication costs. We propose an analytical model to evaluate tradeoffs in terms of application requirements, usage patterns, number of resources and communication costs. We numerically evaluate the proposed model in a case study inspired by the oil and gas industry, indicating how to cope with the tradeoff between statisti- cal multiplexing advantages of centralization and the corresponding increase in communication infrastructure costs.",
    "lastUpdated": "2016-01-15T15:57:04Z",
    "category": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1601.03976v1"
  },
  {
    "title": "A Workflow for Fast Evaluation of Mapping Heuristics Targeting Cloud Infrastructures",
    "author": [
      "Roman Ursu",
      "Khalid Latif",
      "David Novo",
      "Manuel Selva",
      "Abdoulaye Gamatie",
      "Gilles Sassatelli",
      "Dmitry Khabi",
      "Alexey Cheptsov"
    ],
    "abstract": "Resource allocation is today an integral part of cloud infrastructures management to efficiently exploit resources. Cloud infrastructures centers generally use custom built heuristics to define the resource allocations. It is an immediate requirement for the management tools of these centers to have a fast yet reasonably accurate simulation and evaluation platform to define the resource allocation for cloud applications. This work proposes a framework allowing users to easily specify mappings for cloud applications described in the AMALTHEA format used in the context of the DreamCloud European project and to assess the quality for these mappings. The two quality metrics provided by the framework are execution time and energy consumption.",
    "lastUpdated": "2016-01-27T15:48:40Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1601.07420v1"
  },
  {
    "title": "A Secure Data Enclave and Analytics Platform for Social Scientists",
    "author": [
      "Yadu N. Babuji",
      "Kyle Chard",
      "Aaron Gerow",
      "Eamon Duede"
    ],
    "abstract": "Data-driven research is increasingly ubiquitous and data itself is a defining asset for researchers, particularly in the computational social sciences and humanities. Entire careers and research communities are built around valuable, proprietary or sensitive datasets. However, many existing computation resources fail to support secure and cost-effective storage of data while also enabling secure and flexible analysis of the data. To address these needs we present CLOUD KOTTA, a cloud-based architecture for the secure management and analysis of social science data. CLOUD KOTTA leverages reliable, secure, and scalable cloud resources to deliver capabilities to users, and removes the need for users to manage complicated infrastructure. CLOUD KOTTA implements automated, cost-aware models for efficiently provisioning tiered storage and automatically scaled compute resources. CLOUD KOTTA has been used in production for several months and currently manages approximately 10TB of data and has been used to process more than 5TB of data with over 75,000 CPU hours. It has been used for a broad variety of text analysis workflows, matrix factorization, and various machine learning algorithms, and more broadly, it supports fast, secure and cost-effective research.",
    "lastUpdated": "2016-10-10T21:44:12Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1610.03105v1"
  },
  {
    "title": "Road Curb Extraction from Mobile LiDAR Point Clouds",
    "author": [
      "Sheng Xu",
      "Ruisheng Wang",
      "Han Zheng"
    ],
    "abstract": "Automatic extraction of road curbs from uneven, unorganized, noisy and massive 3D point clouds is a challenging task. Existing methods often project 3D point clouds onto 2D planes to extract curbs. However, the projection causes loss of 3D information which degrades the performance of the detection. This paper presents a robust, accurate and efficient method to extract road curbs from 3D mobile LiDAR point clouds. Our method consists of two steps: 1) extracting the candidate points of curbs based on the proposed novel energy function and 2) refining the candidate points using the proposed least cost path model. We evaluated our method on a large-scale of residential area (16.7GB, 300 million points) and an urban area (1.07GB, 20 million points) mobile LiDAR point clouds. Results indicate that the proposed method is superior to the state-of-the-art methods in terms of robustness, accuracy and efficiency. The proposed curb extraction method achieved a completeness of 78.62% and a correctness of 83.29%. These experiments demonstrate that the proposed method is a promising solution to extract road curbs from mobile LiDAR point clouds.",
    "lastUpdated": "2016-10-27T16:19:31Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1610.04673v2"
  },
  {
    "title": "Proceedings of the First International Workshop on Formal Methods for and on the Cloud",
    "author": [
      "Razieh Behjati",
      "Ahmed Elmokashfi"
    ],
    "abstract": "Cloud solutions are increasingly used for a plethora of purposes, including solving memory-intensive and computation-intensive problems. Ensuring the reliability, availability, scalability, and security of cloud solutions, as networked distributed systems with properties such as dynamic reallocation of resources, is a challenging problem that requires rigorous modeling, analysis, and verification tools. Such tools can be devised using the techniques provided by the formal methods community. On the other hand, many formal analysis and verification tools are memory-intensive and computation-intensive solutions, which can benefit from the cloud technology. The goal of the iFMCloud workshop is to identify and better understand challenges of using formal and semi-formal methods for modeling and verification of Cloud-based systems and computer and communication networks, as well as challenges and opportunities in providing formal analysis and verification as services on the Cloud. We aim to reach these goals by bringing together researchers and practitioners from these, and other related fields.",
    "lastUpdated": "2016-10-25T01:18:53Z",
    "category": [
      "cs.DC",
      "cs.LO",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1610.07700v1"
  },
  {
    "title": "Cultivating Software Performance in Cloud Computing",
    "author": [
      "Li Chen",
      "Colin Cunningham",
      "Pooja Jain",
      "Chenggang Qin",
      "Kingsum Chow"
    ],
    "abstract": "There exist multitudes of cloud performance metrics, including workload performance, application placement, software/hardware optimization, scalability, capacity, reliability, agility and so on. In this paper, we consider jointly optimizing the performance of the software applications in the cloud. The challenges lie in bringing a diversity of raw data into tidy data format, unifying performance data from multiple systems based on timestamps, and assessing the quality of the processed performance data. Even after verifying the quality of cloud performance data, additional challenges block optimizing cloud computing. In this paper, we identify the challenges of cloud computing from the perspectives of computing environment, data collection, performance analytics and production environment.",
    "lastUpdated": "2016-11-22T22:19:54Z",
    "category": [
      "cs.PF",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1611.07556v1"
  },
  {
    "title": "Filling missing data in point clouds by merging structured and unstructured point clouds",
    "author": [
      "Franziska Lippoldt",
      "Hartmut Schwandt"
    ],
    "abstract": "Point clouds arising from structured data, mainly as a result of CT scans, provides special properties on the distribution of points and the distances between those. Yet often, the amount of data provided can not compare to unstructured point clouds, i.e. data that arises from 3D light scans or laser scans. This article hereby proposes an approach to extend structured data and enhance the quality by inserting selected points from an unstructured point cloud. The resulting point cloud still has a partial structure that is called \"half-structure\". In this way, missing data that can not be optimally recovered through other surface reconstruction methods can be completed.",
    "lastUpdated": "2017-02-15T14:59:10Z",
    "category": [
      "cs.CG",
      "cs.CV",
      "cs.DM",
      "53A05",
      "F.2.2; G.2.1; I.3.5"
    ],
    "url": "http://arxiv.org/abs/1702.04641v1"
  },
  {
    "title": "Edge-Fog Cloud: A Distributed Cloud for Internet of Things Computations",
    "author": [
      "Nitinder Mohan",
      "Jussi Kangasharju"
    ],
    "abstract": "Internet of Things typically involves a significant number of smart sensors sensing information from the environment and sharing it to a cloud service for processing. Various architectural abstractions, such as Fog and Edge computing, have been proposed to localize some of the processing near the sensors and away from the central cloud servers. In this paper, we propose Edge-Fog Cloud which distributes task processing on the participating cloud resources in the network. We develop the Least Processing Cost First (LPCF) method for assigning the processing tasks to nodes which provide the optimal processing time and near optimal networking costs. We evaluate LPCF in a variety of scenarios and demonstrate its effectiveness in finding the processing task assignments.",
    "lastUpdated": "2017-03-07T10:39:51Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1702.06335v2"
  },
  {
    "title": "Cloud Radiative Effect Study Using Sky Camera",
    "author": [
      "Soumyabrata Dev",
      "Shilpa Manandhar",
      "Feng Yuan",
      "Yee Hui Lee",
      "Stefan Winkler"
    ],
    "abstract": "The analysis of clouds in the earth's atmosphere is important for a variety of applications, viz. weather reporting, climate forecasting, and solar energy generation. In this paper, we focus our attention on the impact of cloud on the total solar irradiance reaching the earth's surface. We use weather station to record the total solar irradiance. Moreover, we employ collocated ground-based sky camera to automatically compute the instantaneous cloud coverage. We analyze the relationship between measured solar irradiance and computed cloud coverage value, and conclude that higher cloud coverage greatly impacts the total solar irradiance. Such studies will immensely help in solar energy generation and forecasting.",
    "lastUpdated": "2017-03-15T02:47:50Z",
    "category": [
      "physics.ao-ph",
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1703.05591v1"
  },
  {
    "title": "Next Generation Cloud Computing: New Trends and Research Directions",
    "author": [
      "Blesson Varghese",
      "Rajkumar Buyya"
    ],
    "abstract": "The landscape of cloud computing has significantly changed over the last decade. Not only have more providers and service offerings crowded the space, but also cloud infrastructure that was traditionally limited to single provider data centers is now evolving. In this paper, we firstly discuss the changing cloud infrastructure and consider the use of infrastructure from multiple providers and the benefit of decentralising computing away from data centers. These trends have resulted in the need for a variety of new computing architectures that will be offered by future cloud infrastructure. These architectures are anticipated to impact areas, such as connecting people and devices, data-intensive computing, the service space and self-learning systems. Finally, we lay out a roadmap of challenges that will need to be addressed for realising the potential of next generation cloud systems.",
    "lastUpdated": "2017-09-08T06:52:30Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1707.07452v3"
  },
  {
    "title": "Correction of \"Cloud Removal By Fusing Multi-Source and Multi-Temporal Images\"",
    "author": [
      "Chengyue Zhang",
      "Zhiwei Li",
      "Qing Cheng",
      "Xinghua Li",
      "Huanfeng Shen"
    ],
    "abstract": "Remote sensing images often suffer from cloud cover. Cloud removal is required in many applications of remote sensing images. Multitemporal-based methods are popular and effective to cope with thick clouds. This paper contributes to a summarization and experimental comparation of the existing multitemporal-based methods. Furthermore, we propose a spatiotemporal-fusion with poisson-adjustment method to fuse multi-sensor and multi-temporal images for cloud removal. The experimental results show that the proposed method has potential to address the problem of accuracy reduction of cloud removal in multi-temporal images with significant changes.",
    "lastUpdated": "2017-07-25T04:20:18Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1707.09959v1"
  },
  {
    "title": "VoxelNet: End-to-End Learning for Point Cloud Based 3D Object Detection",
    "author": [
      "Yin Zhou",
      "Oncel Tuzel"
    ],
    "abstract": "Accurate detection of objects in 3D point clouds is a central problem in many applications, such as autonomous navigation, housekeeping robots, and augmented/virtual reality. To interface a highly sparse LiDAR point cloud with a region proposal network (RPN), most existing efforts have focused on hand-crafted feature representations, for example, a bird's eye view projection. In this work, we remove the need of manual feature engineering for 3D point clouds and propose VoxelNet, a generic 3D detection network that unifies feature extraction and bounding box prediction into a single stage, end-to-end trainable deep network. Specifically, VoxelNet divides a point cloud into equally spaced 3D voxels and transforms a group of points within each voxel into a unified feature representation through the newly introduced voxel feature encoding (VFE) layer. In this way, the point cloud is encoded as a descriptive volumetric representation, which is then connected to a RPN to generate detections. Experiments on the KITTI car detection benchmark show that VoxelNet outperforms the state-of-the-art LiDAR based 3D detection methods by a large margin. Furthermore, our network learns an effective discriminative representation of objects with various geometries, leading to encouraging results in 3D detection of pedestrians and cyclists, based on only LiDAR.",
    "lastUpdated": "2017-11-17T04:25:24Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1711.06396v1"
  },
  {
    "title": "3DContextNet: K-d Tree Guided Hierarchical Learning of Point Clouds Using Local and Global Contextual Cues",
    "author": [
      "Wei Zeng",
      "Theo Gevers"
    ],
    "abstract": "Classification and segmentation of 3D point clouds are important tasks in computer vision. Because of the irregular nature of point clouds, most of the existing methods convert point clouds into regular 3D voxel grids before they are used as input for ConvNets. Unfortunately, voxel representations are highly insensitive to the geometrical nature of 3D data. More recent methods encode point clouds to higher dimensional features to cover the global 3D space. However, these models are not able to sufficiently capture the local structures of point clouds. Therefore, in this paper, we propose a method that exploits both local and global contextual cues imposed by the k-d tree. The method is designed to learn representation vectors progressively along the tree structure. Experiments on challenging benchmarks show that the proposed model provides discriminative point set features. For the task of 3D scene semantic segmentation, our method significantly outperforms the state-of-the-art on the Stanford Large-Scale 3D Indoor Spaces Dataset (S3DIS).",
    "lastUpdated": "2018-12-04T13:45:45Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1711.11379v3"
  },
  {
    "title": "Cyberattack Detection in Mobile Cloud Computing: A Deep Learning Approach",
    "author": [
      "Khoi Khac Nguyen",
      "Dinh Thai Hoang",
      "Dusit Niyato",
      "Ping Wang",
      "Diep Nguyen",
      "Eryk Dutkiewicz"
    ],
    "abstract": "With the rapid growth of mobile applications and cloud computing, mobile cloud computing has attracted great interest from both academia and industry. However, mobile cloud applications are facing security issues such as data integrity, users' confidentiality, and service availability. A preventive approach to such problems is to detect and isolate cyber threats before they can cause serious impacts to the mobile cloud computing system. In this paper, we propose a novel framework that leverages a deep learning approach to detect cyberattacks in mobile cloud environment. Through experimental results, we show that our proposed framework not only recognizes diverse cyberattacks, but also achieves a high accuracy (up to 97.11%) in detecting the attacks. Furthermore, we present the comparisons with current machine learning-based approaches to demonstrate the effectiveness of our proposed solution.",
    "lastUpdated": "2017-12-16T07:24:55Z",
    "category": [
      "cs.CR",
      "cs.DC",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1712.05914v1"
  },
  {
    "title": "3D Point Cloud Descriptors in Hand-crafted and Deep Learning Age: State-of-the-Art",
    "author": [
      "Xian-Feng Han",
      "Shi-Jie Sun",
      "Xiang-Yu Song",
      "Guo-Qiang Xiao"
    ],
    "abstract": "The introduction of inexpensive 3D data acquisition devices has promisingly facilitated the wide availability and popularity of 3D point cloud, which attracts more attention to the effective extraction of novel 3D point cloud descriptors for accuracy of the efficiency of 3D computer vision tasks in recent years. However, how to develop discriminative and robust feature descriptors from 3D point cloud remains a challenging task due to their intrinsic characteristics. In this paper, we give a comprehensively insightful investigation of the existing 3D point cloud descriptors. These methods can principally be divided into two categories according to the advancement of descriptors: hand-crafted based and deep learning-based apporaches, which will be further discussed from the perspective of elaborate classification, their advantages, and limitations. Finally, we present the future research direction of the extraction of 3D point cloud descriptors.",
    "lastUpdated": "2020-07-27T00:42:27Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1802.02297v2"
  },
  {
    "title": "About being the Tortoise or the Hare? - A Position Paper on Making Cloud Applications too Fast and Furious for Attackers",
    "author": [
      "Nane Kratzke"
    ],
    "abstract": "Cloud applications expose - beside service endpoints - also potential or actual vulnerabilities. And attackers have several advantages on their side. They can select the weapons, the point of time and the point of attack. Very often cloud application security engineering efforts focus to harden the fortress walls but seldom assume that attacks may be successful. So, cloud applications rely on their defensive walls but seldom attack intruders actively. Biological systems are different. They accept that defensive \"walls\" can be breached at several layers and therefore make use of an active and adaptive defense system to attack potential intruders - an immune system. This position paper proposes such an immune system inspired approach to ensure that even undetected intruders can be purged out of cloud applications. This makes it much harder for intruders to maintain a presence on victim systems. Evaluation experiments with popular cloud service infrastructures (Amazon Web Services, Google Compute Engine, Azure and OpenStack) showed that this could minimize the undetected acting period of intruders down to minutes.",
    "lastUpdated": "2018-02-10T10:16:20Z",
    "category": [
      "cs.CR",
      "cs.DC",
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/1802.03565v1"
  },
  {
    "title": "PointNetVLAD: Deep Point Cloud Based Retrieval for Large-Scale Place Recognition",
    "author": [
      "Mikaela Angelina Uy",
      "Gim Hee Lee"
    ],
    "abstract": "Unlike its image based counterpart, point cloud based retrieval for place recognition has remained as an unexplored and unsolved problem. This is largely due to the difficulty in extracting local feature descriptors from a point cloud that can subsequently be encoded into a global descriptor for the retrieval task. In this paper, we propose the PointNetVLAD where we leverage on the recent success of deep networks to solve point cloud based retrieval for place recognition. Specifically, our PointNetVLAD is a combination/modification of the existing PointNet and NetVLAD, which allows end-to-end training and inference to extract the global descriptor from a given 3D point cloud. Furthermore, we propose the \"lazy triplet and quadruplet\" loss functions that can achieve more discriminative and generalizable global descriptors to tackle the retrieval task. We create benchmark datasets for point cloud based retrieval for place recognition, and the experimental results on these datasets show the feasibility of our PointNetVLAD. Our code and the link for the benchmark dataset downloads are available in our project website. http://github.com/mikacuy/pointnetvlad/",
    "lastUpdated": "2018-05-16T08:47:33Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1804.03492v3"
  },
  {
    "title": "Spatiotemporal Learning of Dynamic Gestures from 3D Point Cloud Data",
    "author": [
      "Joshua Owoyemi",
      "Koichi Hashimoto"
    ],
    "abstract": "In this paper, we demonstrate an end-to-end spatiotemporal gesture learning approach for 3D point cloud data using a new gestures dataset of point clouds acquired from a 3D sensor. Nine classes of gestures were learned from gestures sample data. We mapped point cloud data into dense occupancy grids, then time steps of the occupancy grids are used as inputs into a 3D convolutional neural network which learns the spatiotemporal features in the data without explicit modeling of gesture dynamics. We also introduced a 3D region of interest jittering approach for point cloud data augmentation. This resulted in an increased classification accuracy of up to 10% when the augmented data is added to the original training data. The developed model is able to classify gestures from the dataset with 84.44% accuracy. We propose that point cloud data will be a more viable data type for scene understanding and motion recognition, as 3D sensors become ubiquitous in years to come.",
    "lastUpdated": "2018-04-24T06:48:56Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1804.08859v1"
  },
  {
    "title": "Professional Development of Teachers Using Cloud Services During Non-formal Education",
    "author": [
      "Svitlana Lytvynova",
      "Oksana Melnyk"
    ],
    "abstract": "The rapid development of cloud services and their implementation in secondary education require an increase in the IC-competence of teachers during non-formal education. The implementation of cloud services will make it possible to create some conditions for learning mobility of all participants of teaching and learning activities. The rapid development of cloud services and their implementation in secondary education require an increase in the IC-competence of teachers during non-formal education. The implementation of cloud services will make it possible to create some conditions for learning mobility of all participants of teaching and learning activities. The paper analyzes the main forms of the organization of teachers learning (workshops, trainings and summer schools). The special features of the non-formal teachers ICT training include the availability of high-speed Internet and some computer equipment. The obtained basic and additional services allow teachers to make the extensive use of cloud services for different activities, namely the organization of students group work and inverted learning, team-work on projects, assistance during homework, preparation for contests, conducting web-quests.",
    "lastUpdated": "2018-07-16T17:39:01Z",
    "category": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1807.05987v1"
  },
  {
    "title": "Models of using cloud technologies at the IT professionals training",
    "author": [
      "O. N. Markova"
    ],
    "abstract": "The article is devoted to the rationale of the use of cloud technologies in teaching mathematical informatics students of technical universities. Purpose of the article - the analysis of domestic and foreign experience in the use of cloud-oriented ICT in the training of future professionals in the field of information technology. Based on a review of experiences and comparisons tools of distance learning technologies and cloud technologies identified the advantages of using cloud technologies for different categories of the learning process participants and models of cloud services, which should be used in training the regulatory academic disciplines cycles of mathematical, scientific and vocational & practical training of the future IT professionals.",
    "lastUpdated": "2018-07-23T07:39:53Z",
    "category": [
      "cs.CY",
      "K.3.2; H.3.5"
    ],
    "url": "http://arxiv.org/abs/1807.08460v1"
  },
  {
    "title": "Cloud Storage Forensic: hubiC as a Case-Study",
    "author": [
      "Ben Blakeley",
      "Chris Cooney",
      "Ali Dehghantanha",
      "Rob Aspin"
    ],
    "abstract": "In today society where we live in a world of constant connectivity, many people are now looking to cloud services in order to store their files so they can have access to them wherever they are. By using cloud services, users can access files anywhere with an internet connection. However, while cloud storage is convenient, it also presents security risks. From a forensics perspective, the increasing popularity of cloud storage platforms, makes investigation into such exploits much more difficult, especially since many platforms such as mobile devices as well as computers are able to use these services. This paper presents investigation of hubiC as one of popular cloud platforms running on Microsoft Windows 8.1. Remaining artefacts pertaining different usage of hubiC namely upload, download, installation and uninstallation on Microsoft Windows 8.1are presented.",
    "lastUpdated": "2018-07-26T15:58:55Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1807.10214v1"
  },
  {
    "title": "Greening Cloud-Enabled Big Data Storage Forensics: Syncany as a Case Study",
    "author": [
      "Yee-Yang Teing",
      "Ali Dehghantanha",
      "Kim-Kwang Raymond Choo"
    ],
    "abstract": "The pervasive nature of cloud-enabled big data storage solutions introduces new challenges in the identification, collection, analysis, preservation and archiving of digital evidences. Investigation of such complex platforms to locate and recover traces of criminal activities is a time-consuming process. Hence, cyber forensics researchers are moving towards streamlining the investigation process by locating and documenting residual artefacts (evidences) of forensic value of users activities on cloud-enabled big data platforms in order to reduce the investigation time and resources involved in a real-world investigation. In this paper, we seek to determine the data remnants of forensic value from Syncany private cloud storage service, a popular storage engine for big data platforms. We demonstrate the types and the locations of the artefacts that can be forensically recovered. Findings from this research contribute to an in-depth understanding of cloud-enabled big data storage forensics, which can result in reduced time and resources spent in real-world investigations involving Syncany-based cloud platforms.",
    "lastUpdated": "2018-07-27T05:53:15Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1807.10445v1"
  },
  {
    "title": "Cloud Chaser: Real Time Deep Learning Computer Vision on Low Computing Power Devices",
    "author": [
      "Zhengyi Luo",
      "Austin Small",
      "Liam Dugan",
      "Stephen Lane"
    ],
    "abstract": "Internet of Things(IoT) devices, mobile phones, and robotic systems are often denied the power of deep learning algorithms due to their limited computing power. However, to provide time-critical services such as emergency response, home assistance, surveillance, etc, these devices often need real-time analysis of their camera data. This paper strives to offer a viable approach to integrate high-performance deep learning-based computer vision algorithms with low-resource and low-power devices by leveraging the computing power of the cloud. By offloading the computation work to the cloud, no dedicated hardware is needed to enable deep neural networks on existing low computing power devices. A Raspberry Pi based robot, Cloud Chaser, is built to demonstrate the power of using cloud computing to perform real-time vision tasks. Furthermore, to reduce latency and improve real-time performance, compression algorithms are proposed and evaluated for streaming real-time video frames to the cloud.",
    "lastUpdated": "2020-11-08T22:00:53Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1810.01069v2"
  },
  {
    "title": "Time Efficient Data Migration among Clouds",
    "author": [
      "Syeda Munazza Marium",
      "Liaquat Ali Thebo",
      "Syed Naveed Ahmed jaffari",
      "Muhammad Hunain Memon"
    ],
    "abstract": "Cloud computing is one of the chief requirement of modern IT trade. Today's cloud industry progressively dependent on it, which lead mutually abundant solutions and challenges. Among the numerous challenges of cloud computing, cloud migration is one of the major concern, and it is necessity to design optimize solutions to advance it with time. Data migration researcher attempt to move data concerning various geographical locations, which contain huge data volumes, compact time limit and problematical architectures. Researchers aim to transfer data with minimal transmission cost and used various efficient scheduling methods and other techniques to achieve this objective. In former research struggles, numerous solution have proposed. In our proposed work, we have explored the contextual factor to accomplish shorter transmission time. Entity Framework Core technology is utilizing for conceptual modelling, mapping and sortage modelling. Meant for minimum transmission cost Object Related Mapping is designated. Desired objective to achieve time efficiency during data migration has been accomplished. Results obtained when data transmission occur among azure and gear host cloud implementation of proposed framework with some size limitations.",
    "lastUpdated": "2018-09-24T05:51:36Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1810.04609v1"
  },
  {
    "title": "Secure outsourced calculations with homomorphic encryption",
    "author": [
      "Qi Wang",
      "Dehua Zhou",
      "Yanling Li"
    ],
    "abstract": "With the rapid development of cloud computing, the privacy security incidents occur frequently, especially data security issues. Cloud users would like to upload their sensitive information to cloud service providers in encrypted form rather than the raw data, and to prevent the misuse of data. The main challenge is to securely process or analyze these encrypted data without disclosing any useful information, and to achieve the rights management efficiently. In this paper, we propose the encrypted data processing protocols for cloud computing by utilizing additively homomorphic encryption and proxy cryptography. For the traditional homomorphic encryption schemes with many limitations, which are not suitable for cloud computing applications. We simulate a cloud computing scenario with flexible access control and extend the original homomorphic cryptosystem to suit our scenario by supporting various arithmetical calculations. We also prove the correctness and security of our protocols, and analyze the advantages and performance by comparing with some latest works.",
    "lastUpdated": "2018-12-03T08:27:14Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1812.00599v1"
  },
  {
    "title": "Learning to Sample",
    "author": [
      "Oren Dovrat",
      "Itai Lang",
      "Shai Avidan"
    ],
    "abstract": "Processing large point clouds is a challenging task. Therefore, the data is often sampled to a size that can be processed more easily. The question is how to sample the data? A popular sampling technique is Farthest Point Sampling (FPS). However, FPS is agnostic to a downstream application (classification, retrieval, etc.). The underlying assumption seems to be that minimizing the farthest point distance, as done by FPS, is a good proxy to other objective functions. We show that it is better to learn how to sample. To do that, we propose a deep network to simplify 3D point clouds. The network, termed S-NET, takes a point cloud and produces a smaller point cloud that is optimized for a particular task. The simplified point cloud is not guaranteed to be a subset of the original point cloud. Therefore, we match it to a subset of the original points in a post-processing step. We contrast our approach with FPS by experimenting on two standard data sets and show significantly better results for a variety of applications. Our code is publicly available at: https://github.com/orendv/learning_to_sample",
    "lastUpdated": "2019-04-01T16:10:37Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1812.01659v2"
  },
  {
    "title": "Blockchain Enabled Trustless API Marketplace",
    "author": [
      "Vijay Arya",
      "Sayandeep Sen",
      "Palani Kodeswaran"
    ],
    "abstract": "There has been an unprecedented surge in the number of service providers offering a wide range of machine learning prediction APIs for tasks such as image classification, language translation, etc. thereby monetizing the underlying data and trained models. Typically, a data owner (API provider) develops a model, often over proprietary data, and leverages the infrastructure services of a cloud vendor for hosting and serving API requests. Clearly, this model assumes complete trust between the API Provider and cloud vendor. On the other hand, a malicious/buggy cloud vendor may copy the APIs and offer an identical service, under-report model usage metrics, or unfairly discriminate between different API providers by offering them a nominal share of the revenue. In this work, we present the design of a blockchain based decentralized trustless API marketplace that enables all the stakeholders in the API ecosystem to audit the behavior of the parties without having to trust a single centralized entity. In particular, our system divides an AI model into multiple pieces and deploys them among multiple cloud vendors who then collaboratively execute the APIs. Our design ensures that cloud vendors cannot collude with each other to steal the combined model, while individual cloud vendors and clients cannot repudiate their input or model executions.",
    "lastUpdated": "2018-12-05T18:45:29Z",
    "category": [
      "cs.CY",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1812.02154v1"
  },
  {
    "title": "PointRCNN: 3D Object Proposal Generation and Detection from Point Cloud",
    "author": [
      "Shaoshuai Shi",
      "Xiaogang Wang",
      "Hongsheng Li"
    ],
    "abstract": "In this paper, we propose PointRCNN for 3D object detection from raw point cloud. The whole framework is composed of two stages: stage-1 for the bottom-up 3D proposal generation and stage-2 for refining proposals in the canonical coordinates to obtain the final detection results. Instead of generating proposals from RGB image or projecting point cloud to bird's view or voxels as previous methods do, our stage-1 sub-network directly generates a small number of high-quality 3D proposals from point cloud in a bottom-up manner via segmenting the point cloud of the whole scene into foreground points and background. The stage-2 sub-network transforms the pooled points of each proposal to canonical coordinates to learn better local spatial features, which is combined with global semantic features of each point learned in stage-1 for accurate box refinement and confidence prediction. Extensive experiments on the 3D detection benchmark of KITTI dataset show that our proposed architecture outperforms state-of-the-art methods with remarkable margins by using only point cloud as input. The code is available at https://github.com/sshaoshuai/PointRCNN.",
    "lastUpdated": "2019-05-16T15:50:01Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1812.04244v2"
  },
  {
    "title": "Lifelong Federated Reinforcement Learning: A Learning Architecture for Navigation in Cloud Robotic Systems",
    "author": [
      "Boyi Liu",
      "Lujia Wang",
      "Ming Liu"
    ],
    "abstract": "This paper was motivated by the problem of how to make robots fuse and transfer their experience so that they can effectively use prior knowledge and quickly adapt to new environments. To address the problem, we present a learning architecture for navigation in cloud robotic systems: Lifelong Federated Reinforcement Learning (LFRL). In the work, We propose a knowledge fusion algorithm for upgrading a shared model deployed on the cloud. Then, effective transfer learning methods in LFRL are introduced. LFRL is consistent with human cognitive science and fits well in cloud robotic systems. Experiments show that LFRL greatly improves the efficiency of reinforcement learning for robot navigation. The cloud robotic system deployment also shows that LFRL is capable of fusing prior knowledge. In addition, we release a cloud robotic navigation-learning website based on LFRL.",
    "lastUpdated": "2019-05-13T07:09:50Z",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.DC",
      "cs.LG",
      "cs.SY"
    ],
    "url": "http://arxiv.org/abs/1901.06455v3"
  },
  {
    "title": "Blockchain-Based Cloud Manufacturing: Decentralization",
    "author": [
      "Ali Vatankhah Barenji",
      "Hanyang Guo",
      "Zonggui Tian",
      "Zhi Li",
      "W. M. Wang",
      "George Q. Huang"
    ],
    "abstract": "Recently, there has been growing interest in the field of cloud manufacturing (CM) amongst researchers in the manufacturing community. Cloud manufacturing is a customer-driven manufacturing model that was inspired by cloud computing, and its major objective was to provide ubiquitous on-demand access to services. However, the current CM architecture suffers from problems that are associated with a centralized based industrial network framework and third part operation. In a nutshell, centralized networking has had issues with flexibility, efficiency, availability, and security. Therefore, this paper aims to tackle these problems by introducing an ongoing project to a decentralized network architecture for cloud manufacturing which is based on the blockchain technology. In essence, this research paper introduces the blockchain technology as a decentralized peer to peer network for multiple cloud manufacturing providers.",
    "lastUpdated": "2019-01-01T05:12:39Z",
    "category": [
      "cs.DC",
      "cs.CR",
      "2018"
    ],
    "url": "http://arxiv.org/abs/1901.10403v1"
  },
  {
    "title": "Dense 3D Visual Mapping via Semantic Simplification",
    "author": [
      "Luca Morreale",
      "Andrea Romanoni",
      "Matteo Matteucci"
    ],
    "abstract": "Dense 3D visual mapping estimates as many as possible pixel depths, for each image. This results in very dense point clouds that often contain redundant and noisy information, especially for surfaces that are roughly planar, for instance, the ground or the walls in the scene. In this paper we leverage on semantic image segmentation to discriminate which regions of the scene require simplification and which should be kept at high level of details. We propose four different point cloud simplification methods which decimate the perceived point cloud by relying on class-specific local and global statistics still maintaining more points in the proximity of class boundaries to preserve the infra-class edges and discontinuities. 3D dense model is obtained by fusing the point clouds in a 3D Delaunay Triangulation to deal with variable point cloud density. In the experimental evaluation we have shown that, by leveraging on semantics, it is possible to simplify the model and diminish the noise affecting the point clouds.",
    "lastUpdated": "2019-02-20T11:23:44Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1902.07511v1"
  },
  {
    "title": "Massive Open Online Courses and Cloud Computing",
    "author": [
      "Mansur Beştaş"
    ],
    "abstract": "One of the most important areas of todays computer technology is Cloud Computing. Benefits of Cloud Computing in various areas cannot be ignored. One field affected by the opportunities provided by Cloud Computing is education. MOOC emerged as a result of opportunities in the field of learning provided by cloud computing. With the ever-increasing demand in recent years, MOOCs are considered to have a promising place in e-learning. Thus, the MOOC model will be investigated as a business model. Customer types, services provided, the sources of income will be analyzed and tabulated. It will be aimed to reveal its relationship with platform and software service among the service models of computing. It was aimed with this study to present the relationship between Cloud Computing and MOOC learning method.",
    "lastUpdated": "2019-02-27T12:21:00Z",
    "category": [
      "cs.CY"
    ],
    "url": "http://arxiv.org/abs/1902.11091v1"
  },
  {
    "title": "A Novel Blockchain-based Trust Model for Cloud Identity Management",
    "author": [
      "Keltoum Bendiab",
      "Nicholas Kolokotronis",
      "Stavros Shiaeles",
      "Samia Boucherkha"
    ],
    "abstract": "Secure and reliable management of identities has become one of the greatest challenges facing cloud computing today, mainly due to the huge number of new cloud-based applications generated by this model, which means more user accounts, passwords, and personal information to provision, monitor, and secure. Currently, identity federation is the most useful solution to overcome the aforementioned issues and simplify the user experience by allowing efficient authentication mechanisms and use of identity information from data distributed across multiple domains. However, this approach creates considerable complexity in managing trust relationships for both the cloud service providers and their clients. Poor management of trust in federated identity management systems brings with it many security, privacy and interoperability issues, which contributes to the reluctance of organizations to move their critical identity data to the cloud. In this paper, we aim to address these issues by introducing a novel trust and identity management model based on the Blockchain for cloud identity management with security and privacy improvements.",
    "lastUpdated": "2019-03-12T07:49:38Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1903.04767v1"
  },
  {
    "title": "ConvPoint: Continuous Convolutions for Point Cloud Processing",
    "author": [
      "Alexandre Boulch"
    ],
    "abstract": "Point clouds are unstructured and unordered data, as opposed to images. Thus, most machine learning approach developed for image cannot be directly transferred to point clouds. In this paper, we propose a generalization of discrete convolutional neural networks (CNNs) in order to deal with point clouds by replacing discrete kernels by continuous ones. This formulation is simple, allows arbitrary point cloud sizes and can easily be used for designing neural networks similarly to 2D CNNs. We present experimental results with various architectures, highlighting the flexibility of the proposed approach. We obtain competitive results compared to the state-of-the-art on shape classification, part segmentation and semantic segmentation for large-scale point clouds.",
    "lastUpdated": "2020-02-19T10:49:28Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1904.02375v5"
  },
  {
    "title": "Total Denoising: Unsupervised Learning of 3D Point Cloud Cleaning",
    "author": [
      "Pedro Hermosilla",
      "Tobias Ritschel",
      "Timo Ropinski"
    ],
    "abstract": "We show that denoising of 3D point clouds can be learned unsupervised, directly from noisy 3D point cloud data only. This is achieved by extending recent ideas from learning of unsupervised image denoisers to unstructured 3D point clouds. Unsupervised image denoisers operate under the assumption that a noisy pixel observation is a random realization of a distribution around a clean pixel value, which allows appropriate learning on this distribution to eventually converge to the correct value. Regrettably, this assumption is not valid for unstructured points: 3D point clouds are subject to total noise, i. e., deviations in all coordinates, with no reliable pixel grid. Thus, an observation can be the realization of an entire manifold of clean 3D points, which makes a na\\\"ive extension of unsupervised image denoisers to 3D point clouds impractical. Overcoming this, we introduce a spatial prior term, that steers converges to the unique closest out of the many possible modes on a manifold. Our results demonstrate unsupervised denoising performance similar to that of supervised learning with clean data when given enough training examples - whereby we do not need any pairs of noisy and clean training data.",
    "lastUpdated": "2019-10-17T22:53:52Z",
    "category": [
      "cs.CV",
      "cs.GR"
    ],
    "url": "http://arxiv.org/abs/1904.07615v2"
  },
  {
    "title": "CloudSegNet: A Deep Network for Nychthemeron Cloud Image Segmentation",
    "author": [
      "Soumyabrata Dev",
      "Atul Nautiyal",
      "Yee Hui Lee",
      "Stefan Winkler"
    ],
    "abstract": "We analyze clouds in the earth's atmosphere using ground-based sky cameras. An accurate segmentation of clouds in the captured sky/cloud image is difficult, owing to the fuzzy boundaries of clouds. Several techniques have been proposed that use color as the discriminatory feature for cloud detection. In the existing literature, however, analysis of daytime and nighttime images is considered separately, mainly because of differences in image characteristics and applications. In this paper, we propose a light-weight deep-learning architecture called CloudSegNet. It is the first that integrates daytime and nighttime (also known as nychthemeron) image segmentation in a single framework, and achieves state-of-the-art results on public databases.",
    "lastUpdated": "2019-04-16T20:49:20Z",
    "category": [
      "physics.ao-ph",
      "cs.CV",
      "eess.IV"
    ],
    "url": "http://arxiv.org/abs/1904.07979v1"
  },
  {
    "title": "2D3D-MatchNet: Learning to Match Keypoints Across 2D Image and 3D Point Cloud",
    "author": [
      "Mengdan Feng",
      "Sixing Hu",
      "Marcelo Ang",
      "Gim Hee Lee"
    ],
    "abstract": "Large-scale point cloud generated from 3D sensors is more accurate than its image-based counterpart. However, it is seldom used in visual pose estimation due to the difficulty in obtaining 2D-3D image to point cloud correspondences. In this paper, we propose the 2D3D-MatchNet - an end-to-end deep network architecture to jointly learn the descriptors for 2D and 3D keypoint from image and point cloud, respectively. As a result, we are able to directly match and establish 2D-3D correspondences from the query image and 3D point cloud reference map for visual pose estimation. We create our Oxford 2D-3D Patches dataset from the Oxford Robotcar dataset with the ground truth camera poses and 2D-3D image to point cloud correspondences for training and testing the deep network. Experimental results verify the feasibility of our approach.",
    "lastUpdated": "2019-04-22T06:49:46Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1904.09742v1"
  },
  {
    "title": "3D Point Cloud Generative Adversarial Network Based on Tree Structured Graph Convolutions",
    "author": [
      "Dong Wook Shu",
      "Sung Woo Park",
      "Junseok Kwon"
    ],
    "abstract": "In this paper, we propose a novel generative adversarial network (GAN) for 3D point clouds generation, which is called tree-GAN. To achieve state-of-the-art performance for multi-class 3D point cloud generation, a tree-structured graph convolution network (TreeGCN) is introduced as a generator for tree-GAN. Because TreeGCN performs graph convolutions within a tree, it can use ancestor information to boost the representation power for features. To evaluate GANs for 3D point clouds accurately, we develop a novel evaluation metric called Frechet point cloud distance (FPD). Experimental results demonstrate that the proposed tree-GAN outperforms state-of-the-art GANs in terms of both conventional metrics and FPD, and can generate point clouds for different semantic parts without prior knowledge.",
    "lastUpdated": "2019-05-16T02:26:59Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1905.06292v2"
  },
  {
    "title": "Function-as-a-Service Benchmarking Framework",
    "author": [
      "Roland Pellegrini",
      "Igor Ivkic",
      "Markus Tauber"
    ],
    "abstract": "Cloud Service Providers deliver their products in form of 'as-a-Service', which are typically categorized by the level of abstraction. This approach hides the implementation details and shows only functionality to the user. However, the problem is that it is hard to measure the performance of Cloud services, because they behave like black boxes. Especially with Function-as-a-Service it is even more difficult because it completely hides server and infrastructure management from users by design. Cloud Service Prodivers usually restrict the maximum size of code, memory and runtime of Cloud Functions. Nevertheless, users need clarification if more ressources are needed to deliver services in high quality. In this regard, we present the architectural design of a new Function-as-a-Service benchmarking tool, which allows users to evaluate the performance of Cloud Functions. Furthermore, the capabilities of the framework are tested on an isolated platform with a specific workload. The results show that users are able to get insights into Function-as-a-Service environments. This, in turn, allows users to identify factors which may slow down or speed up the performance of Cloud Functions.",
    "lastUpdated": "2019-05-28T09:41:17Z",
    "category": [
      "cs.PF",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1905.11707v1"
  },
  {
    "title": "A Systemic IoT-Fog-Cloud Architecture for Big-Data Analytics and Cyber Security Systems: A Review of Fog Computing",
    "author": [
      "Nour Moustafa"
    ],
    "abstract": "Abstract--- With the rapid growth of the Internet of Things (IoT), current Cloud systems face various drawbacks such as lack of mobility support, location-awareness, geo-distribution, high latency, as well as cyber threats. Fog/Edge computing has been proposed for addressing some of the drawbacks, as it enables computing resources at the network's edges and it locally offers big-data analytics rather than transmitting them to the Cloud. The Fog is defined as a Cloud-like system having similar functions, including software-, platform- and infrastructure-as services. The deployment of Fog applications faces various security issues related to virtualisation, network monitoring, data protection and attack detection. This paper proposes a systemic IoT-Fog-Cloud architecture that clarifies the interactions between the three layers of IoT, Fog and Cloud for effectively implementing big-data analytics and cyber security applications. It also reviews security challenges, solutions and future research directions in the architecture.",
    "lastUpdated": "2019-05-04T05:42:00Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1906.01055v1"
  },
  {
    "title": "Direct structural analysis of domains defined by point clouds",
    "author": [
      "László Kudela",
      "Stefan Kollmannsberger",
      "Umut Almac",
      "Ernst Rank"
    ],
    "abstract": "This contribution presents a method that aims at the numerical analysis of solids represented by oriented point clouds. The proposed approach is based on the Finite Cell Method, a high-order immersed boundary technique that computes on a regular background grid of finite elements and requires only inside-outside information from the geometric model. It is shown that oriented point clouds provide sufficient information for these point-membership classifications. Further, we address a tessellation-free formulation of contour integrals that allows to apply Neumann boundary conditions on point clouds without having to recover the underlying surface. Two-dimensional linear elastic benchmark examples demonstrate that the method is able to provide the same accuracy as those computed with conventional, continuous surface descriptions, because the associated error can be controlled by the density of the cloud. Three-dimensional examples computed on point clouds of historical structures show how the method can be employed to establish seamless connections between digital shape measurement techniques and numerical analyses.",
    "lastUpdated": "2019-06-05T15:37:39Z",
    "category": [
      "cs.CE",
      "cs.CG",
      "math.NA"
    ],
    "url": "http://arxiv.org/abs/1906.02077v1"
  },
  {
    "title": "A Mobile Cloud Collaboration Fall Detection System Based on Ensemble Learning",
    "author": [
      "Tong Wu",
      "Yang Gu",
      "Yiqiang Chen",
      "Yunlong Xiao",
      "Jiwei Wang"
    ],
    "abstract": "Falls are one of the important causes of accidental or unintentional injury death worldwide. Therefore, this paper presents a reliable fall detection algorithm and a mobile cloud collaboration system for fall detection. The algorithm is an ensemble learning method based on decision tree, named Falldetection Ensemble Decision Tree (FEDT). The mobile cloud collaboration system can be divided into three stages: 1) mobile stage: use a light-weighted threshold method to filter out the activities of daily livings (ADLs), 2) collaboration stage: transmit data to cloud and meanwhile extract features in the cloud, 3) cloud stage: deploy the model trained by FEDT to give the final detection result with the extracted features. Experiments show that the performance of the proposed FEDT outperforms the others' over 1-3% both on sensitivity and specificity, and more importantly, the system can provide reliable fall detection in practical scenario.",
    "lastUpdated": "2019-07-05T11:57:06Z",
    "category": [
      "eess.SP",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1907.04788v1"
  },
  {
    "title": "A Secure Cloud with Minimal Provider Trust",
    "author": [
      "Amin Mosayyebzadeh",
      "Gerardo Ravago",
      "Apoorve Mohan",
      "Ali Raza",
      "Sahil Tikale",
      "Nabil Schear",
      "Trammell Hudson",
      "Jason Hennessey",
      "Naved Ansari",
      "Kyle Hogan",
      "Charles Munson",
      "Larry Rudolph",
      "Gene Cooperman",
      "Peter Desnoyers",
      "Orran Krieger"
    ],
    "abstract": "Bolted is a new architecture for a bare metal cloud with the goal of providing security-sensitive customers of a cloud the same level of security and control that they can obtain in their own private data centers. It allows tenants to elastically allocate secure resources within a cloud while being protected from other previous, current, and future tenants of the cloud. The provisioning of a new server to a tenant isolates a bare metal server, only allowing it to communicate with other tenant's servers once its critical firmware and software have been attested to the tenant. Tenants, rather than the provider, control the tradeoffs between security, price, and performance. A prototype demonstrates scalable end-to-end security with small overhead compared to a less secure alternative.",
    "lastUpdated": "2019-07-13T17:51:05Z",
    "category": [
      "cs.DC",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1907.07627v1"
  },
  {
    "title": "Blockchain-Powered Software Defined Network-Enabled Networking Infrastructure for Cloud Management",
    "author": [
      "Praveen Fernando",
      "Jin Wei"
    ],
    "abstract": "Cloud architecture has become a valuable solution for different applications, such as big data analytics, due to its high-degree of availability, scalability and strategic value. However, there still remain challenges in managing cloud architecture, in areas such as cloud security. In this paper, we exploit software-defined networking (SDN) and blockchain technologies to secure cloud management platforms from a networking perspective. We develop a blockchain-powered SDN-enabled networking infrastructure in which the integration between blockchain-based security and autonomy management layer and multi-controller SDN networking layer is defined to enhance the integrity of the control and management messages. Furthermore, our proposed networking infrastructure also enables the autonomous bandwidth provisioning to enhance the availability of cloud architecture. In the simulation section, we evaluate the performance of our proposed blockchain-powered SDN-enabled networking infrastructure by considering different scenarios.",
    "lastUpdated": "2019-09-04T14:50:18Z",
    "category": [
      "cs.CR",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1909.01851v1"
  },
  {
    "title": "Research Intelligence (CRIS) and the Cloud: A Review",
    "author": [
      "Otmane Azeroual",
      "Joachim Schöpfel"
    ],
    "abstract": "The purpose of this paper is to explore the impact of the cloud technology on current research information systems (CRIS). Based on an overview of published literature and on empirical evidence from surveys, the paper presents main characteristics, delivery models, service levels and general benefits of cloud computing. The second part assesses how the cloud computing challenges the research information management, from three angles: networking, specific benefits, and the ingestion of data in the cloud. The third part describes three aspects of the implementation of current research systems in the clouds, i.e. service models, requirements and potential risks and barriers. The paper concludes with some perspectives for future work. The paper is written for CRIS administrators and users, in order to improve research information management and to contribute to future development and implementation of these systems, but also for scholars and students who want to have detailed knowledge on this topic.",
    "lastUpdated": "2019-10-02T10:22:33Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1910.00862v1"
  },
  {
    "title": "MeteorNet: Deep Learning on Dynamic 3D Point Cloud Sequences",
    "author": [
      "Xingyu Liu",
      "Mengyuan Yan",
      "Jeannette Bohg"
    ],
    "abstract": "Understanding dynamic 3D environment is crucial for robotic agents and many other applications. We propose a novel neural network architecture called $MeteorNet$ for learning representations for dynamic 3D point cloud sequences. Different from previous work that adopts a grid-based representation and applies 3D or 4D convolutions, our network directly processes point clouds. We propose two ways to construct spatiotemporal neighborhoods for each point in the point cloud sequence. Information from these neighborhoods is aggregated to learn features per point. We benchmark our network on a variety of 3D recognition tasks including action recognition, semantic segmentation and scene flow estimation. MeteorNet shows stronger performance than previous grid-based methods while achieving state-of-the-art performance on Synthia. MeteorNet also outperforms previous baseline methods that are able to process at most two consecutive point clouds. To the best of our knowledge, this is the first work on deep learning for dynamic raw point cloud sequences.",
    "lastUpdated": "2020-02-08T00:22:14Z",
    "category": [
      "cs.CV",
      "cs.LG",
      "cs.RO"
    ],
    "url": "http://arxiv.org/abs/1910.09165v2"
  },
  {
    "title": "Kuksa: A Cloud-Native Architecture for Enabling Continuous Delivery in the Automotive Domain",
    "author": [
      "Ahmad Banijamali",
      "Pooyan Jamshidi",
      "Pasi Kuvaja",
      "Markku Oivo"
    ],
    "abstract": "Connecting vehicles to cloud platforms has enabled innovative business scenarios while raising new quality concerns, such as reliability and scalability, which must be addressed by research. Cloud-native architectures based on microservices are a recent approach to enable continuous delivery and to improve service reliability and scalability. We propose an approach for restructuring cloud platform architectures in the automotive domain into a microservices architecture. To this end, we adopted and implemented microservices patterns from literature to design the cloud-native automotive architecture and conducted a laboratory experiment to evaluate the reliability and scalability of microservices in the context of a real-world project in the automotive domain called Eclipse Kuksa. Findings indicated that the proposed architecture could handle the continuous software delivery over-the-air by sending automatic control messages to a vehicular setting. Different patterns enabled us to make changes or interrupt services without extending the impact to others. The results of this study provide evidences that microservices are a potential design solution when dealing with service failures and high payload on cloud-based services in the automotive domain.",
    "lastUpdated": "2019-10-22T18:33:28Z",
    "category": [
      "cs.SE",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1910.10190v1"
  },
  {
    "title": "Exploiting Local and Global Structure for Point Cloud Semantic Segmentation with Contextual Point Representations",
    "author": [
      "Xu Wang",
      "Jingming He",
      "Lin Ma"
    ],
    "abstract": "In this paper, we propose one novel model for point cloud semantic segmentation, which exploits both the local and global structures within the point cloud based on the contextual point representations. Specifically, we enrich each point representation by performing one novel gated fusion on the point itself and its contextual points. Afterwards, based on the enriched representation, we propose one novel graph pointnet module, relying on the graph attention block to dynamically compose and update each point representation within the local point cloud structure. Finally, we resort to the spatial-wise and channel-wise attention strategies to exploit the point cloud global structure and thereby yield the resulting semantic label for each point. Extensive results on the public point cloud databases, namely the S3DIS and ScanNet datasets, demonstrate the effectiveness of our proposed model, outperforming the state-of-the-art approaches. Our code for this paper is available at https://github.com/fly519/ELGS.",
    "lastUpdated": "2019-11-13T03:51:32Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1911.05277v1"
  },
  {
    "title": "Modelling and Simulation Environment for Self-Adaptive and Self-Aware Cloud Architectures",
    "author": [
      "Maria Salama",
      "Rami Bahsoon",
      "Rajkumar Buyya"
    ],
    "abstract": "Cloud-based software systems are increasingly becoming complex and operating in highly dynamic environments. Self-adaptivity and self-awareness have recently emerged to cope with such level of dynamicity and scalability. Meanwhile, designing and testing such systems have poven to be a challenging task, as well as research benchmarking. Despite the influx of research in both self-adaptivity and cloud computing, as well as the various simulations environments proposed so far, there is a general lack of modelling and simulation environments of self-adaptive and self-aware cloud architectures. To aid researchers and practioners in overcoming such challenges, this paper presents a novel modelling and simulation environment for self-adaptive and self-aware cloud architectures. The environment provides significant benefits for designing self-adaptive and self-aware cloud architectures, as well as testing adaptation and awareness mechanisms. The toolkit is also beneficial as a symbiotic simulator during runtime to support adaptation decisions. We experimentally validated and evaluated the implementation using benchmarks and evaluation use cases.",
    "lastUpdated": "2019-12-11T00:08:15Z",
    "category": [
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/1912.05058v1"
  },
  {
    "title": "Cloud Removal in Satellite Images Using Spatiotemporal Generative Networks",
    "author": [
      "Vishnu Sarukkai",
      "Anirudh Jain",
      "Burak Uzkent",
      "Stefano Ermon"
    ],
    "abstract": "Satellite images hold great promise for continuous environmental monitoring and earth observation. Occlusions cast by clouds, however, can severely limit coverage, making ground information extraction more difficult. Existing pipelines typically perform cloud removal with simple temporal composites and hand-crafted filters. In contrast, we cast the problem of cloud removal as a conditional image synthesis challenge, and we propose a trainable spatiotemporal generator network (STGAN) to remove clouds. We train our model on a new large-scale spatiotemporal dataset that we construct, containing 97640 image pairs covering all continents. We demonstrate experimentally that the proposed STGAN model outperforms standard models and can generate realistic cloud-free images with high PSNR and SSIM values across a variety of atmospheric conditions, leading to improved performance in downstream tasks such as land cover classification.",
    "lastUpdated": "2019-12-14T13:03:31Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1912.06838v1"
  },
  {
    "title": "Federated Imitation Learning: A Novel Framework for Cloud Robotic Systems with Heterogeneous Sensor Data",
    "author": [
      "Boyi Liu",
      "Lujia Wang",
      "Ming Liu",
      "Cheng-Zhong Xu"
    ],
    "abstract": "Humans are capable of learning a new behavior by observing others to perform the skill. Similarly, robots can also implement this by imitation learning. Furthermore, if with external guidance, humans can master the new behavior more efficiently. So, how can robots achieve this? To address the issue, we present a novel framework named FIL. It provides a heterogeneous knowledge fusion mechanism for cloud robotic systems. Then, a knowledge fusion algorithm in FIL is proposed. It enables the cloud to fuse heterogeneous knowledge from local robots and generate guide models for robots with service requests. After that, we introduce a knowledge transfer scheme to facilitate local robots acquiring knowledge from the cloud. With FIL, a robot is capable of utilizing knowledge from other robots to increase its imitation learning in accuracy and efficiency. Compared with transfer learning and meta-learning, FIL is more suitable to be deployed in cloud robotic systems. Finally, we conduct experiments of a self-driving task for robots (cars). The experimental results demonstrate that the shared model generated by FIL increases imitation learning efficiency of local robots in cloud robotic systems.",
    "lastUpdated": "2019-12-24T11:23:23Z",
    "category": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1912.12204v1"
  },
  {
    "title": "Towards Deep Federated Defenses Against Malware in Cloud Ecosystems",
    "author": [
      "Josh Payne",
      "Ashish Kundu"
    ],
    "abstract": "In cloud computing environments with many virtual machines, containers, and other systems, an epidemic of malware can be highly threatening to business processes. In this vision paper, we introduce a hierarchical approach to performing malware detection and analysis using several recent advances in machine learning on graphs, hypergraphs, and natural language. We analyze individual systems and their logs, inspecting and understanding their behavior with attentional sequence models. Given a feature representation of each system's logs using this procedure, we construct an attributed network of the cloud with systems and other components as vertices and propose an analysis of malware with inductive graph and hypergraph learning models. With this foundation, we consider the multicloud case, in which multiple clouds with differing privacy requirements cooperate against the spread of malware, proposing the use of federated learning to perform inference and training while preserving privacy. Finally, we discuss several open problems that remain in defending cloud computing environments against malware related to designing robust ecosystems, identifying cloud-specific optimization problems for response strategy, action spaces for malware containment and eradication, and developing priors and transfer learning tasks for machine learning models in this area.",
    "lastUpdated": "2019-12-27T23:46:06Z",
    "category": [
      "cs.CR",
      "cs.DC",
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1912.12370v1"
  },
  {
    "title": "New Framework Model to Secure Cloud Data Storage",
    "author": [
      "Leila Beldjezzar",
      "Abdelhafid Zitouni",
      "Mahieddine Djoudi",
      "Beldjezzar Leila",
      "Zitouni Abdelhafid",
      "Djoudi Mahieddine"
    ],
    "abstract": "Nowadays companies are increasingly adopting the technology ofcloud computing. This technology is subject to a lot of research and continuousadvances are made. The use of cloud computing in the companies advantagessuch as: reducing costs, sharing and exchange of information between institutions,but the data in the Cloud computing are susceptible to be compromisedand the companies are exposing to see their data loss. In this study, we addressthe subject of security in cloud computing; we expose and discuss someresearches that had been proposed to secure the data stored in the cloud. Andthen we will present our new frameworks that ensure confidentiality of datastorage in the cloud environment",
    "lastUpdated": "2020-01-22T14:24:02Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/2001.08575v1"
  },
  {
    "title": "Online Resource Procurement and Allocation in a Hybrid Edge-Cloud Computing System",
    "author": [
      "Thinh Quang Dinh",
      "Ben Liang",
      "Tony Q. S. Quek",
      "Hyundong Shin"
    ],
    "abstract": "By acquiring cloud-like capacities at the edge of a network, edge computing is expected to significantly improve user experience. In this paper, we formulate a hybrid edge-cloud computing system where an edge device with limited local resources can rent more from a cloud node and perform resource allocation to serve its users. The resource procurement and allocation decisions depend not only on the cloud's multiple rental options but also on the edge's local processing cost and capacity. We first propose an offline algorithm whose decisions are made with full information of future demand. Then, an online algorithm is proposed where the edge node makes irrevocable decisions in each timeslot without future information of demand. We show that both algorithms have constant performance bounds from the offline optimum. Numerical results acquired with Google cluster-usage traces indicate that the cost of the edge node can be substantially reduced by using the proposed algorithms, up to $80\\%$ in comparison with baseline algorithms. We also observe how the cloud's pricing structure and edge's local cost influence the procurement decisions.",
    "lastUpdated": "2020-01-24T12:06:14Z",
    "category": [
      "cs.IT",
      "cs.SY",
      "eess.SY",
      "math.IT"
    ],
    "url": "http://arxiv.org/abs/2001.08956v1"
  },
  {
    "title": "SLO-ML: A Language for Service Level Objective Modelling in Multi-cloud Applications",
    "author": [
      "Abdessalam Elhabbash",
      "Assylbek Jumagaliyev",
      "Gordon S. Blair",
      "Yehia Elkhatib"
    ],
    "abstract": "Cloud modelling languages (CMLs) are designed to assist customers in tackling the diversity of services in the cloud market. While many CMLs have been proposed in the literature, they lack practical support for automating the selection of services based on the specific service level objectives of a customer's application. We put forward SLO-ML, a novel and generative CML to capture service level requirements and, subsequently, to select the services to honour customer requirements and generate the deployment code appropriate to these services. We present the architectural design of SLO-ML and the associated broker that realises the deployment operations. We rigorously evaluate SLO-ML using a mixed methods approach. First, we exploit an experimental case study with a group of researchers and developers using a real-world cloud application. We also assess overheads through an exhaustive set of empirical scalability tests. Through expressing the levels of gained productivity and experienced usability, we highlight SLO-ML's profound potential in enabling user-centric cloud brokers. We also discuss limitations as application requirements grow.",
    "lastUpdated": "2020-01-29T21:05:36Z",
    "category": [
      "cs.DC",
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/2001.11093v1"
  },
  {
    "title": "Shared Mobile-Cloud Inference for Collaborative Intelligence",
    "author": [
      "Mateen Ulhaq",
      "Ivan V. Bajić"
    ],
    "abstract": "As AI applications for mobile devices become more prevalent, there is an increasing need for faster execution and lower energy consumption for neural model inference. Historically, the models run on mobile devices have been smaller and simpler in comparison to large state-of-the-art research models, which can only run on the cloud. However, cloud-only inference has drawbacks such as increased network bandwidth consumption and higher latency. In addition, cloud-only inference requires the input data (images, audio) to be fully transferred to the cloud, creating concerns about potential privacy breaches. We demonstrate an alternative approach: shared mobile-cloud inference. Partial inference is performed on the mobile in order to reduce the dimensionality of the input data and arrive at a compact feature tensor, which is a latent space representation of the input signal. The feature tensor is then transmitted to the server for further inference. This strategy can improve inference latency, energy consumption, and network bandwidth usage, as well as provide privacy protection, because the original signal never leaves the mobile. Further performance gain can be achieved by compressing the feature tensor before its transmission.",
    "lastUpdated": "2020-02-01T07:12:01Z",
    "category": [
      "cs.AI",
      "eess.IV"
    ],
    "url": "http://arxiv.org/abs/2002.00157v1"
  },
  {
    "title": "Study of Cloud-Aided Multi-Way Multiple-Antenna Relaying with Best-User Link Selection and Joint ML Detection",
    "author": [
      "F. L. Duarte",
      "R. C. de Lamare"
    ],
    "abstract": "In this work, we present a cloud-aided uplink framework for multi-way multiple-antenna relay systems which facilitates joint linear Maximum Likelihood (ML) symbol detection in the cloud and where users are selected to simultaneously transmit to each other aided by relays. We also investigate relay selection techniques for the proposed cloud-aided uplink framework that uses cloud-based buffers and physical-layer network coding. In particular, we develop a novel multi-way relay selection protocol based on the selection of the best link, denoted as Multi-Way Cloud-Aided Best-User-Link (MWC-Best-User-Link). We then devise the maximum minimum distance relay selection criterion along with the algorithm that is incorporated into the proposed MWC-Best-User-Link protocol. Simulations show that MWC-Best-User-Link outperforms previous works in terms of average delay, sum-rate and bit error rate.",
    "lastUpdated": "2020-02-03T01:53:44Z",
    "category": [
      "cs.IT",
      "math.IT"
    ],
    "url": "http://arxiv.org/abs/2002.00532v1"
  },
  {
    "title": "Characterizing network paths in and out of the clouds",
    "author": [
      "Igor Sfiligoi",
      "John Graham",
      "Frank Wuerthwein"
    ],
    "abstract": "Commercial Cloud computing is becoming mainstream, with funding agencies moving beyond prototyping and starting to fund production campaigns, too. An important aspect of any scientific computing production campaign is data movement, both incoming and outgoing. And while the performance and cost of VMs is relatively well understood, the network performance and cost is not. This paper provides a characterization of networking in various regions of Amazon Web Services, Microsoft Azure and Google Cloud Platform, both between Cloud resources and major DTNs in the Pacific Research Platform, including OSG data federation caches in the network backbone, and inside the clouds themselves. The paper contains both a qualitative analysis of the results as well as latency and throughput measurements. It also includes an analysis of the costs involved with Cloud-based networking.",
    "lastUpdated": "2020-02-11T17:47:06Z",
    "category": [
      "cs.NI",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/2002.04568v1"
  },
  {
    "title": "Analyzing CNN Based Behavioural Malware Detection Techniques on Cloud IaaS",
    "author": [
      "Andrew McDole",
      "Mahmoud Abdelsalam",
      "Maanak Gupta",
      "Sudip Mittal"
    ],
    "abstract": "Cloud Infrastructure as a Service (IaaS) is vulnerable to malware due to its exposure to external adversaries, making it a lucrative attack vector for malicious actors. A datacenter infected with malware can cause data loss and/or major disruptions to service for its users. This paper analyzes and compares various Convolutional Neural Networks (CNNs) for online detection of malware in cloud IaaS. The detection is performed based on behavioural data using process level performance metrics including cpu usage, memory usage, disk usage etc. We have used the state of the art DenseNets and ResNets in effectively detecting malware in online cloud system. CNN are designed to extract features from data gathered from a live malware running on a real cloud environment. Experiments are performed on OpenStack (a cloud IaaS software) testbed designed to replicate a typical 3-tier web architecture. Comparative analysis is performed for different metrics for different CNN models used in this research.",
    "lastUpdated": "2020-02-15T14:04:33Z",
    "category": [
      "cs.CR",
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2002.06383v1"
  },
  {
    "title": "Are We Susceptible to Rowhammer? An End-to-End Methodology for Cloud Providers",
    "author": [
      "Lucian Cojocar",
      "Jeremie Kim",
      "Minesh Patel",
      "Lillian Tsai",
      "Stefan Saroiu",
      "Alec Wolman",
      "Onur Mutlu"
    ],
    "abstract": "Cloud providers are concerned that Rowhammer poses a potentially critical threat to their servers, yet today they lack a systematic way to test whether the DRAM used in their servers is vulnerable to Rowhammer attacks. This paper presents an end-to-end methodology to determine if cloud servers are susceptible to these attacks. With our methodology, a cloud provider can construct worst-case testing conditions for DRAM. We apply our methodology to three classes of servers from a major cloud provider. Our findings show that none of the CPU instruction sequences used in prior work to mount Rowhammer attacks create worst-case DRAM testing conditions. To address this limitation, we develop an instruction sequence that leverages microarchitectural side-effects to ``hammer'' DRAM at a near-optimal rate on modern Intel Skylake and Cascade Lake platforms. We also design a DDR4 fault injector that can reverse engineer row adjacency for any DDR4 DIMM. When applied to our cloud provider's DIMMs, we find that DRAM rows do not always follow a linear map.",
    "lastUpdated": "2020-03-10T02:05:13Z",
    "category": [
      "cs.CR",
      "cs.AR",
      "D.4.6; B.8.1"
    ],
    "url": "http://arxiv.org/abs/2003.04498v1"
  },
  {
    "title": "Simulated annealing based heuristic for multiple agile satellites scheduling under cloud coverage uncertainty",
    "author": [
      "Chao Han",
      "Yi Gu",
      "Guohua Wu",
      "Xinwei Wang"
    ],
    "abstract": "Agile satellites are the new generation of Earth observation satellites (EOSs) with stronger attitude maneuvering capability. Since optical remote sensing instruments equipped on satellites cannot see through the cloud, the cloud coverage has a significant influence on the satellite observation missions. We are the first to address multiple agile EOSs scheduling problem under cloud coverage uncertainty where the objective aims to maximize the entire observation profit. The chance constraint programming model is adopted to describe the uncertainty initially, and the observation profit under cloud coverage uncertainty is then calculated via sample approximation method. Subsequently, an improved simulated annealing based heuristic combining a fast insertion strategy is proposed for large-scale observation missions. The experimental results show that the improved simulated annealing heuristic outperforms other algorithms for the multiple AEOSs scheduling problem under cloud coverage uncertainty, which verifies the efficiency and effectiveness of the proposed algorithm.",
    "lastUpdated": "2020-03-14T16:37:26Z",
    "category": [
      "eess.SP",
      "cs.AI",
      "physics.space-ph"
    ],
    "url": "http://arxiv.org/abs/2003.08363v1"
  },
  {
    "title": "A generalized Hausdorff distance based quality metric for point cloud geometry",
    "author": [
      "Alireza Javaheri",
      "Catarina Brites",
      "Fernando Pereira",
      "Joao Ascenso"
    ],
    "abstract": "Reliable quality assessment of decoded point cloud geometry is essential to evaluate the compression performance of emerging point cloud coding solutions and guarantee some target quality of experience. This paper proposes a novel point cloud geometry quality assessment metric based on a generalization of the Hausdorff distance. To achieve this goal, the so-called generalized Hausdorff distance for multiple rankings is exploited to identify the best performing quality metric in terms of correlation with the MOS scores obtained from a subjective test campaign. The experimental results show that the quality metric derived from the classical Hausdorff distance leads to low objective-subjective correlation and, thus, fails to accurately evaluate the quality of decoded point clouds for emerging codecs. However, the quality metric derived from the generalized Hausdorff distance with an appropriately selected ranking, outperforms the MPEG adopted geometry quality metrics when decoded point clouds with different types of coding distortions are considered.",
    "lastUpdated": "2020-03-30T17:53:02Z",
    "category": [
      "eess.IV",
      "cs.MM"
    ],
    "url": "http://arxiv.org/abs/2003.13669v1"
  },
  {
    "title": "Provisioning Spot Instances Without Employing Fault-Tolerance Mechanisms",
    "author": [
      "Abdullah Alourani",
      "Ajay D. Kshemkalyani"
    ],
    "abstract": "Cloud computing offers a variable-cost payment scheme that allows cloud customers to specify the price they are willing to pay for renting spot instances to run their applications at much lower costs than fixed payment schemes, and depending on the varying demand from cloud customers, cloud platforms could revoke spot instances at any time. To alleviate the effect of spot instance revocations, applications often employ different fault-tolerance mechanisms to minimize or even eliminate the lost work for each spot instance revocation. However, these fault-tolerance mechanisms incur additional overhead related to application completion time and deployment cost. We propose a novel cloud market-based approach that leverages cloud spot market features to provision spot instances without employing fault-tolerance mechanisms to reduce the deployment cost and completion time of applications. We evaluate our approach in simulations and use Amazon spot instances that contain jobs in Docker containers and realistic price traces from EC2 markets. Our simulation results show that our approach reduces the deployment cost and completion time compared to approaches based on fault-tolerance mechanisms.",
    "lastUpdated": "2020-03-30T22:20:22Z",
    "category": [
      "cs.DC",
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/2003.13846v1"
  },
  {
    "title": "A generic cloud migration process model",
    "author": [
      "Mahdi Fahmideha",
      "Farhad Daneshgarb",
      "Fethi Rabhic",
      "Ghassan Beydound"
    ],
    "abstract": "The cloud computing literature provides various ways to utilise cloud services, each with a different viewpoint, focus, and mostly using heterogeneous technical-centric terms. This hinders efficient and consistent knowledge flow across the community. Little, if any, research has aimed on developing an integrated process model which captures core domain concepts and ties them together to provide an overarching view of migrating legacy systems to cloud platforms that is customisable for a given context. We adopt design science research guidelines in which we use a metamodeling approach to develop a generic process model and then evaluate and refine the model through three case studies and domain expert reviews. This research benefits academics and practitioners alike by underpinning a substrate for constructing, standardising, maintaining, and sharing bespoke cloud migration models that can be applied to given cloud adoption scenarios.",
    "lastUpdated": "2020-04-16T10:23:41Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/2004.10857v1"
  },
  {
    "title": "Revenue Maximization Approaches in IaaS Clouds: Research Challenges and Opportunities",
    "author": [
      "Afzal Badshah",
      "Anwar Ghani",
      "Ali Daud",
      "Anthony Theodore Chronopoulos",
      "Ateeqa Jalal"
    ],
    "abstract": "Revenue generation is the main concern of any business, particularly in the cloud, where there is no direct interaction between the provider and the consumer. Cloud computing is an emerging core for today's businesses, however, Its complications (e.g, installation, and migration) with traditional markets are the main challenges. It earns more but needs exemplary performance and marketing skills. In recent years, cloud computing has become a successful paradigm for providing desktop services. It is expected that more than \\$ 331 billion will be invested by 2023, likewise, 51 billion devices are expected to be connected to the cloud. Infrastructure as a Service (IaaS) provides physical resources (e.g, computing, memory, storage, and network) as VM instances. In this article, the main revenue factors are categorized as SLA and penalty management, resource scalability, customer satisfaction and management, resource utilization and provision, cost and price management, and advertising and auction. These parameters are investigated in detail and new dynamics for researchers in the field of the cloud are discovered.",
    "lastUpdated": "2020-04-24T12:42:36Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/2004.11707v1"
  },
  {
    "title": "Dense-Resolution Network for Point Cloud Classification and Segmentation",
    "author": [
      "Shi Qiu",
      "Saeed Anwar",
      "Nick Barnes"
    ],
    "abstract": "Point cloud analysis is attracting attention from Artificial Intelligence research since it can be widely used in applications such as robotics, Augmented Reality, self-driving. However, it is always challenging due to irregularities, unorderedness, and sparsity. In this article, we propose a novel network named Dense-Resolution Network (DRNet) for point cloud analysis. Our DRNet is designed to learn local point features from the point cloud in different resolutions. In order to learn local point groups more effectively, we present a novel grouping method for local neighborhood searching and an error-minimizing module for capturing local features. In addition to validating the network on widely used point cloud segmentation and classification benchmarks, we also test and visualize the performance of the components. Comparing with other state-of-the-art methods, our network shows superiority on ModelNet40, ShapeNet synthetic and ScanObjectNN real point cloud datasets.",
    "lastUpdated": "2020-11-17T08:02:25Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2005.06734v2"
  },
  {
    "title": "Unconstrained Matching of 2D and 3D Descriptors for 6-DOF Pose Estimation",
    "author": [
      "Uzair Nadeem",
      "Mohammed Bennamoun",
      "Roberto Togneri",
      "Ferdous Sohel"
    ],
    "abstract": "This paper proposes a novel concept to directly match feature descriptors extracted from 2D images with feature descriptors extracted from 3D point clouds. We use this concept to directly localize images in a 3D point cloud. We generate a dataset of matching 2D and 3D points and their corresponding feature descriptors, which is used to learn a Descriptor-Matcher classifier. To localize the pose of an image at test time, we extract keypoints and feature descriptors from the query image. The trained Descriptor-Matcher is then used to match the features from the image and the point cloud. The locations of the matched features are used in a robust pose estimation algorithm to predict the location and orientation of the query image. We carried out an extensive evaluation of the proposed method for indoor and outdoor scenarios and with different types of point clouds to verify the feasibility of our approach. Experimental results demonstrate that direct matching of feature descriptors from images and point clouds is not only a viable idea but can also be reliably used to estimate the 6-DOF poses of query cameras in any type of 3D point cloud in an unconstrained manner with high precision.",
    "lastUpdated": "2020-05-29T11:17:32Z",
    "category": [
      "cs.CV",
      "cs.LG",
      "cs.RO"
    ],
    "url": "http://arxiv.org/abs/2005.14502v1"
  },
  {
    "title": "Multi-scale Cloud Detection in Remote Sensing Images using a Dual Convolutional Neural Network",
    "author": [
      "Markku Luotamo",
      "Sari Metsämäki",
      "Arto Klami"
    ],
    "abstract": "Semantic segmentation by convolutional neural networks (CNN) has advanced the state of the art in pixel-level classification of remote sensing images. However, processing large images typically requires analyzing the image in small patches, and hence features that have large spatial extent still cause challenges in tasks such as cloud masking. To support a wider scale of spatial features while simultaneously reducing computational requirements for large satellite images, we propose an architecture of two cascaded CNN model components successively processing undersampled and full resolution images. The first component distinguishes between patches in the inner cloud area from patches at the cloud's boundary region. For the cloud-ambiguous edge patches requiring further segmentation, the framework then delegates computation to a fine-grained model component. We apply the architecture to a cloud detection dataset of complete Sentinel-2 multispectral images, approximately annotated for minimal false negatives in a land use application. On this specific task and data, we achieve a 16\\% relative improvement in pixel accuracy over a CNN baseline based on patching.",
    "lastUpdated": "2020-06-01T10:27:42Z",
    "category": [
      "cs.CV",
      "cs.LG",
      "cs.NE",
      "I.2.6; I.4.6"
    ],
    "url": "http://arxiv.org/abs/2006.00836v1"
  },
  {
    "title": "Privacy Against Adversarial Classification in Cyber-Physical Systems",
    "author": [
      "Carlos Murguia",
      "Paulo Tabuada"
    ],
    "abstract": "For a class of Cyber-Physical Systems (CPSs), we address the problem of performing computations over the cloud without revealing private information about the structure and operation of the system. We model CPSs as a collection of input-output dynamical systems (the system operation modes). Depending on the mode the system is operating on, the output trajectory is generated by one of these systems in response to driving inputs. Output measurements and driving inputs are sent to the cloud for processing purposes. We capture this \"processing\" through some function (of the input-output trajectory) that we require the cloud to compute accurately - referred here as the trajectory utility. However, for privacy reasons, we would like to keep the mode private, i.e., we do not want the cloud to correctly identify what mode of the CPS produced a given trajectory. To this end, we distort trajectories before transmission and send the corrupted data to the cloud. We provide mathematical tools (based on output-regulation techniques) to properly design distorting mechanisms so that: 1) the original and distorted trajectories lead to the same utility; and the distorted data leads the cloud to misclassify the mode.",
    "lastUpdated": "2020-06-12T10:38:45Z",
    "category": [
      "eess.SY",
      "cs.SY"
    ],
    "url": "http://arxiv.org/abs/2006.07063v1"
  },
  {
    "title": "Wireless 3D Point Cloud Delivery Using Deep Graph Neural Networks",
    "author": [
      "Takuya Fujihashi",
      "Toshiaki Koike-Akino",
      "Siheng Chen",
      "Takashi Watanabe"
    ],
    "abstract": "In typical point cloud delivery, a sender uses octree-based digital video compression to send three-dimensional (3D) points and color attributes over band-limited links. However, the digital-based schemes have an issue called the cliff effect, where the 3D reconstruction quality will be a step function in terms of wireless channel quality. To prevent the cliff effect subject to channel quality fluctuation, we have proposed soft point cloud delivery called HoloCast. Although the HoloCast realizes graceful quality improvement according to wireless channel quality, it requires large communication overheads. In this paper, we propose a novel scheme for soft point cloud delivery to simultaneously realize better quality and lower communication overheads. The proposed scheme introduces an end-to-end deep learning framework based on graph neural network (GNN) to reconstruct high-quality point clouds from its distorted observation under wireless fading channels. We demonstrate that the proposed GNN-based scheme can reconstruct clean 3D point cloud with low overheads by removing fading and noise effects.",
    "lastUpdated": "2020-06-17T13:10:56Z",
    "category": [
      "eess.SP",
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "url": "http://arxiv.org/abs/2006.09835v1"
  },
  {
    "title": "Cost-Efficient Storage for On-Demand Video Streaming on Cloud",
    "author": [
      "Mahmoud Darwich",
      "Yasser Ismail",
      "Talal Darwich",
      "Magdy Bayoumi"
    ],
    "abstract": "Video stream is converted to several formats to support the user's device, this conversion process is called video transcoding, which imposes high storage and powerful resources. With emerging of cloud technology, video stream companies adopted to process video on the cloud. Generally, many formats of the same video are made (pre-transcoded) and streamed to the adequate user's device. However, pre-transcoding demands huge storage space and incurs a high-cost to the video stream companies. More importantly, the pre-transcoding of video streams could be hierarchy carried out through different storage types in the cloud. To minimize the storage cost, in this paper, we propose a method to store video streams in the hierarchical storage of the cloud. Particularly, we develop a method to decide which video stream should be pre-transcoded in its suitable cloud storage to minimize the overall cost. Experimental simulation and results show the effectiveness of our approach, specifically, when the percentage of frequently accessed videos is high in repositories, the proposed approach minimizes the overall cost by up to 40 percent.",
    "lastUpdated": "2020-07-07T13:26:25Z",
    "category": [
      "cs.MM",
      "cs.PF"
    ],
    "url": "http://arxiv.org/abs/2007.03410v1"
  },
  {
    "title": "Polylidar3D -- Fast Polygon Extraction from 3D Data",
    "author": [
      "Jeremy Castagno",
      "Ella Atkins"
    ],
    "abstract": "Flat surfaces captured by 3D point clouds are often used for localization, mapping, and modeling. Dense point cloud processing has high computation and memory costs making low-dimensional representations of flat surfaces such as polygons desirable. We present Polylidar3D, a non-convex polygon extraction algorithm which takes as input unorganized 3D point clouds (e.g., LiDAR data), organized point clouds (e.g., range images), or user-provided meshes. Non-convex polygons represent flat surfaces in an environment with interior cutouts representing obstacles or holes. The Polylidar3D front-end transforms input data into a half-edge triangular mesh. This representation provides a common level of input data abstraction for subsequent back-end processing. The Polylidar3D back-end is composed of four core algorithms: mesh smoothing, dominant plane normal estimation, planar segment extraction, and finally polygon extraction. Polylidar3D is shown to be quite fast, making use of CPU multi-threading and GPU acceleration when available. We demonstrate Polylidar3D's versatility and speed with real-world datasets including aerial LiDAR point clouds for rooftop mapping, autonomous driving LiDAR point clouds for road surface detection, and RGBD cameras for indoor floor/wall detection. We also evaluate Polylidar3D on a challenging planar segmentation benchmark dataset. Results consistently show excellent speed and accuracy.",
    "lastUpdated": "2020-07-23T15:22:43Z",
    "category": [
      "cs.CV",
      "cs.RO"
    ],
    "url": "http://arxiv.org/abs/2007.12065v1"
  },
  {
    "title": "Point Cloud Completion by Learning Shape Priors",
    "author": [
      "Xiaogang Wang",
      "Marcelo H Ang Jr",
      "Gim Hee Lee"
    ],
    "abstract": "In view of the difficulty in reconstructing object details in point cloud completion, we propose a shape prior learning method for object completion. The shape priors include geometric information in both complete and the partial point clouds. We design a feature alignment strategy to learn the shape prior from complete points, and a coarse to fine strategy to incorporate partial prior in the fine stage. To learn the complete objects prior, we first train a point cloud auto-encoder to extract the latent embeddings from complete points. Then we learn a mapping to transfer the point features from partial points to that of the complete points by optimizing feature alignment losses. The feature alignment losses consist of a L2 distance and an adversarial loss obtained by Maximum Mean Discrepancy Generative Adversarial Network (MMD-GAN). The L2 distance optimizes the partial features towards the complete ones in the feature space, and MMD-GAN decreases the statistical distance of two point features in a Reproducing Kernel Hilbert Space. We achieve state-of-the-art performances on the point cloud completion task. Our code is available at https://github.com/xiaogangw/point-cloud-completion-shape-prior.",
    "lastUpdated": "2020-08-02T04:00:32Z",
    "category": [
      "cs.CV",
      "cs.LG",
      "eess.IV"
    ],
    "url": "http://arxiv.org/abs/2008.00394v1"
  },
  {
    "title": "Unsupervised Point Cloud Registration via Salient Points Analysis (SPA)",
    "author": [
      "Pranav Kadam",
      "Min Zhang",
      "Shan Liu",
      "C. -C. Jay Kuo"
    ],
    "abstract": "An unsupervised point cloud registration method, called salient points analysis (SPA), is proposed in this work. The proposed SPA method can register two point clouds effectively using only a small subset of salient points. It first applies the PointHop++ method to point clouds, finds corresponding salient points in two point clouds based on the local surface characteristics of points and performs registration by matching the corresponding salient points. The SPA method offers several advantages over the recent deep learning based solutions for registration. Deep learning methods such as PointNetLK and DCP train end-to-end networks and rely on full supervision (namely, ground truth transformation matrix and class label). In contrast, the SPA is completely unsupervised. Furthermore, SPA's training time and model size are much less. The effectiveness of the SPA method is demonstrated by experiments on seen and unseen classes and noisy point clouds from the ModelNet-40 dataset.",
    "lastUpdated": "2020-09-02T18:40:37Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2009.01293v1"
  },
  {
    "title": "Infrastructure de Services Cloud FaaS sur noeuds IoT",
    "author": [
      "David Fernández Blanco",
      "Frédéric Le Mouël"
    ],
    "abstract": "In this article, we describe the PyCloudIoT cloud infrastructure. PyCloudIoT uses a FaaS cloud computing model for offloading numerical computations on a cluster with resource-constrained nodes rather than powerful datacenter. This infrastructure aims at exploiting unused resources of IoT nodes - already deployed at the edge of the network - to reduce latency of user requests. This extra computation must be done without significant energy consumption - IoT nodes being battery-powered. -- Dans cet article, nous d\\'ecrivons l'infrastructure cloud PyCloudIoT. PyCloudIoT s'appuie sur un mod\\`ele de cloud computing FaaS pour du calcul num\\'erique d\\'eport\\'e vers une ferme de calcul compos\\'ee de noeuds \\`a capacit\\'es restreintes au lieu d'un datacentre puissant. Cette infrastructure vise \\`a tirer profit des ressources inutilis\\'ees d\\'eploy\\'ees sur n{\\oe}uds IoT sans augmenter significativement leur consommation d'\\'energie et, en m\\^eme temps, \\`a rapprocher ces ressources des utilisateurs pour r\\'eduire la latence, en d\\'eveloppant un mod\\`ele cloud en bord de r\\'eseau.",
    "lastUpdated": "2020-09-05T10:29:59Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/2009.02511v1"
  },
  {
    "title": "DV-ConvNet: Fully Convolutional Deep Learning on Point Clouds with Dynamic Voxelization and 3D Group Convolution",
    "author": [
      "Zhaoyu Su",
      "Pin Siang Tan",
      "Junkang Chow",
      "Jimmy Wu",
      "Yehur Cheong",
      "Yu-Hsing Wang"
    ],
    "abstract": "3D point cloud interpretation is a challenging task due to the randomness and sparsity of the component points. Many of the recently proposed methods like PointNet and PointCNN have been focusing on learning shape descriptions from point coordinates as point-wise input features, which usually involves complicated network architectures. In this work, we draw attention back to the standard 3D convolutions towards an efficient 3D point cloud interpretation. Instead of converting the entire point cloud into voxel representations like the other volumetric methods, we voxelize the sub-portions of the point cloud only at necessary locations within each convolution layer on-the-fly, using our dynamic voxelization operation with self-adaptive voxelization resolution. In addition, we incorporate 3D group convolution into our dense convolution kernel implementation to further exploit the rotation invariant features of point cloud. Benefiting from its simple fully-convolutional architecture, our network is able to run and converge at a considerably fast speed, while yields on-par or even better performance compared with the state-of-the-art methods on several benchmark datasets.",
    "lastUpdated": "2020-09-07T07:45:05Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2009.02918v1"
  },
  {
    "title": "High-Performance Mining of COVID-19 Open Research Datasets for Text Classification and Insights in Cloud Computing Environments",
    "author": [
      "Jie Zhao",
      "Maria A. Rodriguez",
      "Rajkumar Buyya"
    ],
    "abstract": "COVID-19 global pandemic is an unprecedented health crisis. Since the outbreak, many researchers around the world have produced an extensive collection of literatures. For the research community and the general public to digest, it is crucial to analyse the text and provide insights in a timely manner, which requires a considerable amount of computational power. Clouding computing has been widely adopted in academia and industry in recent years. In particular, hybrid cloud is gaining popularity since its two-fold benefits: utilising existing resource to save cost and using additional cloud service providers to gain assess to extra computing resources on demand. In this paper, we developed a system utilising the Aneka PaaS middleware with parallel processing and multi-cloud capability to accelerate the ETL and article categorising process using machine learning technology on a hybrid cloud. The result is then persisted for further referencing, searching and visualising. Our performance evaluation shows that the system can help with reducing processing time and achieving linear scalability. Beyond COVID-19, the application might be used directly in broader scholarly article indexing and analysing.",
    "lastUpdated": "2020-09-16T00:25:51Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/2009.07399v1"
  },
  {
    "title": "Subjective Metrics-based Cloud Market Performance Prediction",
    "author": [
      "Ahmed Alharbi",
      "Hai Dong"
    ],
    "abstract": "This paper explores an effective machine learning approach to predict cloud market performance for cloud consumers, providers and investors based on social media. We identified a set of comprehensive subjective metrics that may affect cloud market performance via literature survey. We used a popular sentiment analysis technique to process customer reviews collected from social media. Cloud market revenue growth was selected as an indicator of cloud market performance. We considered the revenue growth of Amazon Web Services as the stakeholder of our experiments. Three machine learning models were selected: linear regression, artificial neural network, and support vector machine. These models were compared with a time series prediction model. We found that the set of subjective metrics is able to improve the prediction performance for all the models. The support vector machine showed the best prediction results compared to the other models.",
    "lastUpdated": "2020-09-21T12:18:01Z",
    "category": [
      "cs.SI",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2009.09794v1"
  },
  {
    "title": "Cloud Removal for Remote Sensing Imagery via Spatial Attention Generative Adversarial Network",
    "author": [
      "Heng Pan"
    ],
    "abstract": "Optical remote sensing imagery has been widely used in many fields due to its high resolution and stable geometric properties. However, remote sensing imagery is inevitably affected by climate, especially clouds. Removing the cloud in the high-resolution remote sensing satellite image is an indispensable pre-processing step before analyzing it. For the sake of large-scale training data, neural networks have been successful in many image processing tasks, but the use of neural networks to remove cloud in remote sensing imagery is still relatively small. We adopt generative adversarial network to solve this task and introduce the spatial attention mechanism into the remote sensing imagery cloud removal task, proposes a model named spatial attention generative adversarial network (SpA GAN), which imitates the human visual mechanism, and recognizes and focuses the cloud area with local-to-global spatial attention, thereby enhancing the information recovery of these areas and generating cloudless images with better quality...",
    "lastUpdated": "2020-11-14T08:17:05Z",
    "category": [
      "eess.IV",
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2009.13015v2"
  },
  {
    "title": "Self-Supervised Few-Shot Learning on Point Clouds",
    "author": [
      "Charu Sharma",
      "Manohar Kaul"
    ],
    "abstract": "The increased availability of massive point clouds coupled with their utility in a wide variety of applications such as robotics, shape synthesis, and self-driving cars has attracted increased attention from both industry and academia. Recently, deep neural networks operating on labeled point clouds have shown promising results on supervised learning tasks like classification and segmentation. However, supervised learning leads to the cumbersome task of annotating the point clouds. To combat this problem, we propose two novel self-supervised pre-training tasks that encode a hierarchical partitioning of the point clouds using a cover-tree, where point cloud subsets lie within balls of varying radii at each level of the cover-tree. Furthermore, our self-supervised learning network is restricted to pre-train on the support set (comprising of scarce training examples) used to train the downstream network in a few-shot learning (FSL) setting. Finally, the fully-trained self-supervised network's point embeddings are input to the downstream task's network. We present a comprehensive empirical evaluation of our method on both downstream classification and segmentation tasks and show that supervised methods pre-trained with our self-supervised learning method significantly improve the accuracy of state-of-the-art methods. Additionally, our method also outperforms previous unsupervised methods in downstream classification tasks.",
    "lastUpdated": "2020-09-29T17:32:44Z",
    "category": [
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2009.14168v1"
  },
  {
    "title": "MaskNet: A Fully-Convolutional Network to Estimate Inlier Points",
    "author": [
      "Vinit Sarode",
      "Animesh Dhagat",
      "Rangaprasad Arun Srivatsan",
      "Nicolas Zevallos",
      "Simon Lucey",
      "Howie Choset"
    ],
    "abstract": "Point clouds have grown in importance in the way computers perceive the world. From LIDAR sensors in autonomous cars and drones to the time of flight and stereo vision systems in our phones, point clouds are everywhere. Despite their ubiquity, point clouds in the real world are often missing points because of sensor limitations or occlusions, or contain extraneous points from sensor noise or artifacts. These problems challenge algorithms that require computing correspondences between a pair of point clouds. Therefore, this paper presents a fully-convolutional neural network that identifies which points in one point cloud are most similar (inliers) to the points in another. We show improvements in learning-based and classical point cloud registration approaches when retrofitted with our network. We demonstrate these improvements on synthetic and real-world datasets. Finally, our network produces impressive results on test datasets that were unseen during training, thus exhibiting generalizability. Code and videos are available at https://github.com/vinits5/masknet",
    "lastUpdated": "2020-10-19T03:18:35Z",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2010.09185v1"
  },
  {
    "title": "Learning Occupancy Function from Point Clouds for Surface Reconstruction",
    "author": [
      "Meng Jia",
      "Matthew Kyan"
    ],
    "abstract": "Implicit function based surface reconstruction has been studied for a long time to recover 3D shapes from point clouds sampled from surfaces. Recently, Signed Distance Functions (SDFs) and Occupany Functions are adopted in learning-based shape reconstruction methods as implicit 3D shape representation. This paper proposes a novel method for learning occupancy functions from sparse point clouds and achieves better performance on challenging surface reconstruction tasks. Unlike the previous methods, which predict point occupancy with fully-connected multi-layer networks, we adapt the point cloud deep learning architecture, Point Convolution Neural Network (PCNN), to build our learning model. Specifically, we create a sampling operator and insert it into PCNN to continuously sample the feature space at the points where occupancy states need to be predicted. This method natively obtains point cloud data's geometric nature, and it's invariant to point permutation. Our occupancy function learning can be easily fit into procedures of point cloud up-sampling and surface reconstruction. Our experiments show state-of-the-art performance for reconstructing With ShapeNet dataset and demonstrate this method's well-generalization by testing it with McGill 3D dataset \\cite{siddiqi2008retrieving}. Moreover, we find the learned occupancy function is relatively more rotation invariant than previous shape learning methods.",
    "lastUpdated": "2020-10-22T02:07:29Z",
    "category": [
      "cs.CV",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2010.11378v1"
  },
  {
    "title": "Point Cloud Attribute Compression via Successive Subspace Graph Transform",
    "author": [
      "Yueru Chen",
      "Yiting Shao",
      "Jing Wang",
      "Ge Li",
      "C. -C. Jay Kuo"
    ],
    "abstract": "Inspired by the recently proposed successive subspace learning (SSL) principles, we develop a successive subspace graph transform (SSGT) to address point cloud attribute compression in this work. The octree geometry structure is utilized to partition the point cloud, where every node of the octree represents a point cloud subspace with a certain spatial size. We design a weighted graph with self-loop to describe the subspace and define a graph Fourier transform based on the normalized graph Laplacian. The transforms are applied to large point clouds from the leaf nodes to the root node of the octree recursively, while the represented subspace is expanded from the smallest one to the whole point cloud successively. It is shown by experimental results that the proposed SSGT method offers better R-D performances than the previous Region Adaptive Haar Transform (RAHT) method.",
    "lastUpdated": "2020-10-29T01:40:54Z",
    "category": [
      "cs.CV",
      "eess.IV",
      "eess.SP"
    ],
    "url": "http://arxiv.org/abs/2010.15302v1"
  },
  {
    "title": "10 Years Later: Cloud Computing is Closing the Performance Gap",
    "author": [
      "Giulia Guidi",
      "Marquita Ellis",
      "Aydin Buluc",
      "Katherine Yelick",
      "David Culler"
    ],
    "abstract": "Large scale modeling and simulation problems, from nanoscale materials to universe-scale cosmology, have in the past used the massive computing resources of High-Performance Computing (HPC) systems. Over the last decade, cloud computing has gained popularity for business applications and increasingly for computationally intensive machine learning problems. Despite the prolific literature, the question remains open whether cloud computing can provide HPC-competitive performance for a wide range of scientific applications. The answer to this question is crucial in guiding the design of future systems and providing access to high-performance resources to a broadened community. Here we present a multi-level approach to identifying the performance gap between HPC and cloud computing and to isolate several variables that contribute to this gap by dividing our experiments into (i) hardware and system microbenchmarks and (ii) user applications. Our results show that today's high-end cloud computing can deliver HPC-like performance - at least at modest scales - not only for computationally intensive applications, but also for memory- and communication-intensive applications, thanks to the high-speed memory systems and interconnects and dedicated batch scheduling now available on some cloud platforms.",
    "lastUpdated": "2020-11-02T00:35:38Z",
    "category": [
      "cs.DC",
      "cs.PF"
    ],
    "url": "http://arxiv.org/abs/2011.00656v1"
  },
  {
    "title": "PREDATOR: Registration of 3D Point Clouds with Low Overlap",
    "author": [
      "Shengyu Huang",
      "Zan Gojcic",
      "Mikhail Usvyatsov",
      "Andreas Wieser",
      "Konrad Schindler"
    ],
    "abstract": "We introduce PREDATOR, a model for pairwise point-cloud registration with deep attention to the overlap region. Different from previous work, our model is specifically designed to handle (also) point-cloud pairs with low overlap. Its key novelty is an overlap-attention block for early information exchange between the latent encodings of the two point clouds. In this way the subsequent decoding of the latent representations into per-point features is conditioned on the respective other point cloud, and thus can predict which points are not only salient, but also lie in the overlap region between the two point clouds. The ability to focus on points that are relevant for matching greatly improves performance: PREDATOR raises the rate of successful registrations by more than 20% in the low-overlap scenario, and also sets a new state of the art for the 3DMatch benchmark with 89% registration recall. Source code and pre-trained models will be available at https://github.com/ShengyuH/OverlapPredator.",
    "lastUpdated": "2020-11-25T20:25:03Z",
    "category": [
      "cs.CV",
      "eess.IV"
    ],
    "url": "http://arxiv.org/abs/2011.13005v1"
  },
  {
    "title": "Spherical Interpolated Convolutional Network with Distance-Feature Density for 3D Semantic Segmentation of Point Clouds",
    "author": [
      "Guangming Wang",
      "Yehui Yang",
      "Huixin Zhang",
      "Zhe Liu",
      "Hesheng Wang"
    ],
    "abstract": "The semantic segmentation of point clouds is an important part of the environment perception for robots. However, it is difficult to directly adopt the traditional 3D convolution kernel to extract features from raw 3D point clouds because of the unstructured property of point clouds. In this paper, a spherical interpolated convolution operator is proposed to replace the traditional grid-shaped 3D convolution operator. This newly proposed feature extraction operator improves the accuracy of the network and reduces the parameters of the network. In addition, this paper analyzes the defect of point cloud interpolation methods based on the distance as the interpolation weight and proposes the self-learned distance-feature density by combining the distance and the feature correlation. The proposed method makes the feature extraction of spherical interpolated convolution network more rational and effective. The effectiveness of the proposed network is demonstrated on the 3D semantic segmentation task of point clouds. Experiments show that the proposed method achieves good performance on the ScanNet dataset and Paris-Lille-3D dataset.",
    "lastUpdated": "2020-11-27T15:35:12Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2011.13784v1"
  },
  {
    "title": "Learning-based lossless compression of 3D point cloud geometry",
    "author": [
      "Dat Thanh Nguyen",
      "Maurice Quach",
      "Giuseppe Valenzise",
      "Pierre Duhamel"
    ],
    "abstract": "This paper presents a learning-based, lossless compression method for static point cloud geometry, based on context-adaptive arithmetic coding. Unlike most existing methods working in the octree domain, our encoder operates in a hybrid mode, mixing octree and voxel-based coding. We adaptively partition the point cloud into multi-resolution voxel blocks according to the point cloud structure and use octree to signal the partitioning. On the one hand, octree representation can eliminate the sparsity in the point cloud. On the other hand, in the voxel domain, convolutions can be naturally expressed, and geometric information (i.e., planes, surfaces, etc.) is explicitly processed by a neural network. Our context model benefits from these properties and learns a probability distribution of the voxels using a deep convolutional neural network with masked filters, called VoxelDNN. Experiments show that our method outperforms the state-of-the-art MPEG G-PCC standard with average rate savings of 28% on a diverse set of point clouds from the Microsoft Voxelized Upper Bodies (MVUB) and MPEG.",
    "lastUpdated": "2020-11-30T11:27:16Z",
    "category": [
      "eess.IV",
      "cs.CV",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2011.14700v1"
  },
  {
    "title": "SRG-Net: Unsupervised Segmentation for Terracotta Warrior Point Cloud with 3D Pointwise CNN methods",
    "author": [
      "Yao Hu",
      "Guohua Geng",
      "Kang Li",
      "Wei Zhou",
      "Xingxing Hao",
      "Xin Cao"
    ],
    "abstract": "In this paper, we present a seed-region-growing CNN(SRG-Net) for unsupervised part segmentation with 3D point clouds of terracotta warriors. Previous neural network researches in 3D are mainly about supervised classification, clustering, unsupervised representation and reconstruction. There are few researches focusing on unsupervised point cloud part segmentation. To address these problems, we present a seed-region-growing CNN(SRG-Net) for unsupervised part segmentation with 3D point clouds of terracotta warriors. Firstly, we propose our customized seed region growing algorithm to coarsely segment the point cloud. Then we present our supervised segmentation and unsupervised reconstruction networks to better understand the characteristics of 3D point clouds. Finally, we combine the SRG algorithm with our improved CNN using a refinement method called SRG-Net to conduct the segmentation tasks on the terracotta warriors. Our proposed SRG-Net are evaluated on the terracotta warriors data and the benchmark dataset of ShapeNet with measuring mean intersection over union(mIoU) and latency. The experimental results show that our SRG-Net outperforms the state-of-the-art methods. Our code is available at https://github.com/hyoau/SRG-Net.",
    "lastUpdated": "2020-12-01T12:02:55Z",
    "category": [
      "cs.CV",
      "cs.AI"
    ],
    "url": "http://arxiv.org/abs/2012.00433v1"
  },
  {
    "title": "ChartPointFlow for Topology-Aware 3D Point Cloud Generation",
    "author": [
      "Takumi Kimura",
      "Takashi Matsubara",
      "Kuniaki Uehara"
    ],
    "abstract": "A point cloud serves as a representation of the surface of a three-dimensional shape. Deep generative models have been adapted to model their variations typically by a map from a ball-like set of latent variables. However, previous approaches have not paid much attention to the topological structure of a point cloud; a continuous map cannot express the varying number of holes and intersections. Moreover, a point cloud is often composed of multiple subparts, and it is also hardly expressed. In this paper, we propose ChartPointFlow, which is a flow-based generative model with multiple latent labels. By maximizing the mutual information, a map conditioned by a label is assigned to a continuous subset of a given point cloud, like a chart of a manifold. This enables our proposed model to preserve the topological structure with clear boundaries, while previous approaches tend to suffer from blurs and to fail in generating holes. Experimental results demonstrate that ChartPointFlow achieves the state-of-the-art performance in generation and reconstruction among sampling-based point cloud generators.",
    "lastUpdated": "2020-12-04T00:49:25Z",
    "category": [
      "cs.CV",
      "cs.GR",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2012.02346v1"
  },
  {
    "title": "PCT: Point Cloud Transformer",
    "author": [
      "Meng-Hao Guo",
      "Jun-Xiong Cai",
      "Zheng-Ning Liu",
      "Tai-Jiang Mu",
      "Ralph R. Martin",
      "Shi-Min Hu"
    ],
    "abstract": "The irregular domain and lack of ordering make it challenging to design deep neural networks for point cloud processing. This paper presents a novel framework named Point Cloud Transformer(PCT) for point cloud learning. PCT is based on Transformer, which achieves huge success in natural language processing and displays great potential in image processing. It is inherently permutation invariant for processing a sequence of points, making it well-suited for point cloud learning. To better capture local context within the point cloud, we enhance input embedding with the support of farthest point sampling and nearest neighbor search. Extensive experiments demonstrate that the PCT achieves the state-of-the-art performance on shape classification, part segmentation and normal estimation tasks.",
    "lastUpdated": "2020-12-17T15:55:17Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2012.09688v1"
  },
  {
    "title": "Assigning Apples to Individual Trees in Dense Orchards using 3D Color Point Clouds",
    "author": [
      "Mouad Zine-El-Abidine",
      "Helin Dutagaci",
      "Gilles Galopin",
      "David Rousseau"
    ],
    "abstract": "We propose a 3D color point cloud processing pipeline to count apples on individual apple trees in trellis structured orchards. Fruit counting at the tree level requires separating trees, which is challenging in dense orchards. We employ point clouds acquired from the leaf-off orchard in winter period, where the branch structure is visible, to delineate tree crowns. We localize apples in point clouds acquired in harvest period. Alignment of the two point clouds enables mapping apple locations to the delineated winter cloud and assigning each apple to its bearing tree. Our apple assignment method achieves an accuracy rate higher than 95%. In addition to presenting a first proof of feasibility, we also provide suggestions for further improvement on our apple assignment pipeline.",
    "lastUpdated": "2020-12-26T11:28:27Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2012.13721v1"
  },
  {
    "title": "Compositional Prototype Network with Multi-view Comparision for Few-Shot Point Cloud Semantic Segmentation",
    "author": [
      "Xiaoyu Chen",
      "Chi Zhang",
      "Guosheng Lin",
      "Jing Han"
    ],
    "abstract": "Point cloud segmentation is a fundamental visual understanding task in 3D vision. A fully supervised point cloud segmentation network often requires a large amount of data with point-wise annotations, which is expensive to obtain. In this work, we present the Compositional Prototype Network that can undertake point cloud segmentation with only a few labeled training data. Inspired by the few-shot learning literature in images, our network directly transfers label information from the limited training data to unlabeled test data for prediction. The network decomposes the representations of complex point cloud data into a set of local regional representations and utilizes them to calculate the compositional prototypes of a visual concept. Our network includes a key Multi-View Comparison Component that exploits the redundant views of the support set. To evaluate the proposed method, we create a new segmentation benchmark dataset, ScanNet-$6^i$, which is built upon ScanNet dataset. Extensive experiments show that our method outperforms baselines with a significant advantage. Moreover, when we use our network to handle the long-tail problem in a fully supervised point cloud segmentation dataset, it can also effectively boost the performance of the few-shot classes.",
    "lastUpdated": "2020-12-28T15:01:34Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2012.14255v1"
  },
  {
    "title": "MOMCC: Market-Oriented Architecture for Mobile Cloud Computing Based on Service Oriented Architecture",
    "author": [
      "Saeid Abolfazli",
      "Zohreh Sanaei",
      "Abdullah Gani",
      "Muhammad Shiraz"
    ],
    "abstract": "The vision of augmenting computing capabilities of mobile devices, especially smartphones with least cost is likely transforming to reality leveraging cloud computing. Cloud exploitation by mobile devices breeds a new research domain called Mobile Cloud Computing (MCC). However, issues like portability and interoperability should be addressed for mobile augmentation which is a non-trivial task using component-based approaches. Service Oriented Architecture (SOA) is a promising design philosophy embraced by mobile computing and cloud computing communities to stimulate portable, complex application using prefabricated building blocks called Services. Utilizing distant cloud resources to host and run Services is hampered by long WAN latency. Exploiting mobile devices in vicinity alleviates long WAN latency, while creates new set of issues like Service publishing and discovery as well as client-server security, reliability, and Service availability. In this paper, we propose a market-oriented architecture based on SOA to stimulate publishing, discovering, and hosting Services on nearby mobiles, which reduces long WAN latency and creates a business opportunity that encourages mobile owners to embrace Service hosting. Group of mobile phones simulate a nearby cloud computing platform. We create new role of \\textit{Service host} by enabling unskilled mobile owners/users to host Services developed by skilled developers. Evidently, Service availability, reliability, and Service-oriented mobile application portability will increase towards green ubiquitous computing in our mobile cloud infrastructure.",
    "lastUpdated": "2012-06-27T09:17:06Z",
    "category": [
      "cs.DC",
      "cs.NI",
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/1206.6209v1"
  },
  {
    "title": "A Placement Vulnerability Study in Multi-tenant Public Clouds",
    "author": [
      "Venkatanathan Varadarajan",
      "Yinqian Zhang",
      "Thomas Ristenpart",
      "Michael Swift"
    ],
    "abstract": "Public infrastructure-as-a-service clouds, such as Amazon EC2, Google Compute Engine (GCE) and Microsoft Azure allow clients to run virtual machines (VMs) on shared physical infrastructure. This practice of multi-tenancy brings economies of scale, but also introduces the risk of sharing a physical server with an arbitrary and potentially malicious VM. Past works have demonstrated how to place a VM alongside a target victim (co-location) in early-generation clouds and how to extract secret information via side- channels. Although there have been numerous works on side-channel attacks, there have been no studies on placement vulnerabilities in public clouds since the adoption of stronger isolation technologies such as Virtual Private Clouds (VPCs). We investigate this problem of placement vulnerabilities and quantitatively evaluate three popular public clouds for their susceptibility to co-location attacks. We find that adoption of new technologies (e.g., VPC) makes many prior attacks, such as cloud cartography, ineffective. We find new ways to reliably test for co-location across Amazon EC2, Google GCE, and Microsoft Azure. We also found ways to detect co-location with victim web servers in a multi-tiered cloud application located behind a load balancer. We use our new co-residence tests and multiple customer accounts to launch VM instances under different strategies that seek to maximize the likelihood of co-residency. We find that it is much easier (10x higher success rate) and cheaper (up to $114 less) to achieve co-location in these three clouds when compared to a secure reference placement policy.",
    "lastUpdated": "2015-07-11T15:00:18Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1507.03114v1"
  },
  {
    "title": "Bandwidth in the Cloud",
    "author": [
      "Jose Luis Garcia-Dorado"
    ],
    "abstract": "The seek for the best quality of service has led Cloud infrastructure clients to disseminate their services, contents and data over multiple cloud data-centers often involving several Cloud Service Providers (CSPs). The consequence of this is that a large amount of bytes must be transmitted across the public Cloud. However, very little is known about its bandwidth dynamics. To address this, we have conducted a measurement campaign for bandwidth between eighteen data-centers of four major CSPs. Such extensive campaign allowed us to characterize the resulting time series of bandwidth as the addition of a stationary component and some infrequent excursions (typically, downtimes). While the former provides a description of the bandwidth users can expect in the Cloud, the latter is closely related to the robustness of the Cloud (i.e., the occurrence of downtimes is correlated). Both components have been studied further by applying a factor analysis, specifically ANOVA, as a mechanism to formally compare data-centers' behaviors and extract generalities. The results show that the stationary process is closely related to data-center locations and CSPs involved in transfers, which fortunately makes both the Cloud more predictable and the set of reported measurements extrapolate. On the other hand, although the correlation in the Cloud is low, i.e., only 10% of the measured pair of paths showed some correlation, we have found evidence that such correlation depends on the particular relationships between pairs of data-centers with little link to more general factors. Positively, this implies that data-centers either at the same area or CSP do not show qualitatively more correlation than others data-centers, which eases the deployment of robust infrastructures. On the downside, this metric is barely generalizable and, consequently, calls for exhaustive monitoring.",
    "lastUpdated": "2015-12-03T15:57:16Z",
    "category": [
      "cs.NI",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1512.01129v1"
  },
  {
    "title": "Not Just Privacy: Improving Performance of Private Deep Learning in Mobile Cloud",
    "author": [
      "Ji Wang",
      "Jianguo Zhang",
      "Weidong Bao",
      "Xiaomin Zhu",
      "Bokai Cao",
      "Philip S. Yu"
    ],
    "abstract": "The increasing demand for on-device deep learning services calls for a highly efficient manner to deploy deep neural networks (DNNs) on mobile devices with limited capacity. The cloud-based solution is a promising approach to enabling deep learning applications on mobile devices where the large portions of a DNN are offloaded to the cloud. However, revealing data to the cloud leads to potential privacy risk. To benefit from the cloud data center without the privacy risk, we design, evaluate, and implement a cloud-based framework ARDEN which partitions the DNN across mobile devices and cloud data centers. A simple data transformation is performed on the mobile device, while the resource-hungry training and the complex inference rely on the cloud data center. To protect the sensitive information, a lightweight privacy-preserving mechanism consisting of arbitrary data nullification and random noise addition is introduced, which provides strong privacy guarantee. A rigorous privacy budget analysis is given. Nonetheless, the private perturbation to the original data inevitably has a negative impact on the performance of further inference on the cloud side. To mitigate this influence, we propose a noisy training method to enhance the cloud-side network robustness to perturbed data. Through the sophisticated design, ARDEN can not only preserve privacy but also improve the inference performance. To validate the proposed ARDEN, a series of experiments based on three image datasets and a real mobile application are conducted. The experimental results demonstrate the effectiveness of ARDEN. Finally, we implement ARDEN on a demo system to verify its practicality.",
    "lastUpdated": "2019-01-05T11:21:17Z",
    "category": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1809.03428v3"
  },
  {
    "title": "Deep learning based cloud detection for medium and high resolution remote sensing images of different sensors",
    "author": [
      "Zhiwei Li",
      "Huanfeng Shen",
      "Qing Cheng",
      "Yuhao Liu",
      "Shucheng You",
      "Zongyi He"
    ],
    "abstract": "Cloud detection is an important preprocessing step for the precise application of optical satellite imagery. In this paper, we propose a deep learning based cloud detection method named multi-scale convolutional feature fusion (MSCFF) for remote sensing images of different sensors. In the network architecture of MSCFF, the symmetric encoder-decoder module, which provides both local and global context by densifying feature maps with trainable convolutional filter banks, is utilized to extract multi-scale and high-level spatial features. The feature maps of multiple scales are then up-sampled and concatenated, and a novel multi-scale feature fusion module is designed to fuse the features of different scales for the output. The two output feature maps of the network are cloud and cloud shadow maps, which are in turn fed to binary classifiers outside the model to obtain the final cloud and cloud shadow mask. The MSCFF method was validated on hundreds of globally distributed optical satellite images, with spatial resolutions ranging from 0.5 to 50 m, including Landsat-5/7/8, Gaofen-1/2/4, Sentinel-2, Ziyuan-3, CBERS-04, Huanjing-1, and collected high-resolution images exported from Google Earth. The experimental results show that MSCFF achieves a higher accuracy than the traditional rule-based cloud detection methods and the state-of-the-art deep learning models, especially in bright surface covered areas. The effectiveness of MSCFF means that it has great promise for the practical application of cloud detection for multiple types of medium and high-resolution remote sensing images. Our established global high-resolution cloud detection validation dataset has been made available online.",
    "lastUpdated": "2019-03-05T02:49:17Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1810.05801v3"
  },
  {
    "title": "Neural Generative Models for 3D Faces with Application in 3D Texture Free Face Recognition",
    "author": [
      "Ahmed ElSayed",
      "Elif Kongar",
      "Ausif Mahmood",
      "Tarek Sobh",
      "Terrance Boult"
    ],
    "abstract": "Using heterogeneous depth cameras and 3D scanners in 3D face verification causes variations in the resolution of the 3D point clouds. To solve this issue, previous studies use 3D registration techniques. Out of these proposed techniques, detecting points of correspondence is proven to be an efficient method given that the data belongs to the same individual. However, if the data belongs to different persons, the registration algorithms can convert the 3D point cloud of one person to another, destroying the distinguishing features between the two point clouds. Another issue regarding the storage size of the point clouds. That is, if the captured depth image contains around 50 thousand points in the cloud for a single pose for one individual, then the storage size of the entire dataset will be in order of giga if not tera bytes. With these motivations, this work introduces a new technique for 3D point clouds generation using a neural modeling system to handle the differences caused by heterogeneous depth cameras, and to generate a new face canonical compact representation. The proposed system reduces the stored 3D dataset size, and if required, provides an accurate dataset regeneration. Furthermore, the system generates neural models for all gallery point clouds and stores these models to represent the faces in the recognition or verification processes. For the probe cloud to be verified, a new model is generated specifically for that particular cloud and is matched against pre-stored gallery model presentations to identify the query cloud. This work also introduces the utilization of Siamese deep neural network in 3D face verification using generated model representations as raw data for the deep network, and shows that the accuracy of the trained network is comparable all published results on Bosphorus dataset.",
    "lastUpdated": "2018-11-11T05:56:09Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1811.04358v1"
  },
  {
    "title": "Exploiting Data Sensitivity on Partitioned Data",
    "author": [
      "Sharad Mehrotra",
      "Kerim Yasin Oktay",
      "Shantanu Sharma"
    ],
    "abstract": "Several researchers have proposed solutions for secure data outsourcing on the public clouds based on encryption, secret-sharing, and trusted hardware. Existing approaches, however, exhibit many limitations including high computational complexity, imperfect security, and information leakage. This chapter describes an emerging trend in secure data processing that recognizes that an entire dataset may not be sensitive, and hence, non-sensitivity of data can be exploited to overcome some of the limitations of existing encryption-based approaches. In particular, data and computation can be partitioned into sensitive or non-sensitive datasets - sensitive data can either be encrypted prior to outsourcing or stored/processed locally on trusted servers. The non-sensitive dataset, on the other hand, can be outsourced and processed in the cleartext. While partitioned computing can bring new efficiencies since it does not incur (expensive) encrypted data processing costs on non-sensitive data, it can lead to information leakage. We study partitioned computing in two contexts - first, in the context of the hybrid cloud where local resources are integrated with public cloud resources to form an effective and secure storage and computational platform for enterprise data. In the hybrid cloud, sensitive data is stored on the private cloud to prevent leakage and a computation is partitioned between private and public clouds. Care must be taken that the public cloud cannot infer any information about sensitive data from inter-cloud data access during query processing. We then consider partitioned computing in a public cloud only setting, where sensitive data is encrypted before outsourcing. We formally define a partitioned security criterion that any approach to partitioned computing on public clouds must ensure in order to not introduce any new vulnerabilities to the existing secure solution.",
    "lastUpdated": "2018-12-04T23:00:04Z",
    "category": [
      "cs.DB",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1812.01741v1"
  },
  {
    "title": "Dogfooding: use IBM Cloud services to monitor IBM Cloud infrastructure",
    "author": [
      "William Pourmajidi",
      "Andriy Miranskyy",
      "John Steinbacher",
      "Tony Erwin",
      "David Godwin"
    ],
    "abstract": "The stability and performance of Cloud platforms are essential as they directly impact customers' satisfaction. Cloud service providers use Cloud monitoring tools to ensure that rendered services match the quality of service requirements indicated in established contracts such as service-level agreements. Given the enormous number of resources that need to be monitored, highly scalable and capable monitoring tools are designed and implemented by Cloud service providers such as Amazon, Google, IBM, and Microsoft. Cloud monitoring tools monitor millions of virtual and physical resources and continuously generate logs for each one of them. Considering that logs magnify any technical issue, they can be used for disaster detection, prevention, and recovery. However, logs are useless if they are not assessed and analyzed promptly. Thus, we argue that the scale of Cloud-generated logs makes it impossible for DevOps teams to analyze them effectively. This implies that one needs to automate the process of monitoring and analysis (e.g., using machine learning and artificial intelligence). If the automation will witness an anomaly in the logs --- it will alert DevOps staff. The automatic anomaly detectors require a reliable and scalable platform for gathering, filtering, and transforming the logs, executing the detector models, and sending out the alerts to the DevOps staff. In this work, we report on implementing a prototype of such a platform based on the 7-layered architecture pattern, which leverages micro-service principles to distribute tasks among highly scalable, resources-efficient modules. The modules interact with each other via an instance of the Publish-Subscribe architectural pattern. The platform is deployed on the IBM Cloud service infrastructure and is used to detect anomalies in logs emitted by the IBM Cloud services, hence the dogfooding.",
    "lastUpdated": "2019-07-13T15:04:03Z",
    "category": [
      "cs.DC",
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/1907.06094v1"
  },
  {
    "title": "LiDAR Data Enrichment Using Deep Learning Based on High-Resolution Image: An Approach to Achieve High-Performance LiDAR SLAM Using Low-cost LiDAR",
    "author": [
      "Jiang Yue",
      "Weisong Wen",
      "Jing Han",
      "Li-Ta Hsu"
    ],
    "abstract": "LiDAR-based SLAM algorithms are extensively studied to providing robust and accurate positioning for autonomous driving vehicles (ADV) in the past decades. Satisfactory performance can be obtained using high-grade 3D LiDAR with 64 channels, which can provide dense point clouds. Unfortunately, the high price significantly prevents its extensive commercialization in ADV. The cost-effective 3D LiDAR with 16 channels is a promising replacement. However, only limited and sparse point clouds can be provided by the 16 channels LiDAR, which cannot guarantee sufficient positioning accuracy for ADV in challenging dynamic environments. The high-resolution image from the low-cost camera can provide ample information about the surroundings. However, the explicit depth information is not available from the image. Inspired by the complementariness of 3D LiDAR and camera, this paper proposes to make use of the high-resolution images from a camera to enrich the raw 3D point clouds from the low-cost 16 channels LiDAR based on a state-of-the-art deep learning algorithm. An ERFNet is firstly employed to segment the image with the aid of the raw sparse 3D point clouds. Meanwhile, the sparse convolutional neural network is employed to predict the dense point clouds based on raw sparse 3D point clouds. Then, the predicted dense point clouds are fused with the segmentation outputs from ERFnet using a novel multi-layer convolutional neural network to refine the predicted 3D point clouds. Finally, the enriched point clouds are employed to perform LiDAR SLAM based on the state-of-the-art normal distribution transform (NDT). We tested our approach on the re-edited KITTI datasets: (1)the sparse 3D point clouds are significantly enriched with a mean square error of 1.1m MSE. (2)the map generated from the LiDAR SLAM is denser which includes more details without significant accuracy loss.",
    "lastUpdated": "2020-08-09T09:20:47Z",
    "category": [
      "cs.CV",
      "cs.LG",
      "cs.RO"
    ],
    "url": "http://arxiv.org/abs/2008.03694v1"
  },
  {
    "title": "Decentralized Overlay for Federation of Enterprise Clouds",
    "author": [
      "Rajiv Ranjan",
      "Rajkumar Buyya"
    ],
    "abstract": "This chapter describes Aneka-Federation, a decentralized and distributed system that combines enterprise Clouds, overlay networking, and structured peer-to-peer techniques to create scalable wide-area networking of compute nodes for high-throughput computing. The Aneka-Federation integrates numerous small scale Aneka Enterprise Cloud services and nodes that are distributed over multiple control and enterprise domains as parts of a single coordinated resource leasing abstraction. The system is designed with the aim of making distributed enterprise Cloud resource integration and application programming flexible, efficient, and scalable. The system is engineered such that it: enables seamless integration of existing Aneka Enterprise Clouds as part of single wide-area resource leasing federation; self-organizes the system components based on a structured peer-to-peer routing methodology; and presents end-users with a distributed application composition environment that can support variety of programming and execution models. This chapter describes the design and implementation of a novel, extensible and decentralized peer-to-peer technique that helps to discover, connect and provision the services of Aneka Enterprise Clouds among the users who can use different programming models to compose their applications. Evaluations of the system with applications that are programmed using the Task and Thread execution models on top of an overlay of Aneka Enterprise Clouds have been described here.",
    "lastUpdated": "2008-11-16T10:58:25Z",
    "category": [
      "cs.DC",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/0811.2563v1"
  },
  {
    "title": "Determinating Timing Channels in Compute Clouds",
    "author": [
      "Amittai Aviram",
      "Sen Hu",
      "Bryan Ford",
      "Ramakrishna Gummadi"
    ],
    "abstract": "Timing side-channels represent an insidious security challenge for cloud computing, because: (a) massive parallelism in the cloud makes timing channels pervasive and hard to control; (b) timing channels enable one customer to steal information from another without leaving a trail or raising alarms; (c) only the cloud provider can feasibly detect and report such attacks, but the provider's incentives are not to; and (d) resource partitioning schemes for timing channel control undermine statistical sharing efficiency, and, with it, the cloud computing business model. We propose a new approach to timing channel control, using provider-enforced deterministic execution instead of resource partitioning to eliminate timing channels within a shared cloud domain. Provider-enforced determinism prevents execution timing from affecting the results of a compute task, however large or parallel, ensuring that a task's outputs leak no timing information apart from explicit timing inputs and total compute duration. Experiments with a prototype OS for deterministic cloud computing suggest that such an approach may be practical and efficient. The OS supports deterministic versions of familiar APIs such as processes, threads, shared memory, and file systems, and runs coarse-grained parallel tasks as efficiently and scalably as current timing channel-ridden systems.",
    "lastUpdated": "2010-07-25T15:40:38Z",
    "category": [
      "cs.OS",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1003.5303v2"
  },
  {
    "title": "A Framework for QoS-aware Execution of Workflows over the Cloud",
    "author": [
      "Moreno Marzolla",
      "Raffaela Mirandola"
    ],
    "abstract": "The Cloud Computing paradigm is providing system architects with a new powerful tool for building scalable applications. Clouds allow allocation of resources on a \"pay-as-you-go\" model, so that additional resources can be requested during peak loads and released after that. However, this flexibility asks for appropriate dynamic reconfiguration strategies. In this paper we describe SAVER (qoS-Aware workflows oVER the Cloud), a QoS-aware algorithm for executing workflows involving Web Services hosted in a Cloud environment. SAVER allows execution of arbitrary workflows subject to response time constraints. SAVER uses a passive monitor to identify workload fluctuations based on the observed system response time. The information collected by the monitor is used by a planner component to identify the minimum number of instances of each Web Service which should be allocated in order to satisfy the response time constraint. SAVER uses a simple Queueing Network (QN) model to identify the optimal resource allocation. Specifically, the QN model is used to identify bottlenecks, and predict the system performance as Cloud resources are allocated or released. The parameters used to evaluate the model are those collected by the monitor, which means that SAVER does not require any particular knowledge of the Web Services and workflows being executed. Our approach has been validated through numerical simulations, whose results are reported in this paper.",
    "lastUpdated": "2011-04-28T13:55:30Z",
    "category": [
      "cs.DC",
      "cs.PF"
    ],
    "url": "http://arxiv.org/abs/1104.5392v1"
  },
  {
    "title": "Optimal Joint Multiple Resource Allocation Method for Cloud Computing Environments",
    "author": [
      "Shin-ichi Kuribayashi"
    ],
    "abstract": "Cloud computing is a model for enabling convenient, on-demand network access to a shared pool of configurable computing resources. To provide cloud computing services economically, it is important to optimize resource allocation under the assumption that the required resource can be taken from a shared resource pool. In addition, to be able to provide processing ability and storage capacity, it is necessary to allocate bandwidth to access them at the same time. This paper proposes an optimal resource allocation method for cloud computing environments. First, this paper develops a resource allocation model of cloud computing environments, assuming both processing ability and bandwidth are allocated simultaneously to each service request and rented out on an hourly basis. The allocated resources are dedicated to each service request. Next, this paper proposes an optimal joint multiple resource allocation method, based on the above resource allocation model. It is demonstrated by simulation evaluation that the proposed method can reduce the request loss probability and as a result, reduce the total resource required, compared with the conventional allocation method. Then, this paper defines basic principles and a measure for achieving fair resource allocation among multiple users in a cloud computing environment, and proposes a fair joint multiple resource allocation method. It is demonstrated by simulation evaluations that the proposed method enables the fair resource allocation among multiple users without a large decline in resource efficiency. Keywords: Cloud computing, joint multiple resource allocation, fairness",
    "lastUpdated": "2011-10-08T12:21:47Z",
    "category": [
      "cs.DC",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1110.1730v1"
  },
  {
    "title": "SLA-Oriented Resource Provisioning for Cloud Computing: Challenges, Architecture, and Solutions",
    "author": [
      "Rajkumar Buyya",
      "Saurabh Kumar Garg",
      "Rodrigo N. Calheiros"
    ],
    "abstract": "Cloud computing systems promise to offer subscription-oriented, enterprise-quality computing services to users worldwide. With the increased demand for delivering services to a large number of users, they need to offer differentiated services to users and meet their quality expectations. Existing resource management systems in data centers are yet to support Service Level Agreement (SLA)-oriented resource allocation, and thus need to be enhanced to realize cloud computing and utility computing. In addition, no work has been done to collectively incorporate customer-driven service management, computational risk management, and autonomic resource management into a market-based resource management system to target the rapidly changing enterprise requirements of Cloud computing. This paper presents vision, challenges, and architectural elements of SLA-oriented resource management. The proposed architecture supports integration of marketbased provisioning policies and virtualisation technologies for flexible allocation of resources to applications. The performance results obtained from our working prototype system shows the feasibility and effectiveness of SLA-based resource provisioning in Clouds.",
    "lastUpdated": "2012-01-22T01:41:04Z",
    "category": [
      "cs.DC",
      "cs.NI",
      "C.1.4"
    ],
    "url": "http://arxiv.org/abs/1201.4522v1"
  },
  {
    "title": "DEPAS: A Decentralized Probabilistic Algorithm for Auto-Scaling",
    "author": [
      "Nicolo M. Calcavecchia",
      "Bogdan Alexandru Caprarescu",
      "Elisabetta Di Nitto",
      "Daniel J. Dubois",
      "Dana Petcu"
    ],
    "abstract": "The dynamic provisioning of virtualized resources offered by cloud computing infrastructures allows applications deployed in a cloud environment to automatically increase and decrease the amount of used resources. This capability is called auto-scaling and its main purpose is to automatically adjust the scale of the system that is running the application to satisfy the varying workload with minimum resource utilization. The need for auto-scaling is particularly important during workload peaks, in which applications may need to scale up to extremely large-scale systems. Both the research community and the main cloud providers have already developed auto-scaling solutions. However, most research solutions are centralized and not suitable for managing large-scale systems, moreover cloud providers' solutions are bound to the limitations of a specific provider in terms of resource prices, availability, reliability, and connectivity. In this paper we propose DEPAS, a decentralized probabilistic auto-scaling algorithm integrated into a P2P architecture that is cloud provider independent, thus allowing the auto-scaling of services over multiple cloud infrastructures at the same time. Our simulations, which are based on real service traces, show that our approach is capable of: (i) keeping the overall utilization of all the instantiated cloud resources in a target range, (ii) maintaining service response times close to the ones obtained using optimal centralized auto-scaling approaches.",
    "lastUpdated": "2012-02-12T09:26:40Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1202.2509v1"
  },
  {
    "title": "CloudGenius: Decision Support for Web Server Cloud Migration",
    "author": [
      "Michael Menzel",
      "Rajiv Ranjan"
    ],
    "abstract": "Cloud computing is the latest computing paradigm that delivers hardware and software resources as virtualized services in which users are free from the burden of worrying about the low-level system administration details. Migrating Web applications to Cloud services and integrating Cloud services into existing computing infrastructures is non-trivial. It leads to new challenges that often require innovation of paradigms and practices at all levels: technical, cultural, legal, regulatory, and social. The key problem in mapping Web applications to virtualized Cloud services is selecting the best and compatible mix of software images (e.g., Web server image) and infrastructure services to ensure that Quality of Service (QoS) targets of an application are achieved. The fact that, when selecting Cloud services, engineers must consider heterogeneous sets of criteria and complex dependencies between infrastructure services and software images, which are impossible to resolve manually, is a critical issue. To overcome these challenges, we present a framework (called CloudGenius) which automates the decision-making process based on a model and factors specifically for Web server migration to the Cloud. CloudGenius leverages a well known multi-criteria decision making technique, called Analytic Hierarchy Process, to automate the selection process based on a model, factors, and QoS parameters related to an application. An example application demonstrates the applicability of the theoretical CloudGenius approach. Moreover, we present an implementation of CloudGenius that has been validated through experiments.",
    "lastUpdated": "2012-03-18T21:19:40Z",
    "category": [
      "cs.DC",
      "cs.SE",
      "D.2.2; H.4.2"
    ],
    "url": "http://arxiv.org/abs/1203.3997v1"
  },
  {
    "title": "Proposed congestion control method for cloud computing environments",
    "author": [
      "Shin-ichi Kuribayashi"
    ],
    "abstract": "As cloud computing services rapidly expand their customer base, it has become important to share cloud resources, so as to provide them economically. In cloud computing services, multiple types of resources, such as processing ability, bandwidth and storage, need to be allocated simultaneously. If there is a surge of requests, a competition will arise between these requests for the use of cloud resources. This leads to the disruption of the service and it is necessary to consider a measure to avoid or relieve congestion of cloud computing environments. This paper proposes a new congestion control method for cloud computing environments which reduces the size of required resource for congested resource type instead of restricting all service requests as in the existing networks. Next, this paper proposes the user service specifications for the proposed congestion control method, and clarifies the algorithm to decide the optimal size of required resource to be reduced, based on the load offered to the system. It is demonstrated by simulation evaluations that the proposed method can handle more requests compared with the conventional methods and relieve the congestion. Then, this paper proposes to enhance the proposed method, so as to enable the fair resource allocation among users in congested situation.",
    "lastUpdated": "2012-04-05T14:35:05Z",
    "category": [
      "cs.NI",
      "cs.SY"
    ],
    "url": "http://arxiv.org/abs/1204.1243v1"
  },
  {
    "title": "Performance Measurement of Cloud Computing Services",
    "author": [
      "Sinung Suakanto",
      "Suhono H Supangkat",
      "Suhardi",
      "Roberd Saragih"
    ],
    "abstract": "Cloud computing today has now been growing as new technologies and new business models. In distributed technology perspective, cloud computing most like client-server services like web-based or web-service but it used virtual resources to execute. Currently, cloud computing relies on the use of an elastic virtual machine and the use of network for data exchange. We conduct an experimental setup to measure the quality of service received by cloud computing customers. Experimental setup done by creating a HTTP service that runs in the cloud computing infrastructure. We interest to know about the impact of increasing the number of users on the average quality received by users. The qualities received by user measured within two parameters consist of average response times and the number of requests time out. Experimental results of this study show that increasing the number of users has increased the average response time. Similarly, the number of request time out increasing with increasing number of users. It means that the qualities of service received by user are decreasing also. We found that the impact of the number of users on the quality of service is no longer in linear trend. The results of this study can be used as a reference model for the network operator in performing services in which a certain number of users in order to obtain optimal quality services.",
    "lastUpdated": "2012-05-08T08:05:34Z",
    "category": [
      "cs.NI",
      "cs.DC",
      "cs.PF"
    ],
    "url": "http://arxiv.org/abs/1205.1622v1"
  },
  {
    "title": "Stream on the Sky: Outsourcing Access Control Enforcement for Stream Data to the Cloud",
    "author": [
      "Tien Tuan Anh Dinh",
      "Anwitaman Datta"
    ],
    "abstract": "There is an increasing trend for businesses to migrate their systems towards the cloud. Security concerns that arise when outsourcing data and computation to the cloud include data confidentiality and privacy. Given that a tremendous amount of data is being generated everyday from plethora of devices equipped with sensing capabilities, we focus on the problem of access controls over live streams of data based on triggers or sliding windows, which is a distinct and more challenging problem than access control over archival data. Specifically, we investigate secure mechanisms for outsourcing access control enforcement for stream data to the cloud. We devise a system that allows data owners to specify fine-grained policies associated with their data streams, then to encrypt the streams and relay them to the cloud for live processing and storage for future use. The access control policies are enforced by the cloud, without the latter learning about the data, while ensuring that unauthorized access is not feasible. To realize these ends, we employ a novel cryptographic primitive, namely proxy-based attribute-based encryption, which not only provides security but also allows the cloud to perform expensive computations on behalf of the users. Our approach is holistic, in that these controls are integrated with an XML based framework (XACML) for high-level management of policies. Experiments with our prototype demonstrate the feasibility of such mechanisms, and early evaluations suggest graceful scalability with increasing numbers of policies, data streams and users.",
    "lastUpdated": "2012-10-02T06:10:50Z",
    "category": [
      "cs.CR",
      "cs.DB",
      "cs.SY"
    ],
    "url": "http://arxiv.org/abs/1210.0660v1"
  },
  {
    "title": "A New Trusted and E-Commerce Architecture for Cloud Computing",
    "author": [
      "Kawser Wazed Nafi",
      "Tonny Shekha Kar",
      "Amjad Hossain",
      "M. M. A Hashem"
    ],
    "abstract": "Cloud computing platform gives people the opportunity for sharing resources, services and information among the people of the whole world. In private cloud system, information is shared among the persons who are in that cloud. Presently, different types of internet based systems are running in Cloud Computing environment. E-commerce is one of them. Present models are not secured enough for executing e-transactions easily, especially in cloud platform. Again, most of the time, clients fail to distinguish between the good online business companies and the bad one, which discourages clients and companies to migrate in cloud. In this paper, we have proposed a newer e-commerce architecture depends on encryption based secured and fuzzy logic based certain trust model which will be helpful to solve present e-commerce problems. We had discussed about the whole working procedure of the model in this paper. Finally, at the end of this paper, we have discussed some experimental results about our proposed model which will help to show the validity of our model.",
    "lastUpdated": "2013-04-25T05:54:00Z",
    "category": [
      "cs.DC",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1304.6809v1"
  },
  {
    "title": "Reporting an Experience on Design and Implementation of e-Health Systems on Azure Cloud",
    "author": [
      "Shilin Lu",
      "Rajiv Ranjan",
      "Peter Strazdins"
    ],
    "abstract": "Electronic Health (e-Health) technology has brought the world with significant transformation from traditional paper-based medical practice to Information and Communication Technologies (ICT)-based systems for automatic management (storage, processing, and archiving) of information. Traditionally e-Health systems have been designed to operate within stovepipes on dedicated networks, physical computers, and locally managed software platforms that make it susceptible to many serious limitations including: 1) lack of on-demand scalability during critical situations; 2) high administrative overheads and costs; and 3) in-efficient resource utilization and energy consumption due to lack of automation. In this paper, we present an approach to migrate the ICT systems in the e-Health sector from traditional in-house Client/Server (C/S) architecture to the virtualised cloud computing environment. To this end, we developed two cloud-based e-Health applications (Medical Practice Management System and Telemedicine Practice System) for demonstrating how cloud services can be leveraged for developing and deploying such applications. The Windows Azure cloud computing platform is selected as an example public cloud platform for our study. We conducted several performance evaluation experiments to understand the Quality Service (QoS) tradeoffs of our applications under variable workload on Azure.",
    "lastUpdated": "2013-06-16T04:07:57Z",
    "category": [
      "cs.CY",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1306.3624v1"
  },
  {
    "title": "Policy Specification in Role based Access Control on Clouds",
    "author": [
      "Gitanjali",
      "Sukhjit Singh Sehra",
      "Jaiteg Singh"
    ],
    "abstract": "Cloud Computing is a set of IT Services that are provided to a customer over a network and these services are delivered by third party provider who owns the infrastructure and reduce the burden at user's end. Nowadays researchers devoted their work access control method to enhance the security on Cloud. RBAC is attractive access model because the number of roles is significantly less hence users can be easily classified according to their roles. The Role-based Access Control (RBAC) model provides efficient way to manage access to information while reducing the cost of security administration and complexity in large networked applications. This paper specify various policies in RBAC on clouds such as migration policy which helps the user to migrate the database schema and roles easily to the Cloud using XML with more security. Restriction policy provide the security enhancement in Role Based Access Model by restricting the number of transaction per user and if the number of transactions will increase the admin will come to know through its monitoring system that unauthorized access has been made and it would be easier to take action against such happening. This paper proposes backup and restoration policy in Role Based Access Model in which if the main cloud is crashed or not working properly then the backup and restoration facility will be available to avoid the lost of important data. In this case chances of loss of data are very less so enhance more security on Cloud Computing.",
    "lastUpdated": "2013-08-23T16:41:56Z",
    "category": [
      "cs.DC",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1308.5177v1"
  },
  {
    "title": "Identifying Potential Risks and Benefits of Using Cloud in Distributed Software Development",
    "author": [
      "Nilay Oza",
      "Jürgen Münch",
      "Juan Garbajosa",
      "Agustin Yague",
      "Eloy Gonzalez Ortega"
    ],
    "abstract": "Cloud-based infrastructure has been increasingly adopted by the industry in distributed software development (DSD) environments. Its proponents claim that its several benefits include reduced cost, increased speed and greater productivity in software development. Empirical evaluations, however, are in the nascent stage of examining both the benefits and the risks of cloud-based infrastructure. The objective of this paper is to identify potential benefits and risks of using cloud in a DSD project conducted by teams based in Helsinki and Madrid. A cross-case qualitative analysis is performed based on focus groups conducted at the Helsinki and Madrid sites. Participants' observations are used to supplement the analysis. The results of the analysis indicated that the main benefits of using cloud are rapid development, continuous integration, cost savings, code sharing, and faster ramp-up. The key risks determined by the project are dependencies, unavailability of access to the cloud, code commitment and integration, technical debt, and additional support costs. The results revealed that if such environments are not planned and set up carefully, the benefits of using cloud in DSD projects might be overshadowed by the risks associated with it.",
    "lastUpdated": "2013-10-24T11:01:35Z",
    "category": [
      "cs.SE",
      "cs.DC",
      "D.2; D.2.9; K.6; K.6.1; K.6.3"
    ],
    "url": "http://arxiv.org/abs/1310.6564v1"
  },
  {
    "title": "Cloud computing security using encryption technique",
    "author": [
      "Geethu Thomas",
      "Prem Jose V",
      "P. Afsar"
    ],
    "abstract": "Cloud Computing has been envisioned as the next generation architecture of IT Enterprise. The Cloud computing concept offers dynamically scalable resources provisioned as a service over the Internet. Economic benefits are the main driver for the Cloud, since it promises the reduction of capital expenditure and operational expenditure. In order for this to become reality, however, there are still some challenges to be solved. Most important among these are security and trust issues,since the users data has to be released to the Cloud and thus leaves the protection sphere of the data owner.In contrast to traditional solutions, where the IT services are under proper physical,logical and personnel controls, Cloud Computing moves the application software and databases to the large data centers, where the management of the data and services may not be fully trustworthy. This unique attribute, however, poses many new security challenges which have not been well understood. Security is to save data from danger and vulnerability. There are so many dangers and vulnerabilities to be handled. Various security issues and some of their solution are explained and are concentrating mainly on public cloud security issues and their solutions. Data should always be encrypted when stored(using separate symmetric encryption keys)and transmitted. If this is implemented appropriately, even if another tenant can access the data, all that will appear is gibberish. So a method is proposed such that we are encrypting the whole data along with the cryptographic key.",
    "lastUpdated": "2013-10-31T06:11:24Z",
    "category": [
      "cs.DC",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1310.8392v1"
  },
  {
    "title": "CryptGraph: Privacy Preserving Graph Analytics on Encrypted Graph",
    "author": [
      "Pengtao Xie",
      "Eric Xing"
    ],
    "abstract": "Many graph mining and analysis services have been deployed on the cloud, which can alleviate users from the burden of implementing and maintaining graph algorithms. However, putting graph analytics on the cloud can invade users' privacy. To solve this problem, we propose CryptGraph, which runs graph analytics on encrypted graph to preserve the privacy of both users' graph data and the analytic results. In CryptGraph, users encrypt their graphs before uploading them to the cloud. The cloud runs graph analysis on the encrypted graphs and obtains results which are also in encrypted form that the cloud cannot decipher. During the process of computing, the encrypted graphs are never decrypted on the cloud side. The encrypted results are sent back to users and users perform the decryption to obtain the plaintext results. In this process, users' graphs and the analytics results are both encrypted and the cloud knows neither of them. Thereby, users' privacy can be strongly protected. Meanwhile, with the help of homomorphic encryption, the results analyzed from the encrypted graphs are guaranteed to be correct. In this paper, we present how to encrypt a graph using homomorphic encryption and how to query the structure of an encrypted graph by computing polynomials. To solve the problem that certain operations are not executable on encrypted graphs, we propose hard computation outsourcing to seek help from users. Using two graph algorithms as examples, we show how to apply our methods to perform analytics on encrypted graphs. Experiments on two datasets demonstrate the correctness and feasibility of our methods.",
    "lastUpdated": "2015-03-18T16:12:46Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1409.5021v2"
  },
  {
    "title": "A Self-adaptive Auto-scaling Method for Scientific Applications on HPC Environments and Clouds",
    "author": [
      "Kiran Mantripragada",
      "Alecio Binotto",
      "Leonardo P. Tizzei"
    ],
    "abstract": "High intensive computation applications can usually take days to months to finish an execution. During this time, it is common to have variations of the available resources when considering that such hardware is usually shared among a plurality of researchers/departments within an organization. On the other hand, High Performance Clusters can take advantage of Cloud Computing bursting techniques for the execution of applications together with the on-premise resources. In order to meet deadlines, high intensive computational applications can use the Cloud to boost their performance when they are data and task parallel. This article presents an ongoing work towards the use of extended resources of an HPC execution platform together with Cloud. We propose an unified view of such heterogeneous environments and a method that monitors, predicts the application execution time, and dynamically shifts part of the domain -- previously running in local HPC hardware -- to be computed on the Cloud, meeting then a specific deadline. The method is exemplified along with a seismic application that, at runtime, adapts itself to move part of the processing to the Cloud (in a movement called bursting) and also auto-scales (the moved part) over cloud nodes. Our preliminary results show that there is an expected overhead for performing this movement and for synchronizing results, but our outcomes demonstrate it is an important feature for meeting deadlines in the case an on-premise cluster is overloaded or cannot provide the capacity needed for a particular project.",
    "lastUpdated": "2015-01-26T18:09:33Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1412.6392v3"
  },
  {
    "title": "Online QoS Modeling in the Cloud: A Hybrid and Adaptive Multi-Learners Approach",
    "author": [
      "Tao Chen",
      "Rami Bahsoon",
      "Xin Yao"
    ],
    "abstract": "Given the on-demand nature of cloud computing, managing cloud-based services requires accurate modeling for the correlation between their Quality of Service (QoS) and cloud configurations/resources. The resulted models need to cope with the dynamic fluctuation of QoS sensitivity and interference. However, existing QoS modeling in the cloud are limited in terms of both accuracy and applicability due to their static and semi- dynamic nature. In this paper, we present a fully dynamic multi- learners approach for automated and online QoS modeling in the cloud. We contribute to a hybrid learners solution, which improves accuracy while keeping model complexity adequate. To determine the inputs of QoS model at runtime, we partition the inputs space into two sub-spaces, each of which applies different symmetric uncertainty based selection techniques, and we then combine the sub-spaces results. The learners are also adaptive; they simultaneously allow several machine learning algorithms to model QoS function and dynamically select the best model for prediction on the fly. We experimentally evaluate our models using RUBiS benchmark and realistic FIFA 98 workload. The results show that our multi-learners approach is more accurate and effective in contrast to the other state-of-the-art approaches.",
    "lastUpdated": "2015-04-15T16:35:40Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1504.03961v1"
  },
  {
    "title": "A Service Broker Model for Cloud based Render Farm Selection",
    "author": [
      "Ruby Annette",
      "Aisha Banu"
    ],
    "abstract": "Cloud computing is gaining popularity in the 3D Animation industry for rendering the 3D images. Rendering is an inevitable task in creating the 3d animated scenes. It is a process where the scene files to be animated is read and converted into 3D photorealistic images automatically. Since it is a computationally intensive task, this process consumes the majority of the time taken for 3D images production. As the scene files could be processed in parallel, clusters of computers called render farms can be used to speed up the rendering process. The advantage of using Cloud based render farms is that it is scalable and can be availed on demand. One of the important challenges faced by the 3D studios is the comparison and selection of the cloud based render farm service provider who could satisfy their functional and the non functional Quality of Service (QoS) requirements. In this paper we propose, a frame work for Cloud Service Broker (CSB) responsible for the selection and provision of the cloud based render farm. The Cloud Service Broker matches the functional and the non functional Quality of Service requirements (QoS) of the user with the service offerings of the render farm service providers and helps the user in selecting the right service provider using an aggregate utility function. The CSB also facilitates the process of Service Level Agreement (SLA) negotiation and monitoring by the third party monitoring services.",
    "lastUpdated": "2015-05-25T05:20:18Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1505.06542v1"
  },
  {
    "title": "DDoS Attacks in Cloud Computing: Issues, Taxonomy, and Future Directions",
    "author": [
      "Gaurav Somani",
      "Manoj Singh Gaur",
      "Dheeraj Sanghi",
      "Mauro Conti",
      "Rajkumar Buyya"
    ],
    "abstract": "Security issues related to the cloud computing are relevant to various stakeholders for an informed cloud adoption decision. Apart from data breaches, the cyber security research community is revisiting the attack space for cloud-specific solutions as these issues affect budget, resource management, and service quality. Distributed Denial of Service (DDoS) attack is one such serious attack in the cloud space. In this paper, we present developments related to DDoS attack mitigation solutions in the cloud. In particular, we present a comprehensive survey with a detailed insight into the characterization, prevention, detection, and mitigation mechanisms of these attacks. Additionally, we present a comprehensive solution taxonomy to classify DDoS attack solutions. We also provide a comprehensive discussion on important metrics to evaluate various solutions. This survey concludes that there is a strong requirement of solutions, which are designed keeping utility computing models in mind. Accurate auto-scaling decisions, multi-layer mitigation, and defense using profound resources in the cloud, are some of the key requirements of the desired solutions. In the end, we provide a definite guideline on effective solution building and detailed solution requirements to help the cyber security research community in designing defense mechanisms. To the best of our knowledge, this work is a novel attempt to identify the need of DDoS mitigation solutions involving multi-level information flow and effective resource management during the attack.",
    "lastUpdated": "2017-08-28T09:26:23Z",
    "category": [
      "cs.CR",
      "C.2.0"
    ],
    "url": "http://arxiv.org/abs/1512.08187v2"
  },
  {
    "title": "Memory DoS Attacks in Multi-tenant Clouds: Severity and Mitigation",
    "author": [
      "Tianwei Zhang",
      "Yinqian Zhang",
      "Ruby B. Lee"
    ],
    "abstract": "In cloud computing, network Denial of Service (DoS) attacks are well studied and defenses have been implemented, but severe DoS attacks on a victim's working memory by a single hostile VM are not well understood. Memory DoS attacks are Denial of Service (or Degradation of Service) attacks caused by contention for hardware memory resources on a cloud server. Despite the strong memory isolation techniques for virtual machines (VMs) enforced by the software virtualization layer in cloud servers, the underlying hardware memory layers are still shared by the VMs and can be exploited by a clever attacker in a hostile VM co-located on the same server as the victim VM, denying the victim the working memory he needs. We first show quantitatively the severity of contention on different memory resources. We then show that a malicious cloud customer can mount low-cost attacks to cause severe performance degradation for a Hadoop distributed application, and 38X delay in response time for an E-commerce website in the Amazon EC2 cloud. Then, we design an effective, new defense against these memory DoS attacks, using a statistical metric to detect their existence and execution throttling to mitigate the attack damage. We achieve this by a novel re-purposing of existing hardware performance counters and duty cycle modulation for security, rather than for improving performance or power consumption. We implement a full prototype on the OpenStack cloud system. Our evaluations show that this defense system can effectively defeat memory DoS attacks with negligible performance overhead.",
    "lastUpdated": "2017-10-04T16:43:59Z",
    "category": [
      "cs.DC",
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1603.03404v3"
  },
  {
    "title": "Managing Deadline-constrained Bag-of-Tasks Jobs on Hybrid Clouds",
    "author": [
      "Bo Wang",
      "Ying Song",
      "Yuzhong Sun",
      "Jun Liu"
    ],
    "abstract": "Outsourcing jobs to a public cloud is a cost-effective way to address the problem of satisfying the peak resource demand when the local cloud has insufficient resources. In this paper, we study on managing deadline-constrained bag-of-tasks jobs on hybrid clouds. We present a binary nonlinear programming (BNP) problem to model the hybrid cloud management where the utilization of physical machines (PMs) in the local cloud/cluster is maximized when the local resources are enough to satisfy the deadline constraints of jobs, while when not, the rent cost from the public cloud is minimized. To solve this BNP problem in polynomial time, we proposed a heuristic algorithm. Its main idea is assigning the task closest to its deadline to current core until the core cannot finish any task within its deadline. When there is no available core, the algorithm adds an available PM with most capacity or rents a new VM with highest cost-performance ratio. Extensive experimental results show that our heuristic algorithm saves 16.2%-76% rent cost and improves 47.3%-182.8% resource utilizations satisfying deadline constraints, compared with first fit decreasing algorithm.",
    "lastUpdated": "2016-04-28T07:48:42Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1604.08335v1"
  },
  {
    "title": "A Systematic Approach for Cross-source Point Cloud Registration by Preserving Macro and Micro Structures",
    "author": [
      "Xiaoshui Huang",
      "Jian Zhang",
      "Lixin Fan",
      "Qiang Wu",
      "Chun Yuan"
    ],
    "abstract": "We propose a systematic approach for registering cross-source point clouds. The compelling need for cross-source point cloud registration is motivated by the rapid development of a variety of 3D sensing techniques, but many existing registration methods face critical challenges as a result of the large variations in cross-source point clouds. This paper therefore illustrates a novel registration method which successfully aligns two cross-source point clouds in the presence of significant missing data, large variations in point density, scale difference and so on. The robustness of the method is attributed to the extraction of macro and micro structures. Our work has three main contributions: (1) a systematic pipeline to deal with cross-source point cloud registration; (2) a graph construction method to maintain macro and micro structures; (3) a new graph matching method is proposed which considers the global geometric constraint to robustly register these variable graphs. Compared to most of the related methods, the experiments show that the proposed method successfully registers in cross-source datasets, while other methods have difficulty achieving satisfactory results. The proposed method also shows great ability in same-source datasets.",
    "lastUpdated": "2016-08-22T23:04:03Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1608.05143v2"
  },
  {
    "title": "Self-Adaptive Trade-off Decision Making for Autoscaling Cloud-Based Services",
    "author": [
      "Tao Chen",
      "Rami Bahsoon"
    ],
    "abstract": "Elasticity in the cloud is often achieved by on-demand autoscaling. In such context, the goal is to optimize the Quality of Service (QoS) and cost objectives for the cloud-based services. However, the difficulty lies in the facts that these objectives, e.g., throughput and cost, can be naturally conflicted, and the QoS of cloud-based services often interfere due to the shared infrastructure in cloud. Consequently, dynamic and effective trade-off decision making of autoscaling in the cloud is necessary, yet challenging. In particular, it is even harder to achieve well-compromised trade-offs, where the decision largely improves the majority of the objectives, while causing relatively small degradations to others. In this paper, we present a self-adaptive decision making approach for autoscaling in the cloud. It is capable to adaptively produce autoscaling decisions that lead to well-compromised trade-offs without heavy human intervention. We leverage on ant colony inspired multi-objective optimization for searching and optimizing the trade-offs decisions, the result is then filtered by compromise-dominance, a mechanism that extracts the decisions with balanced improvements in the trade-offs. We experimentally compare our approach to four state-of-the-arts autoscaling approaches: rule, heuristic, randomized and multi-objective genetic algorithm based solutions. The results reveal the effectiveness of our approach over the others, including better quality of trade-offs and significantly smaller violation of the requirements.",
    "lastUpdated": "2016-08-21T11:21:02Z",
    "category": [
      "cs.DC",
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/1608.05917v1"
  },
  {
    "title": "Securely Outsourcing Large Scale Eigen Value Problem to Public Cloud",
    "author": [
      "Jarin Firose Moon",
      "Shamminuj Aktar",
      "M. M. A. Hashem"
    ],
    "abstract": "Cloud computing enables clients with limited computational power to economically outsource their large scale computations to a public cloud with huge computational power. Cloud has the massive storage, computational power and software which can be used by clients for reducing their computational overhead and storage limitation. But in case of outsourcing, privacy of client's confidential data must be maintained. We have designed a protocol for outsourcing large scale Eigen value problem to a malicious cloud which provides input/output data security, result verifiability and client's efficiency. As the direct computation method to find all eigenvectors is computationally expensive for large dimensionality, we have used power iterative method for finding the largest Eigen value and the corresponding Eigen vector of a matrix. For protecting the privacy, some transformations are applied to the input matrix to get encrypted matrix which is sent to the cloud and then decrypting the result that is returned from the cloud for getting the correct solution of Eigen value problem. We have also proposed result verification mechanism for detecting robust cheating and provided theoretical analysis and experimental result that describes high-efficiency, correctness, security and robust cheating resistance of the proposed protocol.",
    "lastUpdated": "2016-09-06T06:33:04Z",
    "category": [
      "cs.CR",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1609.01410v1"
  },
  {
    "title": "Security and Privacy of performing Data Analytics in the cloud - A three-way handshake of Technology, Policy, and Management",
    "author": [
      "Nidhi Rastogi",
      "Marie Joan Kristine Gloria",
      "James Hendler"
    ],
    "abstract": "Cloud platform came into existence primarily to accelerate IT delivery and to promote innovation. To this point, it has performed largely well to the expectations of technologists, businesses and customers. The service aspect of this technology has paved the road for a faster set up of infrastructure and related goals for both startups and established organizations. This has further led to quicker delivery of many user-friendly applications to the market while proving to be a commercially viable option to companies with limited resources. On the technology front, the creation and adoption of this ecosystem has allowed easy collection of massive data from various sources at one place, where the place is sometimes referred as just the cloud. Efficient data mining can be performed on raw data to extract potentially useful information, which was not possible at this scale before. Targeted advertising is a common example that can help businesses. Despite these promising offerings, concerns around security and privacy of user information suppressed wider acceptance and an all-encompassing deployment of the cloud platform. In this paper, we discuss security and privacy concerns that occur due to data exchanging hands between a cloud servicer provider (CSP) and the primary cloud user - the data collector, from the content generator. We offer solutions that encompass technology, policy and sound management of the cloud service asserting that this approach has the potential to provide a holistic solution.",
    "lastUpdated": "2017-01-24T11:59:28Z",
    "category": [
      "cs.DC",
      "cs.CY",
      "cs.NI",
      "C.2.0; D.4.6; K.4.1; C.2.4"
    ],
    "url": "http://arxiv.org/abs/1701.06828v1"
  },
  {
    "title": "Cloud-based MPC with Encrypted Data",
    "author": [
      "Andreea B. Alexandru",
      "Manfred Morari",
      "George J. Pappas"
    ],
    "abstract": "This paper explores the privacy of cloud outsourced Model Predictive Control (MPC) for a linear system with input constraints. In our cloud-based architecture, a client sends her private states to the cloud who performs the MPC computation and returns the control inputs. In order to guarantee that the cloud can perform this computation without obtaining anything about the client's private data, we employ a partially homomorphic cryptosystem. We propose protocols for two cloud-MPC architectures motivated by the current developments in the Internet of Things: a client-server architecture and a two-server architecture. In the first case, a control input for the system is privately computed by the cloud server, with the assistance of the client. In the second case, the control input is privately computed by two independent, non-colluding servers, with no additional requirements from the client. We prove that the proposed protocols preserve the privacy of the client's data and of the resulting control input. Furthermore, we compute bounds on the errors introduced by encryption. We present numerical simulations for the two architectures and discuss the trade-off between communication, MPC performance and privacy.",
    "lastUpdated": "2018-09-19T13:14:07Z",
    "category": [
      "math.OC",
      "cs.CR",
      "cs.SY"
    ],
    "url": "http://arxiv.org/abs/1803.09891v2"
  },
  {
    "title": "Efficient Resource Allocation for On-Demand Mobile-Edge Cloud Computing",
    "author": [
      "Xu Chen",
      "Wenzhong Li",
      "Sanglu Lu",
      "Zhi Zhou",
      "Xiaoming Fu"
    ],
    "abstract": "Mobile-edge cloud computing is a new paradigm to provide cloud computing capabilities at the edge of pervasive radio access networks in close proximity to mobile users. Aiming at provisioning flexible on-demand mobile-edge cloud service, in this paper we propose a comprehensive framework consisting of a resource-efficient computation offloading mechanism for users and a joint communication and computation (JCC) resource allocation mechanism for network operator. Specifically, we first study the resource-efficient computation offloading problem for a user, in order to reduce user's resource occupation by determining its optimal communication and computation resource profile with minimum resource occupation and meanwhile satisfying the QoS constraint. We then tackle the critical problem of user admission control for JCC resource allocation, in order to properly select the set of users for resource demand satisfaction. We show the admission control problem is NP-hard, and hence develop an efficient approximation solution of a low complexity by carefully designing the user ranking criteria and rigourously derive its performance guarantee. To prevent the manipulation that some users may untruthfully report their valuations in acquiring mobile-edge cloud service, we further resort to the powerful tool of critical value approach to design truthful pricing scheme for JCC resource allocation. Extensive performance evaluation demonstrates that the proposed schemes can achieve superior performance for on-demand mobile-edge cloud computing.",
    "lastUpdated": "2018-06-08T12:53:13Z",
    "category": [
      "cs.DC",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1806.03124v1"
  },
  {
    "title": "Graph-based compression of dynamic 3D point cloud sequences",
    "author": [
      "Dorina Thanou",
      "Philip A. Chou",
      "Pascal Frossard"
    ],
    "abstract": "This paper addresses the problem of compression of 3D point cloud sequences that are characterized by moving 3D positions and color attributes. As temporally successive point cloud frames are similar, motion estimation is key to effective compression of these sequences. It however remains a challenging problem as the point cloud frames have varying numbers of points without explicit correspondence information. We represent the time-varying geometry of these sequences with a set of graphs, and consider 3D positions and color attributes of the points clouds as signals on the vertices of the graphs. We then cast motion estimation as a feature matching problem between successive graphs. The motion is estimated on a sparse set of representative vertices using new spectral graph wavelet descriptors. A dense motion field is eventually interpolated by solving a graph-based regularization problem. The estimated motion is finally used for removing the temporal redundancy in the predictive coding of the 3D positions and the color characteristics of the point cloud sequences. Experimental results demonstrate that our method is able to accurately estimate the motion between consecutive frames. Moreover, motion estimation is shown to bring significant improvement in terms of the overall compression performance of the sequence. To the best of our knowledge, this is the first paper that exploits both the spatial correlation inside each frame (through the graph) and the temporal correlation between the frames (through the motion estimation) to compress the color and the geometry of 3D point cloud sequences in an efficient way.",
    "lastUpdated": "2015-06-19T17:31:34Z",
    "category": [
      "cs.CV",
      "cs.GR"
    ],
    "url": "http://arxiv.org/abs/1506.06096v1"
  },
  {
    "title": "Efficient Proofs of Retrievability with Public Verifiability for Dynamic Cloud Storage",
    "author": [
      "Binanda Sengupta",
      "Sushmita Ruj"
    ],
    "abstract": "Cloud service providers offer various facilities to their clients. The clients with limited resources opt for some of these facilities. They can outsource their bulk data to the cloud server. The cloud server maintains these data in lieu of monetary benefits. However, a malicious cloud server might delete some of these data to save some space and offer this extra amount of storage to another client. Therefore, the client might not retrieve her file (or some portions of it) as often as needed. Proofs of retrievability (POR) provide an assurance to the client that the server is actually storing all of her data appropriately and they can be retrieved at any point of time. In a dynamic POR scheme, the client can update her data after she uploads them to the cloud server. Moreover, in publicly verifiable POR schemes, the client can delegate her auditing task to some third party specialized for this purpose. In this work, we exploit the homomorphic hashing technique to design a publicly verifiable dynamic POR scheme that is more efficient (in terms of bandwidth required between the client and the server) than the \"state-of-the-art\" publicly verifiable dynamic POR scheme. We also analyze security and performance of our scheme.",
    "lastUpdated": "2018-08-16T09:39:34Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1611.03982v6"
  },
  {
    "title": "An Efficient Max-Min Resource Allocator and Task Scheduling Algorithm in Cloud Computing Environment",
    "author": [
      "J. Kok Konjaang",
      "J. Y. Maipan-uku",
      "Kumangkem Kennedy Kubuga"
    ],
    "abstract": "Cloud computing is a new archetype that provides dynamic computing services to cloud users through the support of datacenters that employs the services of datacenter brokers which discover resources and assign them Virtually. The focus of this research is to efficiently optimize resource allocation in the cloud by exploiting the Max-Min scheduling algorithm and enhancing it to increase efficiency in terms of completion time (makespan). This is key to enhancing the performance of cloud scheduling and narrowing the performance gap between cloud service providers and cloud resources consumers/users. The current Max-Min algorithm selects tasks with maximum execution time on a faster available machine or resource that is capable of giving minimum completion time. The concern of this algorithm is to give priority to tasks with maximum execution time first before assigning those with the minimum execution time for the purpose of minimizing makespan. The drawback of this algorithm is that, the execution of tasks with maximum execution time first may increase the makespan, and leads to a delay in executing tasks with minimum execution time if the number of tasks with maximum execution time exceeds that of tasks with minimum execution time, hence the need to improve it to mitigate the delay in executing tasks with minimum execution time. CloudSim is used to compare the effectiveness of the improved Max-Min algorithm with the traditional one. The experimented results show that the improved algorithm is efficient and can produce better makespan than Max-Min and DataAware.",
    "lastUpdated": "2016-11-27T15:29:24Z",
    "category": [
      "cs.DC",
      "F.2.2, I.2.7"
    ],
    "url": "http://arxiv.org/abs/1611.08864v1"
  },
  {
    "title": "Adaptive and Resilient Revenue Maximizing Dynamic Resource Allocation and Pricing for Cloud-Enabled IoT Systems",
    "author": [
      "Muhammad Junaid Farooq",
      "Quanyan Zhu"
    ],
    "abstract": "Cloud computing is becoming an essential component of modern computer and communication systems. The available resources at the cloud such as computing nodes, storage, databases, etc. are often packaged in the form of virtual machines (VMs) to be used by remotely located client applications for computational tasks. However, the cloud has a limited number of VMs available, which have to be efficiently utilized to generate higher productivity and subsequently generate maximum revenue. Client applications generate requests with computational tasks at random times with random complexity to be processed by the cloud. The cloud service provider (CSP) has to decide whether to allocate a VM to a task at hand or to wait for a higher complexity task in the future. We propose a threshold-based mechanism to optimally decide the allocation and pricing of VMs to sequentially arriving requests in order to maximize the revenue of the CSP over a finite time horizon. Moreover, we develop an adaptive and resilient framework based that can counter the effect of realtime changes in the number of available VMs at the cloud server, the frequency and nature of arriving tasks on the revenue of the CSP.",
    "lastUpdated": "2018-03-03T01:38:48Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1707.08691v3"
  },
  {
    "title": "Cloud Computing - Architecture and Applications",
    "author": [
      "Jaydip Sen",
      "Shanrong Zhao",
      "Xiaoying Wang",
      "Guojing Zhang",
      "Mengqin Yang",
      "Jian Wang",
      "Yun Long",
      "Sergey Andreev",
      "Roman Florea",
      "Aleksandr Ometov",
      "Adam Surak",
      "Yevgeni Koucheryavy",
      "Muhammad Ahmad Ashraf",
      "Waleed Tariq Sethi",
      "Abdullah Alfakhri",
      "Saleh Alshebeili",
      "Amr Alasaad"
    ],
    "abstract": "In the era of Internet of Things and with the explosive worldwide growth of electronic data volume, and associated need of processing, analysis, and storage of such humongous volume of data, it has now become mandatory to exploit the power of massively parallel architecture for fast computation. Cloud computing provides a cheap source of such computing framework for large volume of data for real-time applications. It is, therefore, not surprising to see that cloud computing has become a buzzword in the computing fraternity over the last decade. This book presents some critical applications in cloud frameworks along with some innovation design of algorithms and architecture for deployment in cloud environment. It is a valuable source of knowledge for researchers, engineers, practitioners, and graduate and doctoral students working in the field of cloud computing. It will also be useful for faculty members of graduate schools and universities.",
    "lastUpdated": "2017-07-29T09:45:08Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1707.09488v1"
  },
  {
    "title": "Technical Report on Deploying a highly secured OpenStack Cloud Infrastructure using BradStack as a Case Study",
    "author": [
      "Bashir Mohammed",
      "Sibusiso Moyo",
      "K. M Maiyama",
      "Sulayman Kinteh",
      "Al Noaman M. K. Al-Shaidy",
      "M. A. Kamala",
      "M. Kiran"
    ],
    "abstract": "Cloud computing has emerged as a popular paradigm and an attractive model for providing a reliable distributed computing model.it is increasing attracting huge attention both in academic research and industrial initiatives. Cloud deployments are paramount for institution and organizations of all scales. The availability of a flexible, free open source cloud platform designed with no propriety software and the ability of its integration with legacy systems and third-party applications are fundamental. Open stack is a free and opensource software released under the terms of Apache license with a fragmented and distributed architecture making it highly flexible. This project was initiated and aimed at designing a secured cloud infrastructure called BradStack, which is built on OpenStack in the Computing Laboratory at the University of Bradford. In this report, we present and discuss the steps required in deploying a secured BradStack Multi-node cloud infrastructure and conducting Penetration testing on OpenStack Services to validate the effectiveness of the security controls on the BradStack platform. This report serves as a practical guideline, focusing on security and practical infrastructure related issues. It also serves as a reference for institutions looking at the possibilities of implementing a secured cloud solution.",
    "lastUpdated": "2017-12-26T01:03:30Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1712.09152v1"
  },
  {
    "title": "Dynamic Graph CNN for Learning on Point Clouds",
    "author": [
      "Yue Wang",
      "Yongbin Sun",
      "Ziwei Liu",
      "Sanjay E. Sarma",
      "Michael M. Bronstein",
      "Justin M. Solomon"
    ],
    "abstract": "Point clouds provide a flexible geometric representation suitable for countless applications in computer graphics; they also comprise the raw output of most 3D data acquisition devices. While hand-designed features on point clouds have long been proposed in graphics and vision, however, the recent overwhelming success of convolutional neural networks (CNNs) for image analysis suggests the value of adapting insight from CNN to the point cloud world. Point clouds inherently lack topological information so designing a model to recover topology can enrich the representation power of point clouds. To this end, we propose a new neural network module dubbed EdgeConv suitable for CNN-based high-level tasks on point clouds including classification and segmentation. EdgeConv acts on graphs dynamically computed in each layer of the network. It is differentiable and can be plugged into existing architectures. Compared to existing modules operating in extrinsic space or treating each point independently, EdgeConv has several appealing properties: It incorporates local neighborhood information; it can be stacked applied to learn global shape properties; and in multi-layer systems affinity in feature space captures semantic characteristics over potentially long distances in the original embedding. We show the performance of our model on standard benchmarks including ModelNet40, ShapeNetPart, and S3DIS.",
    "lastUpdated": "2019-06-11T06:11:21Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1801.07829v2"
  },
  {
    "title": "URSA: A Neural Network for Unordered Point Clouds Using Constellations",
    "author": [
      "Mark B. Skouson",
      "Brett J. Borghetti",
      "Robert C. Leishman"
    ],
    "abstract": "This paper describes a neural network layer, named Ursa, that uses a constellation of points to learn classification information from point cloud data. Unlike other machine learning classification problems where the task is to classify an individual high-dimensional observation, in a point-cloud classification problem the goal is to classify a set of d-dimensional observations. Because a point cloud is a set, there is no ordering to the collection of points in a point-cloud classification problem. Thus, the challenge of classifying point clouds inputs is in building a classifier which is agnostic to the ordering of the observations, yet preserves the d-dimensional information of each point in the set. This research presents Ursa, a new layer type for an artificial neural network which achieves these two properties. Similar to new methods for this task, this architecture works directly on d-dimensional points rather than first converting the points to a d-dimensional volume. The Ursa layer is followed by a series of dense layers to classify 2D and 3D objects from point clouds. Experiments on ModelNet40 and MNIST data show classification results comparable with current methods, while reducing the training parameters by over 50 percent.",
    "lastUpdated": "2018-10-23T18:08:13Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1808.04848v2"
  },
  {
    "title": "S3BD: Secure Semantic Search over Encrypted Big Data in the Cloud",
    "author": [
      "Jason Woodworth",
      "Mohsen Amini Salehi"
    ],
    "abstract": "Cloud storage is a widely utilized service for both personal and enterprise demands. However, despite its advantages, many potential users with enormous amounts of sensitive data (big data) refrain from fully utilizing the cloud storage service due to valid concerns about data privacy. An established solution to the cloud data privacy problem is to perform encryption on the client-end. This approach, however, restricts data processing capabilities (eg, searching over the data). Accordingly, the research problem we investigate is how to enable real-time searching over the encrypted big data in the cloud. In particular, semantic search is of interest to clients dealing with big data. To address this problem, in this research, we develop a system (termed S3BD) for searching big data using cloud services without exposing any data to cloud providers. To keep real-time response on big data, S3BD proactively prunes the search space to a subset of the whole dataset. For that purpose, we propose a method to cluster the encrypted data. An abstract of each cluster is maintained on the client-end to navigate the search operation to appropriate clusters at the search time. Results of experiments, carried out on real-world big datasets, demonstrate that the search operation can be achieved in real-time and is significantly more efficient than other counterparts. In addition, a fully functional prototype of S3BD is made publicly available.",
    "lastUpdated": "2018-09-21T02:59:20Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1809.07927v1"
  },
  {
    "title": "The Internet of Things, Fog and Cloud Continuum: Integration and Challenges",
    "author": [
      "Luiz F. Bittencourt",
      "Roger Immich",
      "Rizos Sakellariou",
      "Nelson L. S. da Fonseca",
      "Edmundo R. M. Madeira",
      "Marilia Curado",
      "Leandro Villas",
      "Luiz da Silva",
      "Craig Lee",
      "Omer Rana"
    ],
    "abstract": "The Internet of Things needs for computing power and storage are expected to remain on the rise in the next decade. Consequently, the amount of data generated by devices at the edge of the network will also grow. While cloud computing has been an established and effective way of acquiring computation and storage as a service to many applications, it may not be suitable to handle the myriad of data from IoT devices and fulfill largely heterogeneous application requirements. Fog computing has been developed to lie between IoT and the cloud, providing a hierarchy of computing power that can collect, aggregate, and process data from/to IoT devices. Combining fog and cloud may reduce data transfers and communication bottlenecks to the cloud and also contribute to reduced latencies, as fog computing resources exist closer to the edge. This paper examines this IoT-Fog-Cloud ecosystem and provides a literature review from different facets of it: how it can be organized, how management is being addressed, and how applications can benefit from it. Lastly, we present challenging issues yet to be addressed in IoT-Fog-Cloud infrastructures.",
    "lastUpdated": "2018-09-26T13:31:22Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1809.09972v1"
  },
  {
    "title": "Effective Cloud Detection and Segmentation using a Gradient-Based Algorithm for Satellite Imagery; Application to improve PERSIANN-CCS",
    "author": [
      "Negin Hayatbini",
      "Kuo-lin Hsu",
      "Soroosh Sorooshian",
      "Yunji Zhang",
      "Fuqing Zhang"
    ],
    "abstract": "Being able to effectively identify clouds and monitor their evolution is one important step toward more accurate quantitative precipitation estimation and forecast. In this study, a new gradient-based cloud-image segmentation technique is developed using tools from image processing techniques. This method integrates morphological image gradient magnitudes to separable cloud systems and patches boundaries. A varying scale-kernel is implemented to reduce the sensitivity of image segmentation to noise and capture objects with various finenesses of the edges in remote-sensing images. The proposed method is flexible and extendable from single- to multi-spectral imagery. Case studies were carried out to validate the algorithm by applying the proposed segmentation algorithm to synthetic radiances for channels of the Geostationary Operational Environmental Satellites (GOES-R) simulated by a high-resolution weather prediction model. The proposed method compares favorably with the existing cloud-patch-based segmentation technique implemented in the PERSIANN-CCS (Precipitation Estimation from Remotely Sensed Information using Artificial Neural Network - Cloud Classification System) rainfall retrieval algorithm. Evaluation of event-based images indicates that the proposed algorithm has potential to improve rain detection and estimation skills with an average of more than 45% gain comparing to the segmentation technique used in PERSIANN-CCS and identifying cloud regions as objects with accuracy rates up to 98%.",
    "lastUpdated": "2018-09-27T23:59:24Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1809.10801v1"
  },
  {
    "title": "Cloud4IoT: a heterogeneous, distributed and autonomic cloud platform for the IoT",
    "author": [
      "Daniele Pizzolli",
      "Giuseppe Cossu",
      "Daniele Santoro",
      "Luca Capra",
      "Corentin Dupont",
      "Dukas Charalampos",
      "Francesco De Pellegrini",
      "Fabio Antonelli",
      "Silvio Cretti"
    ],
    "abstract": "We introduce Cloud4IoT, a platform offering automatic deployment, orchestration and dynamic configuration of IoT support software components and data-intensive applications for data processing and analytics, thus enabling plug-and-play integration of new sensor objects and dynamic workload scalability. Cloud4IoT enables the concept of Infrastructure as Code in the IoT context: it empowers IoT operations with the flexibility and elasticity of Cloud services. Furthermore it shifts traditionally centralized Cloud architectures towards a more distributed and decentralized computation paradigm, as required by IoT technologies, bridging the gap between Cloud Computing and IoT ecosystems. Thus, Cloud4IoT is playing a role similar to the one covered by solutions like Fog Computing, Cloudlets or Mobile Edge Cloud. The hierarchical architecture of Cloud4IoThosts a central Cloud platform and multiple remote edge Cloud modules supporting dedicated devices, namely the IoT Gateways, through which new sensor objects are made accessible to the platform. Overall, the platform is designed in order to support systems where IoT-based and data intensive applications may pose specific requirements for low latency, restricted available bandwidth, or data locality. Cloud4IoT is built on several Open Source technologies for containerisation and implementations of standards, protocols and services for the IoT. We present the implementation of the platform and demonstrate it in two different use cases.",
    "lastUpdated": "2018-10-03T16:55:12Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1810.01839v1"
  },
  {
    "title": "A Study of Efficient Energy Management Techniques for Cloud Computing Environment",
    "author": [
      "Syed Arshad Ali",
      "Mohammad Affan",
      "Mansaf Alam"
    ],
    "abstract": "The overall performance of the development of computing systems has been engrossed on enhancing demand from the client and enterprise domains. but, the intake of ever-increasing energy for computing systems has commenced to bound in increasing overall performance due to heavy electric payments and carbon dioxide emission. The growth in power consumption of server is increased continuously, and many researchers proposed, if this pattern repeats continuously, then the power consumption cost of a server over its lifespan would be higher than its hardware prices. The power intake troubles more for clusters, grids, and clouds, which encompass numerous thousand heterogeneous servers. Continuous efforts have been done to reduce the electricity intake of these massive-scale infrastructures. To identify the challenges and required future enhancements in the field of efficient energy consumption in Cloud Computing, it is necessary to synthesize and categorize the research and development done so far. In this paper, the authors discuss the reasons and problems associated with huge energy consumption by Cloud data centres and prepare a taxonomy of huge energy consumption problems and its related solutions. The authors cover all aspects of energy consumption by Cloud data centers and analyze many research papers to find the better solution for efficient energy consumption. This work gives an overall information regarding energy-consumption problems of Cloud data centres and energy-efficient solutions for this problem. The paper is concluded with a conversation of future enhancement and development in energy-efficient methods in Cloud Computing",
    "lastUpdated": "2018-10-17T10:19:05Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1810.07458v1"
  },
  {
    "title": "Pied Piper: Rethinking Internet Data Delivery",
    "author": [
      "Aran Bergman",
      "Israel Cidon",
      "Isaac Keslassy",
      "Noga Rotman",
      "Michael Schapira",
      "Alex Markuze",
      "Eyal Zohar"
    ],
    "abstract": "We contend that, analogously to the transition from resource-limited on-prem computing to resource-abundant cloud computing, Internet data delivery should also be adapted to a reality in which the cloud offers a virtually unlimited resource, i.e., network capacity, and virtualization enables delegating local tasks, such as routing and congestion control, to the cloud. This necessitates rethinking the traditional roles of inter- and intra-domain routing and conventional end-to-end congestion control. We introduce Optimized Cloudified Delivery (OCD), a holistic approach for optimizing joint Internet/cloud data delivery, and evaluate OCD through hundreds of thousands of file downloads from multiple locations. We start by examining an OCD baseline approach: traffic from a source A to a destination B successively passes through two cloud virtual machines operating as relays - nearest to A and B; and the two cloud relays employ TCP split. We show that even this naive strategy can outperform recently proposed improved end-to-end congestion control paradigms (BBR and PCC) by an order of magnitude. Next, we present a protocol-free, ideal pipe model of data transmission, and identify where today's Internet data delivery mechanisms diverge from this model. We then design and implement OCD Pied Piper. Pied Piper leverages various techniques, including novel kernel-based transport-layer accelerations, to improve the Internet-Cloud interface so as to approximately match the ideal network pipe model.",
    "lastUpdated": "2018-12-20T13:08:14Z",
    "category": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1812.05582v2"
  },
  {
    "title": "Casualty Detection from 3D Point Cloud Data for Autonomous Ground Mobile Rescue Robots",
    "author": [
      "Roni Permana Saputra",
      "Petar Kormushev"
    ],
    "abstract": "One of the most important features of mobile rescue robots is the ability to autonomously detect casualties, i.e. human bodies, which are usually lying on the ground. This paper proposes a novel method for autonomously detecting casualties lying on the ground using obtained 3D point-cloud data from an on-board sensor, such as an RGB-D camera or a 3D LIDAR, on a mobile rescue robot. In this method, the obtained 3D point-cloud data is projected onto the detected ground plane, i.e. floor, within the point cloud. Then, this projected point cloud is converted into a grid-map that is used afterwards as an input for the algorithm to detect human body shapes. The proposed method is evaluated by performing detection of a human dummy, placed in different random positions and orientations, using an on-board RGB-D camera on a mobile rescue robot called ResQbot. To evaluate the robustness of the casualty detection method to different camera angles, the orientation of the camera is set to different angles. The experimental results show that using the point-cloud data from the on-board RGB-D camera, the proposed method successfully detects the casualty in all tested body positions and orientations relative to the on-board camera, as well as in all tested camera angles.",
    "lastUpdated": "2018-12-21T12:39:13Z",
    "category": [
      "cs.RO"
    ],
    "url": "http://arxiv.org/abs/1812.09084v1"
  },
  {
    "title": "Markov Game Modeling of Moving Target Defense for Strategic Detection of Threats in Cloud Networks",
    "author": [
      "Ankur Chowdhary",
      "Sailik Sengupta",
      "Dijiang Huang",
      "Subbarao Kambhampati"
    ],
    "abstract": "The processing and storage of critical data in large-scale cloud networks necessitate the need for scalable security solutions. It has been shown that deploying all possible security measures incurs a cost on performance by using up valuable computing and networking resources which are the primary selling points for cloud service providers. Thus, there has been a recent interest in developing Moving Target Defense (MTD) mechanisms that helps one optimize the joint objective of maximizing security while ensuring that the impact on performance is minimized. Often, these techniques model the problem of multi-stage attacks by stealthy adversaries as a single-step attack detection game using graph connectivity measures as a heuristic to measure performance, thereby (1) losing out on valuable information that is inherently present in graph-theoretic models designed for large cloud networks, and (2) coming up with certain strategies that have asymmetric impacts on performance. In this work, we leverage knowledge in attack graphs of a cloud network in formulating a zero-sum Markov Game and use the Common Vulnerability Scoring System (CVSS) to come up with meaningful utility values for this game. Then, we show that the optimal strategy of placing detecting mechanisms against an adversary is equivalent to computing the mixed Min-max Equilibrium of the Markov Game. We compare the gains obtained by using our method to other techniques presently used in cloud network security, thereby showing its effectiveness. Finally, we highlight how the method was used for a small real-world cloud system.",
    "lastUpdated": "2019-02-28T01:26:02Z",
    "category": [
      "cs.AI",
      "cs.CR",
      "cs.GT"
    ],
    "url": "http://arxiv.org/abs/1812.09660v2"
  },
  {
    "title": "Skeletonisation Algorithms with Theoretical Guarantees for Unorganised Point Clouds with High Levels of Noise",
    "author": [
      "Vitaliy Kurlin",
      "Philip Smith"
    ],
    "abstract": "Data Science aims to extract meaningful knowledge from unorganised data. Real datasets usually come in the form of a cloud of points with only pairwise distances. Numerous applications require to visualise an overall shape of a noisy cloud of points sampled from a non-linear object that is more complicated than a union of disjoint clusters. The skeletonisation problem in its hardest form is to find a 1-dimensional skeleton that correctly represents a shape of the cloud. This paper compares several algorithms that solve the above skeletonisation problem for any point cloud and guarantee a successful reconstruction. For example, given a highly noisy point sample of an unknown underlying graph, a reconstructed skeleton should be geometrically close and homotopy equivalent to (has the same number of independent cycles as) the underlying graph. One of these algorithm produces a Homologically Persistent Skeleton (HoPeS) for any cloud without extra parameters. This universal skeleton contains sub-graphs that provably represent the 1-dimensional shape of the cloud at any scale. Other subgraphs of HoPeS reconstruct an unknown graph from its noisy point sample with a correct homotopy type and within a small offset of the sample. The extensive experiments on synthetic and real data reveal for the first time the maximum level of noise that allows successful graph reconstructions.",
    "lastUpdated": "2019-06-13T16:16:11Z",
    "category": [
      "cs.CG"
    ],
    "url": "http://arxiv.org/abs/1901.03319v2"
  },
  {
    "title": "Petascale Cloud Supercomputing for Terapixel Visualization of a Digital Twin",
    "author": [
      "Nicolas S. Holliman",
      "Manu Antony",
      "James Charlton",
      "Stephen Dowsland",
      "Philip James",
      "Mark Turner"
    ],
    "abstract": "Background: Photo-realistic terapixel visualization is computationally intensive and to date there have been no such visualizations of urban digital twins, the few terapixel visualizations that exist have looked towards space rather than earth. Objective: our aims are: creating a scalable cloud supercomputer software architecture for visualization; a photo-realistic terapixel 3D visualization of urban IoT data supporting daily updates; a rigorous evaluation of cloud supercomputing for our application. Method: we migrated the Blender Cycles path tracer to the public cloud within a new software framework designed to scale to petaFLOP performance. Results: we demonstrate we can compute a terapixel visualization in under one hour, the system scaling at 98% efficiency to use 1024 public cloud GPU nodes delivering 14 petaFLOPS. The resulting terapixel image supports interactive browsing of the city and its data at a wide range of sensing scales. Conclusion: The GPU compute resource available in the cloud is greater than anything available on our national supercomputers providing access to globally competitive resources. The direct financial cost of access, compared to procuring and running these systems, was low. The indirect cost, in overcoming teething issues with cloud software development, should reduce significantly over time.",
    "lastUpdated": "2019-03-12T11:35:02Z",
    "category": [
      "cs.DC",
      "cs.GR"
    ],
    "url": "http://arxiv.org/abs/1902.04820v2"
  },
  {
    "title": "The Role of Cloud-MANET Framework in the Internet of Things (IoT)",
    "author": [
      "Tanweer Alam",
      "Mohamed Benaida"
    ],
    "abstract": "In the next generation of computing, Mobile ad-hoc network (MANET) will play a very important role in the Internet of Things (IoT). The MANET is a kind of wireless networks that are self-organizing and auto connected in a decentralized system. Every device in MANET can be moved freely from one location to another in any direction. They can create a network with their neighbors smart devices and forward data to another device. The IoT-Cloud-MANET framework of smart devices is composed of IoT, cloud computing, and MANET. This framework can access and deliver cloud services to the MANET users through their smart devices in the IoT framework where all computations, data handling, and resource management are performed. The smart devices can move from one location to another within the range of the MANET network. Various MANETs can connect to the same cloud, they can use cloud service in a real time. For connecting the smart device of MANET to cloud needs integration with mobile apps. My main contribution in this research links a new methodology for providing secure communication on the internet of smart devices using MANET Concept in 5G. The research methodology uses the correct and efficient simulation of the desired study and can be implemented in a framework of the Internet of Things in 5G.",
    "lastUpdated": "2020-06-05T14:30:24Z",
    "category": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1902.09436v2"
  },
  {
    "title": "Zero-shot Learning of 3D Point Cloud Objects",
    "author": [
      "Ali Cheraghian",
      "Shafin Rahman",
      "Lars Petersson"
    ],
    "abstract": "Recent deep learning architectures can recognize instances of 3D point cloud objects of previously seen classes quite well. At the same time, current 3D depth camera technology allows generating/segmenting a large amount of 3D point cloud objects from an arbitrary scene, for which there is no previously seen training data. A challenge for a 3D point cloud recognition system is, then, to classify objects from new, unseen, classes. This issue can be resolved by adopting a zero-shot learning (ZSL) approach for 3D data, similar to the 2D image version of the same problem. ZSL attempts to classify unseen objects by comparing semantic information (attribute/word vector) of seen and unseen classes. Here, we adapt several recent 3D point cloud recognition systems to the ZSL setting with some changes to their architectures. To the best of our knowledge, this is the first attempt to classify unseen 3D point cloud objects in the ZSL setting. A standard protocol (which includes the choice of datasets and the seen/unseen split) to evaluate such systems is also proposed. Baseline performances are reported using the new protocol on the investigated models. This investigation throws a new challenge to the 3D point cloud recognition community that may instigate numerous future works.",
    "lastUpdated": "2019-02-27T00:15:31Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1902.10272v1"
  },
  {
    "title": "An Energy-Efficient Resource Management System for a Mobile Ad Hoc Cloud",
    "author": [
      "Sayed Chhattan Shah"
    ],
    "abstract": "Recently, mobile ad hoc clouds have emerged as a promising technology for mobile cyber-physical system applications, such as mobile intelligent video surveillance and smart homes. Resource management plays a key role in maximizing resource utilization and application performance in mobile ad hoc clouds. Unlike resource management in traditional distributed computing systems, such as clouds, resource management in a mobile ad hoc cloud poses numerous challenges owing to the node mobility, limited battery power, high latency, and the dynamic network environment. The real-time requirements associated with mobile cyber-physical system applications make the problem even more challenging. Currently, existing resource management systems for mobile ad hoc clouds are not designed to support mobile cyber-physical system applications and energy-efficient communication between application tasks. In this paper, we propose a new energy-efficient resource management system for mobile ad hoc clouds. The proposed system consists of two layers: a network layer and a middleware layer. The network layer provides ad hoc network and communication services to the middleware layer and shares the collected information in order to allow efficient and robust resource management decisions. It uses (1) a transmission power control mechanism to improve energy efficiency and network capacity, (2) link lifetimes to reduce communication and energy consumption costs, and (3) link quality to estimate data transfer times. The middleware layer is responsible for the discovery, monitoring, migration, and allocation of resources. It receives application tasks from users and allocates tasks to nodes on the basis of network and node-level information.",
    "lastUpdated": "2019-03-21T13:03:53Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1903.08969v1"
  },
  {
    "title": "FVNet: 3D Front-View Proposal Generation for Real-Time Object Detection from Point Clouds",
    "author": [
      "Jie Zhou",
      "Xin Tan",
      "Zhiwei Shao",
      "Lizhuang Ma"
    ],
    "abstract": "3D object detection from raw and sparse point clouds has been far less treated to date, compared with its 2D counterpart. In this paper, we propose a novel framework called FVNet for 3D front-view proposal generation and object detection from point clouds. It consists of two stages: generation of front-view proposals and estimation of 3D bounding box parameters. Instead of generating proposals from camera images or bird's-eye-view maps, we first project point clouds onto a cylindrical surface to generate front-view feature maps which retains rich information. We then introduce a proposal generation network to predict 3D region proposals from the generated maps and further extrude objects of interest from the whole point cloud. Finally, we present another network to extract the point-wise features from the extruded object points and regress the final 3D bounding box parameters in the canonical coordinates. Our framework achieves real-time performance with 12ms per point cloud sample. Extensive experiments on the 3D detection benchmark KITTI show that the proposed architecture outperforms state-of-the-art techniques which take either camera images or point clouds as input, in terms of accuracy and inference time.",
    "lastUpdated": "2019-11-26T07:54:29Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1903.10750v3"
  },
  {
    "title": "Exploring the Effectiveness of Service Decomposition in Fog Computing Architecture for the Internet of Things",
    "author": [
      "Badraddin Alturki",
      "Stephan Reiff-Marganiec",
      "Charith Perera",
      "Suparna De"
    ],
    "abstract": "The Internet of Things (IoT) aims to connect everyday physical objects to the internet. These objects will produce a significant amount of data. The traditional cloud computing architecture aims to process data in the cloud. As a result, a significant amount of data needs to be communicated to the cloud. This creates a number of challenges, such as high communication latency between the devices and the cloud, increased energy consumption of devices during frequent data upload to the cloud, high bandwidth consumption, while making the network busy by sending the data continuously, and less privacy because of less control on the transmitted data to the server. Fog computing has been proposed to counter these weaknesses. Fog computing aims to process data at the edge and substantially eliminate the necessity of sending data to the cloud. However, combining the Service Oriented Architecture (SOA) with the fog computing architecture is still an open challenge. In this paper, we propose to decompose services to create linked-microservices (LMS). Linked-microservices are services that run on multiple nodes but closely linked to their linked-partners. Linked-microservices allow distributing the computation across different computing nodes in the IoT architecture. Using four different types of architectures namely cloud, fog, hybrid and fog+cloud, we explore and demonstrate the effectiveness of service decomposition by applying four experiments to three different type of datasets. Evaluation of the four architectures shows that decomposing services into nodes reduce the data consumption over the network by 10% - 70%. Overall, these results indicate that the importance of decomposing services in the context of fog computing for enhancing the quality of service.",
    "lastUpdated": "2019-03-31T11:21:47Z",
    "category": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1904.00381v1"
  },
  {
    "title": "CloudCAMP: Automating Cloud Services Deployment and Management",
    "author": [
      "Anirban Bhattacharjee",
      "Yogesh Barve",
      "Aniruddha Gokhale",
      "Takayuki Kuroda"
    ],
    "abstract": "Users of cloud platforms often must expend significant manual efforts in the deployment and orchestration of their services on cloud platforms due primarily to having to deal with the high variabilities in the configuration options for virtualized environment setup and meeting the software dependencies for each service. Despite the emergence of many DevOps cloud automation and orchestration tools, users must still rely on specifying low-level scripting details for service deployment and management using Infrastructure-as-Code (IAC). Using these tools required domain expertise along with a steep learning curve. To address these challenges in a tool-and-technology agnostic manner, which helps promote interoperability and portability of services hosted across cloud platforms, we present initial ideas on a GUI based cloud automation and orchestration framework called CloudCAMP. It incorporates domain-specific modeling so that the specifications and dependencies imposed by the cloud platform and application architecture can be specified at an intuitive, higher level of abstraction without the need for domain expertise using Model-Driven Engineering(MDE) paradigm. CloudCAMP transforms the partial specifications into deployable Infrastructure-as-Code (IAC) using the Transformational-Generative paradigm and by leveraging an extensible and reusable knowledge base. The auto-generated IAC can be handled by existing tools to provision the services components automatically. We validate our approach quantitatively by showing a comparative study of savings in manual and scripting efforts versus using CloudCAMP.",
    "lastUpdated": "2019-04-09T01:27:48Z",
    "category": [
      "cs.SE"
    ],
    "url": "http://arxiv.org/abs/1904.02184v2"
  },
  {
    "title": "Deep AutoEncoder-based Lossy Geometry Compression for Point Clouds",
    "author": [
      "Wei Yan",
      "Yiting shao",
      "Shan Liu",
      "Thomas H Li",
      "Zhu Li",
      "Ge Li"
    ],
    "abstract": "Point cloud is a fundamental 3D representation which is widely used in real world applications such as autonomous driving. As a newly-developed media format which is characterized by complexity and irregularity, point cloud creates a need for compression algorithms which are more flexible than existing codecs. Recently, autoencoders(AEs) have shown their effectiveness in many visual analysis tasks as well as image compression, which inspires us to employ it in point cloud compression. In this paper, we propose a general autoencoder-based architecture for lossy geometry point cloud compression. To the best of our knowledge, it is the first autoencoder-based geometry compression codec that directly takes point clouds as input rather than voxel grids or collections of images. Compared with handcrafted codecs, this approach adapts much more quickly to previously unseen media contents and media formats, meanwhile achieving competitive performance. Our architecture consists of a pointnet-based encoder, a uniform quantizer, an entropy estimation block and a nonlinear synthesis transformation module. In lossy geometry compression of point cloud, results show that the proposed method outperforms the test model for categories 1 and 3 (TMC13) published by MPEG-3DG group on the 125th meeting, and on average a 73.15\\% BD-rate gain is achieved.",
    "lastUpdated": "2019-04-18T02:44:50Z",
    "category": [
      "cs.CV",
      "cs.MM",
      "eess.IV"
    ],
    "url": "http://arxiv.org/abs/1905.03691v1"
  },
  {
    "title": "SvTPM: A Secure and Efficient vTPM in the Cloud",
    "author": [
      "Juan Wang",
      "Chengyang Fan",
      "Jie Wang",
      "Yueqiang Cheng",
      "Yinqian Zhang",
      "Wenhui Zhang",
      "Peng Liu",
      "Hongxin Hu"
    ],
    "abstract": "Virtual Trusted Platform Modules (vTPMs) have been widely used in commercial cloud platforms (e.g. Google Cloud, VMware Cloud, and Microsoft Azure) to provide virtual root-of-trust for virtual machines. Unfortunately, current state-of-the-art vTPM implementations are suffering from confidential data leakage and high performance overhead. In this paper, we present SvTPM, a secure and efficient software-based vTPM implementation based on hardware-rooted Trusted Execution Environment (TEE), providing a whole life cycle protection of vTPMs in the cloud. SvTPM offers strong isolation protection, so that cloud tenants or even cloud administrators cannot get vTPM's private keys or any other sensitive data. In SvTPM, we identify and solve a couple of critical security challenges for vTPM protection with SGX, such as NVRAM replacement attack, rollback attacks, trust establishment, and a fine-grained trusted clock. We implement a prototype of SvTPM on both QEMU and KVM. Performance evaluation results show that SvTPM achieves orders of magnitude of performance gains comparing to the vTPMs protected with physical TPM. The launch time of SvTPM is 2600$\\times$ faster than vTPMs built upon hardware TPM. In the micro-benchmarks evaluation, we find that the command execution latency of SvTPM is smaller than or equal to the existing schemes.",
    "lastUpdated": "2019-05-21T08:39:52Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1905.08493v1"
  },
  {
    "title": "EdgeLens: Deep Learning based Object Detection in Integrated IoT, Fog and Cloud Computing Environments",
    "author": [
      "Shreshth Tuli",
      "Nipam Basumatary",
      "Rajkumar Buyya"
    ],
    "abstract": "Data-intensive applications are growing at an increasing rate and there is a growing need to solve scalability and high-performance issues in them. By the advent of Cloud computing paradigm, it became possible to harness remote resources to build and deploy these applications. In recent years, new set of applications and services based on Internet of Things (IoT) paradigm, require to process large amount of data in very less time. Among them surveillance and object detection have gained prime importance, but cloud is unable to bring down the network latencies to meet the response time requirements. This problem is solved by Fog computing which harnesses resources in the edge of the network along with remote cloud resources as required. However, there is still a lack of frameworks that are successfully able to integrate sophisticated software and applications, especially deep learning, with fog and cloud computing environments. In this work, we propose a framework to deploy deep learning-based applications in fog-cloud environments to harness edge and cloud resources to provide better service quality for such applications. Our proposed framework, called EdgeLens, adapts to the application or user requirements to provide high accuracy or low latency modes of services. We also tested the performance of the software in terms of accuracy, response time, jitter, network bandwidth and power consumption and show how EdgeLens adapts to different service requirements.",
    "lastUpdated": "2019-06-26T12:53:47Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1906.11056v1"
  },
  {
    "title": "Cost-Driven Offloading for DNN-based Applications over Cloud, Edge and End Devices",
    "author": [
      "Bin Lin",
      "Yinhao Huang",
      "Jianshan Zhang",
      "Junqin Hu",
      "Xing Chen",
      "Jun Li"
    ],
    "abstract": "Currently, deep neural networks (DNNs) have achieved a great success in various applications. Traditional deployment for DNNs in the cloud may incur a prohibitively serious delay in transferring input data from the end devices to the cloud. To address this problem, the hybrid computing environments, consisting of the cloud, edge and end devices, are adopted to offload DNN layers by combining the larger layers (more amount of data) in the cloud and the smaller layers (less amount of data) at the edge and end devices. A key issue in hybrid computing environments is how to minimize the system cost while accomplishing the offloaded layers with their deadline constraints. In this paper, a self-adaptive discrete particle swarm optimization (PSO) algorithm using the genetic algorithm (GA) operators was proposed to reduce the system cost caused by data transmission and layer execution. This approach considers the characteristics of DNNs partitioning and layers offloading over the cloud, edge and end devices. The mutation operator and crossover operator of GA were adopted to avert the premature convergence of PSO, which distinctly reduces the system cost through enhanced population diversity of PSO. The proposed offloading strategy is compared with benchmark solutions, and the results show that our strategy can effectively reduce the cost of offloading for DNN-based applications over the cloud, edge and end devices relative to the benchmarks.",
    "lastUpdated": "2019-07-31T04:54:47Z",
    "category": [
      "cs.DC",
      "eess.SP"
    ],
    "url": "http://arxiv.org/abs/1907.13306v1"
  },
  {
    "title": "LassoNet: Deep Lasso-Selection of 3D Point Clouds",
    "author": [
      "Zhutian Chen",
      "Wei Zeng",
      "Zhiguang Yang",
      "Lingyun Yu",
      "Chi-Wing Fu",
      "Huamin Qu"
    ],
    "abstract": "Selection is a fundamental task in exploratory analysis and visualization of 3D point clouds. Prior researches on selection methods were developed mainly based on heuristics such as local point density, thus limiting their applicability in general data. Specific challenges root in the great variabilities implied by point clouds (e.g., dense vs. sparse), viewpoint (e.g., occluded vs. non-occluded), and lasso (e.g., small vs. large). In this work, we introduce LassoNet, a new deep neural network for lasso selection of 3D point clouds, attempting to learn a latent mapping from viewpoint and lasso to point cloud regions. To achieve this, we couple user-target points with viewpoint and lasso information through 3D coordinate transform and naive selection, and improve the method scalability via an intention filtering and farthest point sampling. A hierarchical network is trained using a dataset with over 30K lasso-selection records on two different point cloud data. We conduct a formal user study to compare LassoNet with two state-of-the-art lasso-selection methods. The evaluations confirm that our approach improves the selection effectiveness and efficiency across different combinations of 3D point clouds, viewpoints, and lasso selections. Project Website: https://lassonet.github.io",
    "lastUpdated": "2019-10-07T11:45:48Z",
    "category": [
      "cs.HC",
      "cs.GR"
    ],
    "url": "http://arxiv.org/abs/1907.13538v2"
  },
  {
    "title": "Predictive Generalized Graph Fourier Transform for Attribute Compression of Dynamic Point Clouds",
    "author": [
      "Yiqun Xu",
      "Wei Hu",
      "Shanshe Wang",
      "Xinfeng Zhang",
      "Shiqi Wang",
      "Siwei Ma",
      "Zongming Guo",
      "Wen Gao"
    ],
    "abstract": "As 3D scanning devices and depth sensors advance, dynamic point clouds have attracted increasing attention as a format for 3D objects in motion, with applications in various fields such as immersive telepresence, navigation for autonomous driving and gaming. Nevertheless, the tremendous amount of data in dynamic point clouds significantly burden transmission and storage. To this end, we propose a complete compression framework for attributes of 3D dynamic point clouds, focusing on optimal inter-coding. Firstly, we derive the optimal inter-prediction and predictive transform coding assuming the Gaussian Markov Random Field model with respect to a spatio-temporal graph underlying the attributes of dynamic point clouds. The optimal predictive transform proves to be the Generalized Graph Fourier Transform in terms of spatio-temporal decorrelation. Secondly, we propose refined motion estimation via efficient registration prior to inter-prediction, which searches the temporal correspondence between adjacent frames of irregular point clouds. Finally, we present a complete framework based on the optimal inter-coding and our previously proposed intra-coding, where we determine the optimal coding mode from rate-distortion optimization with the proposed offline-trained $\\lambda$-Q model. Experimental results show that we achieve around 17% bit rate reduction on average over competitive dynamic point cloud compression methods.",
    "lastUpdated": "2020-08-10T09:04:50Z",
    "category": [
      "cs.MM",
      "cs.GR"
    ],
    "url": "http://arxiv.org/abs/1908.01970v4"
  },
  {
    "title": "uPredict: A User-Level Profiler-Based Predictive Framework for Single VM Applications in Multi-Tenant Clouds",
    "author": [
      "Hamidreza Moradi",
      "Wei Wang",
      "Amanda Fernandez",
      "Dakai Zhu"
    ],
    "abstract": "Most existing studies on performance prediction for virtual machines (VMs) in multi-tenant clouds are at system level and generally require access to performance counters in Hypervisors. In this work, we propose uPredict, a user-level profiler-based performance predictive framework for single-VM applications in multi-tenant clouds. Here, three micro-benchmarks are specially devised to assess the contention of CPUs, memory and disks in a VM, respectively. Based on measured performance of an application and micro-benchmarks, the application and VM-specific predictive models can be derived by exploiting various regression and neural network based techniques. These models can then be used to predict the application's performance using the in-situ profiled resource contention with the micro-benchmarks. We evaluated uPredict extensively with representative benchmarks from PARSEC, NAS Parallel Benchmarks and CloudSuite, on both a private cloud and two public clouds. The results show that the average prediction errors are between 9.8% to 17% for various predictive models on the private cloud with high resource contention, while the errors are within 4% on public clouds. A smart load-balancing scheme powered by uPredict is presented and can effectively reduce the execution and turnaround times of the considered application by 19% and 10%, respectively.",
    "lastUpdated": "2019-08-13T05:00:31Z",
    "category": [
      "cs.PF"
    ],
    "url": "http://arxiv.org/abs/1908.04491v1"
  },
  {
    "title": "Fog Robotics: A Summary, Challenges and Future Scope",
    "author": [
      "Siva Leela Krishna Chand Gudi",
      "Benjamin Johnston",
      "Mary-Anne Williams"
    ],
    "abstract": "Human-robot interaction plays a crucial role to make robots closer to humans. Usually, robots are limited by their own capabilities. Therefore, they utilise Cloud Robotics to enhance their dexterity. Its ability includes the sharing of information such as maps, images and the processing power. This whole process involves distributing data which intend to rise enormously. New issues can arise such as bandwidth, network congestion at backhaul and fronthaul systems resulting in high latency. Thus, it can make an impact on seamless connectivity between the robots, users and the cloud. Also, a robot may not accomplish its goal successfully within a stipulated time. As a consequence, Cloud Robotics cannot be in a position to handle the traffic imposed by robots. On the contrary, impending Fog Robotics can act as a solution by solving major problems of Cloud Robotics. Therefore to check its feasibility, we discuss the need and architectures of Fog Robotics in this paper. To evaluate the architectures, we used a realistic scenario of Fog Robotics by comparing them with Cloud Robotics. Next, latency is chosen as the primary factor for validating the effectiveness of the system. Besides, we utilised real-time latency using Pepper robot, Fog robot server and the Cloud server. Experimental results show that Fog Robotics reduces latency significantly compared to Cloud Robotics. Moreover, advantages, challenges and future scope of the Fog Robotics system is further discussed.",
    "lastUpdated": "2019-08-14T03:07:12Z",
    "category": [
      "cs.RO",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1908.04935v1"
  },
  {
    "title": "Integration of Blockchain and Cloud of Things: Architecture, Applications and Challenges",
    "author": [
      "Dinh C Nguyen",
      "Pubudu N Pathirana",
      "Ming Ding",
      "Aruna Seneviratne"
    ],
    "abstract": "The blockchain technology is taking the world by storm. Blockchain with its decentralized, transparent and secure nature has emerged as a disruptive technology for the next generation of numerous industrial applications. One of them is Cloud of Things enabled by the combination of cloud computing and Internet of Things. In this context, blockchain provides innovative solutions to address challenges in Cloud of Things in terms of decentralization, data privacy and network security, while Cloud of Things offer elasticity and scalability functionalities to improve the efficiency of blockchain operations. Therefore, a novel paradigm of blockchain and Cloud of Things integration, called BCoT, has been widely regarded as a promising enabler for a wide range of application scenarios. In this paper, we present a state-of-the-art review on the BCoT integration to provide general readers with an overview of the BCoT in various aspects, including background knowledge, motivation, and integrated architecture. Particularly, we also provide an in-depth survey of BCoT applications in different use-case domains such as smart healthcare, smart city, smart transportation and smart industry. Then, we review the recent BCoT developments with the emerging blockchain and cloud platforms, services, and research projects. Finally, some important research challenges and future directions are highlighted to spur further research in this promising area.",
    "lastUpdated": "2020-08-28T04:41:33Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1908.09058v2"
  },
  {
    "title": "Insecure Until Proven Updated: Analyzing AMD SEV's Remote Attestation",
    "author": [
      "Robert Buhren",
      "Christian Werling",
      "Jean-Pierre Seifert"
    ],
    "abstract": "Customers of cloud services have to trust the cloud providers, as they control the building blocks that form the cloud. This includes the hypervisor enabling the sharing of a single hardware platform among multiple tenants. AMD Secure Encrypted Virtualization (SEV) claims a new level of protection in cloud scenarios. AMD SEV encrypts the main memory of virtual machines with VM-specific keys, thereby denying the higher-privileged hypervisor access to a guest's memory. To enable the cloud customer to verify the correct deployment of his virtual machine, SEV additionally introduces a remote attestation protocol.This paper analyzes the firmware components that implement the SEV remote attestation protocol on the current AMD Epyc Naples CPU series. We demonstrate that it is possible to extract critical CPU-specific keys that are fundamental for the security of the remote attestation protocol.Building on the extracted keys, we propose attacks that allow a malicious cloud provider a complete circumvention of the SEV protection mechanisms. Although the underlying firmware issues were already fixed by AMD, we show that the current series of AMD Epyc CPUs, i.e., the Naples series, does not prevent the installation of previous firmware versions. We show that the severity of our proposed attacks is very high as no purely software-based mitigations are possible. This effectively renders the SEV technology on current AMD Epyc CPUs useless when confronted with an untrusted cloud provider. To overcome these issues, we also propose robust changes to the SEV design that allow future generations of the SEV technology to mitigate the proposed attacks.",
    "lastUpdated": "2019-09-02T14:22:21Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/1908.11680v2"
  },
  {
    "title": "Characterizing the Deep Neural Networks Inference Performance of Mobile Applications",
    "author": [
      "Samuel S. Ogden",
      "Tian Guo"
    ],
    "abstract": "Today's mobile applications are increasingly leveraging deep neural networks to provide novel features, such as image and speech recognitions. To use a pre-trained deep neural network, mobile developers can either host it in a cloud server, referred to as cloud-based inference, or ship it with their mobile application, referred to as on-device inference. In this work, we investigate the inference performance of these two common approaches on both mobile devices and public clouds, using popular convolutional neural networks. Our measurement study suggests the need for both on-device and cloud-based inferences for supporting mobile applications. In particular, newer mobile devices is able to run mobile-optimized CNN models in reasonable time. However, for older mobile devices or to use more complex CNN models, mobile applications should opt in for cloud-based inference. We further demonstrate that variable network conditions can lead to poor cloud-based inference end-to-end time. To support efficient cloud-based inference, we propose a CNN model selection algorithm called CNNSelect that dynamically selects the most appropriate CNN model for each inference request, and adapts its selection to match different SLAs and execution time budgets that are caused by variable mobile environments. The key idea of CNNSelect is to make inference speed and accuracy trade-offs at runtime using a set of CNN models. We demonstrated that CNNSelect smoothly improves inference accuracy while maintaining SLA attainment in 88.5% more cases than a greedy baseline.",
    "lastUpdated": "2019-09-10T22:33:10Z",
    "category": [
      "cs.DC",
      "cs.PF"
    ],
    "url": "http://arxiv.org/abs/1909.04783v1"
  },
  {
    "title": "Reinforcing Edge Computing with Multipath TCP Enabled Mobile Device Clouds",
    "author": [
      "Venkatraman Balasubramanian",
      "Kees Kroep",
      "Kishor Chandra Joshi",
      "R. Venkatesha Prasad"
    ],
    "abstract": "In recent years, enormous growth has been witnessed in the computational and storage capabilities of mobile devices. However, much of this computational and storage capabilities are not always fully used. On the other hand, popularity of mobile edge computing which aims to replace the traditional centralized powerful cloud with multiple edge servers is rapidly growing. In particular, applications having strict latency requirements can be best served by the mobile edge clouds due to a reduced round-trip delay. In this paper we propose a Multi-Path TCP (MPTCP) enabled mobile device cloud (MDC) as a replacement to the existing TCP based or D2D device cloud techniques, as it effectively makes use of the available bandwidth by providing much higher throughput as well as ensures robust wireless connectivity. We investigate the congestion in mobile-device cloud formation resulting mainly due to the message passing for service providing nodes at the time of discovery, service continuity and formation of cloud composition. We propose a user space agent called congestion handler that enable offloading of packets from one sub-flow to the other under link quality constraints. Further, we discuss the benefits of this design and perform preliminary analysis of the system.",
    "lastUpdated": "2019-10-30T13:14:33Z",
    "category": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/1909.05530v2"
  },
  {
    "title": "ClassyTune: A Performance Auto-Tuner for Systems in the Cloud",
    "author": [
      "Yuqing Zhu",
      "Jianxun Liu"
    ],
    "abstract": "Performance tuning can improve the system performance and thus enable the reduction of cloud computing resources needed to support an application. Due to the ever increasing number of parameters and complexity of systems, there is a necessity to automate performance tuning for the complicated systems in the cloud. The state-of-the-art tuning methods are adopting either the experience-driven tuning approach or the data-driven one. Data-driven tuning is attracting increasing attentions, as it has wider applicability. But existing data-driven methods cannot fully address the challenges of sample scarcity and high dimensionality simultaneously. We present ClassyTune, a data-driven automatic configuration tuning tool for cloud systems. ClassyTune exploits the machine learning model of classification for auto-tuning. This exploitation enables the induction of more training samples without increasing the input dimension. Experiments on seven popular systems in the cloud show that ClassyTune can effectively tune system performance to seven times higher for high-dimensional configuration space, outperforming expert tuning and the state-of-the-art auto-tuning solutions. We also describe a use case in which performance tuning enables the reduction of 33% computing resources needed to run an online stateless service.",
    "lastUpdated": "2019-10-12T04:05:24Z",
    "category": [
      "cs.PF",
      "cs.DC",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/1910.05482v1"
  },
  {
    "title": "POIRot: A rotation invariant omni-directional pointnet",
    "author": [
      "Liu Yang",
      "Rudrasis Chakraborty",
      "Stella X. Yu"
    ],
    "abstract": "Point-cloud is an efficient way to represent 3D world. Analysis of point-cloud deals with understanding the underlying 3D geometric structure. But due to the lack of smooth topology, and hence the lack of neighborhood structure, standard correlation can not be directly applied on point-cloud. One of the popular approaches to do point correlation is to partition the point-cloud into voxels and extract features using standard 3D correlation. But this approach suffers from sparsity of point-cloud and hence results in multiple empty voxels. One possible solution to deal with this problem is to learn a MLP to map a point or its local neighborhood to a high dimensional feature space. All these methods suffer from a large number of parameters requirement and are susceptible to random rotations. A popular way to make the model \"invariant\" to rotations is to use data augmentation techniques with small rotations but the potential drawback includes \\item more training samples \\item susceptible to large rotations. In this work, we develop a rotation invariant point-cloud segmentation and classification scheme based on the omni-directional camera model (dubbed as {\\bf POIRot$^1$}). Our proposed model is rotationally invariant and can preserve geometric shape of a 3D point-cloud. Because of the inherent rotation invariant property, our proposed framework requires fewer number of parameters (please see \\cite{Iandola2017SqueezeNetAA} and the references therein for motivation of lean models). Several experiments have been performed to show that our proposed method can beat the state-of-the-art algorithms in classification and part segmentation applications.",
    "lastUpdated": "2019-10-30T02:51:50Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1910.13050v2"
  },
  {
    "title": "A GMM based algorithm to generate point-cloud and its application to neuroimaging",
    "author": [
      "Liu Yang",
      "Rudrasis Chakraborty"
    ],
    "abstract": "Recent years have witnessed the emergence of 3D medical imaging techniques with the development of 3D sensors and technology. Due to the presence of noise in image acquisition, registration researchers focused on an alternative way to represent medical images. An alternative way to analyze medical imaging is by understanding the 3D shapes represented in terms of point-cloud. Though in the medical imaging community, 3D point-cloud processing is not a ``go-to'' choice, it is a ``natural'' way to capture 3D shapes. However, as the number of samples for medical images are small, researchers have used pre-trained models to fine-tune on medical images. Furthermore, due to different modality in medical images, standard generative models can not be used to generate new samples of medical images. In this work, we use the advantage of point-cloud representation of 3D structures of medical images and propose a Gaussian mixture model-based generation scheme. Our proposed method is robust to outliers. Experimental validation has been performed to show that the proposed scheme can generate new 3D structures using interpolation techniques, i.e., given two 3D structures represented as point-clouds, we can generate point-clouds in between. We have also generated new point-clouds for subjects with and without dementia and show that the generated samples are indeed closely matched to the respective training samples from the same class.",
    "lastUpdated": "2019-11-05T10:54:53Z",
    "category": [
      "cs.LG",
      "eess.IV",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1911.01705v1"
  },
  {
    "title": "Cumulo: A Dataset for Learning Cloud Classes",
    "author": [
      "Valentina Zantedeschi",
      "Fabrizio Falasca",
      "Alyson Douglas",
      "Richard Strange",
      "Matt J. Kusner",
      "Duncan Watson-Parris"
    ],
    "abstract": "One of the greatest sources of uncertainty in future climate projections comes from limitations in modelling clouds and in understanding how different cloud types interact with the climate system. A key first step in reducing this uncertainty is to accurately classify cloud types at high spatial and temporal resolution. In this paper, we introduce Cumulo, a benchmark dataset for training and evaluating global cloud classification models. It consists of one year of 1km resolution MODIS hyperspectral imagery merged with pixel-width 'tracks' of CloudSat cloud labels. Bringing these complementary datasets together is a crucial first step, enabling the Machine-Learning community to develop innovative new techniques which could greatly benefit the Climate community. To showcase Cumulo, we provide baseline performance analysis using an invertible flow generative model (IResNet), which further allows us to discover new sub-classes for a given cloud class by exploring the latent space. To compare methods, we introduce a set of evaluation criteria, to identify models that are not only accurate, but also physically-realistic. CUMULO can be download from https://www.dropbox.com/sh/6gca7f0mb3b0ikz/AADq2lk4u7k961Qa31FwIDEpa?dl=0 .",
    "lastUpdated": "2020-04-14T10:01:33Z",
    "category": [
      "physics.ao-ph",
      "cs.CV",
      "cs.LG",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/1911.04227v2"
  },
  {
    "title": "Resource- and Message Size-Aware Scheduling of Stream Processing at the Edge with application to Realtime Microscopy",
    "author": [
      "Ben Blamey",
      "Ida-Maria Sintorn",
      "Andreas Hellander",
      "Salman Toor"
    ],
    "abstract": "Whilst computational resources at the cloud edge can be leveraged to improve latency and reduce the costs of cloud services for a wide variety mobile, web, and IoT applications; such resources are naturally constrained. For distributed stream processing applications, there are clear advantages to offloading some processing work to the cloud edge. Many state of the art stream processing applications such as Flink and Spark Streaming, being designed to run exclusively in the cloud, are a poor fit for such hybrid edge/cloud deployment settings, not least because their schedulers take limited consideration of the heterogeneous hardware in such deployments. In particular, their schedulers broadly assume a homogeneous network topology (aside from data locality consideration in, e.g., HDFS/Spark). Specialized stream processing frameworks intended for such hybrid deployment scenarios, especially IoT applications, allow developers to manually allocate specific operators in the pipeline to nodes at the cloud edge. In this paper, we investigate scheduling stream processing in hybrid cloud/edge deployment settings with sensitivity to CPU costs and message size, with the aim of maximizing throughput with respect to limited edge resources. We demonstrate real-time edge processing of a stream of electron microscopy images, and measure a consistent reduction in end-to-end latency under our approach versus a resource-agnostic baseline scheduler, under benchmarking.",
    "lastUpdated": "2019-12-19T09:44:18Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/1912.09088v1"
  },
  {
    "title": "A Comprehensive Study and Comparison of Core Technologies for MPEG 3D Point Cloud Compression",
    "author": [
      "Hao Liu",
      "Hui Yuan",
      "Qi Liu",
      "Junhui Hou",
      "Ju Liu"
    ],
    "abstract": "Point cloud based 3D visual representation is becoming popular due to its ability to exhibit the real world in a more comprehensive and immersive way. However, under a limited network bandwidth, it is very challenging to communicate this kind of media due to its huge data volume. Therefore, the MPEG have launched the standardization for point cloud compression (PCC), and proposed three model categories, i.e., TMC1, TMC2, and TMC3. Because the 3D geometry compression methods of TMC1 and TMC3 are similar, TMC1 and TMC3 are further merged into a new platform namely TMC13. In this paper, we first introduce some basic technologies that are usually used in 3D point cloud compression, then review the encoder architectures of these test models in detail, and finally analyze their rate distortion performance as well as complexity quantitatively for different cases (i.e., lossless geometry and lossless color, lossless geometry and lossy color, lossy geometry and lossy color) by using 16 benchmark 3D point clouds that are recommended by MPEG. Experimental results demonstrate that the coding efficiency of TMC2 is the best on average (especially for lossy geometry and lossy color compression) for dense point clouds while TMC13 achieves the optimal coding performance for sparse and noisy point clouds with lower time complexity.",
    "lastUpdated": "2019-12-20T07:23:20Z",
    "category": [
      "eess.IV",
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/1912.09674v1"
  },
  {
    "title": "Skeleton Extraction from 3D Point Clouds by Decomposing the Object into Parts",
    "author": [
      "Vijai Jayadevan",
      "Edward Delp",
      "Zygmunt Pizlo"
    ],
    "abstract": "Decomposing a point cloud into its components and extracting curve skeletons from point clouds are two related problems. Decomposition of a shape into its components is often obtained as a byproduct of skeleton extraction. In this work, we propose to extract curve skeletons, from unorganized point clouds, by decomposing the object into its parts, identifying part skeletons and then linking these part skeletons together to obtain the complete skeleton. We believe it is the most natural way to extract skeletons in the sense that this would be the way a human would approach the problem. Our parts are generalized cylinders (GCs). Since, the axis of a GC is an integral part of its definition, the parts have natural skeletal representations. We use translational symmetry, the fundamental property of GCs, to extract parts from point clouds. We demonstrate how this method can handle a large variety of shapes. We compare our method with state of the art methods and show how a part based approach can deal with some of the limitations of other methods. We present an improved version of an existing point set registration algorithm and demonstrate its utility in extracting parts from point clouds. We also show how this method can be used to extract skeletons from and identify parts of noisy point clouds. A part based approach also provides a natural and intuitive interface for user interaction. We demonstrate the ease with which mistakes, if any, can be fixed with minimal user interaction with the help of a graphical user interface.",
    "lastUpdated": "2019-12-26T20:52:57Z",
    "category": [
      "cs.GR",
      "cs.CV",
      "cs.RO"
    ],
    "url": "http://arxiv.org/abs/1912.11932v1"
  },
  {
    "title": "Energy Efficient Virtual Machines Placement over Cloud-Fog Network Architecture",
    "author": [
      "Hatem Alharbi",
      "Taisir E. H. Elgorashi",
      "Jaafar M. H. Elmirghani"
    ],
    "abstract": "Fog computing is an emerging paradigm that aims to improve the efficiency and QoS of cloud computing by extending the cloud to the edge of the network. This paper develops a comprehensive energy efficiency analysis framework based on mathematical modeling and heuristics to study the offloading of virtual machine (VM) services from the cloud to the fog. The analysis addresses the impact of different factors including the traffic between the VM and its users, the VM workload, the workload versus number of users profile and the proximity of fog nodes to users. Overall, the power consumption can be reduced if the VM users traffic is high and/or the VMs have a linear power profile. In such a linear profile case, the creation of multiple VM replicas does not increase the computing power consumption significantly (there may be a slight increase due to idle / baseline power consumption) if the number of users remains constant, however the VM replicas can be brought closer to the end users, thus reducing the transport network power consumption. In our scenario, the optimum placement of VMs over a cloud-fog architecture significantly decreased the total power consumption by 56% and 64% under high user data rates compared to optimized distributed clouds placement and placement in the existing AT&T network cloud locations, respectively.",
    "lastUpdated": "2020-01-15T00:48:53Z",
    "category": [
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/2001.05091v1"
  },
  {
    "title": "Runtime Deep Model Multiplexing for Reduced Latency and Energy Consumption Inference",
    "author": [
      "Amir Erfan Eshratifar",
      "Massoud Pedram"
    ],
    "abstract": "We propose a learning algorithm to design a light-weight neural multiplexer that given the input and computational resource requirements, calls the model that will consume the minimum compute resources for a successful inference. Mobile devices can use the proposed algorithm to offload the hard inputs to the cloud while inferring the easy ones locally. Besides, in the large scale cloud-based intelligent applications, instead of replicating the most-accurate model, a range of small and large models can be multiplexed from depending on the input's complexity which will save the cloud's computational resources. The input complexity or hardness is determined by the number of models that can predict the correct label. For example, if no model can predict the label correctly, then the input is considered as the hardest. The proposed algorithm allows the mobile device to detect the inputs that can be processed locally and the ones that require a larger model and should be sent a cloud server. Therefore, the mobile user benefits from not only the local processing but also from an accurate model hosted on a cloud server. Our experimental results show that the proposed algorithm improves mobile's model accuracy by 8.52% which is because of those inputs that are properly selected and offloaded to the cloud server. In addition, it saves the cloud providers' compute resources by a factor of 2.85x as small models are chosen for easier inputs.",
    "lastUpdated": "2020-09-17T17:07:31Z",
    "category": [
      "cs.DC",
      "cs.CV",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2001.05870v2"
  },
  {
    "title": "ImVoteNet: Boosting 3D Object Detection in Point Clouds with Image Votes",
    "author": [
      "Charles R. Qi",
      "Xinlei Chen",
      "Or Litany",
      "Leonidas J. Guibas"
    ],
    "abstract": "3D object detection has seen quick progress thanks to advances in deep learning on point clouds. A few recent works have even shown state-of-the-art performance with just point clouds input (e.g. VoteNet). However, point cloud data have inherent limitations. They are sparse, lack color information and often suffer from sensor noise. Images, on the other hand, have high resolution and rich texture. Thus they can complement the 3D geometry provided by point clouds. Yet how to effectively use image information to assist point cloud based detection is still an open question. In this work, we build on top of VoteNet and propose a 3D detection architecture called ImVoteNet specialized for RGB-D scenes. ImVoteNet is based on fusing 2D votes in images and 3D votes in point clouds. Compared to prior work on multi-modal detection, we explicitly extract both geometric and semantic features from the 2D images. We leverage camera parameters to lift these features to 3D. To improve the synergy of 2D-3D feature fusion, we also propose a multi-tower training scheme. We validate our model on the challenging SUN RGB-D dataset, advancing state-of-the-art results by 5.7 mAP. We also provide rich ablation studies to analyze the contribution of each design choice.",
    "lastUpdated": "2020-01-29T05:09:28Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2001.10692v1"
  },
  {
    "title": "Automatic marker-free registration of tree point-cloud data based on rotating projection",
    "author": [
      "Xiuxian Xu",
      "Pei Wang",
      "Xiaozheng Gan",
      "Yaxin Li",
      "Li Zhang",
      "Qing Zhang",
      "Mei Zhou",
      "Yinghui Zhao",
      "Xinwei Li"
    ],
    "abstract": "Point-cloud data acquired using a terrestrial laser scanner (TLS) play an important role in digital forestry research. Multiple scans are generally used to overcome occlusion effects and obtain complete tree structural information. However, it is time-consuming and difficult to place artificial reflectors in a forest with complex terrain for marker-based registration, a process that reduces registration automation and efficiency. In this study, we propose an automatic coarse-to-fine method for the registration of point-cloud data from multiple scans of a single tree. In coarse registration, point clouds produced by each scan are projected onto a spherical surface to generate a series of two-dimensional (2D) images, which are used to estimate the initial positions of multiple scans. Corresponding feature-point pairs are then extracted from these series of 2D images. In fine registration, point-cloud data slicing and fitting methods are used to extract corresponding central stem and branch centers for use as tie points to calculate fine transformation parameters. To evaluate the accuracy of registration results, we propose a model of error evaluation via calculating the distances between center points from corresponding branches in adjacent scans. For accurate evaluation, we conducted experiments on two simulated trees and a real-world tree. Average registration errors of the proposed method were 0.26m around on simulated tree point clouds, and 0.05m around on real-world tree point cloud.",
    "lastUpdated": "2020-01-30T06:53:59Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2001.11192v1"
  },
  {
    "title": "PointASNL: Robust Point Clouds Processing using Nonlocal Neural Networks with Adaptive Sampling",
    "author": [
      "Xu Yan",
      "Chaoda Zheng",
      "Zhen Li",
      "Sheng Wang",
      "Shuguang Cui"
    ],
    "abstract": "Raw point clouds data inevitably contains outliers or noise through acquisition from 3D sensors or reconstruction algorithms. In this paper, we present a novel end-to-end network for robust point clouds processing, named PointASNL, which can deal with point clouds with noise effectively. The key component in our approach is the adaptive sampling (AS) module. It first re-weights the neighbors around the initial sampled points from farthest point sampling (FPS), and then adaptively adjusts the sampled points beyond the entire point cloud. Our AS module can not only benefit the feature learning of point clouds, but also ease the biased effect of outliers. To further capture the neighbor and long-range dependencies of the sampled point, we proposed a local-nonlocal (L-NL) module inspired by the nonlocal operation. Such L-NL module enables the learning process insensitive to noise. Extensive experiments verify the robustness and superiority of our approach in point clouds processing tasks regardless of synthesis data, indoor data, and outdoor data with or without noise. Specifically, PointASNL achieves state-of-the-art robust performance for classification and segmentation tasks on all datasets, and significantly outperforms previous methods on real-world outdoor SemanticKITTI dataset with considerate noise. Our code is released through https://github.com/yanx27/PointASNL.",
    "lastUpdated": "2020-05-05T07:46:18Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2003.00492v3"
  },
  {
    "title": "HierTrain: Fast Hierarchical Edge AI Learning with Hybrid Parallelism in Mobile-Edge-Cloud Computing",
    "author": [
      "Deyin Liu",
      "Xu Chen",
      "Zhi Zhou",
      "Qing Ling"
    ],
    "abstract": "Nowadays, deep neural networks (DNNs) are the core enablers for many emerging edge AI applications. Conventional approaches to training DNNs are generally implemented at central servers or cloud centers for centralized learning, which is typically time-consuming and resource-demanding due to the transmission of a large amount of data samples from the device to the remote cloud. To overcome these disadvantages, we consider accelerating the learning process of DNNs on the Mobile-Edge-Cloud Computing (MECC) paradigm. In this paper, we propose HierTrain, a hierarchical edge AI learning framework, which efficiently deploys the DNN training task over the hierarchical MECC architecture. We develop a novel \\textit{hybrid parallelism} method, which is the key to HierTrain, to adaptively assign the DNN model layers and the data samples across the three levels of edge device, edge server and cloud center. We then formulate the problem of scheduling the DNN training tasks at both layer-granularity and sample-granularity. Solving this optimization problem enables us to achieve the minimum training time. We further implement a hardware prototype consisting of an edge device, an edge server and a cloud server, and conduct extensive experiments on it. Experimental results demonstrate that HierTrain can achieve up to 6.9x speedup compared to the cloud-based hierarchical training approach.",
    "lastUpdated": "2020-03-22T12:40:06Z",
    "category": [
      "cs.NI",
      "cs.DC",
      "cs.LG"
    ],
    "url": "http://arxiv.org/abs/2003.09876v1"
  },
  {
    "title": "Hedge Your Bets: Optimizing Long-term Cloud Costs by Mixing VM Purchasing Options",
    "author": [
      "Pradeep Ambati",
      "Noman Bashir",
      "David Irwin",
      "Mohammad Hajiesmaili",
      "Prashant Shenoy"
    ],
    "abstract": "Cloud platforms offer the same VMs under many purchasing options that specify different costs and time commitments, such as on-demand, reserved, sustained-use, scheduled reserve, transient, and spot block. In general, the stronger the commitment, i.e., longer and less flexible, the lower the price. However, longer and less flexible time commitments can increase cloud costs for users if future workloads cannot utilize the VMs they committed to buying. Large cloud customers often find it challenging to choose the right mix of purchasing options to reduce their long-term costs, while retaining the ability to adjust capacity up and down in response to workload variations. To address the problem, we design policies to optimize long-term cloud costs by selecting a mix of VM purchasing options based on short- and long-term expectations of workload utilization. We consider a batch trace spanning 4 years from a large shared cluster for a major state University system that includes 14k cores and 60 million job submissions, and evaluate how these jobs could be judiciously executed using cloud servers using our approach. Our results show that our policies incur a cost within 41% of an optimistic optimal offline approach, and 50% less than solely using on-demand VMs.",
    "lastUpdated": "2020-04-08T23:51:54Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/2004.04302v1"
  },
  {
    "title": "Multi-view polarimetric scattering cloud tomography and retrieval of droplet size",
    "author": [
      "Aviad Levis",
      "Yoav Y. Schechner",
      "Anthony B. Davis",
      "Jesse Loveridge"
    ],
    "abstract": "Tomography aims to recover a three-dimensional (3D) density map of a medium or an object. In medical imaging, it is extensively used for diagnostics via X-ray computed tomography (CT). Optical diffusion tomography is an alternative to X-ray CT that uses multiply scattered light to deliver coarse density maps for soft tissues. We define and derive tomography of cloud droplet distributions via passive remote sensing. We use multi-view polarimetric images to fit a 3D polarized radiative transfer (RT) forward model. Our motivation is 3D volumetric probing of vertically-developed convectively-driven clouds that are ill-served by current methods in operational passive remote sensing. These techniques are based on strictly 1D RT modeling and applied to a single cloudy pixel, where cloud geometry is assumed to be that of a plane-parallel slab. Incident unpolarized sunlight, once scattered by cloud-droplets, changes its polarization state according to droplet size. Therefore, polarimetric measurements in the rainbow and glory angular regions can be used to infer the droplet size distribution. This work defines and derives a framework for a full 3D tomography of cloud droplets for both their mass concentration in space and their distribution across a range of sizes. This 3D retrieval of key microphysical properties is made tractable by our novel approach that involves a restructuring and differentiation of an open-source polarized 3D RT code to accommodate a special two-step optimization technique. Physically-realistic synthetic clouds are used to demonstrate the methodology with rigorous uncertainty quantification.",
    "lastUpdated": "2020-05-22T23:39:21Z",
    "category": [
      "physics.comp-ph",
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2005.11423v1"
  },
  {
    "title": "Exploiting Local and Cloud Sensor Fusion in Intermittently Connected Sensor Networks",
    "author": [
      "Michal Yemini",
      "Stephanie Gil",
      "Andrea Goldsmith"
    ],
    "abstract": "We consider a detection problem where sensors experience noisy measurements and intermittent communication opportunities to a centralized fusion center (or cloud). The objective of the problem is to arrive at the correct estimate of event detection in the environment. The sensors may communicate locally with other sensors (local clusters) where they fuse their noisy sensor data to estimate the detection of an event locally. In addition, each sensor cluster can intermittently communicate to the cloud, where a centralized fusion center fuses estimates from all sensor clusters to make a final determination regarding the occurrence of the event across the deployment area. We refer to this hybrid communication scheme as a cloud-cluster architecture. Minimizing the expected loss function of networks where noisy sensors are intermittently connected to the cloud, as in our hybrid communication scheme, has not been investigated to our knowledge. We leverage recently improved concentration inequalities to arrive at an optimized decision rule for each cluster and we analyze the expected detection performance resulting from our hybrid scheme. Our analysis shows that clustering the sensors provides resilience to noise in the case of low communication probability with the cloud. For larger clusters, a steep improvement in detection performance is possible even for a low communication probability by using our cloud-cluster architecture.",
    "lastUpdated": "2020-09-21T22:59:18Z",
    "category": [
      "eess.SY",
      "cs.SY",
      "eess.SP"
    ],
    "url": "http://arxiv.org/abs/2005.12495v2"
  },
  {
    "title": "Road Segmentation on low resolution Lidar point clouds for autonomous vehicles",
    "author": [
      "Leonardo Gigli",
      "B Ravi Kiran",
      "Thomas Paul",
      "Andres Serna",
      "Nagarjuna Vemuri",
      "Beatriz Marcotegui",
      "Santiago Velasco-Forero"
    ],
    "abstract": "Point cloud datasets for perception tasks in the context of autonomous driving often rely on high resolution 64-layer Light Detection and Ranging (LIDAR) scanners. They are expensive to deploy on real-world autonomous driving sensor architectures which usually employ 16/32 layer LIDARs. We evaluate the effect of subsampling image based representations of dense point clouds on the accuracy of the road segmentation task. In our experiments the low resolution 16/32 layer LIDAR point clouds are simulated by subsampling the original 64 layer data, for subsequent transformation in to a feature map in the Bird-Eye-View (BEV) and SphericalView (SV) representations of the point cloud. We introduce the usage of the local normal vector with the LIDAR's spherical coordinates as an input channel to existing LoDNN architectures. We demonstrate that this local normal feature in conjunction with classical features not only improves performance for binary road segmentation on full resolution point clouds, but it also reduces the negative impact on the accuracy when subsampling dense point clouds as compared to the usage of classical features alone. We assess our method with several experiments on two datasets: KITTI Road-segmentation benchmark and the recently released Semantic KITTI dataset.",
    "lastUpdated": "2020-05-27T00:38:39Z",
    "category": [
      "cs.CV",
      "stat.ML"
    ],
    "url": "http://arxiv.org/abs/2005.13102v1"
  },
  {
    "title": "Securing Smart Home Edge Devices against Compromised Cloud Servers",
    "author": [
      "Rahmadi Trimananda",
      "Ali Younis",
      "Thomas Kwa",
      "Brian Demsky",
      "Harry Xu"
    ],
    "abstract": "Smart home IoT systems often rely on cloud-based servers for communication between components. Although there exists a body of work on IoT security, most of it focuses on securing clients (i.e., IoT devices). However, cloud servers can also be compromised. Existing approaches do not typically protect smart home systems against compromised cloud servers. This paper presents FIDELIUS: a runtime system for secure cloud-based storage and communication even in the presence of compromised servers. FIDELIUS's design is tailored for smart home systems that have intermittent Internet access. In particular, it supports local control of smart home devices in the event that communication with the cloud is lost, and provides a consistency model using transactions to mitigate inconsistencies that can arise due to network partitions. We have implemented FIDELIUS, developed a smart home benchmark that uses FIDELIUS, and measured FIDELIUS's performance and power consumption. Our experiments show that compared to the commercial Particle.io framework, FIDELIUS reduces more than 50% of the data communication time and increases battery life by 2X. Compared to PyORAM, an alternative (ORAM-based) oblivious storage implementation, FIDELIUS has 4-7X faster access times with 25-43X less data transferred.",
    "lastUpdated": "2020-06-23T02:17:18Z",
    "category": [
      "cs.CR"
    ],
    "url": "http://arxiv.org/abs/2006.11657v2"
  },
  {
    "title": "Self-Scaling Clusters and Reproducible Containers to Enable Scientific Computing",
    "author": [
      "Peter Z. Vaillancourt",
      "J. Eric Coulter",
      "Richard Knepper",
      "Brandon Barker"
    ],
    "abstract": "Container technologies such as Docker have become a crucial component of many software industry practices especially those pertaining to reproducibility and portability. The containerization philosophy has influenced the scientific computing community, which has begun to adopt - and even develop - container technologies (such as Singularity). Leveraging containers for scientific software often poses challenges distinct from those encountered in industry, and requires different methodologies. This is especially true for HPC. With an increasing number of options for HPC in the cloud (including NSF-funded cloud projects), there is strong motivation to seek solutions that provide flexibility to develop and deploy scientific software on a variety of computational infrastructures in a portable and reproducible way. The flexibility offered by cloud services enables virtual HPC clusters that scale on-demand, and the Cyberinfrastructure Resource Integration team in the XSEDE project has developed a set of tools which provides scalable infrastructure in the cloud. We now present a solution which uses the Nix package manager in an MPI-capable Docker container that is converted to Singularity. It provides consistent installations, dependencies, and environments in each image that are reproducible and portable across scientific computing infrastructures. We demonstrate the utility of these containers with cluster benchmark runs in a self-scaling virtual cluster using the Slurm scheduler deployed in the Jetstream and Aristotle Red Cloud OpenStack clouds. We conclude this technique is useful as a template for scientific software application containers to be used in the XSEDE compute environment, other Singularity HPC environments, and cloud computing environments.",
    "lastUpdated": "2020-08-03T23:40:15Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/2006.14784v2"
  },
  {
    "title": "Cloud-based Privacy-Preserving Collaborative Consumption for Sharing Economy",
    "author": [
      "Lingjuan Lyu",
      "Sid Chi-Kin Chau",
      "Nan Wang",
      "Yifeng Zheng"
    ],
    "abstract": "Cloud computing has been a dominant paradigm for a variety of information processing platforms, particularly for enabling various popular applications of sharing economy. However, there is a major concern regarding data privacy on these cloud-based platforms. This work presents novel cloud-based privacy-preserving solutions to support collaborative consumption applications for sharing economy. In typical collaborative consumption, information processing platforms need to enable fair cost-sharing among multiple users for utilizing certain shared facilities and communal services. Our cloud-based privacy-preserving protocols, based on homomorphic Paillier cryptosystems, can ensure that the cloud-based operator can only obtain an aggregate schedule of all users in facility sharing, or a service schedule conforming to service provision rule in communal service sharing, but is unable to track the personal schedules or demands of individual users. More importantly, the participating users are still able to settle cost-sharing among themselves in a fair manner for the incurred costs, without knowing each other's private schedules or demands. Our privacy-preserving protocols involve no other third party who may compromise privacy. We also provide an extensive evaluation study and a proof-of-concept system prototype of our protocols.",
    "lastUpdated": "2020-07-15T06:06:07Z",
    "category": [
      "cs.CR",
      "cs.MA",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/2007.07499v1"
  },
  {
    "title": "ConfEx: A Framework for Automating Text-based Software Configuration Analysis in the Cloud",
    "author": [
      "Ozan Tuncer",
      "Anthony Byrne",
      "Nilton Bila",
      "Sastry Duri",
      "Canturk Isci",
      "Ayse K. Coskun"
    ],
    "abstract": "Modern cloud services have complex architectures, often comprising many software components, and depend on hundreds of configurations parameters to function correctly, securely, and with high performance. Due to the prevalence of open-source software, developers can easily deploy services using third-party software without mastering the configurations of that software. As a result, configuration errors (i.e., misconfigurations) are among the leading causes of service disruptions and outages. While existing cloud automation tools ease the process of service deployment and management, support for detecting misconfigurations in the cloud has not been addressed thoroughly, likely due to the lack of frameworks suitable for consistent parsing of unstandardized configuration files. This paper introduces ConfEx, a framework that enables discovery and extraction of text-based software configurations in the cloud. ConfEx uses a novel vocabulary-based technique to identify configuration files in cloud system instances with unlabeled content. To extract the information in these files, ConfEx leverages existing configuration parsers and post-processes the extracted data for analysis. We show that ConfEx achieves over 99% precision and 100% recall in identifying configuration files on 7805 popular Docker Hub images. Using two applied examples, we demonstrate that ConfEx also enables detecting misconfigurations in the cloud via existing tools that are designed for configurations represented as key-value pairs, revealing 184 errors in public Docker Hub images.",
    "lastUpdated": "2020-08-31T16:49:18Z",
    "category": [
      "cs.SE",
      "cs.DC",
      "D.2.9; I.7.5; C.2.4"
    ],
    "url": "http://arxiv.org/abs/2008.08656v2"
  },
  {
    "title": "Multi-Sensor Data Fusion for Cloud Removal in Global and All-Season Sentinel-2 Imagery",
    "author": [
      "Patrick Ebel",
      "Andrea Meraner",
      "Michael Schmitt",
      "Xiaoxiang Zhu"
    ],
    "abstract": "This work has been accepted by IEEE TGRS for publication. The majority of optical observations acquired via spaceborne earth imagery are affected by clouds. While there is numerous prior work on reconstructing cloud-covered information, previous studies are oftentimes confined to narrowly-defined regions of interest, raising the question of whether an approach can generalize to a diverse set of observations acquired at variable cloud coverage or in different regions and seasons. We target the challenge of generalization by curating a large novel data set for training new cloud removal approaches and evaluate on two recently proposed performance metrics of image quality and diversity. Our data set is the first publically available to contain a global sample of co-registered radar and optical observations, cloudy as well as cloud-free. Based on the observation that cloud coverage varies widely between clear skies and absolute coverage, we propose a novel model that can deal with either extremes and evaluate its performance on our proposed data set. Finally, we demonstrate the superiority of training models on real over synthetic data, underlining the need for a carefully curated data set of real observations. To facilitate future research, our data set is made available online",
    "lastUpdated": "2020-09-16T13:40:42Z",
    "category": [
      "eess.IV",
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2009.07683v1"
  },
  {
    "title": "ElasticBroker: Combining HPC with Cloud to Provide Realtime Insights into Simulations",
    "author": [
      "Feng Li",
      "Dali Wang",
      "Feng Yan",
      "Fengguang Song"
    ],
    "abstract": "For large-scale scientific simulations, it is expensive to store raw simulation results to perform post-analysis. To minimize expensive I/O, \"in-situ\" analysis is often used, where analysis applications are tightly coupled with scientific simulations and can access and process the simulation results in memory. Increasingly, scientific domains employ Big Data approaches to analyze simulations for scientific discoveries. However, it remains a challenge to organize, transform, and transport data at scale between the two semantically different ecosystems (HPC and Cloud systems). In an effort to address these challenges, we design and implement the ElasticBroker software framework, which bridges HPC and Cloud applications to form an \"in-situ\" scientific workflow. Instead of writing simulation results to parallel file systems, ElasticBroker performs data filtering, aggregation, and format conversions to close the gap between an HPC ecosystem and a distinct Cloud ecosystem. To achieve this goal, ElasticBroker reorganizes simulation snapshots into continuous data streams and send them to the Cloud. In the Cloud, we deploy a distributed stream processing service to perform online data analysis. In our experiments, we use ElasticBroker to setup and execute a cross-ecosystem scientific workflow, which consists of a parallel computational fluid dynamics (CFD) simulation running on a supercomputer, and a parallel dynamic mode decomposition (DMD) analysis application running in a Cloud computing platform. Our results show that running scientific workflows consisting of decoupled HPC and Big Data jobs in their native environments with ElasticBroker, can achieve high quality of service, good scalability, and provide high-quality analytics for ongoing simulations.",
    "lastUpdated": "2020-11-30T02:55:15Z",
    "category": [
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/2010.04828v2"
  },
  {
    "title": "IF-Defense: 3D Adversarial Point Cloud Defense via Implicit Function based Restoration",
    "author": [
      "Ziyi Wu",
      "Yueqi Duan",
      "He Wang",
      "Qingnan Fan",
      "Leonidas J. Guibas"
    ],
    "abstract": "Point cloud is an important 3D data representation widely used in many essential applications. Leveraging deep neural networks, recent works have shown great success in processing 3D point clouds. However, those deep neural networks are vulnerable to various 3D adversarial attacks, which can be summarized as two primary types: point perturbation that affects local point distribution, and surface distortion that causes dramatic changes in geometry. In this paper, we propose a novel 3D adversarial point cloud defense method leveraging implicit function based restoration (IF-Defense) to address both the aforementioned attacks. It is composed of two steps: 1) it predicts an implicit function that captures the clean shape through a surface recovery module, and 2) restores a clean and complete point cloud via minimizing the difference between the attacked point cloud and the predicted implicit function under geometry- and distribution- aware constraints. Our experimental results show that IF-Defense achieves the state-of-the-art defense performance against all existing adversarial attacks on PointNet, PointNet++, DGCNN and PointConv. Comparing with previous methods, IF-Defense presents 20.02% improvement in classification accuracy against salient point dropping attack and 16.29% against LG-GAN attack on PointNet. Our code is available at https://github.com/Wuziyi616/IF-Defense.",
    "lastUpdated": "2020-11-17T04:57:19Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2010.05272v2"
  },
  {
    "title": "ParaNet: Deep Regular Representation for 3D Point Clouds",
    "author": [
      "Qijian Zhang",
      "Junhui Hou",
      "Yue Qian",
      "Juyong Zhang",
      "Ying He"
    ],
    "abstract": "Although convolutional neural networks have achieved remarkable success in analyzing 2D images/videos, it is still non-trivial to apply the well-developed 2D techniques in regular domains to the irregular 3D point cloud data. To bridge this gap, we propose ParaNet, a novel end-to-end deep learning framework, for representing 3D point clouds in a completely regular and nearly lossless manner. To be specific, ParaNet converts an irregular 3D point cloud into a regular 2D color image, named point geometry image (PGI), where each pixel encodes the spatial coordinates of a point. In contrast to conventional regular representation modalities based on multi-view projection and voxelization, the proposed representation is differentiable and reversible. Technically, ParaNet is composed of a surface embedding module, which parameterizes 3D surface points onto a unit square, and a grid resampling module, which resamples the embedded 2D manifold over regular dense grids. Note that ParaNet is unsupervised, i.e., the training simply relies on reference-free geometry constraints. The PGIs can be seamlessly coupled with a task network established upon standard and mature techniques for 2D images/videos to realize a specific task for 3D point clouds. We evaluate ParaNet over shape classification and point cloud upsampling, in which our solutions perform favorably against the existing state-of-the-art methods. We believe such a paradigm will open up many possibilities to advance the progress of deep learning-based point cloud processing and understanding.",
    "lastUpdated": "2020-12-05T13:19:55Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2012.03028v1"
  },
  {
    "title": "PMP-Net: Point Cloud Completion by Learning Multi-step Point Moving Paths",
    "author": [
      "Xin Wen",
      "Peng Xiang",
      "Zhizhong Han",
      "Yan-Pei Cao",
      "Pengfei Wan",
      "Wen Zheng",
      "Yu-Shen Liu"
    ],
    "abstract": "The task of point cloud completion aims to predict the missing part for an incomplete 3D shape. A widely used strategy is to generate a complete point cloud from the incomplete one. However, the unordered nature of point clouds will degrade the generation of high-quality 3D shapes, as the detailed topology and structure of discrete points are hard to be captured by the generative process only using a latent code. In this paper, we address the above problem by reconsidering the completion task from a new perspective, where we formulate the prediction as a point cloud deformation process. Specifically, we design a novel neural network, named PMP-Net, to mimic the behavior of an earth mover. It moves move each point of the incomplete input to complete the point cloud, where the total distance of point moving paths (PMP) should be shortest. Therefore, PMP-Net predicts a unique point moving path for each point according to the constraint of total point moving distances. As a result, the network learns a strict and unique correspondence on point-level, which can capture the detailed topology and structure relationships between the incomplete shape and the complete target, and thus improves the quality of the predicted complete shape. We conduct comprehensive experiments on Completion3D and PCN datasets, which demonstrate our advantages over the state-of-the-art point cloud completion methods.",
    "lastUpdated": "2020-12-07T01:34:38Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2012.03408v1"
  },
  {
    "title": "Sparse Single Sweep LiDAR Point Cloud Segmentation via Learning Contextual Shape Priors from Scene Completion",
    "author": [
      "Xu Yan",
      "Jiantao Gao",
      "Jie Li",
      "Ruimao Zhang",
      "Zhen Li",
      "Rui Huang",
      "Shuguang Cui"
    ],
    "abstract": "LiDAR point cloud analysis is a core task for 3D computer vision, especially for autonomous driving. However, due to the severe sparsity and noise interference in the single sweep LiDAR point cloud, the accurate semantic segmentation is non-trivial to achieve. In this paper, we propose a novel sparse LiDAR point cloud semantic segmentation framework assisted by learned contextual shape priors. In practice, an initial semantic segmentation (SS) of a single sweep point cloud can be achieved by any appealing network and then flows into the semantic scene completion (SSC) module as the input. By merging multiple frames in the LiDAR sequence as supervision, the optimized SSC module has learned the contextual shape priors from sequential LiDAR data, completing the sparse single sweep point cloud to the dense one. Thus, it inherently improves SS optimization through fully end-to-end training. Besides, a Point-Voxel Interaction (PVI) module is proposed to further enhance the knowledge fusion between SS and SSC tasks, i.e., promoting the interaction of incomplete local geometry of point cloud and complete voxel-wise global structure. Furthermore, the auxiliary SSC and PVI modules can be discarded during inference without extra burden for SS. Extensive experiments confirm that our JS3C-Net achieves superior performance on both SemanticKITTI and SemanticPOSS benchmarks, i.e., 4% and 3% improvement correspondingly.",
    "lastUpdated": "2020-12-07T14:58:25Z",
    "category": [
      "cs.CV"
    ],
    "url": "http://arxiv.org/abs/2012.03762v1"
  },
  {
    "title": "JANUS: Benchmarking Commercial and Open-Source Cloud and Edge Platforms for Object and Anomaly Detection Workloads",
    "author": [
      "Karthick Shankar",
      "Pengcheng Wang",
      "Ran Xu",
      "Ashraf Mahgoub",
      "Somali Chaterji"
    ],
    "abstract": "With diverse IoT workloads, placing compute and analytics close to where data is collected is becoming increasingly important. We seek to understand what is the performance and the cost implication of running analytics on IoT data at the various available platforms. These workloads can be compute-light, such as outlier detection on sensor data, or compute-intensive, such as object detection from video feeds obtained from drones. In our paper, JANUS, we profile the performance/$ and the compute versus communication cost for a compute-light IoT workload and a compute-intensive IoT workload. In addition, we also look at the pros and cons of some of the proprietary deep-learning object detection packages, such as Amazon Rekognition, Google Vision, and Azure Cognitive Services, to contrast with open-source and tunable solutions, such as Faster R-CNN (FRCNN). We find that AWS IoT Greengrass delivers at least 2X lower latency and 1.25X lower cost compared to all other cloud platforms for the compute-light outlier detection workload. For the compute-intensive streaming video analytics task, an opensource solution to object detection running on cloud VMs saves on dollar costs compared to proprietary solutions provided by Amazon, Microsoft, and Google, but loses out on latency (up to 6X). If it runs on a low-powered edge device, the latency is up to 49X lower.",
    "lastUpdated": "2020-12-09T06:07:26Z",
    "category": [
      "cs.CV",
      "cs.DC"
    ],
    "url": "http://arxiv.org/abs/2012.04880v1"
  },
  {
    "title": "Sampling Training Data for Continual Learning Between Robots and the Cloud",
    "author": [
      "Sandeep Chinchali",
      "Evgenya Pergament",
      "Manabu Nakanoya",
      "Eyal Cidon",
      "Edward Zhang",
      "Dinesh Bharadia",
      "Marco Pavone",
      "Sachin Katti"
    ],
    "abstract": "Today's robotic fleets are increasingly measuring high-volume video and LIDAR sensory streams, which can be mined for valuable training data, such as rare scenes of road construction sites, to steadily improve robotic perception models. However, re-training perception models on growing volumes of rich sensory data in central compute servers (or the \"cloud\") places an enormous time and cost burden on network transfer, cloud storage, human annotation, and cloud computing resources. Hence, we introduce HarvestNet, an intelligent sampling algorithm that resides on-board a robot and reduces system bottlenecks by only storing rare, useful events to steadily improve perception models re-trained in the cloud. HarvestNet significantly improves the accuracy of machine-learning models on our novel dataset of road construction sites, field testing of self-driving cars, and streaming face recognition, while reducing cloud storage, dataset annotation time, and cloud compute time by between 65.7-81.3%. Further, it is between 1.05-2.58x more accurate than baseline algorithms and scalably runs on embedded deep learning hardware. We provide a suite of compute-efficient perception models for the Google Edge Tensor Processing Unit (TPU), an extended technical report, and a novel video dataset to the research community at https://sites.google.com/view/harvestnet.",
    "lastUpdated": "2020-12-12T05:52:33Z",
    "category": [
      "cs.RO",
      "cs.CV",
      "cs.DC",
      "cs.LG",
      "cs.NI"
    ],
    "url": "http://arxiv.org/abs/2012.06739v1"
  }
]